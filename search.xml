<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常见排序算法（2）]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%952%2F</url>
    <content type="text"><![CDATA[冒泡排序，插入排序，选择排序，快速排序，希尔排序，归并排序等可参考： 排序算法（1） 快速排序优化及分区扫描法： 该篇文章主要记录了堆排序，计数排序，桶排序，基数排序等。 堆排序堆排序的概念：堆排序（英语：Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。（百度百科） 堆的概念： 堆（英语：heap)是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。堆总是满足下列性质： 堆中某个节点的值总是不大于或不小于其父节点的值； 堆总是一棵完全二叉树。 将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。 算法描述：因为堆是有大根堆和小根堆，利用堆的性质，可以对数组排序。具体做法： 首先将无序数组建立大根堆。(建立大根堆的过程运用了递归，从最后将每个根元素与左右孩子比较，将较大的放到根位置，递归执行每个节点。最后根元素就是最大值。) 然后数组第一个肯定为最大数，将第一个与数组最后一个数交换。 缩小堆的范围，将堆总长度减1，不用管最后一个，最后一个肯定是最大数。此时，在缩小堆的基础上继续建立大根堆。然后第一个为此堆的最大，与倒数第二个数互换。 循环这个2-3过程，就从小到大排好了序。 动图演示： 图：堆排序过程示意图## java代码示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class HeapSort &#123; public static void main(String[] args) &#123; int[] arr = &#123;13, 91, 52, 66, 95, 89, 62, 75, 61, 6&#125;; util.ArrayUtil.printArr(arr); heapSort(arr); util.ArrayUtil.printArr(arr); &#125; public static void heapSort(int[] arr) &#123; //先进行堆化 bigHeap(arr); //把堆顶元素和最后一个元素对调 int n = arr.length; for(int x = n - 1; x &gt; 0; x--) &#123; util.Swap.swap(arr, 0, x); //缩小堆的范围，对堆顶元素进行向下调整 bigHeapFixUp(arr, 0, x - 1); &#125; &#125; //制作大根堆 public static void bigHeap(int[] arr) &#123; int n = arr.length; for(int i = n / 2 - 1; i &gt;= 0; i--) &#123; bigHeapFixUp(arr, i, n); &#125; &#125; //大根上浮调整 public static void bigHeapFixUp(int[] arr, int i, int n)&#123; //找到左右两孩子 int left = 2 * i + 1; int right = 2 * i + 2; //左孩子已经越界，i就是叶子节点 if(left &gt;= n) &#123; return; &#125; //找出左孩子和有孩子中较大的一个 int max = left; //右孩子已经越界 if(right &gt;= n ) &#123; max = left; &#125;else &#123; if(arr[left] &lt; arr[right]) &#123; max = right; &#125; &#125; //如果arr[i]大于两个数不用调整 if(arr[i] &gt;= arr[max]) &#123; return; &#125; //否则，与两个孩子中较大的值，交换 int tmp = arr[i]; arr[i] = arr[max]; arr[max] = tmp; bigHeapFixUp(arr, max, n); &#125;&#125;程序运行结果：1284 36 57 94 75 22 28 86 17 68 17 22 28 36 57 68 75 84 86 94## 算法分析：- 时间复杂度： 堆化：一半的元素修复，修复是单分支的，所以整体堆化为nlgn/2- 排序：n个元素都要取出，因此调整n次，每次调整修复同上是lgn的，整体为nlgn- 空间复杂度：不需要开辟辅助空间# 计数排序计数排序：用辅助数组对数组中出现的数字计数，元素转下标，下标转元素。## 算法描述：1. 假设元素均大于等于0，依次扫描原数组，将元素值K记录在辅助数组的k位上。2. 依次扫描辅助数组，如果为1，将其插入目标数组的空白处。## 动图演示： 图：计数排序动图演示 java示例代码：12345678910111213141516171819202122232425262728293031323334public class CountSort &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(10); util.ArrayUtil.printArr(arr); countSort(arr); util.ArrayUtil.printArr(arr); &#125; public static void countSort(int[] arr) &#123; int[] helper = new int[maxOf(arr) + 1]; for(int e : arr) &#123; helper[e]++; &#125; int current = 0; //数据回填的位置 for(int i = 1; i &lt; helper.length; i++) &#123; //打印出重复的数据 while (helper[i] &gt; 0) &#123; arr[current++] = i; helper[i]--; &#125; &#125; &#125; //找出数组中最大的数值，用来开辟辅助空间 public static int maxOf(int[] arr) &#123; int max = arr[0]; for(int i = 1; i &lt; arr.length; i++) &#123; if(max &lt; arr[i]) &#123; max = arr[i]; &#125; &#125; return max; &#125;&#125; 程序运行结果： 125 1 94 66 64 12 68 70 90 32 1 5 12 32 64 66 68 70 90 94 上面的代码只能排都是正数的数组，当有负数时，不能用。 对于有负数的情况，我的思路是重新开辟一个空间，专门用来存放负数，当恢复的时候，倒着恢复即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class CountSort &#123; public static void main(String[] args) &#123; //int[] arr = util.ArrayUtil.arr(10); int[] arr = &#123;1, 3, -3, 6, -2, 1, 0, -5, 2&#125;; util.ArrayUtil.printArr(arr); countSort1(arr); util.ArrayUtil.printArr(arr); public static int maxOf1(int[] arr) &#123; int max = Math.abs(arr[0]); for(int i = 0; i &lt; arr.length; i++) &#123; if(max &lt; Math.abs(arr[i])) &#123; max = Math.abs(arr[i]); &#125; &#125; return max; &#125; public static void countSort1(int[] arr) &#123; int[] helper1 = new int[maxOf1(arr) + 1]; int[] helper2 = new int[maxOf1(arr) + 1]; for(int e : arr) &#123; if(e &lt; 0) &#123; helper2[-e]++; &#125;else &#123; helper1[e]++; &#125; &#125; int current = 0; //数据回填的位置 //先恢复负数序列 for(int i = helper2.length - 1; i &gt; 0; i--) &#123; while (helper2[i] &gt; 0) &#123; arr[current++] = -i; helper2[i]--; &#125; &#125; //先恢复正数序列 for(int i = 0; i &lt; helper1.length; i++) &#123; //打印出重复的数据 while (helper1[i] &gt; 0) &#123; arr[current++] = i; helper1[i]--; &#125; &#125; &#125;&#125; 程序运行结果： 121 3 -3 6 -2 1 0 -5 2 -5 -3 -2 0 1 1 2 3 6 性能分析：优点：速度快。 缺点：数据范围很大，比较稀疏，会导致辅助空间很大，也稀疏，造成空间的浪费。 时间复杂度： 扫描一次原数组，扫描一次helper，复杂度为N+k 空间复杂度：辅助空间k，k=maxOf(arr) 非原址排序 稳定性：相同元素不会出现交叉，非原址都是拷来拷去 如果要优化一下空间，可以求minOf(arr)，helper的长度位max-min+1，这样能短点 计数有缺陷，数据较为密集或范围较小时，适用。 桶排序桶排序（BucketSort）：一句话概括为，通过“分配”和“收集”过程来实现排序。 工作的原理是将数组分到有限数量的桶子里 每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序） 桶排序是鸽巢排序的一种归纳结果。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间 算法思想： 设计k个桶（bucket），编号0~k-1，然后将n个输入数分布到各个桶中去，对各个桶中的数进行排序，然后按照次序把各个桶中的元素罗从小到大列出来即可。 动图演示： 图：桶数排序动图演示 java代码示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import java.util.ArrayList;import java.util.Collections;public class BucketSort &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(10); util.ArrayUtil.printArr(arr); bucketSort(arr); util.ArrayUtil.printArr(arr); &#125; // hash函数，用来往桶里分配数据。此时桶的个数等于数组元素个数 public static int hash(int element, int max, int length) &#123; return (element * length) / (max + 1); &#125; public static void bucketSort(int[] arr) &#123; int length = arr.length; @SuppressWarnings("unchecked") //初始化每个桶 ArrayList&lt;Integer&gt;[] bucket = new ArrayList[length];// 桶的个数=length for(int i = 0; i &lt; length; i++) &#123; bucket[i] = new ArrayList&lt;Integer&gt;(); &#125; int max = maxOf(arr); //入桶 for(int i = 0; i &lt; length; i++) &#123; //扫描每个元素 int value = arr[i]; int hash = hash(value, max, length); //如果是桶为空，则直接添加到桶中 if(bucket[hash] == null) &#123; bucket[hash].add(value); &#125;else &#123;//否则，以从小到大的排序插入桶的元素中 bucket[hash].add(value); Collections.sort(bucket[hash]); &#125; &#125; //出桶 int k = 0;//记录数组下标，回填数据 for(int i = 0; i &lt; length; i++) &#123; //如果桶内不为空，从小到大回填到数组 if(!bucket[i].isEmpty()) &#123; for(int j = 0; j &lt; bucket[i].size(); j++) &#123; arr[k++] = bucket[i].get(j); &#125; &#125; &#125; &#125; //找出数组中最大的数值 public static int maxOf(int[] arr) &#123; int max = arr[0]; for(int i = 1; i &lt; arr.length; i++) &#123; if(max &lt; arr[i]) &#123; max = arr[i]; &#125; &#125; return max; &#125;&#125; 程序运行结果： 1215 52 72 45 83 54 35 14 54 61 14 15 35 45 52 54 54 61 72 83 算法分析： 时间复杂度： O(N+C)，其中C=N*(logN-logM) 空间复杂度：N+M，M为桶的个数 非原址排序 稳定性：稳定 桶排序假设数据会均匀入桶，在这个前提下，桶排序很快！ 基数排序基数排序(Radix Sort)：是一种特殊的桶排序。通过位数来分配和收集。 算法思想： 先初始化0-9号十个桶，按个位数字，将关键字入桶，入完后，依次遍历10个桶，按检出顺序回填到数组中，如： ​ 321 322 331 500 423 476 926 ​ 0:500 ​ 1:321 331 ​ 2:322 ​ 3:423 ​ 4:无 ​ 5:无 ​ 6:476 926 检出后数组序列为： 500 321 331 423 476 926，然后取十位数字重复过程一，得到 ​ 0:500 ​ 1:无 ​ 2:321 423 926 ​ 3:331 ​ 4:无 ​ 5:无 ​ 7:476 检出后数组序列为： 500 321 423 926 331 476，然后取百位数字重复过程一，得到 ​ 0:无 ​ 1:无 ​ 2:无 ​ 3:321 331 ​ 4:423 476 ​ 5:500 ​ 9:926 检出后数组序列为： 321 331 423 476 500 926，已然有序 但是我们应该继续入桶，不过因为再高位全部是0了，这些元素会按顺序全部进入0号桶，这时0号桶的size==数组的size，这时结束标志 最后再回填到数组，数组就是升序排列的了 动图演示： 图：基数排序原理动图演示 java代码示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import java.util.ArrayList;public class RadixSort &#123; // 10个桶，每个桶装的数个数不定，适合用数组加ArrayList @SuppressWarnings("unchecked") private static ArrayList&lt;Integer&gt;[] bucket = new ArrayList[10]; // 初始化桶 static &#123; for (int i = 0; i &lt; bucket.length; i++) &#123; bucket[i] = new ArrayList&lt;Integer&gt;(); &#125; &#125; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(10); util.ArrayUtil.printArr(arr); radixSort(arr); util.ArrayUtil.printArr(arr); &#125; public static void radixSort(int[] arr) &#123; //找出数组中的最大值 int max = maxOf(arr); int d = 1; //入桶依据位初始为1 int dNum = 1; //最大数据的位数 while(max/10 != 0) &#123; dNum++; max/=10; &#125; while(d &lt;= dNum) &#123; BucketSort(arr, d++); &#125; &#125; public static void BucketSort(int[] arr, int d) &#123; //入桶 for(int i = 0; i &lt; arr.length; i++) &#123; inputBucket(arr[i], d); &#125; //出桶 int k = 0;//记录数组下标，回填数据 for(int i = 0; i &lt; bucket.length; i++) &#123; //如果桶内不为空，从小到大回填到数组 if(!bucket[i].isEmpty()) &#123; for(int j = 0; j &lt; bucket[i].size(); j++) &#123; arr[k++] = bucket[i].get(j); &#125; &#125; &#125; //清空桶 for(ArrayList&lt;Integer&gt; b : bucket) &#123; b.clear(); &#125; &#125; public static void inputBucket(int value, int d) &#123; int pos = (int) (value / Math.pow(10, d - 1) % 10); switch (pos) &#123; case 0: bucket[0].add(value); break; case 1: bucket[1].add(value); break; case 2: bucket[2].add(value); break; case 3: bucket[3].add(value); break; case 4: bucket[4].add(value); break; case 5: bucket[5].add(value); break; case 6: bucket[6].add(value); break; case 7: bucket[7].add(value); break; case 8: bucket[8].add(value); break; default: bucket[9].add(value); break; &#125; &#125; //找出数组中最大的数值 public static int maxOf(int[] arr) &#123; int max = arr[0]; for(int i = 1; i &lt; arr.length; i++) &#123; if(max &lt; arr[i]) &#123; max = arr[i]; &#125; &#125; return max; &#125;&#125; 程序运行结果： 124 49 56 16 67 36 3 27 88 89 3 4 16 27 36 49 56 67 88 89 算法分析： 时间复杂度： 假设最大的数有k位，就要进行k次入桶和回填，每次入桶和回填是线性的，所以整体复杂度为kN,其中k为最大数的10进制位数 空间复杂度：桶是10个，10个桶里面存n个元素，这些空间都是额外开辟的，所以额外的空间是N+k，k是进制 肯定是非原址排序 稳定性：假设有相等的元素，它们会次第入桶，次第回数组，不会交叉，所以是稳定的]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法案例]]></title>
    <url>%2F2019%2F02%2F25%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[题目：调整数组顺序使奇数位于偶数前面 输入一个整数数组，调整数组中数字的顺序，使得所有奇数位于数组的前班部分，所有偶数位于数组的后半部分。要求时间复杂度为O(n)。 解题思想： 方案1：​ 归并排序的思想。利用辅助空间进行排序，判断每个数，如果是奇数放入数组的左边，如果是偶数从右边开始放。 方案2：快速排序的思想。不需要辅助空间，利用两个指针，从最左边和最右边的数判断，如果左指针指向的数为偶数，右指针指向的数为奇数，交换着两个数。 java实现代码示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445public class 调整数组顺序_奇左偶右 &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(10); util.ArrayUtil.printArr(arr); megerAdjust(arr); util.ArrayUtil.printArr(arr); quickAdjust(arr); util.ArrayUtil.printArr(arr); &#125; //归并思想，开辟辅助空间，进行调整 public static void megerAdjust(int[] arr) &#123; int[] helper = new int[arr.length]; //left:指向调整数组的左边，都是奇数，right：指向右边，偶数 int left = 0, right = arr.length-1; int current = 0; //指向原数组的待调整数 System.arraycopy(arr, 0, helper, 0, arr.length); while(current &lt; arr.length) &#123; if(helper[current] % 2 == 1) &#123; arr[left++] = helper[current++]; &#125;else &#123; arr[right--] = helper[current++]; &#125; &#125; &#125; //快速排序思想，不需要辅助空间。 public static void quickAdjust(int[] arr) &#123; int left = 0, right = arr.length - 1; while(left &lt; right) &#123; if(arr[left] % 2 == 1) &#123; left++; &#125; if(arr[right] % 2 == 0) &#123; right--; &#125; if(arr[left] % 2 == 0 &amp;&amp; arr[right] % 2 == 1)&#123; util.Swap.swap(arr, left, right); left++; right--; &#125; &#125; &#125;&#125; 程序执行结果： 12351 29 34 65 22 55 89 58 51 61 51 29 65 55 89 51 61 58 22 34 51 29 65 55 89 51 61 58 22 34 题目：第K个元素 以尽量高的效率求出一个乱序数组中按数值顺序的第k个元素。 解题思想： 利用分区法的思想。每次找到一个中位数主元，将小于主元的放左边，大于主元的放右边。递归寻找。 代码示例：123456789101112131415161718192021public class 第k小数 &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(10); util.ArrayUtil.printArr(arr); QuickSort1.quickSort(arr, 0, arr.length - 1); util.ArrayUtil.printArr(arr); int K = selectK(arr, 0, arr.length - 1, 3); System.out.println("K = " + K); &#125; public static int selectK(int[] arr, int p, int r, int k) &#123; //调用快速排序中寻找主元的方法 int q = QuickSrot.partition2(arr, p, r);//主元的下标 int qK = q - p + 1;//主元是第几个元素 if(qK == k) return arr[q]; else if (qK &gt; k) return selectK(arr, p, q - 1, k); else return selectK(arr, q + 1, r, k - qK); &#125;&#125; 程序运行结果： 12374 90 98 8 82 21 5 30 32 49 5 8 21 30 32 49 74 82 90 98 K = 21 题目：超过一半的数字 数组汇总有一个数字出现的次数超过了数组长度的一半，找出这个数字 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.Arrays;public class MoreThanHalf &#123; //找出数组中出现次数过半的元素 public static void main(String[] args) &#123; int[] arr = &#123;1, 2, 3, 3, 3, 6, 6, 4, 3, 3, 3, 3&#125;; solve1(arr); solve2(arr); solve3(arr); &#125; //解法1：排序后返回中间的元素。时间复杂度：O(nlg(n)) public static void solve1(int [] arr) &#123; Arrays.sort(arr); System.out.println(arr[arr.length/2]); &#125; //解法2：顺序统计，O(n) //该题解法调用了找第k个数的方法。 public static void solve2(int[] arr) &#123; int k = chapter3_排序.第k小数.selectK(arr, 0, arr.length-1, arr.length/2); System.out.println(k); &#125; //解法3：不同的数进行消除 /*不同的数，进行消除，O(N)*/ public static void solve3(int[] arr) &#123; //候选数，先定位第一个元素 int candidate = arr[0]; //出现的次数 int nTimes = 1; //扫描数组 for (int i = 1; i &lt; arr.length; i++) &#123; //两两消减为0，应该把现在的元素作为候选值 if (nTimes == 0) &#123; candidate = arr[i]; nTimes = 1; continue; &#125; //遇到和候选值相同的，次数加1 if (arr[i] == candidate) nTimes++; //不同的数，进行消减 else nTimes--; &#125; System.out.println(candidate); &#125;&#125; 程序运行结果： 123333 变化：出现的数恰好为总数的一半，求出这个数1234567891011121314151617181920212223242526272829303132333435363738 //变化，出现次数恰好为个数的一半，求出这个数 /* * 关于加强版水王的题我有个想法可以扫描一遍数组就解决问题： 水王占总数的一半，说明总数必为偶数； 不失一般性，假设隔一个数就是水王的id，两两不同最后一定会消减为0 水王可能是最后一个元素，每次扫描的时候，多一个动作，和最后一个元素做比较，单独计数，计数恰好等于一半 如果不是，计数不足一半，那么去掉最后一个元素，水王就是留下的那个candidate*/ public static void solve5(int[] arr) &#123; int candidate = arr[0]; int nTimes = 0; int countOfLast = 0;//统计最后这个元素出现的次数 int N = arr.length; for (int i = 0; i &lt; N; i++) &#123; //增加和最后一个元素比较的步骤 if (arr[i] == arr[N - 1]) countOfLast++; if (nTimes == 0) &#123; candidate = arr[i]; nTimes = 1; continue; &#125; if (arr[i] == candidate) nTimes++; else nTimes--; &#125; //最后一个元素出现次数是n/2 if (countOfLast == N / 2) System.out.println(arr[N - 1]); else System.out.println(candidate); &#125; public static void main(String[] args) &#123; solve3(new int[]&#123;0, 1, 2, 1, 1&#125;); &#125;&#125; 题目：最小可用ID 在非负数组（乱序）中找到最小的可分配的id（从1开始编号），数量1000000. 1234567891011121314151617181920212223242526272829303132333435363738public class 最小可用id &#123; public static void main(String[] args) &#123; int[] arr = &#123;3, 1, 2, 6, 9, 4, 10, 13, 7&#125;; System.out.println(find1(arr)); System.out.println(find2(arr, 0, arr.length-1)); &#125; //方法1：新建长为n+1的数组，初始全为0，扫描原数组中的元素，将小于 //总数n的对应的位置标记为1，最后再扫描辅助数组，第一个为0的元素下标即为最小可用id private static int find1(int[] arr) &#123; int[] helper = new int[arr.length+1]; for(int i = 0; i &lt; arr.length; i++) &#123; if(arr[i] &lt;= arr.length - 1) helper[arr[i]] = 1; &#125; for(int i = 1; i &lt;= arr.length; i++) &#123; if(helper[i] == 0) &#123; return i; &#125; &#125; return arr.length + 1; &#125; //方法2：递归,不需要辅助空间 public static int find2(int[] arr, int l, int r) &#123; if(l &gt; r) return l + 1; int midIndex = l + ((r - l) &gt;&gt; 1);//中间下标 //实际在中间位置的值 int q = chapter3_排序.第k小数.selectK(arr, l, r, midIndex - l + 1); int t = midIndex + 1; //期望值 if(q == t) &#123; //左侧紧密 return find2(arr, midIndex + 1, r); &#125;else &#123; return find2(arr, l, midIndex - 1); &#125; &#125;&#125; 题目：合并有序数组 给定两个排序后的数组A和B，其中A的末端有足够的空间容纳B。编写一个方法，将B合并入A并排序。 123456789101112131415161718192021222324public class 合并有序数组 &#123; public static void main(String[] args) &#123; //模拟a有足够空间 int[] a = &#123;1, 2, 6, 9, 10, 13, 15, 0, 0, 0, 0, 0, 0, 0&#125;; int[] b = &#123;3, 4, 5, 7, 8&#125;; meger(a, b); util.ArrayUtil.printArr(a); &#125; //解法：利用归并的思想，从大到小排序 private static void meger(int[] a, int[] b) &#123; int aMax = 7 - 1;//假设a有7个数。a的有序数组的最大数的下标 int bMax = b.length - 1; int right = 7 + b.length - 1; while(bMax &gt;= 0) &#123; if(b[bMax] &gt;= a[aMax]) &#123; a[right--] = b[bMax--]; &#125;else &#123; a[right--] = a[aMax--]; &#125; &#125; &#125;&#125; 程序运行结果： 11 2 3 4 5 6 7 8 9 10 13 15 0 0 题目：逆序对个数 一个数列，如果左边的数大，右边的数小，则称这两个数位一个逆序对。求出一个数列中有多少个逆序对。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package chapter3_排序;public class 逆序对个数 &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(10); util.ArrayUtil.printArr(arr); System.out.println(niXu(arr)); System.out.println(niXu2(arr)); &#125; //方法1：暴力破解，时间复杂度O(n) private static int niXu(int[] arr) &#123; int sum = 0; for(int i = 0; i &lt; arr.length; i++) &#123; for(int j = i+1; j &lt; arr.length; j++) &#123; if(arr[j] &lt; arr[i])&#123; sum++; &#125; &#125; &#125; return sum; &#125; //方法2：利用归并排序思想。时间复杂度nlg(n) //在每次比较两个有序数组时，如果取右边的的数时，左边数组剩余的个数即为逆序对 static int[] helper; //辅助空间，和arr的长度一样 static int niXu = 0; public static int niXu2(int[] arr) &#123; helper = new int[arr.length]; megerSort(arr, 0, arr.length- 1); return niXu; &#125; public static void megerSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; int mid = p + ((r - p) &gt;&gt; 1); megerSort(arr, p, mid); megerSort(arr, mid + 1, r); meger(arr, p, mid, r); &#125; &#125; private static void meger(int[] arr, int p, int mid, int r) &#123; System.arraycopy(arr, p, helper, p, r - p + 1); int left = p; // 左侧队伍的头部指针，指向待比较的元素 int right = mid + 1; //右侧队伍的头部指针，指向待比较的元素 int current = p; //原数组的指针，指向待填入数据的位置 while(left &lt;= mid &amp;&amp; right &lt;= r) &#123; if(helper[left] &lt;= helper[right]) &#123; arr[current++] = helper[left++]; &#125;else &#123; arr[current++] = helper[right++]; niXu += mid - left + 1; &#125; &#125; //如果左侧队伍没比较完，需要将左侧的数依次添加到原队列后面 while(left &lt;= mid) &#123; arr[current++] = helper[left++]; &#125; &#125;&#125; 程序运行结果： 12397 40 30 69 78 55 84 5 6 62 2727 二叉树与数组： 将二叉树存储在数组中，并遍历二叉树。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package chapter3_排序;public class TreeAndArray &#123; public static void main(String[] args) &#123; /*Tree: * 1 * / \ * 2 3 * / \ / \ * 4 5 6 7 */ int[] tree = &#123;1, 2, 3, 4, 5, 6, 7&#125;; System.out.print("先序遍历："); preOrder(tree, 0); System.out.println(); System.out.print("中序遍历："); inOrder(tree, 0); System.out.println(); System.out.print("后序遍历："); posOrder(tree, 0); &#125; //先序遍历 public static void preOrder(int[] arr, int index) &#123; if(index &gt;= arr.length) return; System.out.print(arr[index] + " "); preOrder(arr, index * 2 + 1); preOrder(arr, index * 2 + 2); &#125; //中序遍历 public static void inOrder(int[] arr, int index) &#123; if(index &gt;= arr.length) return; inOrder(arr, index * 2 + 1); System.out.print(arr[index] + " "); inOrder(arr, index * 2 + 2); &#125; //后序遍历 public static void posOrder(int[] arr, int index) &#123; if(index &gt;= arr.length) return; posOrder(arr, index * 2 + 2); posOrder(arr, index * 2 + 1); System.out.print(arr[index] + " "); &#125;&#125; 程序运行结果： 123先序遍历：1 2 4 5 3 6 7 中序遍历：4 2 5 1 6 3 7 后序遍历：7 6 3 5 4 2 1]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序优化及扫描分区法]]></title>
    <url>%2F2019%2F01%2F07%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96%E5%8F%8A%E6%89%AB%E6%8F%8F%E5%88%86%E5%8C%BA%E6%B3%95%2F</url>
    <content type="text"><![CDATA[快速排序扫描分区法：通过单向扫描，双向扫描，以及三指针分区分别实现快速排序算法。着重体现分区的思想。 一遍单向扫描法：思路： 一遍扫描法的思路是，用两个指针将数组划分为三个区间， 扫描指针(scan_pos)左边是确认小于等于主元的，扫描指针到某个指针(next_bigger_pos)中间为未知的，因此我们将第二个指针(next_bigger_pos)成为位未知区间末指针，末指针的右边区间为确认大于主元的元素。 代码示例：12345678910111213141516171819202122232425262728293031323334public class QuickSrot &#123; public static void main(String[] args) &#123; //随机获取15个整数 int[] arr = util.ArrayUtil.arr(15); util.ArrayUtil.printArr(arr); quickSort(arr, 0, arr.length-1); util.ArrayUtil.printArr(arr); &#125; public static void quickSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; int q = partition1(arr, p, r); quickSort(arr, p, q - 1); quickSort(arr, q + 1, r); &#125; &#125; // 单向扫描 public static int partition1(int[] arr, int p, int r) &#123; int pivot = arr[p]; int sp = p + 1; //扫描指针 int bigger = r; //右侧指针 while(sp &lt;= bigger) &#123; if(arr[sp] &lt;= pivot) &#123; sp++; &#125;else &#123; util.Swap.swap(arr, sp, bigger); bigger--; &#125; &#125; util.Swap.swap(arr, p, bigger); return bigger; &#125; 程序运行结果： 1297 15 1 32 44 33 27 98 36 30 34 74 83 98 44 1 15 27 30 32 33 34 36 44 44 74 83 97 98 98 双向扫描分区法：思路： 双向扫描的思路是，头尾指针往中间扫描，从左找到大于主元的元素，从右找到小于等于主元的元素二者交换，继续扫描，直到左侧无大于元素，右侧无小于主元元素。 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243public class QuickSrot &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(15); util.ArrayUtil.printArr(arr); quickSort(arr, 0, arr.length-1); util.ArrayUtil.printArr(arr); &#125; public static void quickSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; int q = partition2(arr, p, r); quickSort(arr, p, q - 1); quickSort(arr, q + 1, r); &#125; &#125; //双向扫描分区法 public static int partition2(int[] arr, int p, int r) &#123; int left = p + 1; //左侧扫描指针 int right = r; //右侧指针 int pivot = arr[p]; while(left &lt;= right) &#123; // left不停往右走，直到遇到大于住院的元素 // 循环退出时，left一定是指向第一个大于主元的位置 while(left &lt;= right &amp;&amp; arr[left] &lt;= pivot) &#123; left++; &#125; // right不停往左走，直到遇到小于住院的元素 // 循环退出时，right一定是指向从右到左第一个小于于主元的位置 while(left &lt;= right &amp;&amp; arr[right] &gt; pivot) &#123; right--; &#125; if(left &lt; right) util.Swap.swap(arr, left, right); &#125; // 循环退出时，两者交错，且right指向的最后一个小于等于主元的位置，也就是主元应该待得位置 util.Swap.swap(arr, p, right); return right; &#125;&#125; 程序运行结果： 1253 4 87 32 24 99 18 74 91 56 52 24 38 76 30 4 18 24 24 30 32 38 52 53 56 74 76 87 91 99 三分法：思路： 当待排序数组中，如果有大量相同的元素，则可用三分区法，每次将与主元相等的元素找到，排行序，并记录这组主主元相等元素序列的开始下标和结束下标。在进行下次递归排序是，排除这部分相同的元素。从而减少递归次数。 如上图，紫色部分为拍好序的与主元相等的元素，在递归拍其它两边的元素时，可排除这部分元素。具体实现代码如下： 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package chapter3_排序;public class QuickSort_Three &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(15); util.ArrayUtil.printArr(arr); quickSort(arr, 0, arr.length-1); util.ArrayUtil.printArr(arr); &#125; public static void quickSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; int[] q = partition(arr, p , r); quickSort(arr, p, q[0] - 1); quickSort(arr, q[1] + 1, r); &#125; &#125; private static int[] partition(int[] arr, int p, int r) &#123; int s = p + 1; //左扫描指针 int e = s; //记录与主元相等元素序列的开始下标 int bigger = r; //右侧扫描指针 int pivot = arr[p]; //主元 while (s &lt;= bigger) &#123; while(s &lt;= bigger &amp;&amp; arr[s] &lt;= pivot) &#123; //当从一开始没有找到与主语相等的元素，且都小于主元时，指针右移 if(s &lt;= bigger &amp;&amp; s == e &amp;&amp; arr[s] &lt; pivot) &#123; s++; e++; &#125; //如过s!=e时，说明已经找到与主元相等的元素，且e记录的为与主元相等元素的开始下标 //如果下一个元素小于主元，则将小于主元的元素和与主元相等序列的第一个元素交换位置 if(s &lt;= bigger &amp;&amp; s != e &amp;&amp; arr[s] &lt; pivot) &#123; util.Swap.swap(arr, s, e); e++; s++; &#125; //如果遇到等于主元的元素，左扫描指针++， 记录与主元相等序列的开始下标e不变 if(s &lt;= bigger &amp;&amp; arr[s] == pivot) &#123; s++; &#125; &#125; //右侧扫描指针 while(s &lt;= bigger &amp;&amp; arr[bigger] &gt; pivot) &#123; bigger--; &#125; //将左侧指针指向大的元素与右侧小于主元的元素交换 if(s &lt;= bigger &amp;&amp; arr[s] &gt; arr[bigger]) &#123; util.Swap.swap(arr, s, bigger); &#125; &#125; //最后，数组下标为p的开始元素，和与主元相等序列的前一个元素交换，e-- util.Swap.swap(arr, p, --e); //返回与主元相等序列的开始下标和结束下标 int[] q = &#123;e, bigger&#125;; return q; &#125;&#125; 程序运行结果： 125 5 1 8 8 5 6 3 8 2 6 1 6 3 0 0 1 1 2 3 3 5 5 5 6 6 6 8 8 8 快速排序优化_三点中值法：思路： 上面三个例子中，每次取得主元都是待排序子序列的开始第一个元素，很大可能不是属于中间的元素，从而容易加大递归的层数。 通过三点中值法，对比待排序序列的开始，中间，最后三个元素的大小，去中间值，更大概率能使主元选择成为中间的元素，从而减少递归层数。 代码示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package chapter3_排序;import javax.rmi.CORBA.Util;//工程实践中针对快速排序的其他优化public class QuickSort1 &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(15); util.ArrayUtil.printArr(arr); quickSort(arr, 0, arr.length-1); util.ArrayUtil.printArr(arr); &#125; public static void quickSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; int q = partition(arr, p , r); quickSort(arr, p, q - 1); quickSort(arr, q + 1, r); &#125; &#125; //三点中值法 public static int partition(int[] arr, int p, int r) &#123; //优化，在p, r, mid之间，选一个中间值作为主元 int minIndex = p + ((r - p) &gt;&gt; 1);//中间下标 int minValueIndex = -1;//中值的下标 if(arr[p] &lt;= arr[minIndex] &amp;&amp; arr[p] &gt;= arr[r]) &#123; minValueIndex = p; &#125;else if(arr[r] &lt;= arr[minIndex] &amp;&amp; arr[r] &gt;= arr[p]) &#123; minValueIndex = r; &#125;else &#123; minValueIndex = minIndex; &#125; util.Swap.swap(arr, p, minValueIndex); int pivot = arr[p]; int left = p + 1; //左侧指针 int right = r; //右侧指针 while(left &lt;= right) &#123; while(left &lt;= right &amp;&amp; arr[left] &lt;= pivot) &#123; left++; &#125; while(left &lt;= right &amp;&amp; arr[right] &gt; pivot) &#123; right--; &#125; if(left &lt; right) &#123; util.Swap.swap(arr, left, right); &#125; &#125; util.Swap.swap(arr, p, right); return right; &#125;&#125; 程序运行结果： 1220 76 81 19 9 74 48 69 62 98 37 14 96 6 40 6 9 14 19 20 37 40 48 62 69 74 76 81 96 98 快速排序优化_绝对中值法：思路： 三点中值法也有很大的随机性，如果想要得到绝对的中值，可以通过绝对中法来获取主元。通过将待排序序以5分为一组，去中间值，取到整个数组的各组中间值，再将这些数组排序，主元取中间值。 一般因为寻找绝对中值，也会花费时间。所以使用三点中值法居多 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package chapter3_排序;//工程实践中针对快速排序的其他优化public class 快速排序_绝对中值法 &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(15); util.ArrayUtil.printArr(arr); quickSort(arr, 0, arr.length-1); util.ArrayUtil.printArr(arr); &#125; public static void quickSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; int q = partition(arr, p , r); quickSort(arr, p, q - 1); quickSort(arr, q + 1, r); &#125; &#125; //绝对中值法 public static int partition(int[] arr, int p, int r) &#123; int pivot = getMedian(arr, p, r); int midValueIndex = search(arr, p, r, pivot); util.Swap.swap(arr, p, midValueIndex); int left = p + 1; //左侧指针 int right = r; //右侧指针 while(left &lt;= right) &#123; while(left &lt;= right &amp;&amp; arr[left] &lt;= pivot) &#123; left++; &#125; while(left &lt;= right &amp;&amp; arr[right] &gt; pivot) &#123; right--; &#125; if(left &lt; right) &#123; util.Swap.swap(arr, left, right); &#125; &#125; util.Swap.swap(arr, p, right); return right; &#125; public static int search(int[] arr, int p, int r, int pivot) &#123; for(int i = p; i &lt; r + 1; i++) &#123; if(arr[i] == pivot) return i; &#125; return -1; &#125; public static int getMedian(int[] arr, int p, int r) &#123; int size = r - p + 1;//数组长度 // 每五个元素一组 int groupSize = (size % 5 == 0) ? (size / 5) : (size / 5 + 1); int medians[] = new int[groupSize]; int indexOfMedians = 0; //对每一组进行插入排序 for(int i = 0; i &lt; groupSize; i++) &#123; //单独处理最后一组，因为最后一组可能不满5个元素 if(i == groupSize - 1) &#123; // 排序最后一组 InsertionSort.insertSort(arr, p + i*5, r); // 最后一组的中间那个 medians[indexOfMedians++] = arr[(p + i * 5 + r) / 2]; &#125;else &#123; //排序非最后一组的其他组 InsertionSort.insertSort(arr, p + i * 5, p + i * 5 + 4); // 当前组排序后中间那个元素 medians[indexOfMedians++] = arr[p + i * 5 + 2]; &#125; &#125; // 对medians排序 InsertionSort.insertSort(arr, 0, medians.length - 1); return medians[medians.length/2]; &#125;&#125; 程序运行结果： 1239 27 73 78 80 69 42 99 19 87 74 14 50 15 21 14 15 19 21 27 39 42 50 69 73 74 78 80 87 99 快速排序优化_待排序列较短时，用插入排序：思想： 当待拍序列较短时，如果一直用递归，花费的时间远比，用插入排序长。所以当待拍序列小于一定长度时，可使用插入排序，提高速度。 代码示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package chapter3_排序;//工程实践中针对快速排序的其他优化public class 快速排序_优化 &#123; public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(25); util.ArrayUtil.printArr(arr); quickSort(arr, 0, arr.length-1); util.ArrayUtil.printArr(arr); &#125; public static void quickSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; //待排序个数小于8个的时候，用插入排序 if(r - p + 1 &lt;= 8) &#123; InsertionSort.insertSort(arr, p, r); &#125;else &#123; int q = partition(arr, p , r); quickSort(arr, p, q - 1); quickSort(arr, q + 1, r); &#125; &#125; &#125; //三点中值法 public static int partition(int[] arr, int p, int r) &#123; //优化，在p, r, mid之间，选一个中间值作为主元 int minIndex = p + ((r - p) &gt;&gt; 1);//中间下标 int minValueIndex = -1;//中值的下标 if(arr[p] &lt;= arr[minIndex] &amp;&amp; arr[p] &gt;= arr[r]) &#123; minValueIndex = p; &#125;else if(arr[r] &lt;= arr[minIndex] &amp;&amp; arr[r] &gt;= arr[p]) &#123; minValueIndex = r; &#125;else &#123; minValueIndex = minIndex; &#125; util.Swap.swap(arr, p, minValueIndex); int pivot = arr[p]; int left = p + 1; //左侧指针 int right = r; //右侧指针 while(left &lt;= right) &#123; while(left &lt;= right &amp;&amp; arr[left] &lt;= pivot) &#123; left++; &#125; while(left &lt;= right &amp;&amp; arr[right] &gt; pivot) &#123; right--; &#125; if(left &lt; right) &#123; util.Swap.swap(arr, left, right); &#125; &#125; util.Swap.swap(arr, p, right); return right; &#125;&#125; 程序运行结果： 1286 2 79 72 34 2 20 50 44 75 97 86 93 64 3 5 67 72 22 56 37 69 55 55 53 2 2 3 5 20 22 34 37 44 50 53 55 55 56 64 67 69 72 72 75 79 86 86 93 97]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多维数组和矩阵程序练习]]></title>
    <url>%2F2019%2F01%2F03%2F%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84%E5%92%8C%E7%9F%A9%E9%98%B5%E7%A8%8B%E5%BA%8F%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[顺时针打印二维数组：题目： 顺时针打印二维数组。 例如：将如下数组： 12345&gt; &#123;&#123;1, 2, 3, 4&#125;,&gt; &#123;5, 6, 7, 8&#125;,&gt; &#123;9, 10, 11, 12&#125;,&gt; &#123;13, 14, 15, 16&#125;&#125;&gt; 输出为：1 2 3 4 8 12 16 15 14 13 9 5 6 7 11 10 思路： 可以先一圈一圈的打印。先打印外圈，再缩小边界范围循环打印内圈即可。打印的时候注意控制边界。 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class 顺时针打印二维数组 &#123; public static void main(String[] args) &#123; int[][] matrix = &#123;&#123;1, 2, 3, 4&#125;, &#123;5, 6, 7, 8&#125;, &#123;9, 10, 11, 12&#125;, &#123;13, 14, 15, 16&#125;&#125;; print(matrix); &#125; public static void print(int[][] matrix) &#123; int leftUpRow = 0, leftUpCol = 0; int rightDownRow = matrix.length - 1; int rightDownCol = matrix[0].length - 1; while(leftUpCol &lt;= rightDownCol &amp;&amp; leftUpRow &lt;= rightDownRow) &#123; int c = leftUpCol, r = leftUpRow; // 打印上面一条边 while (c &lt;= rightDownCol) &#123; System.out.print(matrix[r][c++] + " "); &#125; // 恢复 c = rightDownCol; r++; //打印右边一条边 while (r &lt;= rightDownRow) &#123; System.out.print(matrix[r++][c] + " "); &#125; // 恢复 r = rightDownRow; c--; //打印下面一条边 while (c &gt;= leftUpRow) &#123; System.out.print(matrix[r][c--] + " "); &#125; // 恢复 c = leftUpRow; r--; //打印下面一条边 while (r &gt; leftUpRow) &#123; System.out.print(matrix[r--][c] + " "); &#125; leftUpCol++;leftUpRow++;rightDownCol--;rightDownRow--; &#125; &#125;&#125; 程序运行结果： 11 2 3 4 8 12 16 15 14 13 9 5 6 7 11 10 0所在的行列清零：题目： 如果矩阵中某个元素为0，则将其所在的行和列清零。 1 2 3 4 5 6 0 8 9 0 11 12 13 14 15 16 思路： 先扫描整个二维数组，开辟两个一维数组，分别标记零所在的行和列。最后，在整个二维数组中，如果发现行或者列被标记，所在的行或者列的数据就清零。 代码示例：123456789101112131415161718192021222324252627282930313233343536public class 零所在的行和列清零 &#123; public static void main(String[] args) &#123; int[][] matrix = &#123;&#123;1, 2, 3, 4&#125;, &#123;5, 0, 7, 8&#125;, &#123;9, 10, 0, 12&#125;, &#123;13, 14, 15, 16&#125;&#125;; clear(matrix); util.ArrayUtil.printMatrix(matrix); &#125; public static void clear(int[][] matrix) &#123; // 标记0所在的行 int[] rowFlag = new int[matrix.length]; // 标记0所在列 int[] colFlag = new int[matrix[0].length]; for(int i = 0; i &lt; matrix.length; i++) &#123; for(int j = 0; j &lt; matrix[0].length; j++) &#123; if(matrix[i][j] == 0) &#123; rowFlag[i] = 1; colFlag[j] = 1; &#125; &#125; &#125; for(int i = 0; i &lt; matrix.length; i++) &#123; for(int j = 0; j &lt; matrix[0].length; j++) &#123; // 如果行或者列被标记，则该行和该列的所有数据清零 if(rowFlag[i] == 1 || colFlag[j] == 1) &#123; matrix[i][j] = 0; &#125; &#125; &#125; &#125;&#125; 程序运行结果： 12341 0 0 4 0 0 0 0 0 0 0 0 13 0 0 16 Z字形打印矩阵：题目： 按如下规律，打印出矩阵元素。 思路： 做该题时，可以分解为打印两个方向，从左下角打印到右上角，再从右上角打印到左下角。分别控制好边界的转化方向即可。 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Z形打印矩阵 &#123; public static void main(String[] args) &#123; int[][] matrix = &#123;&#123;1, 2, 3, 4&#125;, &#123;5, 6, 7, 8&#125;, &#123;9, 10, 11, 12&#125;&#125;; zPrint(matrix); &#125; public static void zPrint(int[][] matrix) &#123; int row = matrix.length; int col = matrix[0].length; int r = 0; int c = 0; // 打印方向，true为从左下角向右上方打印。false为从右上方像向左下方打印 boolean direction = true; while(r &lt; row &amp;&amp; c &lt; col) &#123; if(direction) &#123; // 从左下到右上的斜线 System.out.print(matrix[r][c] + " "); // 在第一行，列未到边界，只能向右走 if(r == 0 &amp;&amp; c &lt; col - 1) &#123; c++; direction = false; continue; &#125;else if(r &gt; 0 &amp;&amp; c == col - 1)&#123;//走到最后一列，只能向下走 r++; direction = false; continue; &#125;else &#123; // 继续走上坡 r--; c++; &#125; &#125;else &#123; // 从右上角往左下角走 System.out.print(matrix[r][c] + " "); // 走到第一列，行未到边界。只能往下走 if(c == 0 &amp;&amp; r &lt; row - 1) &#123; r++; direction = true; continue; &#125;else if(r == row - 1)&#123; // 走到最后一行，只能往右走 direction = true; c++; continue; &#125;else &#123; // 继续走下坡路 r++; c--; &#125; &#125; 程序运行结果： 11 2 5 9 6 3 4 7 10 11 8 12 边界为1的最大子方阵：题目： 给定一个N * N 的矩阵matrix，这个矩阵中，只有0和1两种值，返回边框全是1的最大正方形的边长长度。 例如： 123456&gt; &#123;0, 1, 1, 1, 1&#125;,&gt; &#123;0, 1, 0, 0, 1&#125;,&gt; &#123;0, 1, 0, 0, 1&#125;,&gt; &#123;0, 1, 1, 1, 1&#125;,&gt; &#123;1, 1, 0, 1, 1&#125; &gt; 其中，边框全是1的最大正方形的大小是4*4，返回4. 思路： 本题为基础解法，枚举。下道题该题的优化的解法。 枚举，从n ~ 1 遍历每个正方形的四条边，如果四条边都是1，则返回n。 代码示例:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class 边界为1的最大子方阵 &#123; public static void main(String[] args) &#123; int[][] matrix = &#123; &#123;0, 1, 1, 1, 1&#125;, &#123;0, 1, 0, 0, 1&#125;, &#123;0, 1, 0, 0, 1&#125;, &#123;0, 1, 1, 1, 1&#125;, &#123;1, 1, 0, 1, 1&#125;&#125;; int max = solve(matrix); System.out.println(max); &#125; private static int solve(int[][] matrix) &#123; int N = matrix.length; int n =N; //记录最大子方阵边长 while (n &gt; 0) &#123; for(int i = 0; i &lt; N; i++) &#123; if(i + n &gt; N) break; L3: // 标签，当在检查子方阵边长时，如果遇到边长有0，则跳出循环，重新继续执行下一行 for(int j = 0; j &lt; N; j++) &#123; if(j + n &gt; N) break; //检查四条边是否全为1 int row = i; int col = j; //判断上边一条边 while (col &lt; j + n) &#123; if(matrix[row][col++] == 0) &#123; continue L3; &#125; &#125; col--; //判断右边一条边 while (row &lt; i + n) &#123; if(matrix[row++][col] == 0) &#123; continue L3; &#125; &#125; row--; //判断下边一条边 while (col &gt;= j) &#123; if(matrix[row][col--] == 0) &#123; continue L3; &#125; &#125; col++; //判断左边一条边 while (row &gt;= i) &#123; if(matrix[row--][col] == 0) &#123; continue L3; &#125; &#125; return n; &#125; &#125; n--; &#125; return 0; &#125;&#125; 程序运行结果： 14 边界为1的最大子方阵优化：思路分析： 上题中的枚举算法时间复杂度为O(n^4), N N N * 4n的时间复杂度。 可以通过优化4n的时间复杂度，将整个解法的时间复杂度降到O(n^3). 思路：预处理方法。 ​ 通过预处理方法，先生成一个对应的三维数组，二维平面空间和矩阵大小相等，第三维存储两个元素，第一个数表示，包括自己以及右方连续为1的个数，如果自己为0，则该数为0。第二个数表示，包括自己以及下方连续为1的个数，如果自己为0，则该数为0。通过生成这个辅助表，可以在判断是否是最大方阵的时候大大加快判断速度，可将4个while循环去除，每次只需判断一次即可，判断复杂度变为O(1)。 生成辅助举证举例如下：矩阵为记为A 123456&gt; &#123;0, 1, 1, 1, 1&#125;,&gt; &#123;0, 1, 0, 0, 1&#125;,&gt; &#123;0, 1, 0, 0, 1&#125;,&gt; &#123;0, 1, 1, 1, 1&#125;,&gt; &#123;1, 1, 0, 1, 1&#125; &gt; 如以上矩阵可以生成如下辅助数组help： 12345678&gt; &#123;&#123;0， 0&#125;, &#123;4， 4&#125;, &#123;3, 1&#125;, &#123;2, 1&#125;, &#123;1, 5&#125;&#125;,&gt; &#123;&#123;0， 0&#125;, &#123;1， 4&#125;, &#123;0, 0&#125;, &#123;0, 0&#125;, &#123;1, 4&#125;&#125;,&gt; &#123;&#123;0， 0&#125;, &#123;1， 3&#125;, &#123;0, 0&#125;, &#123;0, 0&#125;, &#123;1, 3&#125;&#125;,&gt; &#123;&#123;0， 0&#125;, &#123;4, 2&#125;, &#123;3, 1&#125;, &#123;2, 2&#125;, &#123;1, 2&#125;&#125;,&gt; &#123;&#123;2， 1&#125;, &#123;1， 1&#125;, &#123;0, 0&#125;, &#123;2, 1&#125;, &#123;1, 1&#125;&#125;&gt; //注意：生成辅助数组时，因为每个点记录的都是右下方的统计值，所以&gt; // 必须从右下方开始倒退生成整个辅助数组。&gt; 当生成如上辅助数组时，每次检查四条边的时候，可以直接检查三个顶点的数字，即可判断是否四条边都是1。例如：当检查n=4时，检查到 A[0][1] 点时，可以直接判断（help[0][1][0] &gt;= n &amp;&amp;help[0][1][1] &gt;= n help[0][1+n][1] &gt;= n help[0+n][1][0] &gt;= n）如果都成立，即可知四条边上的值为1。此时直接返回n即可。具体代码示例如下： 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697public class 边界为1的最大子方阵_优化 &#123; static int[][][] help; //声明全局变量，辅助数组 public static void main(String[] args) &#123; int[][] matrix = &#123; &#123;0, 1, 1, 1, 1&#125;, &#123;0, 1, 0, 0, 1&#125;, &#123;0, 1, 0, 0, 1&#125;, &#123;0, 1, 1, 1, 1&#125;, &#123;1, 1, 0, 1, 1&#125;&#125;; generateHelp(matrix); System.out.println("生成的辅助数组数据如下："); System.out.println("-------------------------------------"); printHelp(help, matrix.length); System.out.println("-------------------------------------"); int max = solve(matrix); System.out.println("最大子方阵的边长为：" + max); &#125; // 打印生成辅助的数组数据 private static void printHelp(int[][][] help, int N) &#123; for(int i = 0; i &lt; N; i++) &#123; for(int j = 0; j &lt; N; j++) &#123; System.out.print(help[i][j][0] + "," + help[i][j][1] + "\t"); &#125; System.out.println(); &#125; &#125; // 生成辅助数组的方法 private static void generateHelp(int[][] matrix) &#123; int N = matrix.length; help = new int[N][N][2]; int lastRow = N - 1; // 先初始化最后一行辅助数据。用于生成其他数据 for(int i = N - 1; i &gt;= 0; i--) &#123; int value = matrix[lastRow][i]; if(value == 1) &#123; if(i == N - 1) &#123; // 当初始化最后一列时，如果value为1，则右边为1 help[lastRow][i][0] = 1; &#125;else &#123; // 如果非最后一列，则右边的初始化为：从自身到右边的连续1的个数 help[lastRow][i][0] = help[lastRow][i + 1][0] + 1; &#125; // 当value=1时，下方1的个数初始化为1 help[lastRow][i][1] = 1; &#125; &#125; // 生成整个辅助数组的数据 for(int i = N - 2; i &gt;= 0; i--) &#123; for(int j = N - 1; j &gt;= 0; j--) &#123; int value = matrix[i][j]; if(value == 1) &#123; if(j == N - 1) &#123; help[i][j][0] = 1; &#125;else &#123; // 当value=1时，右方连续1的个数 help[i][j][0] = help[i][j+1][0] + 1; &#125; // 当value=1时，下方连续1的个数 help[i][j][1] = help[i+1][j][1] + 1; &#125; &#125; &#125; &#125; private static int solve(int[][] matrix) &#123; int N = matrix.length; int n =N; //记录最大子方阵边长 while (n &gt; 0) &#123; for(int i = 0; i &lt; N; i++) &#123; if(i + n &gt; N) break; for(int j = 0; j &lt; N; j++) &#123; if(j + n &gt; N) break; if(check(i, j, n)) return n; &#125; &#125; n--; &#125; return 0; &#125; //检查以matrix[i][j]为左顶点的，边长为n的方阵的边上的数是否都为1 private static boolean check(int i, int j, int n) &#123; // 左上角那个点往右数的1的数目要 &gt;= n // 左上角那个点往下数的1的数目要 &gt;= n // 右上角那个点往下数的1的数目要 &gt;= n // 左下角那个点往右数的1的数目要 &gt;= n if(help[i][j][0] &gt;= n &amp;&amp; help[i][j][1] &gt;= n &amp;&amp; help[i+n-1][j][0] &gt;= n &amp;&amp; help[i][j+n-1][1] &gt;= n) return true; return false; &#125;&#125; 程序运行结果： 123456789生成的辅助数组数据如下：-------------------------------------0,0 4,5 3,1 2,1 1,5 0,0 1,4 0,0 0,0 1,4 0,0 1,3 0,0 0,0 1,3 0,0 4,2 3,1 2,2 1,2 2,1 1,1 0,0 2,1 1,1 -------------------------------------最大子方阵的边长为：4 子数组最大和累加：题目： 给定一个数组arr，返回子数组的最大累加和。 例如：arr[1, -2, 3, 5, -2, 6, -1]；所有的子数组中[3, 5, -2, 6]可以累加出最大和12，所以返回12； 思路： 有两种解法： 方法1 ： 暴力法 可以通过暴力法，把所有可能的子数组情况进行累加。最后比较，得出最大值即可。 时间复杂度为：O(n^2); 方法2：递推法： 可以通过扫描一次数组，挨着累加，当累加和出现负数，直接舍弃，证明该段子数量最最大子序列没有贡献。每次累加后，与最大的数比较，如果比最大数大，就替换。详细代码如下： 时间复杂度为：O(n) 代码示例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class MaxSubArray &#123; public static void main(String[] args) &#123; //获取10000 个 -100 - 100 的随机整数 int[] arr = util.ArrayUtil.getRandomArr(10000, -100, 100); util.ArrayUtil.printArr(arr); long begin = System.currentTimeMillis(); System.out.println("子数组最大累加和为：" + maxSum(arr)); System.out.print("暴力法："); util.CountTime.countTime(begin); long begin1 = System.currentTimeMillis(); System.out.println("子数组最大累加和为：" + maxSum1(arr)); System.out.print("递推法："); util.CountTime.countTime(begin1); &#125; //暴力法 public static int maxSum(int[] arr) &#123; if(arr.length == 0) return 0; int maxSum = arr[0]; //用来记录最大的和 for(int i = 0; i &lt; arr.length; i++) &#123; int sum = 0; for(int j = i; j &lt; arr.length; j++) &#123; sum += arr[j]; if(sum &gt; maxSum) &#123; maxSum = sum; &#125; &#125; &#125; return maxSum; &#125; // 递推法 时间复杂度O(n) public static int maxSum1(int[] arr) &#123; if(arr.length == 0) return 0; int maxSum = arr[0]; int sum = 0; // left，right用来记录最大子序列和的开始和结束下标 int left = 0, right = 0; for(int i = 0; i &lt; arr.length; i++) &#123; if(sum &gt;= 0) &#123; //左子表的最大和为正，继续向后累加 sum += arr[i]; &#125;else &#123; //为负，则舍弃，从下一个数重新开始累加。 sum = arr[i]; left = i; //记录左开始累加的左下标 &#125; if(sum &gt; maxSum) &#123; //如果每次累加的和大于最大记录，则替换 maxSum = sum; right = i; //替换后此时，记录最大子序列的右下标 &#125; &#125; System.out.println("最大子序列和的开始下标和结束下标为：" + left + "-&gt;" + right); return maxSum; &#125;&#125; 程序执行结果： 12345631 78 93 99 -64 78 41 35 …… 子数组最大累加和为：4253暴力法：程序执行时间：54ms最大子序列和的开始下标和结束下标为：8995-&gt;3811子数组最大累加和为：4253递推法：程序执行时间：0ms 子矩阵最大累加和：题目： 给定一个矩阵matrix，其中的值有正、有负、有0，返回子矩阵的最大累加和。 例如：matrix 为： 1234&gt; -1 -1 -1&gt; -1 2 2&gt; -1 -1 -1&gt; 其中最大累加和的子矩阵为：2 2 ，所以返回4. 思路： 有两种方案： 方案1：暴力法，求出所有可能性。不推荐。 方案2：递推法，同上题。 每行为单位，求出单行的最大子序列和。将多行的值累加为一行的值进行累加。最后求出最大值。 代码示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MaxSubMatrix &#123; public static void main(String[] args) &#123; int[][] matrix = &#123;&#123;-1, -1, -1&#125;, &#123;-1, 2, 2&#125;, &#123;-1, -1, -1&#125;&#125;; System.out.println(maxSubMatrixSum(matrix)); &#125; private static int maxSubMatrixSum(int[][] matrix) &#123; if(matrix.length == 0) return 0; final int row = matrix.length; final int col = matrix[0].length; int maxSum = 0; //历史最大的子矩阵和 int beginRow = 0;//以它为起始行 while(beginRow &lt; row) &#123; //按列求和 int[] sums = new int[col]; for(int i = beginRow; i &lt; row; i++) &#123; //按列累加 for(int j = 0; j &lt; col; j++) &#123; sums[j] += matrix[i][j]; &#125; //累加完成 该方法头上题解法2 int sum = maxSubArraySum(sums); if(sum &gt; maxSum) &#123; maxSum = sum; &#125; &#125; beginRow++; &#125; return maxSum; &#125; private static int maxSubArraySum(int[] arr) &#123; if(arr.length == 0) return 0; int maxSum = arr[0]; int sum = 0; for(int i = 0; i &lt; arr.length; i++) &#123; if(sum &gt;= 0) &#123; //左子表的最大和为正，继续向后累加 sum += arr[i]; &#125;else &#123; //为负，则舍弃，从下一个数重新开始累加。 sum = arr[i]; &#125; if(sum &gt; maxSum) &#123; //如果每次累加的和大于最大记录，则替换 maxSum = sum; &#125; &#125; return maxSum; &#125;&#125; 程序运行结果： 14]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>Java编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓝桥杯程序练习（2）]]></title>
    <url>%2F2019%2F01%2F02%2F%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%A8%8B%E5%BA%8F%E7%BB%83%E4%B9%A0%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[最大连续递增子序列（部分有序）：问题描述： 在一组部分有序的数组中，找出长递增子序列。 例：（1， 9, 5，7, 3， 4， 6， 8， 0）中最长的递增子序列为（3， 4， 6，8）。 代码示例：1234567891011121314151617181920212223242526272829303132333435public class 最长连续递增子序列 &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 9, 2, 5, 7, 3, 4, 6, 8, 9, 0&#125;; System.out.println("最大递增子序列的长度是：" + maxLenth(arr)); &#125; public static int maxLenth(int[] arr) &#123; int maxLength = 0; int maxBegin = 0; int maxEnd = 0; int begin = 0; int end = 0; for(int i = 0; i &lt; arr.length - 1; i++) &#123; if(arr[i+1] &gt;= arr[i]) &#123; end++; &#125;else &#123; int length = end - begin + 1; if(length &gt; maxLength) &#123; maxBegin = begin; maxEnd = end; maxLength = length; &#125; begin = end + 1; end++; &#125; &#125; System.out.print("最大递增的子序列是："); for(int i = maxBegin; i &lt;= maxEnd; i++) &#123; System.out.print(arr[i]); &#125; System.out.println(); return maxLength; &#125;&#125; 程序运行结果： 12最大递增的子序列是：34689最大递增子序列的长度是：5 设计一个高效的求a的n次幂的算法：1234567891011121314151617181920212223242526272829303132333435363738394041424344public class a的n次幂 &#123; public static void main(String[] args) &#123; int n = 10; int a = 2; System.out.println(pow(a, n)); System.out.println(pow1(a, n)); &#125; // 累乘法 // 时间复杂度为 O(n) public static long pow(int a, int n) &#123; long res = 1; for(int i = 0; i &lt; n; i++) &#123; res *= a; &#125; return res; &#125; /** * 算法改进： * 通过减少累乘次数，提高算法的效率。 * 上面的方法需要累乘n次才可以得到结果。 * 下面改进后，例如：当求2^6的时候，按指数可以分解 * 指数 5 可以分为 2 * 2 + 2，即2^6 = (2^2)^2 * 2 * 2; * 即将原来的2*2*2*2*2*2简化为：((2*2)^2) * 2 * 2; * 当指数很大时，可以极大减少累乘次数 * @param a * @param n * @return */ public static long pow1(int a, int n) &#123; if(n == 0) return 1; long res = a; int ex = 1; // 能翻 while((ex&lt;&lt;1) &lt;= n) &#123; res *= res; // 翻 ex&lt;&lt;=1; // 指数 &#125; // 不能翻 //差 n-ex次方没有乘到结果里面 return res * pow1(a, n - ex); &#125;&#125; 程序运行结果： 1210241024]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>Java编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python获取Cookie时遇到重定向的情况]]></title>
    <url>%2F2019%2F01%2F01%2FPython%E8%8E%B7%E5%8F%96Cookie%E6%97%B6%E9%81%87%E5%88%B0%E9%87%8D%E5%AE%9A%E5%90%91%E7%9A%84%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[问题描述和解决：在模拟登录教务处的时候，需要通过获取cookie来进行后面一系列操作。 但是刚开始，python模拟登录一直失败，提示的没权限。通过网页抓包分析，最后看到每次输入地址进行登录时候，会发生302重定向，重定向后的地址和原来一样，但是会在地址后面传入一段随机值。 通过Burpsuite抓包查看每次登录请求头部信息，提交的Cookie有两个字段。在以前的时候一直是 ：Cookie: JSESSIONID=gde7KUAgMlZ-zdMkvOjGw一个字段，但是通过抓包分析，每次在重定向的时候也会添加一个字段，而这个cookie字段是通过浏览器随机生成的。 所以想到的解决思路是，是否可以通过抓取两个cookie字段，来进行模拟登录。但是正常通过request请求，只能得到一个Cookie。 最后，通过在request库请求的时候，加入一个参数：allow_redirects=False ,来禁止网页进行302重定向，从而成功的获取了第一个cookie字段，再利用获取到的这个cookie字段，以及获取到的url，重新封装请求头部。重新进行了网页请求，从而获取了第二个cookie字段。通过抓分分析，将获取的两个cookie字段，进行了拼接成为一个字符串。将新的cookie进行了封装到请求头信息，从而提交账号密码等信息，从而成功实现了登录。以及后面获得了各种想要的信息。 但是现在，教务处系统经过修改，302重定向又没有了，只需要正常请求一次就可以获取一个字段的cookie。 实例代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546zjh = self.get_body_argument('zjh') mm = self.get_body_argument('mm') postdata = &#123; 'evalue' : '', 'zjh1' :'', 'zjh' : zjh, 'fs' : '', 'v_yzm' : '', 'lx' : '', 'mm' : mm, 'eflag' : '', 'dzslh' : '', 'tips' : '' &#125; # 禁止网页自己进行重定向 r = requests.get('http://211.82.47.7', allow_redirects=False) # 获取第一个字段的cookie cookie1 = r.headers['Set-Cookie'] #print(cookie1) # 重新封装请求头部 head1 = &#123;'Cookie':cookie1&#125; # 利用封装好的头部，重新请求网页 r1 = requests.get(r.url, headers = head1) # 获取cookie的第二字段 cookie2 = r1.headers['Set-Cookie'] #print(cookie2) # 拼接cookie字段 cookie = cookie1 + ';' + cookie2 #print(cookie) head = &#123; #封装新的请求头部 'Proxy-Connection':'keep-alive', 'Content-Length': '75', 'Cache-Control': 'max-age=0', 'Origin': 'http://211.82.47.7', 'Upgrade-Insecure-Requests': '1', 'Content-Type': 'application/x-www-form-urlencoded', 'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'Referer': 'http://211.82.47.7/', 'Accept-Encoding': 'gzip, deflate', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Cookie': cookie &#125; # 利用获取的cookie成功实现了登录 res = requests.post('http://211.82.47.7/loginAction.do', data = postdata, headers=head) res.close()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python学习笔记</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python实现爬取教务处成绩系统]]></title>
    <url>%2F2019%2F01%2F01%2FPython%E5%AE%9E%E7%8E%B0%E7%88%AC%E5%8F%96%E6%95%99%E5%8A%A1%E5%A4%84%E6%88%90%E7%BB%A9%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Python查询教务处成绩系统简介项目简介：该项目是利用tornado框架写的，程序运行后，可以在浏览器输入地址进行访问网站，可以实现输入账号密码后查询成绩。以及可以进行评教。 项目工程文件目录： 图：项目工程文件 图：网页文件 程序功能和效果图如下： 登录界面： 登录界面要求输入账号密码，如果账号密码不正确，都会提示错误。 图：登录界面菜单界面： 菜单界面，实现的功能有，查询本学期成绩，一次性查询历年所有成绩。以及可以进行评教。还可以查询各学习的成绩。 图：菜单界面 查看本学期成绩： 进入该页面，可以列出本学习需要考试的课程，当成绩出来后，可以显示每门课的成绩信息，点击每门课的标题，还可进一步查看本课程的详细信息。 图：查看本学期成绩 查看课程详细成绩： 可以查看课程的更详细成绩，最高分，最低分，平均分等。 图：查看课程详细成绩 查看各学期成绩： 查看各学习的成绩，可以统计各学习的总学分，通过课程数等。 图：查看各学期成绩 评教界面： 分为以评估和待评估列表。可以进行相应的操作。点击代评估课程，可以进行评教。点击已评估课程，可以查看该课程的评教结果。 图：评教界面 Python实现代码demo.py1234567891011121314151617181920212223242526272829303132333435363738394041424344import tornado.httpserverimport tornado.webfrom tornado.options import options,defineimport tornado.ioloopimport os.pathfrom handler import *#import pymysql as sqldefine("port", default=8899, help="run on give port", type=int)class Application(tornado.web.Application): def __init__(self): #conn = sql.connect(host='localhost', user='root', password='root', port=3306, database='dtxt', charset='utf8') #self.db = conn handlers = [ (r'/', Index), (r'/menu', Menu), (r'/login', login), (r'/list', tlist), (r'/toEval', toEval), (r'/EvalResult', ResultShow), (r'/Showbxqcjcx', Showbxqcjcx), (r'/ShowAllScore', ShowAllScore), (r'/ShowTermScore', ShowTermScore), (r'/ShowSubjectScore',ShowSubjectScore), (r'/SaveAllScore', SaveAllScore) ] settings = dict( template_path = os.path.join(os.path.dirname(__file__), "templates"), static_path = os.path.join(os.path.dirname(__file__), "static"), debug = True, autoreload = True, cookie_secret="feljjfesrh48thfe2qrf3np2zl90bmwj", xsrf_cookie=True, ) tornado.web.Application.__init__(self, handlers = handlers, **settings)if __name__ == "__main__": tornado.options.parse_command_line() http_server = tornado.httpserver.HTTPServer(Application()) http_server.listen(options.port) tornado.ioloop.IOLoop.instance().start() handler.py 该程序为程序实现的主体。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402import tornado.web#import pymysql as sqlimport requestsfrom lxml import etreefrom tornado import genimport timefrom urllib import parseimport refrom bs4 import BeautifulSoupclass BaseHandler(tornado.web.RequestHandler): def get_current_user(self): user = self.get_secure_cookie('Cookie') if user: return user.decode() else: self.redirect('/login')class Index(tornado.web.RequestHandler): @gen.coroutine def get(self): self.redirect('/login')class Menu(BaseHandler): @gen.coroutine def get(self): uid = self.current_user #uid = self.current_user if not uid: self.redirect('/login') head = &#123; 'Accept': 'image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, */*', 'Accept-Language': 'zh-CN', 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36', 'Host': '211.82.47.2', 'Cookie': uid &#125; #all_score = requests.get('http://211.82.47.2/gradeLnAllAction.do?type=ln&amp;oper=qbinfo&amp;lnxndm=2016-2017学年秋(两学期)#2016-2017学年秋(两学期)', headers = head) all_score = requests.get('http://211.82.47.2/gradeLnAllAction.do?type=ln&amp;oper=qbinfo', headers = head) all_score.close() scoreSoup = BeautifulSoup(all_score.text, 'html.parser') term = [] #存放学期 for i in scoreSoup.find_all('a'): term.append(i['name']) self.render('menu.html', term = term) class login(tornado.web.RequestHandler): @gen.coroutine def get(self): self.render("login.html") @gen.coroutine def post(self): zjh = self.get_body_argument('zjh') mm = self.get_body_argument('mm') postdata = &#123; 'evalue' : '', 'zjh1' :'', 'zjh' : zjh, 'fs' : '', 'v_yzm' : '', 'lx' : '', 'mm' : mm, 'eflag' : '', 'dzslh' : '', 'tips' : '' &#125; head = &#123; "Accept-Language":"zh-CN,zh;q=0.8", 'Accept':"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", "User-Agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36", "Connection":"keep-alive", &#125; res = requests.post('http://211.82.47.2/loginAction.do', data = postdata, headers=head) res.close() if len(res.content) &lt; 2000: cookie = res.headers['Set-Cookie'][:32] self.set_secure_cookie("Cookie", cookie, expires_days=None, expires=time.time()+500) self.redirect('/menu') else: self.write("账号密码错误")class tlist(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if uid: #self.write('JSESSIONID: %s' % uid) head = &#123; "Accept-Language":"zh-CN,zh;q=0.8", 'Accept':"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", "User-Agent":"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36", "Connection":"keep-alive", "Cookie" : uid &#125; two = requests.get('http://211.82.47.2/jxpgXsAction.do?oper=listWj&amp;pageSize=300', headers = head) notPg = [] hadPg = [] content = etree.HTML(two.text) for link in content.xpath('//img')[0:-5]: if link.get('title') == '评估': notPg.append(link.get('name').split('#@')) else: hadPg.append(link.get('name').split('#@')) """ret = '' for i in hadPg: ret += i ret += '&lt;br&gt;' self.write(ret)""" self.render('teacher_list.html', notPg = notPg, hadPg = hadPg)class toEval(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if not uid: self.redirect('/login') head = dict() head['Content-Type'] = 'application/x-www-form-urlencoded' #head['Referer'] = 'http://211.82.47.2/jxpgXsAction.do' head['Accept-Language'] = 'zh-CN' head['Cache-Control'] = 'no-cache' head['Accept'] = 'text/html,application/xhtml+xml,application/xml' head['Accept-Encoding'] = 'gzip, deflate' head['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36' head['Cookie'] = uid bpr = self.get_argument('bpr') wjbm = self.get_argument('wjbm') pgnr = self.get_argument('pgnr') wj = &#123; 'bpr': bpr, 'bprm': self.get_argument('bprm'), 'wjmc': self.get_argument('wjmc'), 'wjbz': 'null', 'wjbm': wjbm, 'pgnrm': self.get_argument('pgnrm'), 'pgnr': pgnr, 'pageSize': '20', 'pageNo': '', 'page': '1', 'oper': 'wjShow', 'currentPage': '1' &#125; wj = parse.urlencode(wj, encoding='gbk').encode() two = requests.post('http://211.82.47.2/jxpgXsAction.do', data = wj, headers=head) two.close() self.render("eval_page.html", bpr = bpr, wjbm = wjbm, pgnr = pgnr) #self.write(two.text) @gen.coroutine def post(self): uid = self.current_user if not uid: self.redirect('/login') head1 = dict() head1['Content-Type'] = 'application/x-www-form-urlencoded' head1['Referer'] = 'http://211.82.47.2/jxpgXsAction.do' head1['Accept-Language'] = 'zh-CN' head1['Cache-Control'] = 'no-cache' head1['Accept'] = 'text/html,application/xhtml+xml,application/xml' head1['Accept-Encoding'] = 'gzip, deflate' head1['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36' head1['Cookie'] = uid one = self.get_body_argument('one') two = self.get_body_argument('two') three = self.get_body_argument('three') four = self.get_body_argument('four') zero = self.get_body_argument('zero') data = &#123; '0000000002': zero, '0000000003': zero, '0000000011': one, '0000000012': one, '0000000013': three, '0000000014': three, '0000000021': four, '0000000022': three, '0000000023': one, '0000000024': two, '0000000031': three, '0000000032': two, '0000000033': three, '0000000034': three, '0000000041': zero, '0000000042': zero, '0000000043': four, 'bpr': self.get_body_argument('bpr'), 'pgnr': self.get_body_argument('pgnr'), 'wjbm': self.get_body_argument('wjbm'), 'wjbz': 'null', 'xumanyzg': 'zg', 'zgpj': self.get_body_argument("zgpj") &#125; data = parse.urlencode(data, encoding='gbk').encode() three = requests.post('http://211.82.47.2/jxpgXsAction.do?oper=wjpg', data=data, headers = head1) three.close() if b'back' in three.content: self.render("Failed.html") else: self.render("Success.html")class ResultShow(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if not uid: self.redirect('/login') head1 = dict() head1['Content-Type'] = 'application/x-www-form-urlencoded' head1['Referer'] = 'http://211.82.47.2/jxpgXsAction.do?oper=listWj' head1['Accept-Language'] = 'zh-CN' head1['Cache-Control'] = 'no-cache' head1['Accept'] = 'text/html,application/xhtml+xml,application/xml' head1['Accept-Encoding'] = 'gzip, deflate' head1['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36' head1['Cookie'] = uid data = &#123; 'bpr': self.get_argument('bpr'), 'bprm': self.get_argument("bprm"), 'currentPage': '1', 'oper': 'wjResultShow', 'page': '1', 'pageNo': '', 'pageSize': '20', 'pgnr': self.get_argument("pgnr"), 'pgnrm': self.get_argument('pgnrm'), 'wjbm': self.get_argument('wjbm'), 'wjbz': '', 'wjmc': self.get_argument('wjmc') &#125; data = parse.urlencode(data, encoding='gbk').encode() result = requests.post('http://211.82.47.2/jxpgXsAction.do', data = data, headers = head1) result.close() a = re.sub('href=\".*?\"','href=\"\"', result.text) a = re.sub('src=\".*?\"', 'src=\"\"', a) self.write(a)class ShowAllScore(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if not uid: self.redirect('/login') head = &#123; 'Accept': 'image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, */*', 'Accept-Language': 'zh-CN', 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36', 'Host': '211.82.47.2', 'Cookie': uid &#125; all_score = requests.get('http://211.82.47.2/gradeLnAllAction.do?type=ln&amp;oper=fainfo', headers = head) all_score.close() scoreSoup = BeautifulSoup(all_score.text, 'html.parser') displayTag = [] #标题 for tag in scoreSoup.find_all('th' , class_='sortable'): displayTag.append(str.strip(tag.text)) scoreData = [] #成绩数据 for score in scoreSoup.find_all('tr', class_='odd'): subject = [] for data in score.find_all('td'): subject.append(str.strip(data.text)) scoreData.append(subject) counts = [] #学分统计 for font in scoreSoup.find_all('font'): counts.append(str.strip(font.text)) self.render('ShowAllScore.html', displayTag = displayTag, scoreData = scoreData, counts = counts)class SaveAllScore(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if not uid: self.redirect('/login') #获取成绩单的cookie #cjd = requests.post('http://211.82.47.2/reportFiles/student/cj_zwcjd_all.jsp', allow_redirects=False) #cjd.close() #cookie1 = cjd.headers['Set-Cookie'] #cookie = cookie1 + ';' + uid header = &#123; 'Accept':'*/*', 'Accept-Language': 'zh-CN', 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36', 'Host': '211.82.47.2', 'Cookie': uid &#125; cj = requests.get('http://211.82.47.2/reportFiles/student/cj_zwcjd_all.jsp', headers=header) cj.close() self.write(cj.text) class Showbxqcjcx(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if not uid: self.redirect('/login') head = &#123; 'Accept': 'image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, */*', 'Referer':'http://211.82.47.2/menu/menu.jsp', 'Accept-Language': 'zh-CN', 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36', 'Host': '211.82.47.2', 'Cookie': uid &#125; cur_score = requests.get('http://211.82.47.2/bxqcjcxAction.do',headers = head) cur_score.close() scoreSoup = BeautifulSoup(cur_score.text, 'html.parser') displayTag = [] #标题 for tag in scoreSoup.find_all('th' , class_='sortable'): displayTag.append(str.strip(tag.text)) scoreData = [] #成绩数据 count = 0 for score in scoreSoup.find_all('tr', class_='odd'): subject = [] for data in score.find_all('td'): subject.append(str.strip(data.text)) count = count + 1 scoreData.append(subject) self.render('Showbxqcjcx.html', displayTag = displayTag, scoreData = scoreData) class ShowSubjectScore(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if not uid: self.redirect('/login') num = self.get_argument('num') head = &#123; 'Accept': 'image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, */*', 'Referer':'http://211.82.47.2/menu/menu.jsp', 'Accept-Language': 'zh-CN', 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36', 'Host': '211.82.47.2', 'Cookie': uid &#125; cur_score = requests.get('http://211.82.47.2/bxqcjcxAction.do',headers = head) cur_score.close() scoreSoup = BeautifulSoup(cur_score.text, 'html.parser') displayTag = [] #标题 for tag in scoreSoup.find_all('th' , class_='sortable'): displayTag.append(str.strip(tag.text)) scoreData = [] #成绩数据 count = 0 for score in scoreSoup.find_all('tr', class_='odd'): subject = [] for data in score.find_all('td'): subject.append(str.strip(data.text)) count = count + 1 scoreData.append(subject) self.render('ShowSubjectScore.html', subject = scoreData[int(num)])class ShowTermScore(BaseHandler): @gen.coroutine def get(self): uid = self.current_user if not uid: self.redirect('/login') term = self.get_argument('term') head = &#123; 'Accept': 'image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, */*', 'Accept-Language': 'zh-CN', 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36', 'Host': '211.82.47.2', 'Cookie': uid &#125; all_score = requests.get('http://211.82.47.2/gradeLnAllAction.do?type=ln&amp;oper=qbinfo&amp;lnxndm=2016-2017学年秋(两学期)#2016-2017学年秋(两学期)', headers = head) all_score.close() scoreSoup = BeautifulSoup(all_score.text, 'html.parser') terms = [] #存放学期 for i in scoreSoup.find_all('a'): terms.append(i['name']) tables = scoreSoup.find_all('table', id='user') displayTags = [] #所有标题数据 scoreDatas = [] for table in tables: displayTag = [] #标题 for tag in table.find_all('th' , class_='sortable'): displayTag.append(str.strip(tag.text)) displayTags.append(displayTag) scoreData = [] #成绩数据 for score in table.find_all('tr', class_='odd'): subject = [] for data in score.find_all('td'): subject.append(str.strip(data.text)) scoreData.append(subject) scoreDatas.append(scoreData) counts = [] #总计 for count in scoreSoup.find_all('td', height = "21"): s = str.strip(count.text) string = [] string.append(s[0:13]) string.append(s[13:29]) string.append(s[29:44]) string.append(s[44:]) counts.append(string) self.render("ShowTermScore.html", displayTag = displayTags[int(term)], scoreData = scoreDatas[int(term)], term = terms[int(term)], count = counts[int(term)])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python学习笔记</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位运算的奇巧淫技]]></title>
    <url>%2F2018%2F12%2F31%2F%E4%BD%8D%E8%BF%90%E7%AE%97%E7%9A%84%E5%A5%87%E5%B7%A7%E6%B7%AB%E6%8A%80%2F</url>
    <content type="text"><![CDATA[位运算简介位运算简介：​ 程序中的所有数在计算机内存中都是以二进制的形式储存的。位运算就是直接对整数在内存中的二进制位进行操作。比如，and运算本来是一个逻辑运算符，但整数与整数之间也可以进行and运算。举个例子，6的二进制是110，11的二进制是1011，那么6 and 11的结果就是2，它是二进制对应位进行逻辑运算的结果（0表示False，1表示True，空位都当0处理）。 位运算的特点： 在处理整形数值时，可以直接对组成整形数值的各个位进行操作。这意味着可以使用屏蔽技术获得整个数中的各个位。 &amp;（与）、|（或）、^(异或)、~（非/取反） >&gt;和&lt;&lt;运算符将二进制位进行右移或者左移操作。 >&gt;&gt;运算符将用0填充高位；>&gt;运算符用符号位填充高位，没有\&lt;&lt;&lt;运算符。 对于int型，1&lt;&lt;35与1&lt;&lt;3是相同的，而左边的操作数是long型是需要对右侧的操作数作数模64。 与：相同为1，或：有一个为1结果为1，异或：相同为0，不同为1. 位运算的规则： 图：位运算的规则 异或的性质： 异或，可以理解为不进位的加法：1+1=0； 0+0=0；1+0=1 交换律：可任意交换运算因子的位置，结果不变。 结合律：即（a^b）^c == a^(b^c) 对于任何数x，都有x^x =0, x^0 = x， 同自己求异或为0，同0求异或为自己。 自反性：A^B^B = A^0=A,连续喝同一个因子做异或运算，最终结果为自己。 位运算的简单应用判断奇偶数：思路： 任何整数，如果是奇数，则转化为二进制数后，最后一位二进制位肯定为1，为偶数，则最后一位二进制位为0。利用这个性质，将任意整数x与1作与运算，如果结果为1，则x为奇数；结果为0，则x为0数。 示例代码：12345678910111213141516public class Case1_JudjeOddEven &#123; public static void main(String[] args) &#123; int a = 40; int b = 31; judjeOddEven(a); judjeOddEven(b); &#125; public static void judjeOddEven(int x) &#123; System.out.println( ((x&amp;1) == 0) ? (x + "是偶数！") : (x + "是奇数！") ); &#125;&#125;//-------------------------------------------------------// 运行结果：40是偶数！31是奇数！ 获取二进制位是1还是0（两种解决方法）：思路： 方案1：做与运算。例如：判断x的第五位二进制是1还是0，可以与1&lt;&lt;4做与运算，然后将结果&gt;&gt;4位，判断最终结果是1还是0。如果最终结果是0，则x的第五位为0，否则第五位的二进制位1。 方案2：做与运算。例如：判断x的第五位二进制是1还是0，可以将x&gt;&gt;4位，与1做与运算，判断最终结果是1还是0。如果最终结果是0，则x的第五位为0，否则第五位的二进制位1。 代码示例：123456789101112131415161718192021222324public class Case2_Judje0_1 &#123; public static void main(String[] args) &#123; judje0_1(10, 2); judje0_1(10, 3); judje0_1_2(10, 2); judje0_1_2(10, 3); &#125; /** * 判断整数x的第y位的二进制位是0还是1 * @param x 一个整数x * @param y 判断x的二进制的第几位 */ //方案1代码 public static void judje0_1(int x ,int y) &#123; System.out.println(x + "的第" + y + "位的二进制位为：" + ( ((x &amp; (1&lt;&lt;(y-1)))&gt;&gt;(y-1)) == 0 ? "0":"1")); &#125; //方案2代码 public static void judje0_1_2(int x ,int y) &#123; System.out.println(x + "的第" + y + "位的二进制位为：" + ( ((x&gt;&gt;(y-1)) &amp; 1) == 0 ? "0":"1")); &#125;&#125; 程序运行结果： 123410的第2位的二进制位为：110的第3位的二进制位为：010的第2位的二进制位为：110的第3位的二进制位为：0 交换两个整数变量的值：思路： 利用异或的性质实现。对于任何数x，都有x^x =0, x^0 = x， 同自己求异或为0，同0求异或为自己。 自反性：A^B^B = A^0=A,连续喝同一个因子做异或运算，最终结果为自己。如交换A、B的值，有： A = A ^ B B = A ^ B （B = A ^ B ^ B = A） A = A ^ B (A = A ^ A ^ B = B) 代码示例：1234567891011public class Case3_SwapValue &#123; public static void main(String[] args) &#123; int a = 3, b = 6; System.out.println("交换前：a=" + a + " b=" + b); a = a ^ b; b = a ^ b; a = a ^ b; System.out.println("交换后：a=" + a + " b=" + b); &#125;&#125; 运行结果： 12交换前：a=3 b=6交换后：a=6 b=3 不用判断语句，求整数的绝对值：思路： 利用位运算的移位，异或运算实现。 原理：将一个整型整数x，带符号右移31位，则结果要么是0，要么是-1。其中如果是0，则x为正数，为-1则x为负数。然后，将x与右移31位后的结果做异或运算，当与x^0是，结果还是x。 当x^-1时，结果为x取反，即x的反码，然后+1，即为x的绝对值。 代码示例：12 程序运行结果： 1231的绝对值是：31-21的绝对值是：21 位运算的例题题1_找出唯一成对的数：题目： ​ 1-1000这1000个数放在10001个元素的数组中，只有唯一的一个元素值重复，其他均只出现一次。每个数组元素只能访问一次，设计一个算法，将他找出来；不用辅助存储空间，能否设计一个算法实现？ 思路： 利用位运算异或的性质，A^A=0;A^0=A. 将1001个数一起做异或运算，会把相同的那组数去除。但是要找的数为相同的数，所以在和1-1000的每个数做异或，最后就能找到那个数。 代码实现：为了方便查看结果，测试用了1-10，有一个数重复。 12345678910111213141516public class Case5_唯一成对的数 &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5&#125;; int x = 0; //数组中每个数都互相进行异或运算。相同数会被消除 for(int i = 0; i &lt; arr.length; i++) &#123; x = x ^ arr[i]; &#125; //再将异或运算结果与1-10所有数进行异或，就会消除所有不同的数，最后剩下唯一一个数。 for(int i = 1; i &lt; arr.length; i++) &#123; x = x ^ i; &#125; System.out.println("数组中唯一重复的数是：" + x); &#125;&#125; 程序运算结果： 1数组中唯一重复的数是：5 题2_找出落单的那个数：题目： 一个数组里除了某个数字之外，其他的数字都出现了两次。请写程序找出这个只出现了一次的数字。 思路： 和上题思路相同。利用异或，相同的数异或，会消去。 示例代码：12345678910public class 找出落单的那个数 &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 7, 5, 3, 10, 6, 3, 6, 7, 8, 5, 10, 1&#125;; int x = 0; for(int i = 0; i &lt; arr.length; i++) &#123; x = x ^ arr[i]; &#125; System.out.println("落单的那个数是：" + x); &#125;&#125; 程序运行结果： 1落单的那个数是：8 题3_二进制中1的个数：题目： 请实现一个函数，输入一个整数，输出该数二进制表示中1的个数。 例：9的二进制表示为1001，有2位是1. 思路： 解题方式有三种方式：与上面判断某位是1还是0思想相同。 方案1：与上面判断某位是1还是0思想相同。第一种方案是：例如：判断x的第五位二进制是1还是0，可以与1&lt;&lt;4做与运算，然后将结果&gt;&gt;4位，判断最终结果是1还是0。如果最终结果是0，则x的第五位为0，否则第五位的二进制位1。然后循环判断每个二进制位。 方案2：做与运算。例如：判断x的第五位二进制是1还是0，可以将x&gt;&gt;4位，与1做与运算，判断最终结果是1还是0。如果最终结果是0，则x的第五位为0，否则第五位的二进制位1。 方案3：（x-1）&amp; x，利用该式可循环消去低位的1，循环了多少次，就有多少个1。原理： 12345678910111213141516&gt; 例如9：二进制位1001&gt; 1001 //x &gt; - 1 //x-1&gt; ---------&gt; 1000 //消去了低位的1&gt; &amp; 1001 //(x-1) &amp; x&gt; ---------&gt; 1000 //新的x&gt; - 1&gt; ---------&gt; 0111&gt; &amp; 1000 // (x-1) &amp; x &gt; ---------&gt; 0000 //消去了最后一个1. &gt; // 循环多少次则该数的二进制有多少个1&gt; 代码示例：12345678910111213141516171819202122232425262728293031323334public class 二进制中1的个数 &#123; public static void main(String[] args) &#123; int x = 2352; // 输出x的二进制位，作为验证。 System.out.println(Integer.toBinaryString(x)); // 方案1 int count = 0; //初始化，用来记录1的个数 for(int i = 0; i &lt; 32; i++) &#123; if(((x&amp;(1&lt;&lt;i))&gt;&gt;i) == 1) &#123; count++; &#125; &#125; System.out.println(count); // 方案2 count = 0; //初始化，用来记录1的个数 for(int i = 0; i &lt; 32; i++) &#123; if(((x&gt;&gt;i) &amp; 1) == 1) &#123; count++; &#125; &#125; System.out.println(count); // 方案3 count = 0; while(x != 0) &#123; x = ((x-1) &amp; x); count++; &#125; System.out.println(count); &#125;&#125; 程序运行结果： 1234100100110000444 题4_是不是2的整数次方：题目： 用一条语句判断一个整数是不是2的整数次方。 思路： 思路为上题的方案3. 代码示例：123456789101112131415public class 是不是2的整数次方 &#123; public static void main(String[] args) &#123; is2(1024); is2(1000); &#125; public static void is2(int x)&#123; if(((x-1) &amp; x) == 0) &#123; System.out.println(x + "是2的整数次方！"); &#125;else &#123; System.out.println(x + "不是2的整数次方！"); &#125; &#125;&#125; 程序运行结果： 121024是2的整数次方！1000不是2的整数次方！ 题5_将整数的奇偶位互换：题目： 将一个整数的二进制位上的1与0做交换。 思路： 利用位运算的异或运算和与运算。 12345678910111213141516&gt; //例如：求10,交换后的数。 10的二进制为：1010&gt; &gt; 1010&gt; &amp; 01010101 01010101 01010101 01010101&gt; ---------------------------------------&gt; x 0000 //保留奇数位上的数&gt; &gt; 1010&gt; &amp; 10101010 10101010 10101010 10101010&gt; ---------------------------------------&gt; y 1010 //保留偶数位上的数&gt; &gt; (x&lt;&lt;1) ^ (y&gt;&gt;1) = (0000&lt;&lt;1) ^ (1010&gt;&gt;1)&gt; = 0000 ^ 0101&gt; = 0101 //从而实现了，奇偶位互换&gt; 代码示例：1234567891011121314151617181920public class 将整数奇偶位互换 &#123; public static void main(String[] args) &#123; int n = 10; System.out.println(Integer.toBinaryString(n)); int a = swapOddEven(n); System.out.println("10的二进制位交换后变为" + a); System.out.println(Integer.toBinaryString(a)); &#125; public static int swapOddEven(int n) &#123; //消除奇数位，保留偶数位 //和01010101 01010101 01010101 01010101做运算 int x = n &amp; 0x55555555; //消除偶数位，保留奇数位 //和10101010 10101010 10101010 10101010做运算 int y = n &amp; 0xaaaaaaaa; return (x&lt;&lt;1)^(y&gt;&gt;1); &#125;&#125; 程序运行结果： 123101010的二进制位交换后变为5101 题6_0~1间浮点实数的二进制表示：题目： 给定一个介于0和1之间的实数，如（0.625），类型为double，打印它的二进制表示（0.101，因为小数点后的二进制分别表示为0.5 , 0.25, 0.125…). 如果该数字无法精确的用32位以内的二进制表示，则打印“ERROR”。 思路： 可以每次讲x * 2，然后去整数部分，如果整数部分为1，则在二进制表示在0. 后面加1，如果为0，则加0. 循环，直到x为0结束。 代码示例：12345678910111213141516171819202122232425public class 浮点实数的二进制表示 &#123; public static void main(String[] args) &#123; double x = 0.625; StringBuffer sb = new StringBuffer("0."); while(x &gt; 0) &#123; // 乘2: 挪整 double r = x * 2; //判断整数部分 if (r &gt;= 1) &#123; sb.append("1"); // 消除掉整数部分 x = r - 1; &#125;else&#123; sb.append("0"); x = r; &#125; if(sb.length() &gt; 34) &#123; System.out.println("ERROR"); return; &#125; &#125; System.out.println(sb.toString()); &#125;&#125; 程序运行结果： 10.101 题7_出现k次与出现1次：题目： 数组中只有一个数出现了1次，其他的数都出现了K次，请输出只出现了一次的数。 思路： 2个相同的2进制数做不进位加法，结果为0. 10个相同的10进制数做不进位加法，结果为0. k个相同的k进制数做不进位加法，结果为0. 解题方式：做k进制的不进位加。 代码示例：1234567891011121314151617181920212223242526272829303132333435public class 出现K次 &#123; public static void main(String[] args) &#123; //假设K=3时的解题方法 int[] arr = &#123;2, 2, 2, 9, 7, 7, 7, 3, 3, 3, 6, 6, 6, 0, 0, 0&#125;; int len = arr.length; // 存取每个数的三进制 char[][] kRadix = new char[len][]; int k = 3; //转化k进制字符数组 //记录转化三进制后最长的长度 int maxlen = 0; //对于每个数字 for(int i = 0; i &lt; len; i++) &#123; kRadix[i] = new StringBuffer(Integer.toString(arr[i], k)).reverse().toString().toCharArray(); if(kRadix[i].length &gt; maxlen) maxlen = kRadix[i].length; &#125; int[] resArr = new int[maxlen]; for(int i = 0; i &lt; len; i++) &#123; // 不进位加法 for(int j = 0; j &lt; maxlen; j++) &#123; if(j &gt;= kRadix[i].length) resArr[j] += 0; else resArr[j] += (kRadix[i][j] - '0'); &#125; &#125; int res = 0; for(int i = 0; i &lt; maxlen; i++) &#123; res += (resArr[i] % k) * (int)(Math.pow(k, i)); &#125; System.out.println(res); &#125;&#125; 程序运行结果： 19]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP服务器搭建和配置]]></title>
    <url>%2F2018%2F10%2F25%2FFTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E5%92%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[FTP服务简介FTP概述：​ FTP是文件传输协议（File Transfer Protocal）的简写，主要完成与远程计算机的文件传输。 FTP采用客户/服务器模式，客户机与服务器之间利用TCP建立连接，客户可以从服务器上下载文件，也可以把本地文件上传至服务器。 FTP服务器有匿名的和授权的两种。匿名的FTP服务器向公众开放，用户可以用“ftp”或“anonymous”为帐号，用电子邮箱地址为密码登录服务器；授权的FTP服务器必须用授权的账户名和密码才能登录服务器。通常匿名的用户权限较低，只能下载文件，不能上传文件。 FTP工作原理：FTP是一个CS架构的软件，一边是客户端，一边是服务端。客户端有一个用户界面，可以是LeapFTP这样的图形界面，也可以是命令行形式的文本文件方式来使用。一旦用户有一个操作，就会通过用户协议解释器转换成对应的FTP命令，通过控制连接发送给服务器端，控制连接的端口号是21，首先是客户端去连接服务器端的21端口，建立了控制连接，控制连接主要是用于FTP命令以及FTP命令的响应。一旦服务器端收到一个命令以后就要进行相应的工作，比如收到了用户名和密码，就要进行相应的验证。验证成功之后就给客户端响应，验证失败的话就给一个失败的响应。FTP传送命令的时候，主要是为了文件传输，也就是会涉及到文件传输的命令，这些命令也是通过控制连接来发送的，一旦服务器端解析到一个文件传输的命令之后，就要和客户端建立一个新的连接通道，这个通道称为数据连接通道，用于传输文件。这个连接的建立，可以由客户端主动发起，也可以由服务器端发起。这就对应到了两种不同的工作模式。如果是客户端上传文件的话，就会读取本地文件系统中的文件，传输给服务器端，服务端就将它写到服务器端对应的文件系统。如果是下载的话，服务器端读取文件系统中的数据，写入到数据连接，通过数据连接发送给客户端，客户端就读取数据连接中的数据，写入到本地的文件系统。这就是FTP工作的基本原理。 数据连接并不是永久性存在的，一旦传输完毕就会将这个连接关闭掉，但是控制连接不会关闭，除非将客户端关闭了，控制连接才会随之关闭。控制连接是随客户端一起存在的，而数据连接是短暂存在的，只要文件传输或者列表传输完成，数据连接就关闭了。 FTP的两种工作模式：主要是针对数据连接而言的，控制连接的建立总是由客户端向服务器端发起。而数据连接通道的建立则不同，既可以是服务器端向客户端发起连接建立数据连接通道，这种模式称为主动模式。也可以是客户端向服务器端发起连接建立数据连接通道，这种模式称为被动模式。 主动模式：FTP服务器主动向客户端发起连接请求。 被动模式：FTP服务器等待客户端发起连接请求（FTP的默认工作模式）。 VSFTP简介：vsftpd（very secure ftp daemon，非常安全的FTP守护进程）是一款运行在Linux操作系统上的FTP服务程序，不仅完全开源而且免费，此外，还具有很高的安全性、传输速度，以及支持虚拟用户验证等其他FTP服务程序不具备的特点。 特点： vsftp一般以普通用户运行，降低了进程的权限，提高了安全性 任何需要执行较高权限的指令都需要上层程序的许可 ftp的命令都被整合到了vsftp中，不需要系统额外提供命令 用于chroot功能，可以改变用户的根目录，限制用户只能在自己的家目录 vsftpd 是一个基于GPL发布的FTP服务器软件。其中的vs是“ Very Secure”的缩写，由此名称缩写可以看出，本服务器的初衷就是服务的安全性。 vsftpd是RedHat Linux默认使用的ftp服务端软件。 vsftpd不再依赖于xinetd服务 vsftpd可同时允许匿名（ anonymous ）与本地用户(local)访问,还可以支持虚拟用户。 VSFTP的传输模式： 文本模式：ASCII模式，以文本序列传输数据。 二进制模式：Binary模式，以二进制序列传输数据。 FTP用户类型： 匿名用户：anonymous或ftp 本地用户：账号名称、密码等信息保存早passwd/shadow文件中。 虚拟用户：使用独立的账号和密码数据文件。 Linux下FTP服务器的搭建vsftp主要配置文件的介绍： 配置文件作用 配置文件路径 vsftpd的可执行文件（主程序） /usr/sbin/vsftpd vsftpd启动脚本 /etc/rc.d/init.d/vsftpd vsftpd主配置文件 /etc/vsftpd/vsftpd.conf vsftpd的PAM认证文件 /etc/pam.d/vsftpd 禁止使用vsftpd的用户列表文件 /etc/vsftpd/ftpusers 禁止或允许使用vsftpd的用户列表文件 /etc/vsftpd/user_list 匿名用户主目录 /var/ftp vsftp的安装步骤：第一步：安装vsftp服务 12345[root@localhost ~]# yum -y install vsftpd[root@localhost ~]# systemctl restart vsftpd[root@localhost ~]# systemctl enable vsftpd[root@localhost ~]# firewall-cmd --permanent --add-service=ftp[root@localhost ~]# firewall-cmd --reload 第二步：配置文件 （1）常用的全局配置 listen_address=192.168.245.128 设置监听的IP地址 listen=YES 是否以独立运行的方式监听服务 listen_port=21 设置监听FTP服务的端口号 write_enable=YES 是否启用写入权限 download_enable＝YES 是否允许下载文件 max_clients=0 限制并发客户端连接数 max_per_ip=0 限制同一IP地址的并发连接数 pasv_enable=yes 设置最小的被动端口号 pasv_min_port=9981 设置最小的被动端口号 pasv_max_port=9981 设置最大的被动端口号 dirmessage_enable=yes 是否显示目录说明文件 xferlog_enable=yes 是否记录ftp传输过程 xferlog_file=/var/log/vsftpd.log 日志的路径和名字 xferlog_std_format=yes 是否使用标准的ftp xferlog chown_username=username 是否改变上传文件的属主，如果是则需要输入一个系统用户名 idle_session_timeout=600 设置默认不活跃session时间 date_connection_timeout=120 设置数据传输超时时间 （2）本地用户访问限制： userlist_enable=YES 是否启用user_list列表文件 userlist_deny=YES 是否禁用user_list中的用户 （3）本地用户权限控制： local_enable=YES 是否启用本地系统用户 local_umask=022 本地用户所上传文件的权限掩码 local_root=/var/ftp 设置本地用户的FTP根目录 chroot_local_user=YES 是否将用户禁锢在主目录 local_max_rate=0 限制最大传输速率（字节/秒） chroot_list_enable=YES 配合下面的文件使用 chroot_list_file=/etc/vsftpd/chroot_list 配合使用，列表中的用户将被禁锢在目录中 （4）匿名权限控制： anonymous_enable=YES 启用匿名访问 anon_umask=022 匿名用户所上传文件的权限掩码 anon_root=/var/ftp 匿名用户的FTP根目录 anon_word_readable_only=YES 允许匿名下载 anon_upload_enable=YES 允许上传文件anon_mkdir_write_enable=YES：允许创建目录 anon_other_write_enable=YES 开放其他写入权 anon_max_rate=0 限制最大传输速率（字节/秒） 第三步：安装要求更改配置后，重启服务即可。 FTP常用命令介绍： ftp IP地址 /域名 ：登录到指定FTP服务器。 dir ：显示目录和文件列表 ls：显示简易的文件列表 cd ：进入指定的目录。 type : 查看当前的传输方式 ascii : 设定传输方式为ASCII码方式。 binary ： 设定传承方式为二进制方式。 get ： 下载指定文件。 mget ： 下载多个文件。支持通配符 put：上传指定文件。 close、quit、bye：结束ftp会话。 pwd：查看当前工作目录。 rename oldname newname : 重命名文件。 delete filename：删除文件。 配置示例1：配置匿名访问在vsftpd服务程序中，匿名开放模式是最不安全的一种认证模式。任何人都可以无需密码验证而直接登录到FTP服务器。这种模式一般用来访问不重要的公开文件（在生产环境中尽量不要存放重要文件）。 vsftpd服务程序默认开启了匿名开放模式，需要做的就是开放匿名用户的上传、下载文件的权限，以及让匿名用户创建、删除、更名文件的权限。 图：匿名用户配置 12 注意：在开启匿名用户登录后，必须要修改ftp根目录的所属身份。因为默认是root用户，只用root用户具有写入权限。 chown -Rf ftp /var/ftp/pub 执行该命令后，即可上传文件，创建目录等。 在做本实验时，selinux都是默认关闭的。如果还有问题，关闭selinux或者更改selinux的权限即可。 setsebool -P ftpd_full_access=on 配置示例2：本地用户模式相较于匿名开放模式，本地用户模式要更安全，而且配置起来也很简单。如果大家之前用的是匿名开放模式，现在就可以将它关了，然后开启本地用户模式。 参数 作用 anonymous_enable=NO 禁止匿名访问模式 local_enable=YES 允许本地用户模式 write_enable=YES 设置可写权限 local_umask=022 本地用户模式创建文件的umask值 userlist_deny=YES 启用“禁止用户名单”，名单文件为ftpusers和user_list userlist_enable=YES 开启用户作用名单文件功能 12345678910111213141516171819202122232425262728#按如下操作修改配置文件即可，修改后重启服务。#在客户端测试[root@localhost ~]# ftp 192.168.245.128Connected to 192.168.245.128 (192.168.245.128).220 (vsFTPd 3.0.2)Name (192.168.245.128:root): cao331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls227 Entering Passive Mode (192,168,245,128,67,44).150 Here comes the directory listing.drwxr-xr-x 2 1000 1000 6 Oct 25 12:35 dirdrwxr-xr-x 2 1000 1000 6 Oct 01 11:14 下载drwxr-xr-x 2 1000 1000 6 Oct 01 11:14 公共drwxr-xr-x 2 1000 1000 6 Oct 01 11:14 图片drwxr-xr-x 2 1000 1000 6 Oct 01 11:14 文档drwxr-xr-x 2 1000 1000 6 Oct 01 11:14 桌面drwxr-xr-x 2 1000 1000 6 Oct 01 11:14 模板drwxr-xr-x 2 1000 1000 6 Oct 01 11:14 视频drwxr-xr-x 2 1000 1000 6 Oct 01 11:14 音乐226 Directory send OK.ftp&gt; pwd257 "/home/cao"ftp&gt; 注意： 在登录时，默认不能使用root用户，因为在vsftp中，默认有两个文件中的用户禁止登录。如果想使用root用户登录，删除两文件中的root即可。 采用本地账户登录后，默认访问的目录是该用户的家目录。而且该目录的默认所有者，所属组都是该用户自己，所以不存在权限问题。当有权限问题时，检查selinux设置即可。 1234567891011121314151617181920212223242526272829303132333435363738[root@localhost ~]# cat /etc/vsftpd/user_list # vsftpd userlist# If userlist_deny=NO, only allow users in this file# If userlist_deny=YES (default), never allow users in this file, and# do not even prompt for a password.# Note that the default vsftpd pam config also checks /etc/vsftpd/ftpusers# for users that are denied.rootbindaemonadmlpsyncshutdownhaltmailnewsuucpoperatorgamesnobody[root@localhost ~]# cat /etc/vsftpd/ftpusers # Users that are not allowed to login via ftprootbindaemonadmlpsyncshutdownhaltmailnewsuucpoperatorgamesnobody[root@localhost ~]# 在window电脑上访问ftp服务器时，都会弹出要求输入账户和密码的输入框。通过认证即可访问ftp的资源。 配置示例3：虚拟用户模式虚拟模式是三种模式中，最安全的模式。 第一步：创建用于进行FTP认证的用户数据库文件，其中奇数行为账户名，偶数行为密码。例如，我们分别创建出zhangsan和lisi两个用户，密码均为redhat。 12345678910[root@localhost vsftpd]# vim vuser.listzhangsanredhat123lisiredhat123[root@localhost ~]# db_load -T -t hash -f /etc/vsftpd/vuser.list vuser.db[root@localhost ~]# file /etc/vsftpd/vuser.dbvuser.db: Berkeley DB (Hash, version 9, native byte-order)[root@localhost ~]# chmod 600 /etc/vsftpd/vuser.db[root@localhost ~]# rm -f /etc/vsftpd/vuser.list 第二步：创建vsftpd服务程序用于存储文件的根目录以及虚拟用户映射的系统本地用户。FTP服务用于存储文件的根目录指的是，当虚拟用户登录后所访问的默认位置。 由于Linux系统中的每一个文件都有所有者、所属组属性，例如使用虚拟账户“张三”新建了一个文件，但是系统中找不到账户“张三”，就会导致这个文件的权限出现错误。为此，需要再创建一个可以映射到虚拟用户的系统本地用户。简单来说，就是让虚拟用户默认登录到与之有映射关系的这个系统本地用户的家目录中，虚拟用户创建的文件的属性也都归属于这个系统本地用户，从而避免Linux系统无法处理虚拟用户所创建文件的属性权限。 为了方便管理FTP服务器上的数据，可以把这个系统本地用户的家目录设置为/var目录（该目录用来存放经常发生改变的数据）。并且为了安全起见，我们将这个系统本地用户设置为不允许登录FTP服务器，这不会影响虚拟用户登录，而且还可以避免黑客通过这个系统本地用户进行登录。 123456[root@localhost ~]# useradd -d /var/ftproot -s /sbin/nologin virtual[root@localhost ~]# ls -ld /var/ftproot/drwx------ 3 virtual virtual 78 10月 25 20:52 /var/ftproot/[root@localhost ~]# chmod -Rf 755 /var/ftpftp/ ftproot/ [root@localhost ~]# chmod -Rf 755 /var/ftproot/ 第三步：建立用于支持虚拟用户的PAM文件。 PAM（可插拔认证模块）是一种认证机制，通过一些动态链接库和统一的API把系统提供的服务与认证方式分开，使得系统管理员可以根据需求灵活调整服务程序的不同认证方式。 通俗来讲，PAM是一组安全机制的模块，系统管理员可以用来轻易地调整服务程序的认证方式，而不必对应用程序进行任何修改。PAM采取了分层设计（应用程序层、应用接口层、鉴别模块层）的思想，其结构如图下图所示： 图：PAM的分层设计结构 新建一个用于虚拟用户认证的PAM文件vsftpd.vu，其中PAM文件内的“db=”参数为使用db_load命令生成的账户密码数据库文件的路径，但不用写数据库文件的后缀： 123[root@localhost ~]# vim /etc/pam.d/vsftpd.vuauth required pam_userdb.so db=/etc/vsftpd/vuseraccount required pam_userdb.so db=/etc/vsftpd/vuser 第四步：**在vsftpd服务程序的主配置文件中通过pam_service_name参数将PAM认证文件的名称修改为vsftpd.vu，**PAM作为应用程序层与鉴别模块层的连接纽带，可以让应用程序根据需求灵活地在自身插入所需的鉴别功能模块。当应用程序需要PAM认证时，则需要在应用程序中定义负责认证的PAM配置文件，实现所需的认证功能。 例如，在vsftpd服务程序的主配置文件中默认就带有参数pam_service_name=vsftpd，表示登录FTP服务器时是根据/etc/pam.d/vsftpd文件进行安全认证的。现在我们要做的就是把vsftpd主配置文件中原有的PAM认证文件vsftpd修改为新建的vsftpd.vu文件即可。 利用PAM文件进行认证时使用的参数以及作用： 参数 作用 anonymous_enable=NO 禁止匿名开放模式 local_enable=YES 允许本地用户模式 guest_enable=YES 开启虚拟用户模式 guest_username=virtual 指定虚拟用户账户 pam_service_name=vsftpd.vu 指定PAM文件 allow_writeable_chroot=YES 允许对禁锢的FTP根目录执行写入操作，而且不拒绝用户的登录请求 第五步：为虚拟用户设置不同的权限。 虽然账户zhangsan和lisi都是用于vsftpd服务程序认证的虚拟账户，但是我们依然想对这两人进行区别对待。比如，允许张三上传、创建、修改、查看、删除文件，只允许李四查看文件。这可以通过vsftpd服务程序来实现。只需新建一个目录，在里面分别创建两个以zhangsan和lisi命名的文件，其中在名为zhangsan的文件中写入允许的相关权限（使用匿名用户的参数）： 1234567[root@localhost ~]# mkdir /etc/vsftpd/vusers_dir/[root@localhost ~]# cd /etc/vsftpd/vusers_dir/[root@localhost vusers_dir]# touch lisi[root@localhost vusers_dir]# vim zhangsananon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES 然后再次修改vsftpd主配置文件，通过添加user_config_dir参数来定义这两个虚拟用户不同权限的配置文件所存放的路径。 添加：user_config_dir=/etc/vsftpd/vusers_dir 在windows上测试： 输入指定ftp服务器后，会要求输入账号密码，这儿输如的张三，密码redhat123.可成功连接。 zhangsan用户具有读写权限，所以可以新建文件等。但是lisi没有权限。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ISCSI服务器搭建与配置]]></title>
    <url>%2F2018%2F10%2F23%2FISCSI%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[ISCSI服务简介ISCSI简介：iSCSI( Internet Small Computer System Interface 互联网小型计算机系统接口) 技术是一种新存储技术，该技术是将现有的SCSI接口与以太网技术相结合，使服务器可与使用IP网络的存储装置互相交换资料。 iscsi 结构基于客户/服务器模型，其主要功能是在TCP/IP网络上的主机系统（启动器initlator）和存储设备（目标 target） 之间进行大量的数据封装和可靠传输过程，此外，iscsi 提供了在IP网络封装SCSI命令，切运行在TCP上。 实际生产环境中，一般都是使用集群搭建服务器，如果两台或多台服务器都是使用独立磁盘，使用ISCSI 技术，实现远程磁盘的使用，集群的服务器都挂在同一个远程存储设备到本地实现数据读写，这样也就减少了一个同步数据的任务，大大减轻了服务器的资源消耗 作为服务器的系统通常需要存储设备的，而存储设备除了可以使用系统內间的磁盘之外，如果內间的磁盘容量不够大，而且没有额外的磁盘插槽（SATA 或IDE）可用时，常见的解决方案是增加NAS（网络附加存储服务器）或外接式存储设备高档一点的，可能会用到SAN（存储局域网络）。 NAS与SAN简介：NAS （network attached storage，网络附加存储服务器）NAS是一部客制化好的主机，只要将NAS链接上网络，那么网络上面的其他主机就能够存取NSA上头的数据了，简单的说，NAS 就是一部file server，NAS 由于是接在网络上面，所以如果网络上有某个用户大量存取NAS上头的数据时，很容易造成网络停顿问题，此外BAS 也通常支持TCP/IP，并会提供NFS,SAMA,FTP等常见的通讯协议来提供客户端取得文件系统 SAN （storage area networks，存储局域网络）NAS 就是一部可以提供大量容量文件系统的主机，我们知道单个主机能够提供的插槽时有限的，所以不能无限制的安插磁盘在同一部实体主机上，因此便有了SANSAN 视为一个外接式的存储设备，可以透过某些特殊的接口或信道来提供局域网络内的所有机器进行磁盘存取， SAN是提供磁盘给主机用，而不是像NAS 提供的是[网络协议的文件系统（NFS SMB）]，因此挂载SAN的主机会多出一个大磁盘，并可针对SAN提供的磁盘进行分割与格式化等动作，而NAS则不能，另外NAS可以透过网络使用SAN， NAS和SAN的更多介绍可以参考： NAS技术及应用： SAN技术及应用： ISCSI历史：早期的企业使用的服务器若有大容量的磁盘的需求时，通常是透过SCSI来串接SCSI磁盘，因此服务器上必须要加装SCSI适配卡，而且这个SCSI是专属于该服务器的，后来这个外接式的SCSI设备被SAN的架构取代，SAN的一个缺点是要使用光纤信道，而光纤信道贵，很多中小型企业不能普及。 后期IP封包为基础的LAN技术普及，以太网速度加快，所以就有厂商将SAN的链接方式改为利用IP技术来处理，人后再透过一些标准指定，得到了ISCSI。ISCSI 主要是透过TCP/IP的技术，将存储设备端透过ISCSI target (ISCSI目标）功能，做成可以提供磁盘的服务器端，再透过ISCSI initator（ISCSI初始化用户）功能，做成能够挂载使用ISCSI target的客户端，如此便能透过ISCSI协议来进行磁盘的应用了。 ISCSI 这个架构主要将存储装置与使用的主机分别为两部分，分别是： ISCSI target ：就是存储设备端，存放磁盘或RAID的设备，目前也能够将Linux主机仿真成ISCSI target了，目的在提供其他主机使用的磁盘。 ISCSI inITiator： 就是能够使用target的客户端，通常是服务器，只有装有iscsi initiator的相关功能后才能使用ISCSI target 提供的磁盘。 服务器取得磁盘或者文件系统的方式 直接存取：在本机上的磁盘，就是直接存取设备 透过存储局域网络（SAN），来自区网内的其他设备提供的磁盘。 网络文件系统NAS（：来自NAS提供的文件系统）只能立即使用，不能进行格式化。 Linux下ISCSI服务搭建简介：iSCSI技术在工作形式上分为服务端（target）与客户端（initiator）。iSCSI服务端即用于存放硬盘存储资源的服务器，它作为前面创建的RAID磁盘阵列的存储端，能够为用户提供可用的存储资源。iSCSI客户端则是用户使用的软件，用于访问远程服务端的存储资源。 iscsi server被称为target server，模拟scsi设备，后端存储设备可以使用文件/LVM/磁盘/RAID等不同类型的设备；启动设备（initiator）：发起I/O请求的设备，需要提供iscsi服务，比如PC机安装iscsi-initiator-utils软件实现，或者通过网卡自带的PXE启动。esp+ip+scsi iscsi再传输数据的时候考虑了安全性，可以通过IPSEC 对流量加密，并且iscsi提供CHAP认证机制以及ACL访问控制，但是在访问iscsi-target的时候需要IQN（iscsi完全名称，区分唯一的initiator和target设备），格式iqn.年月.域名后缀(反着写)：[target服务器的名称或IP地址] iscsi使用TCP端口3260提供服务 ISCSI服务端配置：第一步：安装服务端程序target，添加要一块磁盘分区。 12345678910111213141516171819202122232425262728293031323334[root@localhost ~]# yum -y install targetd targetcli[root@localhost ~]# systemctl restart targetd[root@localhost ~]# systemctl enable targetd Created symlink from /etc/systemd/system/multi-user.target.wants/targetd.service to /usr/lib/systemd/system/targetd.service.[root@localhost ~]# fdisk /dev/sdb欢迎使用 fdisk (util-linux 2.23.2)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。命令(输入 m 获取帮助)：nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): Using default response p分区号 (1-4，默认 1)：起始 扇区 (2048-20971519，默认为 2048)：将使用默认值 2048Last 扇区, +扇区 or +size&#123;K,M,G&#125; (2048-20971519，默认为 20971519)：+2G分区 1 已设置为 Linux 类型，大小设为 2 GiB命令(输入 m 获取帮助)：wThe partition table has been altered!Calling ioctl() to re-read partition table.WARNING: Re-reading the partition table failed with error 16: 设备或资源忙.The kernel still uses the old table. The new table will be used atthe next reboot or after you run partprobe(8) or kpartx(8)正在同步磁盘。[root@localhost ~]# partprobe 第二步：配置iSCSI服务端共享资源 targetcli是用于管理iSCSI服务端存储资源的专用配置命令，它能够提供类似于fdisk命令的交互式配置功能，将iSCSI共享资源的配置内容抽象成“目录”的形式，我们只需将各类配置信息填入到相应的“目录”中即可。这里的难点主要在于认识每个“参数目录”的作用。当把配置参数正确地填写到“目录”中后，iSCSI服务端也可以提供共享资源服务了。 在执行targetcli命令后就能看到交互式的配置界面了。在该界面中可以使用很多Linux命令，比如利用ls查看目录参数的结构，使用cd切换到不同的目录中。/backstores/block是iSCSI服务端配置共享设备的位置。我们需要把刚刚创建的磁盘分区文件加入到配置共享设备的“资源池”中，并将该文件重新命名为block1，这样用户就不会知道是由服务器中的哪块硬盘来提供共享存储资源，而只会看到一个名为block1的存储设备。 123456789101112131415161718[root@localhost ~]# targetcli targetcli shell version 2.1.fb41Copyright 2011-2013 by Datera, Inc and others.For help on commands, type 'help'./&gt; /&gt; lso- / ...................................................... [...] o- backstores ........................................... [...] | o- block ............................... [Storage Objects: 0] | o- fileio .............................. [Storage Objects: 0] | o- pscsi ............................... [Storage Objects: 0] | o- ramdisk ............................. [Storage Objects: 0] o- iscsi ......................................... [Targets: 0] o- loopback ...................................... [Targets: 0]/&gt; /&gt; cd backstores/block #创建一个名为block1的存储块/backstores/block&gt; create name=block1 dev=/dev/sdb1 Created block storage object block1 using /dev/sdb1. 第三步：创建iSCSI target名称及配置共享资源。 iSCSI target名称是由系统自动生成的，这是一串用于描述共享资源的唯一字符串。稍后用户在扫描iSCSI服务端时即可看到这个字符串，因此我们不需要记住它。系统在生成这个target名称后，还会在/iscsi参数目录中创建一个与其字符串同名的新“目录”用来存放共享资源。我们需要把前面加入到iSCSI共享资源池中的硬盘设备添加到这个新目录中，这样用户在登录iSCSI服务端后，即可默认使用这硬盘设备提供的共享存储资源了。 12345678910111213141516171819/&gt; cd iscsi /iscsi&gt; lso- iscsi ........................................... [Targets: 0]/iscsi&gt; create wwn=iqn.2018-10.com.example:serverCreated target iqn.2018-10.com.example:server.Created TPG 1.Global pref auto_add_default_portal=trueCreated default portal listening on all IPs (0.0.0.0), port 3260./iscsi&gt; cd iqn.2018-10.com.example:server//iscsi/iqn.20...xample:server&gt; lso- iqn.2018-10.com.example:server ..................... [TPGs: 1] o- tpg1 ................................ [no-gen-acls, no-auth] o- acls ........................................... [ACLs: 0] o- luns ........................................... [LUNs: 0] o- portals ..................................... [Portals: 1] o- 0.0.0.0:3260 ...................................... [OK]&gt;/iscsi/iqn.20...ver/tpg1/luns&gt; create /backstores/block/block1 Created LUN 0.#创建需要共享的设备 第四步：设置访问控制列表（ACL）。 iSCSI协议是通过客户端名称进行验证的，也就是说，用户在访问存储共享资源时不需要输入密码，只要iSCSI客户端的名称与服务端中设置的访问控制列表中某一名称条目一致即可，因此需要在iSCSI服务端的配置文件中写入一串能够验证用户信息的名称。acls参数目录用于存放能够访问iSCSI服务端共享存储资源的客户端名称。推荐在刚刚系统生成的iSCSI target后面追加上类似于:client的参数，这样既能保证客户端的名称具有唯一性，又非常便于管理和阅读。 12345/iscsi/iqn.20...ver/tpg1/luns&gt; cd ../iscsi/iqn.20...e:server/tpg1&gt; cd acls /iscsi/iqn.20...ver/tpg1/acls&gt; create iqn.2018-10.com.example:clientCreated Node ACL for iqn.2018-10.com.example:clientCreated mapped LUN 0. 第五步：设置iSCSI服务端的监听IP地址和端口号。 位于生产环境中的服务器上可能有多块网卡，那么到底是由哪个网卡或IP地址对外提供共享存储资源呢？这就需要我们在配置文件中手动定义iSCSI服务端的信息，即在portals参数目录中写上服务器的IP地址。接下来将由系统自动开启服务器192.168.245.128的3260端口将向外提供iSCSI共享存储资源服务： 12345/iscsi/iqn.20...d80/tpg1/acls&gt; cd ../iscsi/iqn.20...c356ad80/tpg1&gt; cd portals /iscsi/iqn.20.../tpg1/portals&gt; create 192.168.245.128 ip_port=3260Using default IP port 3260Created network portal 192.168.245.128:3260. 第六步：配置妥当后检查配置信息，重启iSCSI服务端程序并配置防火墙策略。 在参数文件配置妥当后，可以浏览刚刚配置的信息，确保与下面的信息基本一致。在确认信息无误后输入exit命令来退出配置。注意，千万不要习惯性地按Ctrl + C组合键结束进程，这样不会保存配置文件，我们的工作也就白费了。最后重启iSCSI服务端程序，再设置firewalld防火墙策略，使其放行3260/tcp端口号的流量。 图：target服务端配置 12345[root@localhost ~]# systemctl restart targetd[root@localhost ~]# firewall-cmd --permanent --add-port=3260/tcpsuccess[root@localhost ~]# firewall-cmd --reloadsuccess 配置Linux客户端：在RHEL 7系统中，已经默认安装了iSCSI客户端服务程序initiator。如果您的系统没有安装的话，可以使用Yum软件仓库手动安装。 1[root@localhost ~]# yum -y install iscsi-initiator-utils.i686 iSCSI协议是通过客户端的名称来进行验证，而该名称也是iSCSI客户端的唯一标识，而且必须与服务端配置文件中访问控制列表中的信息一致，否则客户端在尝试访问存储共享设备时，系统会弹出验证失败的保存信息。 下面我们编辑iSCSI客户端中的initiator名称文件，把服务端的访问控制列表名称填写进来，然后重启客户端iscsid服务程序并将其加入到开机启动项中： 123456[root@localhost ~]# vim /etc/iscsi/initiatorname.iscsi InitiatorName=iqn.2018-10.com.example:client[root@localhost ~]# systemctl restart iscsidWarning: iscsid.service changed on disk. Run 'systemctl daemon-reload' to reload units.[root@localhost ~]# systemctl enable iscsidCreated symlink from /etc/systemd/system/multi-user.target.wants/iscsid.service to /usr/lib/systemd/system/iscsid.service. iscsiadm是用于管理、查询、插入、更新或删除iSCSI数据库配置文件的命令行工具，用户需要先使用这个工具扫描发现远程iSCSI服务端，然后查看找到的服务端上有哪些可用的共享存储资源。其中，-m discovery参数的目的是扫描并发现可用的存储资源，-t st参数为执行扫描操作的类型，-p 192.168.245.128参数为iSCSI服务端的IP地址.可通过 man iscsiadm | grep \\-mode 来查看帮助。 1234567891011121314[root@localhost ~]# man iscsiadm | grep \\-mode -m, --mode op iscsiadm --mode discoverydb --type sendtargets --portal 192.168.1.10 --discover iscsiadm --mode node --targetname iqn.2001-05.com.doe:test --portal 192.168.1.1:3260 --login iscsiadm --mode node --targetname iqn.2001-05.com.doe:test --portal 192.168.1.1:3260 --logout iscsiadm --mode node iscsiadm --mode node --targetname iqn.2001-05.com.doe:test --portal 192.168.1.1:3260[root@localhost ~]# iscsiadm --mode discoverydb --type sendtargets --portal 192.168.245.128 --discover#通过该命令可发现指定IP地址的iSCSI服务192.168.245.128:3260,1 iqn.2018-10.com.example:server [root@localhost ~]# iscsiadm --mode node --targetname iqn.2018-10.com.example:server --portal 192.168.245.128:3260 --login #使用该命令进行登录Logging in to [iface: default, target: iqn.2018-10.com.example:server, portal: 192.168.245.128,3260] (multiple)Login to [iface: default, target: iqn.2018-10.com.example:server, portal: 192.168.245.128,3260] successful. 登录成功后，会发现在该客户端下多出一个/dev/sdb的设备文件。通过格式化分区挂载即可使用该硬盘。 12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost ~]# file /dev/sdb/dev/sdb: block special[root@localhost ~]# mkfs.ext4 /dev/sdbmke2fs 1.42.9 (28-Dec-2013)/dev/sdb is entire device, not just one partition!Proceed anyway? (y,n) yFilesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=1024 blocks196608 inodes, 786432 blocks39321 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=80530636824 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912Allocating group tables: done Writing inode tables: done Creating journal (16384 blocks): doneWriting superblocks and filesystem accounting information: done [root@localhost ~]# mkdir /mnt/iscsi[root@localhost ~]# mount /dev/sdb /mnt/iscsi/[root@localhost ~]# df -ThFilesystem Type Size Used Avail Use% Mounted on/dev/mapper/rhel-root xfs 17G 3.2G 14G 19% /devtmpfs devtmpfs 1.4G 0 1.4G 0% /devtmpfs tmpfs 1.4G 88K 1.4G 1% /dev/shmtmpfs tmpfs 1.4G 9.1M 1.4G 1% /runtmpfs tmpfs 1.4G 0 1.4G 0% /sys/fs/cgroup/dev/sr0 iso9660 3.6G 3.6G 0 100% /mnt/cdrom/dev/sda1 xfs 1014M 173M 842M 18% /boottmpfs tmpfs 280M 12K 280M 1% /run/user/0/dev/sdb ext4 2.9G 9.0M 2.8G 1% /mnt/iscsi[root@localhost ~]# 注意： 由于udev服务是按照系统识别硬盘设备的顺序来命名硬盘设备的，当客户端主机同时使用多个远程存储资源时，如果下一次识别远程设备的顺序发生了变化，则客户端挂载目录中的文件也将随之混乱。为了防止发生这样的问题，我们应该在/etc/fstab配置文件中使用设备的UUID唯一标识符进行挂载，这样，不论远程设备资源的识别顺序再怎么变化，系统也能正确找到设备所对应的目录。 blkid命令用于查看设备的名称、文件系统及UUID 由于/dev/sdb是一块网络存储设备，而iSCSI协议是基于TCP/IP网络传输数据的，因此必须在/etc/fstab配置文件中添加上_netdev参数，表示当系统联网后再进行挂载操作，以免系统开机时间过长或开机失败： 当不在需要使用该硬盘时，可通过iscsiadm命令-u卸载： 1234[root@localhost ~]# iscsiadm -m node -T iqn.2018-10.com.example:server -uLogging out of session [sid: 1, target: iqn.2018-10.com.example:server, portal: 192.168.245.128,3260]Logout of [sid: 1, target: iqn.2018-10.com.example:server, portal: 192.168.245.128,3260] successful.[root@localhost ~]# 配置Windows客户端连接iSCSI设备：第一步：运行iSCSI发起程序。上 控制面板–&gt;系统和安全–&gt;管理工具–&gt;iSCSI发起程序。 第二步：更改客户端iqn属性： 第三步：点击连接，就会在本次磁盘新加一款硬盘。 第四步：通过格式化新建卷就可使用该硬盘。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba服务器搭建与配置]]></title>
    <url>%2F2018%2F10%2F18%2FSamba%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Samba服务简介Samba的起源： 对于windows的网上邻居来讲，共享文件的方式用的是SMB和CIFS协议以及NETBIOS协议Linux/Unix之间用的是NFS协议。 ​ 但是Linux和Windows之间是不能共享的，所以澳大利亚国立大学的Andrew Tridgell，决定开发一款软件，这款软件就是为了实现不同的系统之间互相共享文件的，于是一款叫做SMB的软件横空出世了，但是这个名字不能被注册成商标，因为已经有SMB协议了，于是作者给名字上加了两个A，就成了我们即将使用的功能强的文件共享服务器： SAMBA。 什么是Samba: Samba是一个能让Linux系统应用Microsoft网络通讯协议的软件，而SMB是Server Message Block的缩写，即为服务器消息块 ，SMB主要是作为Microsoft的网络通讯协议，后来Samba将SMB通信协议应用到了Linux系统上，就形成了现在的Samba软件。后来微软又把 SMB 改名为 CIFS（Common Internet File System），即公共 Internet 文件系统，并且加入了许多新的功能，这样一来，使得Samba具有了更强大的功能。 Samba的功能： Samba最大的功能就是可以用于Linux与windows系统直接的文件共享和打印共享，Samba既可以用于windows与Linux之间的文件共享，也可以用于Linux与Linux之间的资源共享，由于NFS(网络文件系统）可以很好的完成Linux与Linux之间的数据共享，因而 Samba较多的用在了Linux与windows之间的数据共享上面。 Samba的工作原理： SMB是基于客户机/服务器型的协议，因而一台Samba服务器既可以充当文件共享服务器，也可以充当一个Samba的客户端，例如，一台在Linux 下已经架设好的Samba服务器，windows客户端就可以通过SMB协议共享Samba服务器上的资源文件，同时，Samba服务器也可以访问网络中 其它windows系统或者Linux系统共享出来的文件。 ​ 事实上， 就像 NFS 是架构在 RPC Server 上面一样， SAMBA 这个文件系统是架构在 NetBIOS (Network Basic Input/Output System, NetBIOS) 这个通讯协议上面所开发出来的。 ​ Samba在windows下使用的是NetBIOS协议，如果你要使用Linux下共享出来的文件，请确认你的windows系统下是否安装了NetBIOS协议。 组成Samba运行的有两个服务，一个是SMB，另一个是NMB；SMB是Samba 的核心启动服务，主要负责建立 Linux Samba服务器与Samba客户机之间的对话， 验证用户身份并提供对文件和打印系统的访问，只有SMB服务启动，才能实现文件的共享，监听139 TCP端口；而NMB服务是负责解析用的，类似与DNS实现的功能，NMB可以把Linux系统共享的工作组名称与其IP对应起来，如果NMB服务没有启动，就只能通过IP来访问共享文件，监听137和138 UDP端口。 Samba使用的 damons：NetBIOS 机器间的沟通 取得对方主机的NetBIOS name 定位该主机所在： 利用对方给予权限存取可用资源 SAMBA 使用下面两个服务来控制上面两步骤，分别是： nmbd 这个daemon是用来管理工作组，NetBIOS name等等的解析。 主要利用 UDP 协议开启 port 137 138 来负责名称解析的任务。 smbd 这个daemon主要用来管理SAMBA主机分享的目录，档案与打印机等等。 主要利用可靠的TCP协议来传输数据，开放端口为139. 所以SAMBA每次启动至少都需要有这个daemon，而当我启动了SAMBA之后，主机系统就会启动137,138 这两个UDP 及139这个TCP端口。 Samba联机模式介绍：两种最常见的局域网的联机模式 peer/peer(对等模式) domain model（主控模式） （1）peer/peer （workgroup model，对等模式） 图：对等模式原理 使用 peer/peer 的架构的好处是每部计算机均可以独立运作，而不受他人的影响！不过， 缺点就是当整个网域内的所有人员都要进行数据分享时，光是知道所有计算机里面的账号与密码，就会很伤脑筋了！ 所以， Peer/Peer 的架构是比较适合 ： 小型的网域 没有需要常常进行档案数据分享的网络环境 每个使用者都独自拥有该计算机的拥有权 (2)domain model（主控模式) 图：主控模式原理 将所有的账号与密码都放置在一部主控计算机 (Primary Domain Controller, PDC) 上面，在我的网域里面，任何人想要使用任何计算机时，都需要在屏幕前方输入账号与密码，然后通通藉由 PDC 服务器的辨识后，才给予适当的权限。也就是说，不同的身份还具有不一样的计算机资源权限。 Samba的常见应用：Samba能做什么？ 分享档案与打印机服务 可以提供用户登入Samba主机时的身份认证，以提供不同身份者的个别数据。 可以进行windows网络上的主机名解析 可以进行装置的分享 Samba服务器的应用实例： 利用软件直接编修WWW主机上面的网页数据 用FTP修改，后上传；不方便，很有可能传上去旧版本的。 在线修改比较能迅速看到结果。 做成可直接联机的文件服务器 因为每个人登陆的账户名不同，这样对目录的权限也不同，实现权限控制。 Samba服务器的搭建第一步：安装Samba服务123456789101112[root@localhost ~]# yum -y install samba* [root@localhost ~]# systemctl start smbdFailed to start smbd.service: Unit not found.[root@localhost ~]# systemctl start smb[root@localhost ~]# systemctl enable smb[root@localhost ~]# firewall-cmd --permanent --add-service=sambasuccess[root@localhost ~]# firewall-cmd --reloadsuccessCreated symlink from /etc/systemd/system/multi-user.target.wants/nmb.service to /usr/lib/systemd/system/nmb.service.[root@localhost ~]# getenforce Permissive 安装包说明： samba-common //主要提供samba服务器的设置文件与设置文件语法检验程序testparm samba-client //客户端软件，主要提供linux主机作为客户端时，所需要的工具指令集 samba-swat //基于https协议的samba服务器web配置界面 samba //服务器端软件，主要提供samba服务器的守护程序，共享文档，日志的轮替，开机默认选项Samba服务器安装完毕，会生成配置文件目录/etc/samba和其它一些samba可执行命令工具，/etc/samba/smb.conf是samba的核心配置文件。 第二步：Samba服务的配置Samba服务的主要配置文件为：/etc/sambs/smb.conf。安装后samba后，除了该文件还有/etc/sambs/smb.conf.example 文件作为参考。 1234567891011121314151617181920212223242526272829303132333435363738394041[root@localhost ~]# vim /etc/samba/smb.conf# See smb.conf.example for a more detailed config file or# read the smb.conf manpage.# Run 'testparm' to verify the config is correct after# you modified it.[global] #全局参数。 workgroup =MYGROUP #设定Samba Server所要加入的工作组或域 security = user #安装验证方式，总共有四种 passdb backend = tdbsam #定义用户后台类型，总共有三种 printing = cups printcap name = cups load printers = yes #设置在Samba服务启动时是否共享打印机设备 cups options = raw #打印机的选项[homes] comment = Home Directories #描述信息 valid users = %S, %D%w%S #有效访问用户 path = ~ #文件路径 browseable = No #指定共享信息是否在“网上邻居”中可见 read only = No #是否只读 inherit acls = Yes [printers] comment = All Printers path = /var/tmp #共享文件的实际路径。 printable = Yes create mask = 0600 browseable = No[print$] comment = Printer Drivers path = /var/lib/samba/drivers write list = root create mask = 0664 directory mask = 0775 Samba服务器的主要配置参数介绍： 主配置文件由两部分构成：Global 部分和 Share 部分。 Global部分参数解释：该设置都是与Samba服务整体运行环境有关的选项，它的设置项目是针对所有共享资源的。 workgroup = WORKGROUP 说明：设定 Samba Server 所要加入的工作组或者域 server string = Samba Server Version %v 说明：设定 Samba Server 的注释，可以是任何字符串，也可以不填。宏%v表示显示Samba的版本号。 netbios name = smbserver 说明：设置Samba Server的NetBIOS名称。如果不填，则默认会使用该服务器的DNS名称的第一部分。netbios name和workgroup名字不要设置成一样了。 interfaces = lo eth0 192.168.12.2/24 192.168.13.2/24 说明：设置Samba Server监听哪些网卡，可以写网卡名，也可以写该网卡的IP地址。 hosts allow = 127. 192.168.1. 192.168.10.1 说明：表示允许连接到Samba Server的客户端，多个参数以空格隔开。可以用一个IP表示，也可以用一个网段表示。hosts deny 与hosts allow 刚好相反。例如：hosts allow=172.17.2.EXCEPT172.17.2.50表示容许来自172.17.2.*的主机连接，但排除172.17.2.50 hosts allow=172.17.2.0/255.255.0.0 说明：表示允许来自172.17.2.0/255.255.0.0子网中的所有主机连接 hosts allow=@example.com 表示允许来自example.com网域的所有计算机连接 max connections = 0 说明：max connections用来指定连接Samba Server的最大连接数目。如果超出连接数目，则新的连接请求将被拒绝。0表示不限制。 deadtime = 0 说明：deadtime用来设置断掉一个没有打开任何文件的连接的时间。单位是分钟，0代表Samba Server不自动切断任何连接。 time server = yes/no 说明：time server用来设置让nmdb成为windows客户端的时间服务器。 log file = /var/log/samba/log.%m 说明：设置Samba Server日志文件的存储位置以及日志文件名称。在文件名后加个宏%m（主机名），表示对每台访问SambaServer的机器都单独记录一个日志文件。如果pc1、pc2访问过SambaServer，就会在/var/log/samba目录下留下log.pc1和log.pc2两个日志文件。 max log size = 50 说明：设置Samba Server日志文件的最大容量，单位为kB，0代表不限制。 security = user 说明：设置用户访问Samba Server的验证方式，一共有四种验证方式。 share：用户访问Samba Server不需要提供用户名和口令, 安全性能较低。（在Redhat7上安装，该选项已被弃用，选择该选择，服务不能启动） user：Samba Server共享目录只能被授权的用户访问,由Samba Server负责检查账号和密码的正确性。账号和密码要在本Samba Server中建立。 server：依靠其他Windows NT/2000或SambaServer来验证用户的账号和密码,是一种代理验证。此种安全模式下,系统管理员可以把所有的Windows用户和口令集中到一个NT系统上,使用Windows NT进行Samba认证, 远程服务器可以自动认证全部用户和口令,如果认证失败,Samba将使用用户级安全模式作为替代的方式。 domain：域安全级别,使用主域控制器(PDC)来完成认证。 passdb backend = tdbsam 说明：passdb backend就是用户后台的意思。目前有三种后台：smbpasswd、tdbsam和ldapsam。sam应该是security account manager（安全账户管理）的简写。 smbpasswd：该方式是使用smb自己的工具smbpasswd来给系统用户（真实用户或者虚拟用户）设置一个Samba密码，客户端就用这个密码来访问Samba的资源。smbpasswd文件默认在/etc/samba目录下，不过有时候要手工建立该文件。 tdbsam：该方式则是使用一个数据库文件来建立用户数据库。数据库文件叫passdb.tdb，默认在/etc/samba目录下。passdb.tdb用户数据库可以使用smbpasswd –a来建立Samba用户，不过要建立的Samba用户必须先是系统用户。我们也可以使用pdbedit命令来建立Samba账户。pdbedit命令的参数很多，我们列出几个主要的。 pdbedit –a username：新建Samba账户 pdbedit –x username：删除Samba账户。 pdbedit –L：列出Samba用户列表，读取passdb.tdb数据库文件。 pdbedit –Lv：列出Samba用户列表的详细信息。 pdbedit –c “[D]” –u username：暂停该Samba用户的账号。 pdbedit –c “[]” –u username：恢复该Samba用户的账号。 ldapsam：该方式则是基于LDAP的账户管理方式来验证用户。首先要建立LDAP服务，然后设置“passdb backend = ldapsam:ldap://LDAP Server encrypt passwords = yes/no 说明：是否将认证密码加密。因为现在windows操作系统都是使用加密密码，所以一般要开启此项。不过配置文件默认已开启。 smb passwd file = /etc/samba/smbpasswd [如果之前设置的是smbpasswd模式的话] 说明：用来定义samba用户的密码文件。smbpasswd文件如果没有那就要手工新建 username map = /etc/samba/smbusers 说明：用来定义用户名映射，比如可以将root换成administrator、admin等。不过要事先在smbusers文件中定义好。比如：root = administrator admin，这样就可以用administrator或admin这两个用户来代替root登陆Samba Server，更贴近windows用户的习惯。 guest account = nobody 说明：用来设置guest用户名。 socket options = TCP_NODELAY SO_RCVBUF=8192 SO_SNDBUF=8192 说明：用来设置服务器和客户端之间会话的Socket选项，可以优化传输速度。 domain master = yes/no 说明：设置Samba服务器是否要成为网域主浏览器，网域主浏览器可以管理跨子网域的浏览服务 local master = yes/no 说明：local master用来指定Samba Server是否试图成为本地网域主浏览器。如果设为no，则永远不会成为本地网域主浏览器。但是即使设置为yes，也不等于该Samba Server就能成为主浏览器，还需要参加选举。 preferred master = yes/no 说明：设置Samba Server一开机就强迫进行主浏览器选举，可以提高Samba Server成为本地网域主浏览器的机会。如果该参数指定为yes时，最好把domain master也指定为yes。使用该参数时要注意：如果在本Samba Server所在的子网有其他的机器（不论是windows NT还是其他Samba Server）也指定为首要主浏览器时，那么这些机器将会因为争夺主浏览器而在网络上大发广播，影响网络性能。如果同一个区域内有多台Samba Server，将上面三个参数设定在一台即可。 os level = 200 说明：设置samba服务器的os level。该参数决定Samba Server是否有机会成为本地网域的主浏览器。os level从0到255，winNT的os level是32，win95/98的os level是1。Windows 2000的os level是64。如果设置为0，则意味着Samba Server将失去浏览选择。如果想让Samba Server成为PDC，那么将它的os level值设大些。 domain logons = yes/no 说明：设置Samba Server是否要做为本地域控制器。主域控制器和备份域控制器都需要开启此项。 logon script = %u.bat 说明：当使用者用windows客户端登陆，那么Samba将提供一个登陆档。如果设置成%u.bat，那么就要为每个用户提供一个登陆档。如果人比较多，那就比较麻烦。可以设置成一个具体的文件名，比如start.bat，那么用户登陆后都会去执行start.bat，而不用为每个用户设定一个登陆档了。这个文件要放置在[netlogon]的path设置的目录路径下。 wins support = yes/no 说明：设置samba服务器是否提供wins服务。 wins server = wins服务器IP地址 说明：设置Samba Server是否使用别的wins服务器提供wins服务。 wins proxy = yes/no 说明：设置Samba Server是否开启wins代理服务。 dns proxy = yes/no 说明：设置Samba Server是否开启dns代理服务。 load printers = yes/no 说明：设置是否在启动Samba时就共享打印机。 printcap name = cups 说明：设置共享打印机的配置文件。 printing = cups 说明：设置Samba共享打印机的类型。现在支持的打印系统有：bsd, sysv, plp, lprng, aix, hpux, qnx Share部分参数解释：该设置针对的是共享目录个别的设置，只对当前的共享资源起作用。 [共享名] comment = 任意字符串 说明：comment是对该共享的描述，可以是任意字符串。 path = 共享目录路径 说明：path用来指定共享目录的路径。可以用%u、%m这样的宏来代替路径里的unix用户和客户机的Netbios名，用宏表示主要用于[homes]共享域。例如：如果我们不打算用home段做为客户的共享，而是在/home/share/下为每个Linux用户以他的用户名建个目录，作为他的共享目录，这样path就可以写成：path = /home/share/%u; 用户在连接到这共享时具体的路径会被他的用户名代替，要注意这个用户名路径一定要存在，否则，客户机在访问时会找不到网络路径。同样，如果我们不是以用户来划分目录，而是以客户机来划分目录，为网络上每台可以访问samba的机器都各自建个以它的netbios名的路径，作为不同机器的共享资源，就可以这样写：path= /home/share/%m 。 browseable = yes/no 说明：browseable用来指定该共享是否可以浏览。 writable = yes/no 说明：writable用来指定该共享路径是否可写。 available = yes/no 说明：available用来指定该共享资源是否可用。 admin users = 该共享的管理者 说明：admin users用来指定该共享的管理员（对该共享具有完全控制权限）。在samba 3.0中，如果用户验证方式设置成“security=share”时，此项无效。例如：admin users =david，sandy（多个用户中间用逗号隔开）。 valid users = 允许访问该共享的用户 说明：valid users用来指定允许访问该共享资源的用户。例如：valid users = david，@dave，@tech（多个用户或者组中间用逗号隔开，如果要加入一个组就用“@组名”表示。） invalid users = 禁止访问该共享的用户 说明：invalid users用来指定不允许访问该共享资源的用户。例如：invalid users = root，@bob（多个用户或者组中间用逗号隔开。） write list = 允许写入该共享的用户 说明：write list用来指定可以在该共享下写入文件的用户。例如：write list = david，@dave public = yes/no 说明：public用来指定该共享是否允许guest账户访问。 guest ok = yes/no 说明：意义同“public”。 第三步：(测试)共享一个/common目录 要求： 在 服务器上配置 SMB 服务您的 SMB 服务器必须是 STAFF 工作组的一个成员共享 /common 目录共享名必须为 common只有 192.168.245.0/24内的客户端可以访问 common 共享common 必须是可以浏览的用户 rob 必须能够读取共享中的内容，如果需要的话，验证的密码是 compede。要求 rob 用户以只读的方式访问该目录，brian 可以用读写的方式来访问该目录，brian 密码为 postroll。 配置如下： 123456789101112131415161718192021222324252627282930[root@localhost ~]# pdbedit -x brian[root@localhost ~]# pdbedit -x rob[root@localhost ~]# userdel -r brian[root@localhost ~]# userdel -r rob[root@localhost ~]# [root@localhost ~]# useradd -s /sbin/nologin brian[root@localhost ~]# useradd -s /sbin/nologin rob[root@localhost ~]# pdbedit -L[root@localhost ~]# pdbedit -a briannew password:retype new password:[root@localhost ~]# (echo compede; echo compede) | smbpasswd -a robNew SMB password:Retype new SMB password:Added user rob.[root@localhost ~]# pdbedit -Lbrian:1012:rob:1013:[root@localhost /]# mkdir /commom[root@localhost /]# vim /etc/samba/smb.conf#做如下更改[global] workgroup = STAFF[common] path = /common public = yes browseable = yes write list = brian hosts allow = 192.168.245.0/24 #做完以上操作后，重启服务，放开防火墙即可。 在另一台Linux系统上测试挂载smb共享目录： 要求： 通过 smb 多用户的方式将共享目录 common 挂载到/mnt/private上。要求在对该共享目录挂载时，以 rob 的身份进行操作。要求每次开机该共享目录可以自动挂载 123456789101112131415161718192021222324252627282930313233343536373839[root@localhost ~]# yum -y install samba-client cifs-utils[root@localhost ~]# smbclient -L //192.168.245.128 -N#通过该命令可匿名查看smb服务器共享的目录Anonymous login successfulDomain=[STAFF] OS=[Windows 6.1] Server=[Samba 4.4.4] Sharename Type Comment --------- ---- ------- print$ Disk Printer Drivers common Disk IPC$ IPC IPC Service (Samba 4.4.4)Anonymous login successfulDomain=[STAFF] OS=[Windows 6.1] Server=[Samba 4.4.4] Server Comment --------- ------- LOCALHOST Samba 4.4.4 Workgroup Master --------- ------- STAFF LOCALHOST WORKGROUP ðí├Î▒╩╝Ã▒¥[root@localhost ~]# vim /root/cred.robusername=robpassword=compede[root@localhost ~]# vim /etc/fstab#在该文件中添加如下语句//192.168.245.128/common /mnt/private cifs credentials=/root/cred.rob,multiuser,sec=ntlmssp 0 0[root@localhost ~]# mount -a[root@localhost ~]# df -ThFilesystem Type Size Used Avail Use% Mounted on/dev/mapper/rhel-root xfs 17G 3.1G 14G 18% /devtmpfs devtmpfs 1.4G 0 1.4G 0% //192.168.245.128/common cifs 17G 3.9G 14G 23% /mnt/private[root@localhost ~]# useradd brian[root@localhost ~]# su - brian[brian@localhost ~]$ echo postroll | cifscreds add 192.168.245.128 [brian@localhost ~]$ echo ok &gt;&gt; /mnt/private/rw.txt 在Windows上挂载smb的共享目录：第一步：打开windows的smb功能。 第二步：添加网络映射 注意：要求添加凭证的时候，直接填写smb服务器已经存在的账号和密码即可。这儿添加了brian，该用户具有写权限。 添加成功：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下autofs自动挂载服务]]></title>
    <url>%2F2018%2F10%2F16%2FLinux%E4%B8%8Bautofs%E8%87%AA%E5%8A%A8%E6%8C%82%E8%BD%BD%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Autofs简介Autofs介绍：mount是用来挂载文件系统的，可以在系统启动的时候挂载也可以在系统启动后挂载。对于本地固定设备，如硬盘可以使用mount挂载；而光盘、软盘、NFS、SMB等文件系统具有动态性，即需要的时候才有必要挂载。光驱和软盘我们一般知道什么时候需要挂载，但NFS和SMB共享等就不一定知道了，即我们一般不能及时知道NFS共享和SMB什么时候可以挂载。而autofs服务就提供这种功能，好像windows中的光驱自动打开功能，能够及时挂载动态加载的文件系统。免去我们手动挂载的麻烦。要实现光驱，软盘等的动态自动挂载，需要进行相关的配置。 Autofs特点：Autofs与Mount/Umount的不同之处在于，它是一种看守程序。如果它检测到用户正试图访问一个尚未挂接的文件系统，它就会自动检测该文件系统，如果存在，那么Autofs会自动将其挂接。另一方面， 如果它检测到某个已挂接的文件系统在一段时间内没有被使用，那么Autofs会自动将其卸载。因此一旦运行了Autofs后，用户就不再需要手动完成文件系统的挂接和卸载。 无论是Samba服务还是NFS服务，都要把挂载信息写入到/etc/fstab中，这样远程共享资源就会自动随服务器开机而进行挂载。虽然这很方便，但是如果挂载的远程资源太多，则会给网络带宽和服务器的硬件资源带来很大负载。如果在资源挂载后长期不使用，也会造成服务器硬件资源的浪费。可能会有读者说，“可以在每次使用之前执行mount命令进行手动挂载”。这是一个不错的选择，但是每次都需要先挂载再使用，您不觉得麻烦吗？ autofs自动挂载服务可以帮我们解决这一问题。与mount命令不同，autofs服务程序是一种Linux系统守护进程，当检测到用户试图访问一个尚未挂载的文件系统时，将自动挂载该文件系统。换句话说，我们将挂载信息填入/etc/fstab文件后，系统在每次开机时都自动将其挂载，而autofs服务程序则是在用户需要使用该文件系统时才去动态挂载，从而节约了网络资源和服务器的硬件资源。 Autofs服务安装与配置第一步：安装autofs软件1234[root@localhost ~]# yum -y install autofs.x86_64 [root@localhost ~]# systemctl start autofs[root@localhost ~]# systemctl enable autofsCreated symlink from /etc/systemd/system/multi-user.target.wants/autofs.service to /usr/lib/systemd/system/autofs.service. 第二步：编辑配置文件。处于生产环境中的Linux服务器，一般会同时管理许多设备的挂载操作。如果把这些设备挂载信息都写入到autofs服务的主配置文件中，无疑会让主配置文件臃肿不堪，不利于服务执行效率，也不利于日后修改里面的配置内容，因此在autofs服务程序的主配置文件中需要按照“挂载目录 子配置文件”的格式进行填写。挂载目录是设备挂载位置的上一级目录。例如，光盘设备一般挂载到/media/cdrom目录中，那么挂载目录写成/media即可。对应的子配置文件则是对这个挂载目录内的挂载设备信息作进一步的说明。子配置文件需要用户自行定义，文件名字没有严格要求，但后缀建议以.misc结束。 1234567891011121314151617181920212223242526272829[root@localhost ~]# vi /etc/auto.master## Sample auto.master file# This is a 'master' automounter map and it has the following format:# mount-point [map-type[,format]:]map [options]# For details of the format look at auto.master(5).#/misc /etc/auto.misc## NOTE: mounts done from a hosts map will be mounted with the# "nosuid" and "nodev" options unless the "suid" and "dev"# options are explicitly given.#/net -hosts## Include /etc/auto.master.d/*.autofs# The included files must conform to the format of this file.#+dir:/etc/auto.master.d## Include central master map if it can be found using# nsswitch sources.## Note that if there are entries for /net or /misc (as# above) in the included master map any keys that are the# same will not be seen as the first read key seen takes# precedence.#+auto.master 在子配置文件中，应按照“挂载目录 挂载文件类型及权限 :设备名称 ”的格式进行填写。例如，要把光盘设备挂载到/media/iso目录中，可将挂载目录写为iso，而-fstype为文件系统格式参数，iso9660为光盘设备格式，ro、nosuid及nodev为光盘设备具体的权限参数，/dev/cdrom则是定义要挂载的设备名称。 12[root@localhost ~]# vim /etc/iso.misciso -fstype=iso9660,ro,nosuid,nodev :/dev/cdrom 挂载NFS共享目录实验： 在/etc/auto.master 文件中加入一行，/mnt/nfs /etc/nfs.misc vi /etc/nfs.misc ,添加如下配置。 nfs -fstype=nfs,ro 192.168.245.128:/public 重启autofs服务，到/mnt/nfs中，即可看到已经挂载上。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS服务器搭建与配置]]></title>
    <url>%2F2018%2F10%2F16%2FNFS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[NFS服务简介什么是NFS？NFS就是Network File System的缩写，它最大的功能就是可以通过网络，让不同的机器、不同的操作系统可以共享彼此的文件。 ​ NFS服务器可以让PC将网络中的NFS服务器共享的目录挂载到本地端的文件系统中，而在本地端的系统中来看，那个远程主机的目录就好像是自己的一个磁盘分区一样，在使用上相当便利； NFS一般用来存储共享视频，图片等静态数据。 NFS挂载原理： 图；服务器挂载结构图如上图示： 当我们在NFS服务器设置好一个共享目录/home/public后，其他的有权访问NFS服务器的NFS客户端就可以将这个目录挂载到自己文件系统的某个挂载点，这个挂载点可以自己定义，如上图客户端A与客户端B挂载的目录就不相同。并且挂载好后我们在本地能够看到服务端/home/public的所有数据。如果服务器端配置的客户端只读，那么客户端就只能够只读。如果配置读写，客户端就能够进行读写。挂载后，NFS客户端查看磁盘信息命令：#df –h。既然NFS是通过网络来进行服务器端和客户端之间的数据传输，那么两者之间要传输数据就要有想对应的网络端口，NFS服务器到底使用哪个端口来进行数据传输呢？基本上NFS这个服务器的端口开在2049,但由于文件系统非常复杂。因此NFS还有其他的程序去启动额外的端口，这些额外的用来传输数据的端口是随机选择的，是小于1024的端口；既然是随机的那么客户端又是如何知道NFS服务器端到底使用的是哪个端口呢？这时就需要通过远程过程调用（Remote Procedure Call,RPC）协议来实现了！## RPC与NFS通讯原理：​ 因为NFS支持的功能相当多，而不同的功能都会使用不同的程序来启动，每启动一个功能就会启用一些端口来传输数据，因此NFS的功能对应的端口并不固定，客户端要知道NFS服务器端的相关端口才能建立连接进行数据传输，而RPC就是用来统一管理NFS端口的服务，并且统一对外的端口是111，RPC会记录NFS端口的信息，如此我们就能够通过RPC实现服务端和客户端沟通端口信息。PRC最主要的功能就是指定每个NFS功能所对应的port number,并且通知客户端，记客户端可以连接到正常端口上去。 那么RPC又是如何知道每个NFS功能的端口呢？ 首先当NFS启动后，就会随机的使用一些端口，然后NFS就会向RPC去注册这些端口，RPC就会记录下这些端口，并且RPC会开启111端口，等待客户端RPC的请求，如果客户端有请求，那么服务器端的RPC就会将之前记录的NFS端口信息告知客户端。如此客户端就会获取NFS服务器端的端口信息，就会以实际端口进行数据的传输了。&gt; 注意：在启动NFS SERVER之前，首先要启动RPC服务（即portmap服务，下同）否则NFS SERVER就无法向RPC服务区注册，另外，如果RPC服务重新启动，原来已经注册好的NFS端口数据就会全部丢失。因此此时RPC服务管理的NFS程序也要重新启动以重新向RPC注册。特别注意：一般修改NFS配置文档后，是不需要重启NFS的，直接在命令执行systemctl reload nfs或exportfs –rv即可使修改的/etc/exports生效## NFS客户端和NFS服务器通讯过程：图：NFS工作原理图 首先服务器端启动RPC服务，并开启111端口 服务器端启动NFS服务，并向RPC注册端口信息 客户端启动RPC（portmap服务），向服务端的RPC(portmap)服务请求服务端的NFS端口 服务端的RPC(portmap)服务反馈NFS端口信息给客户端。 客户端通过获取的NFS端口来建立和服务端的NFS连接并进行数据的传输。 Linux下NFS服务器部署NFS服务所需软件及主要配置文件：安装NFS服务，需要安装两个软件，分别是： RPC主程序：rpcbind NFS 其实可以被视为一个 RPC 服务，因为启动任何一个 RPC 服务之前，我们都需要做好 port 的对应 (mapping) 的工作才行，这个工作其实就是『 rpcbind 』这个服务所负责的！也就是说， 在启动任何一个 RPC 服务之前，我们都需要启动 rpcbind 才行！ (在 CentOS 5.x 以前这个软件称为 portmap，在 CentOS 6.x 之后才称为 rpcbind 的！)。 NFS主程序：nfs-utils 就是提供 rpc.nfsd 及 rpc.mountd 这两个 NFS daemons 与其他相关 documents 与说明文件、执行文件等的软件！这个就是 NFS 服务所需要的主要软件。 NFS的相关文件： 主要配置文件：/etc/exports这是 NFS 的主要配置文件了。该文件是空白的，有的系统可能不存在这个文件，主要手动建立。NFS的配置一般只在这个文件中配置即可。 NFS 文件系统维护指令：/usr/sbin/exportfs这个是维护 NFS 分享资源的指令，可以利用这个指令重新分享 /etc/exports 变更的目录资源、将 NFS Server 分享的目录卸除或重新分享。 分享资源的登录档：/var/lib/nfs/*tab在 NFS 服务器的登录文件都放置到 /var/lib/nfs/ 目录里面，在该目录下有两个比较重要的登录档， 一个是 etab ，主要记录了 NFS 所分享出来的目录的完整权限设定值；另一个 xtab 则记录曾经链接到此 NFS 服务器的相关客户端数据。 客户端查询服务器分享资源的指令：/usr/sbin/showmount这是另一个重要的 NFS 指令。exportfs 是用在 NFS Server 端，而 showmount 则主要用在 Client 端。showmount 可以用来察看 NFS 分享出来的目录资源。 服务端安装NFS服务步骤：第一步：安装NFS和rpc。 1234[root@localhost ~]# yum install -y rpc-bind nfs-utils #安装nfs服务[root@localhost ~]# yum install -y rpcbind#安装rpc服务 第二步：启动服务和设置开启启动： 注意：先启动rpc服务，再启动nfs服务。 123456789[root@localhost ~]# systemctl start rpcbind #先启动rpc服务[root@localhost ~]# systemctl enable rpcbind #设置开机启动[root@localhost ~]# systemctl start nfs-server nfs-secure-server #启动nfs服务和nfs安全传输服务[root@localhost ~]# systemctl enable nfs-server nfs-secure-server[root@localhost /]# firewall-cmd --permanent --add-service=nfssuccess #配置防火墙放行nfs服务[root@localhost /]# firewall-cmd --reload success 第三步：配置共享文件目录，编辑配置文件： 首先创建共享目录，然后在/etc/exports配置文件中编辑配置即可。 1234567[root@localhost /]# mkdir /public#创建public共享目录[root@localhost /]# vi /etc/exports /public 192.168.245.0/24(ro) /protected 192.168.245.0/24（rw）[root@localhost /]# systemctl reload nfs #重新加载NFS服务，使配置文件生效 配置文件说明： 格式： 共享目录的路径 允许访问的NFS客户端（共享权限参数） 如上，共享目录为/public , 允许访问的客户端为192.168.245.0/24网络用户，权限为只读。 请注意，NFS客户端地址与权限之间没有空格。 NFS输出保护需要用到kerberos加密（none，sys，krb5，krb5i，krb5p），格式sec=XXX none：以匿名身份访问，如果要允许写操作，要映射到nfsnobody用户，同时布尔值开关要打开，setsebool nfsd_anon_write 1 sys：文件的访问是基于标准的文件访问，如果没有指定，默认就是sys， 信任任何发送过来用户名 krb5：客户端必须提供标识，客户端的表示也必须是krb5，基于域环境的认证 krb5i：在krb5的基础上做了加密的操作，对用户的密码做了加密，但是传输的数据没有加密 krb5p：所有的数据都加密 用于配置NFS服务程序配置文件的参数： 参数 作用 ro 只读 rw 读写 root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的匿名用户 no_root_squash 当NFS客户端以root管理员访问时，映射为NFS服务器的root管理员 all_squash 无论NFS客户端使用什么账户访问，均映射为NFS服务器的匿名用户 sync 同时将数据写入到内存与硬盘中，保证不丢失数据 async 优先将数据保存到内存，然后再写入硬盘；这样效率更高，但可能会丢失数据 NFS客户端挂载配置：第一步：使用showmount命令查看nfs服务器共享信息。输出格式为“共享的目录名称 允许使用客户端地址”。 1234[root@localhost ~]# showmount -e 192.168.245.128 Export list for 192.168.245.128:/protected 192.168.245.0/24/public 192.168.245.0/24 showmount命令的用法； 参数 作用 -e 显示NFS服务器的共享列表 -a 显示本机挂载的文件资源的情况NFS资源的情况 -v 显示版本号 第二步，在客户端创建目录，并挂载共享目录。 1234567[root@localhost ~]# mkdir /mnt/public[root@localhost ~]# mkdir /mnt/date[root@localhost ~]# vim /etc/fstab #在该文件中挂载，使系统每次启动时都能自动挂载 192.168.245.128:/public /mnt/public nfs defaults 0 0 192.168.245.128:/protected /mnt/data nfs defaults 0 1[root@localhost ~]# mount -a #是文件/etc/fstab生效 第三步：检查： 123456789101112[root@mail ~]# df -ThFilesystem Type Size Used Avail Use% Mounted on/dev/mapper/rhel-root xfs 17G 3.1G 14G 18% /devtmpfs devtmpfs 1.4G 0 1.4G 0% /devtmpfs tmpfs 1.4G 140K 1.4G 1% /dev/shmtmpfs tmpfs 1.4G 9.1M 1.4G 1% /runtmpfs tmpfs 1.4G 0 1.4G 0% /sys/fs/cgroup/dev/sda1 xfs 1014M 173M 842M 18% /boottmpfs tmpfs 280M 32K 280M 1% /run/user/0/dev/sr0 iso9660 3.6G 3.6G 0 100% /mnt/cdrom192.168.245.128:/public nfs4 17G 3.7G 14G 22% /mnt/public192.168.245.128:/protected nfs4 17G 3.7G 14G 22% /mnt/data 在Window上挂载NFS第一步：在控制面板–&gt;添加程序和功能–&gt;添加NFS组件。 第二步：在此电脑，映射驱动器中添加nfs地址，和要共享的文件夹。 第三步：如果权限有问题，打开注册表：regedit, 在HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\ClientForNFS\CurrentVersion\Default 下新建两个OWORD（64）位值，添加值AnonymousGid，值默认为0，AnonymousUid，值默认为0。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务器搭建与配置]]></title>
    <url>%2F2018%2F10%2F15%2FDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[DNS服务介绍DNS服务简介：DNS(Domain Name System–域名系统),是因特网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。是一个应用层的协议DNS使用TCP和UDP端口53。 DNS是一个分布式数据库,命名系统采用层次的逻辑结构,如同一颗倒置的树,这个逻辑的树形结构称为域名空间,由于DNS划分了域名空间,所以各机构可以使用自己的域名空间创建DNS信息. 注:DNS域名空间中,树的最大深度不得超过127层,树中每个节点最长可以存储63个字符. DNS名词解释：1. 域和域名DNS树的每个节点代表一个域.通过这些节点,对整个域名空间进行划分,成为一个层次结构. 域名空间的每个域的名字,通过域名进行表示. 域名:通常由一个完全合格域名（FQDN）标识.FQDN能准确表示出其相对于DNS 域树根的位置,也就是节点到DNS 树根的完整表述方式,从节点到树根采用反向书写,并将每个节点用“.”分隔,对于DNS 域google 来说,其完全正式域名（FQDN）为google.com. 例如：google为com域的子域,其表示方法为google.com，而www为google域中的子域,可以使用www.google.com表示 注意:通常,FQDN 有严格的命名限制,长度不能超过256 字节,只允许使用字符a-z,0-9,A-Z和减号（-）.点号（.）只允许在域名标志之间（例如“google.com”）或者FQDN 的结尾使用. 域名不区分大小. 由最顶层到下层,可以分成:根域、顶级域、二级域、子域. Internet 域名空间的最顶层是根域（root）,其记录着Internet 的重要DNS 信息,由Internet域名注册授权机构管理,该机构把域名空间各部分的管理责任分配给连接到Internet 的各个组织. “.”全球有13个根(root)服务器 DNS 根域下面是顶级域,也由Internet 域名注册授权机构管理.共有3 种类型的顶级域. 组织域:采用3 个字符的代号,表示DNS 域中所包含的组织的主要功能或活动.比如com 为商业机构组织,edu 为教育机构组织,gov 为政府机构组织,mil 为军事机构组织,net 为网络机构组织,org 为非营利机构组织,int 为国际机构组织. 地址域:采用两个字符的国家或地区代号.如cn 为中国,kr 为韩国,us 为美国. 反向域:这是个特殊域,名字为in-addr.arpa,用于将IP 地址映射到名字（反向查询）. 对于顶级域的下级域,Internet 域名注册授权机构授权给Internet 的各种组织.当一个组织获得了对域名空间某一部分的授权后,该组织就负责命名所分配的域及其子域,包括域中的计算机和其他设备,并管理分配域中主机名与IP 地址的映射信息. 2、区（Zone）：区是DNS 名称空间的一部分,其包含了一组存储在DNS 服务器上的资源记录. 使用区的概念,DNS 服务器回答关于自己区中主机的查询,每个区都有自己的授权服务器. 3.主域名服务器和辅助域名服务器：当区的辅助服务器启动时,它与该区的主控服务器进行连接并启动一次区传输,区辅助服务器定期与区主控服务器通信,查看区数据是否改变.如果改变了,它就启动一次数据更新传输.每个区必须有主服务器,另外每个区至少要有一台辅助服务器,否则如果该区的主服务器崩溃了,就无法解析该区的名称. 辅助服务器的优点: 容错能力 配置辅助服务器后,在该区主服务器崩溃的情况下,客户机仍能解析该区的名称.一般把区的主服务器和区的辅助服务器安装在不同子网上,这样如果到一个子网的连接中断,DNS 客户机还能直接查询另一个子网上的名称服务器. 减少广域链路的通信量 如果某个区在远程有大量客户机,用户就可以在远程添加该区的辅助服务器,并把远程的客户机配置成先查询这些服务器,这样就能防止远程客户机通过慢速链路通信来进行DNS 查询. 减轻主服务器的负载 辅助服务器能回答该区的查询,从而减少该区主服务器必须回答的查询数. 4.DNS相关概念： DNS服务器： 运行DNS 服务器程序的计算机,储存DNS 数据库信息.DNS 服务器会尝试解析客户机的查询请求. 在解答查询时,如果DNS 服务器能提供所请求的信息,就直接回应解析结果,如果该DNS 服务器没有相应的域名信息,则为客户机提供另一个能帮助解析查询的服务器地址,如果以上两种方法均失败,则回应客户机没有所请求的信息或请求的信息不存在. DNS缓存： 运行DNS 服务器程序的计算机,储存DNS 数据库信息.DNS 服务器会尝试解析客户机的查询请求. 在解答查询时,如果DNS 服务器能提供所请求的信息,就直接回应解析结果,如果该DNS 服务器没有相应的域名信息,则为客户机提供另一个能帮助解析查询的服务器地址,如果以上两种方法均失败,则回应客户机没有所请求的信息或请求的信息不存在. 5、DNS两种查询方式： 递归查询： 递归查询是一种DNS 服务器的查询模式,在该模式下DNS 服务器接收到客户机请求,必须使用一个准确的查询结果回复客户机.如果DNS 服务器本地没有存储查询DNS 信息,那么该服务器会询问其他服务器,并将返回的查询结果提交给客户机. 迭代查询： DNS 服务器另外一种查询方式为迭代查询,当客户机发送查询请求时,DNS 服务器并不直接回复查询结果,而是告诉客户机另一台DNS 服务器地址,客户机再向这台DNS 服务器提交请求,依次循环直到返回查询的结果为止. 6、正向解析和方向解析： 正向解析：是指域名到IP地址的解析过程。 反向解析：是指IP地址到域名的解析过程。 7、DNS资源记录： SOA 资源记录(全区唯一) 每个区在区的开始处都包含了一个起始授权记录（Start of Authority Record）,简称SOA 记录. SOA 定义了域的全局参数,进行整个域的管理设置.一个区域文件只允许存在唯一的SOA 记录. NS 资源记录: NS（Name Server）记录是域名服务器记录,用来指定该域名由哪个DNS服务器来进行解析.每个区在区根处至少包含一个NS 记录. A 资源记录 地址（A）资源记录把FQDN 映射到IP 地址. 因为有此记录,所以DNS服务器能解析FQDN域名对应的IP 地址. A ：是IPv4地址。 AAAA是IPv6主机地址。 PTR 资源记录 相对于A 资源记录,指针（PTR）记录把IP地址映射到FQDN. 用于反向查询,通过IP地址,找到域名. CNAME 资源记录 别名记录（CNAME）资源记录创建特定FQDN 的别名.用户可以使用CNAME 记录来隐藏用户网络的实现细节,使连接的客户机无法知道真正的域名. 例:ping百度时,解析到了百度的别名服务器.百度有个cname=www.a.shifen.com.的别名 MX 资源记录 邮件交换（MX）资源记录,为DNS 域名指定邮件交换服务器. 邮件交换服务器是为DNS 域名处理或转发邮件的主机.处理邮件指把邮件投递到目的地或转交另一不同类型的邮件传送者.转发邮件指把邮件发送到最终目的服务器,用简单邮件传输协议SMTP 把邮件发送给离最终目的地最近的邮件交换服务器,或使邮件经过一定时间的排队. DNS工作原理：查询过程假设www.abc.com的主机要查询www.xyz.abc.com的服务器ip地址。 递归查询：第一步：在hosts静态文件、DNS解析器缓存中查找某主机的ip地址 hosts文件：以静态映射的方式提供IP地址与主机名的对照表，类似ARP表 域：abc.com是一个域，它可以划分为多个区域，如abc.com和xyz.abc.com 第二步：上一步无法找到，去DNS本地服务器（即域服务器）查找，其本质是去区域服务器、服务器缓存中查找 第三步：本地DNS服务器查不到就根据‘根提示文件’向负责顶级域‘.com’的DNS服务器查询 第四步：‘根DNS服务器’根据查询域名中的‘xyz.com’，再向xyz.com的区域服务器查询 第五步：www.xyz.abc.com的DNS服务器直接解析该域名，将查询到的ip再原路返回给请求查询的主机 迭代查询第一步：在hosts静态文件、DNS解析器缓存中查找某主机的ip地址 第二步：上一步无法找到，在DNS本地服务器（即域服务器）查找所有本层次的区域服务器 第三步：本地DNS服务器查不到就查询上一层次的所有区域服务器，以此类推直至根域名DNS服务器‘.’ 第四步：到达根域名服务器后又向下查询，直至查到结果为止。 迭代查询与递归查询结合递归查询需要经过逐层查询才能获得查询结果，当查询具有许多层次的DNS结构时效率很低，所以一般采用两者相结合的查询方式。 第一步：在hosts静态文件、DNS解析器缓存中查找某主机的ip地址 第二步：上一步无法找到，去DNS本地服务器（即域服务器）查找，其本质是去区域服务器、服务器缓存中查找 第三步：本地DNS服务器查不到就根据‘根提示文件’向负责顶级域‘.com’的根DNS服务器查询 第四步：根DNS服务器直接将其区域DNS服务器的ip地址返回给本地服务器，而不用再向xyz.com的区域服务器查询。 第五步：本地DNS服务器将结果返回给请求的主机 图：DNS查询流程图 Linux下DNS服务器安装BIND简介：BIND（Berkeley Internet Name Domain，伯克利因特网名称域）服务是全球范围内使用最广泛、最安全可靠且高效的域名解析服务程序。DNS域名解析服务作为互联网基础设施服务，其责任之重可想而知，因此建议大家在生产环境中安装部署bind服务程序时加上chroot（俗称牢笼机制）扩展包，以便有效地限制bind服务程序仅能对自身的配置文件进行操作，以确保整个服务器的安全。 安装bind服务和启动步骤：1234567[root@localhost ~]# yum install -y bind*#安装bind组件[root@localhost ~]# systemctl start named#启动dns服务[root@localhost ~]# systemctl enable named#设置dns服务开机启动Created symlink from /etc/systemd/system/multi-user.target.wants/named.service to /usr/lib/systemd/system/named.service. DNS配置的主要文件组： /etc/hosts 主机的一个文件列表 添加记录如:111.13.100.92 www.baidu.com 对于简单的主机名解析（点分表示法），默认在请求DNS或NIS网络域名服务器前，/etc/named.conf 通常会告诉程序先查看此文件。 /etc/resolv.conf 转换程序配置文件 在配置程序请求BIND域名查询服务查询主机名时，必须告诉程序使用哪个域名服务器和IP地址来完成这个任务 /etc/named.conf BIND主文件 设置一般的name参数，指向该服务器使用的域数据库的信息源 /var/named/named.ca 根域名配置服务器指向文件 指向根域名配置服务器，用于告诉缓存服务器初始化 /var/named/localhost.zone localhost区正向域名解析文件 用于将本地IP地址（127.0.0.1）转换为本地回送IP地址（127.0.0.1） /var/named/name.local localhost区反向域名解析文件 用于将localhost名字转换为本地回送IP地址（127.0.0.1） /etc/named.rfc1912.zones 区块设置文件 name.conf文件的主要配置信息： acl 定义ip地址的访问控制清单 control 定义rndc使用的控制通道 include 把其他的文件包含到配置文件中 key 定义授权的安全密钥 logging 定义日志内容和位置 options 定义全局配置选项和默认值 server 定义远程服务的特征 zone 定义一个区 DNS的资源记录（Resource Record, RR）格式：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106DNS域名数据库有资源记录和区文件指令组成，由SOA（Start Of Authority起始授权机构记录，SOA 记录说明了在众多NS记录里那一台才是主名称服务器。RR开始，同时包括NS RR；正向解析文件包括A internet Address，作用，FQDN --&gt; IP） MX （Mail eXchanger，邮件交换器）CNAME（Canonical NAME 别名） 反向解析文件包括PTR（PTR: PoinTeR，IP --&gt; FQDN）RR 语法：name [TTL] IN type value （字段之间由空格和制表符隔开）注意： (1) TTL可从全局继承 (2) @可用于引用当前区域的名字 (3) 同一个名字可以通过多条记录定义多个不同的值；此时 DNS服务器会以轮询方式响应 (4) 同一个值也可能有多个不同的定义名字；通过多个不同的 名字指向同一个值进行定义；此仅表示通过多个不同的名字 可以找到同一个主机SOA记录：name: 当前区域的名字，例如“heiye.com.” value: 有多部分组成 (1) 当前区域的主DNS服务器的FQDN，也可以使用当前区域的名字； (2) 当前区域管理员的邮箱地址；地址中不能使用@符号，一般用.替换 如linuxedu.heiye.com (3) 主从服务区域传输相关定义以及否定的答案的统一的TTL 例如： heiye.com. 86400 IN SOA ns.heiye.com. nsadmin.heiye.com. ( 2015042201 ; 序列号 2H ; 刷新时间 10M ; 重试时间 1W ; 过期时间 1D ; 否定答案的TTL值 )NS记录：name: 当前区域的名字 value: 当前区域的某DNS服务器的名字，例如 ns.heiye.com. 注意：一个区域可以有多个NS记录例如：heiye.com. IN NS ns1.heiye.com. heiye.com. IN NS ns2.heiye.com.注意： (1) 相邻的两个资源记录的name相同时，后续的可省略 (2) 对NS记录而言，任何一个ns记录后面的服务器名字 ，都应该在后续有一个A记录MX记录（Mail eXchanger）：name: 当前区域的名字 value: 当前区域的某邮件服务器(smtp服务器)的主机名 ， 一个区域内，MX记录可有多个；但每个记录的value之前应 该有一个数字(0-99)，表示此服务器的优先级；数字越小优 先级越高 例如：heiye.com. IN MX 10 mx1.heiye.com. IN MX 20 mx2.heiye.com.注意： (1) 对MX记录而言，任何一个MX记录后面的服务器名字 ，都应该在后续有一个A记录A记录（Addrss）:name: 某主机的FQDN，例如www.heiye.com. value: 主机名对应主机的IP地址例如： www.heiye.com. IN A 1.1.1.1 www.heiye.com. IN A 2.2.2.2 mx1.heiye.com. IN A 3.3.3.3 mx2.heiye.com. IN A 4.4.4.4 *.heiye.com. IN A 5.5.5.5 heiye.com. IN A 6.6.6.6 避免用户写错名称时给错误答案，可通过泛域名解析进行解 析至某特定地址其他记录：AAAA: name: FQDN value: IPv6 PTR: name: IP，有特定格式，把IP地址反过来写，1.2.3.4，要写 作4.3.2.1；而有特定后缀：in-addr.arpa.，所以完整写法为 ：4.3.2.1.in-addr.arpa. value: FQDN例如： 4.3.2.1. in-addr.arpa. IN PTR www.heiye.com.如1.2.3为网络地址，可简写成： 4 IN PTR www.heiye.com.注意：网络地址及后缀可省略；主机地址依然需要反着写别名记录:name: 别名的FQDN value: 真正名字的FQDN例如： www.heiye.com. IN CNAME websrv.heiye.com.named字段： （1）根域以” . “结束，并且只有一个，没有上级域。而在Internet中，根域一般不需要表现出来。 （2）@：默认域，文件使用$ORIGIN domain 来说明默认域。 （3）ttl 全称”Time to Live “，以秒为单位记录该资源记录中存放高速缓存中的时间长度。通常此处设为空，表示采用SOA的最小ttl值。 （4）IN：将该记录标志为一个Internet DNS资源记录。type字段: (1)A记录：主机名对应的IP地址记录，用户可将该域名下网站服务器指向自己的Web服务器，同时也可设置域名的二级域名。 (2)MX记录：邮件交换记录可将该域下所有邮件服务器 指向自己的邮件服务器，只需在线填写服务器的IP地址。 (3)CNAME记录：别名记录，可允许多个名字映射到同一计算机，通常用于同时提供Web和邮件服务器的计算机。 (4)SOA记录：一个授权区的开始，配置文件的第一个记录必须是SOA的开始。 (5)PTR记录：用于地址到主机名的映射。 (6)HINFO记录：由一组描述主机的信息文件组成，通常包括硬件名称和操作系统名称。value字段： （1）A :存放IP地址。 （2）CNAME：设置主机别名。 （3）HINFO：通常为两行，分别对应Hareware（计算机硬件名称）和OS-type（操作系统名称）。 （4）NS：域名服务器的名称。 （5）PTR:主机真实名称。测试检查配置文件错误的工具：nslookup、dig、named-checkzone、host、named-checkconf及dlint。 Linux下DNS服务器配置实验配置DNS正向解析：在配置Bind服务时，主要用到以下三个配置文件： 主配置文件（/etc/named.conf）：用来定义bind服务程序的运行。 区域配置文件（/etc/named.rfc1912.zones）：用来保存域名和IP地址对应关系的所在位置。类似于图书的目录，对应着每个域和相应IP地址所在的具体位置，当需要查看或修改时，可根据这个位置找到相关文件。 数据配置文件目录（/var/named）：该目录用来保存域名和IP地址真实对应关系的数据配置文件。 第一步：修改主配置文件/etc/named.conf。将监听地址和运行查询的地址都改为 any，分别表示服务器上的所有IP地址均可提供DNS域名解析服务，以及允许所有人对本服务器发送DNS查询请求。 图：主配置文件要修改的地方 第二步：修改区域配置文件（/etc/named.rfc1912.zones）。用来保存域名和IP地址对应关系的所在位置。在这个文件中，定义了域名与IP地址解析规则保存的文件位置以及服务类型等内容，而没有包含具体的域名、IP地址对应关系等信息。服务类型有三种，分别为hint（根区域）、master（主区域）、slave（辅助区域），其中常用的master和slave指的就是主服务器和从服务器。 123zone &quot;example.com&quot; IN &#123; type master; file &quot;example.com.zone&quot;; DNS默认端口是53的TCP和UPD,UDP是供用户查询的，主从复制用TCP和UDP的53端口都用。 BIND的ACL：bind有四个内置的acl: none: 没有一个主机 any: 任意主机 localhost: 本机 localnet: 本机的IP同掩码运算后得到的网络地址段 注意：只能先定义，后使用；因此一般定义在配置文件中， 处于options的前面，当然也可自定义如下 acl lan｛ ​ 192.168.25.0/24 } ; 访问控制： 访问控制的指令： allow-query {}： 允许查询的主机；白名单 allow-transfer {}：允许区域传送的主机；（白名单，一般用于主从） allow-recursion {}: 允许递归的主机,建议全局使用 allow-update {}: 允许更新区域数据库中的内容 第三步：编辑数据配置文件。**从/var/named目录中复制一份正向解析的模板文件（named.localhost），然后把域名和IP地址的对应数据填写数据配置文件中并保存。在复制时记得加上-a参数，这可以保留原始文件的所有者、所属组、权限属性等信息，以便让bind服务程序顺利读取文件内容： 123456789101112131415161718192021222324[root@localhost named]# cp -a named.localhost example.com[root@localhost named]# vim example.com.zone $TTL 1D@ IN SOA @ example.com. ( #授权信息开始: #DNS区域的地址,在域地址后面还可以加管理员邮箱，不能加@，用.代替。 20181001 ; serial #更新序列号 1D ; refresh #更新时间 1H ; retry #重试时间 1W ; expire #失效时间 3H ) ; minimum #无效解析记录的缓存时间 NS ns.example.com. #DNS区域的地址ns A 192.168.245.128 #地址记录www A 192.168.245.128 #www站点记录mail A 192.168.245.129 #地址记录 MX 10 mail.example.com. #邮箱交换记录example.com. A 192.168.245.200# 即使不写主机名，DNS也能解析到另外一个指定的地址$GENERATE 1-245 server$ A 1.1.1.$#如果服务器过多，对应主机名也很多，则可以这样写.例如：#server1.example.com对应地址为：1.1.1.1#server100.exmaple.com对应地址为：1.1.1.50bbs CNAME www #别名记录* A 192.168.245.128#“*”代表所有，即便主机www写错，DNS也能正确解析出来。这就是泛域名解析 图：正向解析文件配置 第四步：检查配置,重启服务和测试。 检查和重启服务： 1234567891011[root@localhost ~]# named-checkconf #检查主配置文件语法[root@localhost ~]# named-checkzone eample.com /var/named/example.com.zone #检查区域配置文件语法/var/named/example.com.zone:13: ignoring out-of-zone data (example.com)zone eample.com/IN: loaded serial 20181001[root@localhost ~]# vi /etc/resolv.conf#进入该配置文件，指定使用的域名解析服务器。 # Generated by NetworkManager nameserver 192.168.245.128 search 192.168.245.128[root@localhost ~]# systemctl restart named #重启服务 测试： 图；正向解析测试 nslookup测试 配置DNS反向解析：在DNS域名解析服务中，反向解析的作用是将用户提交的IP地址解析为对应的域名信息，它一般用于对某个IP地址上绑定的所有域名进行整体屏蔽，屏蔽由某些域名发送的垃圾邮件。它也可以针对某个IP地址进行反向解析，大致判断出有多少个网站运行在上面。当购买虚拟主机时，可以使用这一功能验证虚拟主机提供商是否有严重的超售问题。 第一步：配置区域文件。 反向解析是把IP地址解析成域名格式，因此在定义zone（区域）时应该要把IP地址反写，比如原来是192.168.10.0，反写后应该就是10.168.192，而且只需写出IP地址的网络位即可。 123456[root@localhost ~]# vim /etc/named.rfc1912.zones#在中添加反向数据文件的记录zone "245.168.192.in-addr.arpa" IN &#123; type master; file "245.168.192.arpa";&#125;; 第二步：编辑数据配置文件。 反向解析是把IP地址解析成域名格式，因此在定义zone（区域）时应该要把IP地址反写，比如原来是192.168.10.0，反写后应该就是10.168.192，而且只需写出IP地址的网络位即可。 1234[root@localhost ~]# cp -a /var/named/named.loopback /var/named/245.168.192.arpa [root@localhost ~]# vi /var/named/245.168.192.arpa#编辑反正配置文件即可，和正向解析格式类似#PTR为指针记录，仅用于反向解析中。 图：反向配置文件 第三步：检查配置文件，重启服务，测试。 12345[root@localhost ~]# named-checkconf [root@localhost ~]# named-checkzone 245.168.192 /var/named/245.168.192.arpa zone 245.168.192/IN: loaded serial 20181001OK[root@localhost ~]# systemctl restart named 图：反向解析测试 搭建DNS主从服务器：从而起到备份解析记录与负载均衡的作用，因此通过部署从服务器可以减轻主服务器的负载压力，还可以提升用户的查询效率。 第一步：在主服务器的区域配置文件中允许该从服务器的更新请求，即修改allow-update {允许更新区域信息的主机地址;};参数，然后重启主服务器的DNS服务程序。 123456789101112[root@localhost ~]# vi /etc/named.rfc191zone "example.com" IN &#123; type master; file "example.com.zone"; allow-update &#123; 192.168.245.129; &#125;;&#125;;zone "245.168.192.in-addr.arpa" IN &#123; type master; file "245.168.192.arpa"; allow-update &#123; 192.168.245.129; &#125;;&#125;;[root@localhost ~]# systemctl restart named 第二步： 在从服务器中填写主服务器的IP地址与要抓取的区域信息，然后重启服务。注意此时的服务类型应该是slave（从），而不再是master（主）。masters参数后面应该为主服务器的IP地址，而且file参数后面定义的是同步数据配置文件后要保存到的位置，稍后可以在该目录内看到同步的文件。 1234567891011121314151617181920212223242526[root@localhost ~]# vi /etc/named.confoptions &#123; listen-on port 53 &#123; any; &#125;; #改为any， listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; any; &#125;; #改为any，允许所有主机查询[root@localhost ~]# vi /etc/named.rfc191zone "example.com" IN &#123; type master; file "example.com.zone"; allow-update &#123; 192.168.245.129; &#125;;&#125;;zone "245.168.192.in-addr.arpa" IN &#123; type master; file "245.168.192.arpa"; allow-update &#123; 192.168.245.129; &#125;;&#125;;[root@localhost ~]# vi /etc/named.conf^C[root@localhost ~]# iptables -F #关闭防火墙[root@localhost ~]# setenforce 0setenforce: SELinux is disabled[root@localhost ~]# systemctl restart named[root@localhost ~]# systemctl enable named 重启以后，成功的话会在/var/named/slaves/下看见同步的文件。 123&gt; [root@localhost named]# ls /var/named/slaves/&gt; 245.168.192.arpa example.com.zone&gt; 第三步：测试。可将从服务的DNS地址改为自己，进行地址解析。 1234567891011121314151617181920212223242526[root@localhost named]# dig www.example.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-37.el7 &lt;&lt;&gt;&gt; www.example.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 9870;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 2;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;www.example.com. IN A;; ANSWER SECTION:www.example.com. 86400 IN A 192.168.245.128;; AUTHORITY SECTION:example.com. 86400 IN NS ns.example.com.;; ADDITIONAL SECTION:ns.example.com. 86400 IN A 192.168.245.128;; Query time: 1 msec;; SERVER: 192.168.245.129#53(192.168.245.129);; WHEN: Tue Oct 16 11:19:04 CST 2018;; MSG SIZE rcvd: 93 这种情况下，证明DNS主从服务器搭建成功。一旦主DNS发生故障，将自动利用DNS从服务器进行解析，实现了某种程度上的容错。 配置DNS安全的加密传输：TSIG主要是利用了密码编码的方式来保护区域信息的传输（Zone Transfer），即TSIG加密机制保证了DNS服务器之间传输域名区域信息的安全性。 第一步：在主服务上生产密钥。dnssec-keygen命令用于生成安全的DNS服务密钥，其格式为“dnssec-keygen [参数]”，常用的参数以及作用如下： 参数 作用 -a 指定加密算法，包括RSAMD5（RSA）、RSASHA1、DSA、NSEC3RSASHA1、NSEC3DSA等 -b 密钥长度（HMAC-MD5的密钥长度在1~512位之间） -n 密钥的类型（HOST表示与主机相关） 使用下述命令生成一个主机名称为master-slave的128位HMAC-MD5算法的密钥文件。在执行该命令后默认会在当前目录中生成公钥和私钥文件，在传输配置文件中会用到该秘钥。 123456789101112[root@localhost ~]# dnssec-keygen -a HMAC-MD5 -b 128 -n HOST master-slave Kmaster-slave.+157+15811[root@localhost ~]# cat Kmaster-slave.+157+47396.keymaster-slave. IN KEY 512 3 157 9+m1PlQOAF7xnMLClzNmXw==[root@localhost ~]# cat Kmaster-slave.+157+47396.private Private-key-format: v1.3Algorithm: 157 (HMAC_MD5)Key: 9+m1PlQOAF7xnMLClzNmXw== Bits: AAA=Created: 20181016033058Publish: 20181016033058Activate: 20181016033058 第二步：在主服务器中创建验证秘钥文件。 进入bind服务程序用于保存配置文件的目录，把刚刚生成的密钥名称、加密算法和私钥加密字符串按照下面格式写入到tansfer.key传输配置文件中。为了安全起见，我们需要将文件的所属组修改成named，并将文件权限设置得要小一点，然后把该文件做一个硬链接到/etc目录中。 12345678[root@localhost ~]# vim /var/named/chroot/etc/transfer.keykey "master-slave" &#123;algorithm hmac-md5;secret "9+m1PlQOAF7xnMLClzNmXw==";&#125;;[root@localhost ~]# chown root:named/var/named/chroot/etc/transfer.key[root@localhost ~]# ln /var/named/chroot/etc/transfer.key /etc/transfer.key 第三步：开启主服务器密钥验证功能： 开启并加载Bind服务的密钥验证功能。首先需要在主服务器的主配置文件中加载密钥验证文件，然后进行设置，使得只允许带有master-slave密钥认证的DNS服务器同步数据配置文件： 12345678910include "/etc/transfer.key"; //在主服务器中添加此条options &#123; listen-on port 53 &#123; any; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; any; &#125;; allow-transfer &#123; key master-slave; &#125;; 至此，DNS主服务器的TSIG密钥加密传输功能就已经配置完成。此时清空DNS从服务器同步目录中所有的数据配置文件，然后再次重启bind服务程序，这时就已经获取不到主服务器的配置文件了。 第四步：配置从服务器支持秘钥验证： 12345[root@localhost ~]# scp /var/named/chroot/etc/transfer.key root@192.168.245.128:/var/named/chroot/etc/transfer.keyroot@192.168.245.128's password: transfer.key 100% 79 0.1KB/s 00:00 [root@localhost ~]# chown root:named /var/named/chroot/etc/transfer.key[root@localhost ~]# ln /var/named/chroot/etc/transfer.key /etc/transfer.key 第五步：配置从服务器配置文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@localhost ~]# vi /etc/named.conf include "/etc/transfer.key"; #在此添加秘钥文件options &#123; listen-on port 53 &#123; any; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; any; &#125;; /* recursion. reduce such attack surface */ recursion yes; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;#在此添加主服务器地址，位置不能太靠前，否则bind服务程序会因为没有加载完预设参数而报错：server 192.168.245.128 &#123; keys &#123; master-slave; &#125;;&#125;;logging &#123; channel default_debug &#123; file "data/named.run"; severity dynamic; &#125;;&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;include "/etc/named.rfc1912.zones";include "/etc/named.root.key"; 至此，主从服务器配置完成，重启服务后，可在/var/named/slaves/目录下看到同步过来的文件。 123[root@localhost ~]# systemctl restart named[root@localhost ~]# ls /var/named/slaves/245.168.192.arpa example.com.zone 配置DNS缓存服务器：DNS缓存服务器（Caching DNS Server）是一种不负责域名数据维护的DNS服务器。简单来说，缓存服务器就是把用户经常使用到的域名与IP地址的解析记录保存在主机本地，从而提升下次解析的效率。DNS缓存服务器一般用于经常访问某些固定站点而且对这些网站的访问速度有较高要求的企业内网中，但实际的应用并不广泛。而且，缓存服务器是否可以成功解析还与指定的上级DNS服务器的允许策略有关。 1234567891011[root@localhost ~]# vim /etc/named.confoptions &#123;10 listen-on port 53 &#123; any; &#125;;11 listen-on-v6 port 53 &#123; ::1; &#125;;12 directory "/var/named";13 dump-file "/var/named/data/cache_dump.db";14 statistics-file "/var/named/data/named_stats.txt";15 memstatistics-file "/var/named/data/named_mem_stats.txt";16 allow-query &#123; any; &#125;;17 forwarders &#123; 目标地址; &#125;; #在此处添加转发地址即可......]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux笔记</tag>
        <tag>Linux服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下systemctl命令和service、chkconfig命令的区别]]></title>
    <url>%2F2018%2F10%2F15%2FLinux%E4%B8%8Bsystemctl%E5%91%BD%E4%BB%A4%E5%92%8Cservice%E3%80%81chkconfig%E5%91%BD%E4%BB%A4%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[systemctl和service、chkconfig命令的关系 systemctl命令：是一个systemd工具，主要负责控制systemd系统和服务管理器。 service命令：可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。 chkconfig命令：是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。 systemctl命令是系统服务管理器指令，它实际上将 service 和 chkconfig 这两个命令组合到一起。 systemctl是RHEL 7 的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。可以使用它永久性或只在当前会话中启用/禁用服务。 所以systemctl命令是service命令和chkconfig命令的集合和代替。 例如：使用service启动服务实际上也是调用systemctl命令。 12[root@localhost ~]# service httpd startRedirecting to /bin/systemctl start httpd.service systemctl命令的用法Systemctl命令简介：Systemctl是一个systemd工具，主要负责控制systemd系统和服务管理器。 Systemd是一个系统管理守护进程、工具和库的集合，用于取代System V初始进程。Systemd的功能是用于集中管理和配置类UNIX系统。 systemd即为system daemon,是linux下的一种init软件。 Systemctl命令常见用法：（1）列出所有可用单元： 1234567891011121314[root@localhost ~]# systemctl list-unit-files UNIT FILE STATE proc-sys-fs-binfmt_misc.automount static dev-hugepages.mount static dev-mqueue.mount static proc-fs-nfsd.mount static proc-sys-fs-binfmt_misc.mount static sys-fs-fuse-connections.mount static sys-kernel-config.mount static sys-kernel-debug.mount static tmp.mount disabledvar-lib-nfs-rpc_pipefs.mount static brandbot.path disabledcups.path enabled （2）列出所有可用单元： 1234567891011[root@localhost ~]# systemctl list-units UNIT LOAD ACTIVE SUB DESCRIPTION proc-sys-fs-binfmt_misc.automount loaded active waiting Arbitrary sys-devices-pci0000:00-0000:00:10.0-host2-target2:0:0-2:0:0:0-block-sda sys-devices-pci0000:00-0000:00:10.0-host2-target2:0:0-2:0:0:0-block-sda sys-devices-pci0000:00-0000:00:10.0-host2-target2:0:0-2:0:0:0-block-sda sys-devices-pci0000:00-0000:00:10.0-host2-target2:0:1-2:0:1:0-block-sdb sys-devices-pci0000:00-0000:00:10.0-host2-target2:0:1-2:0:1:0-block-sdb sys-devices-pci0000:00-0000:00:11.0-0000:02:01.0-net-ens33.device loade sys-devices-pci0000:00-0000:00:11.0-0000:02:02.0-sound-card0.device lo .............. (3)列出所有失败单元： 1234567891011[root@localhost ~]# systemctl --failed UNIT LOAD ACTIVE SUB DESCRIPTION● network.service loaded failed failed LSB: Bring up/down networking● teamd@team0.service loaded failed failed Team Daemon for device team0LOAD = Reflects whether the unit definition was properly loaded.ACTIVE = The high-level unit activation state, i.e. generalization of SUBSUB = The low-level unit activation state, values depend on unit type.2 loaded units listed. Pass --all to see loaded but inactive units, too.To show all installed unit files use 'systemctl list-unit-files'. （4）检查某个单元是否启动： 12[root@localhost ~]# systemctl is-enabled httpd.service enabled （5）检查某个服务的运行状态： 123456789101112131415161718[root@localhost ~]# systemctl status httpd.service ● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled) Active: active (running) since 日 2018-10-14 18:21:46 CST; 1 day 2h ago Docs: man:httpd(8) man:apachectl(8) Main PID: 19020 (httpd) Status: "Total requests: 0; Current requests/sec: 0; Current traffic: 0 B/sec" CGroup: /system.slice/httpd.service ├─19020 /usr/sbin/httpd -DFOREGROUND ├─27310 /usr/sbin/httpd -DFOREGROUND ├─27311 /usr/sbin/httpd -DFOREGROUND ├─27312 /usr/sbin/httpd -DFOREGROUND ├─27313 /usr/sbin/httpd -DFOREGROUND └─27314 /usr/sbin/httpd -DFOREGROUND10月 14 18:21:46 localhost systemd[1]: Starting The Apache HTTP Serv....10月 14 18:21:46 localhost httpd[19020]: AH00558: httpd: Could not r...e （6）列出所有服务： 123456789101112131415[root@localhost ~]# systemctl list-unit-files --type=serviceUNIT FILE STATE abrt-ccpp.service enabled abrt-oops.service enabled abrt-pstoreoops.service disabledabrt-xorg.service enabled abrtd.service enabled accounts-daemon.service enabled alsa-restore.service static alsa-state.service static alsa-store.service static arp-ethers.service disabledatd.service disabledauditd.service enabled auth-rpcgss-module.service static （7）启动，停止，重启服务等： 12345[root@localhost ~]# systemctl restart httpd.service# systemctl restart httpd.service# systemctl stop httpd.service# systemctl reload httpd.service# systemctl status httpd.service （8）查询服务是否激活，和配置是否开机启动： 123456[root@localhost ~]# systemctl is-active httpdactive[root@localhost ~]# systemctl disable httpdRemoved symlink /etc/systemd/system/multi-user.target.wants/httpd.service.[root@localhost ~]# systemctl enable httpd Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. （9）使用systemctl命令杀死服务： 1[root@localhost ~]# systemctl kill httpd （10）列出系统的各项服务，挂载，设备等： 123[root@localhost ~]# systemctl list-unit-files --type automount device path snapshot swap timerbusname mount service socket target （11）获得系统默认启动级别和设置默认启动级别： 123[root@localhost ~]# systemctl get-default graphical.target[root@localhost ~]# systemctl set-default multi-user.target （12）启动运行等级： 1systemctl isolate multiuser.target （13）重启、停止，挂起、休眠系统等： 12345# systemctl reboot# systemctl halt# systemctl suspend# systemctl hibernate# systemctl hybrid-sleep Service命令用法service命令可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。 service命令的作用是去/etc/init.d目录下寻找相应的服务，进行开启和关闭等操作。 使用示例： 开启关闭一个服务：service httpd start/stop 12[root@localhost ~]# service httpd startRedirecting to /bin/systemctl start httpd.service 查看系统服务的状态：service –status-all 12345678910111213[root@localhost ~]# service --status-all未加载 netconsole 模块已配置设备：lo ens33 ens33.old team0 team0-port1 team0-port1.old team0-port2 team0-port2.old team0.old当前活跃设备：lo ens33 virbr0 ens38 ens39 team0● rhnsd.service - LSB: Starts the Spacewalk Daemon Loaded: loaded (/etc/rc.d/init.d/rhnsd; bad; vendor preset: disabled) Active: active (running) since 五 2018-10-12 14:53:19 CST; 3 days ago Docs: man:systemd-sysv-generator(8) Main PID: 1380 (rhnsd) CGroup: /system.slice/rhnsd.service └─1380 rhnsd chkconfig命令用法chkconfig是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。 chkconfig可以更新(启动或停止)和查询系统服务(service)运行级信息。更简单一点，chkconfig是一个用于维护/etc/rc[0-6].d目录的命令行工具。 chkconfig常见用法： 123456789[root@localhost ~]# chkconfig --helpchkconfig 版本 1.7.2 - 版权 (C) 1997-2000 红帽公司在 GNU 公共许可条款下，本软件可以自由重发行。用法： chkconfig [--list] [--type &lt;类型&gt;] [名称] chkconfig --add &lt;名称&gt; chkconfig --del &lt;名称&gt; chkconfig --override &lt;名称&gt; chkconfig [--level &lt;级别&gt;] [--type &lt;类型&gt;] &lt;名称&gt; &lt;on|off|reset|resetpriorities&gt; （一）设置service开机是否启动： 1chkconfig name on/off/reset on、off、reset用于改变service的启动信息。 on表示开启，off表示关闭，reset表示重置。 默认情况下，on和off开关只对运行级2，3，4，5有效，reset可以对所有运行级有效。 12[root@localhost ~]# chkconfig httpd on注意：正在将请求转发到“systemctl enable httpd.service”。 在Redhat7上，运行chkconfig命令，都会被转到systemcle命令上。 （2）设置service运行级别： 1chkconfig --level levels 该命令可以用来指定服务的运行级别，即指定运行级别2,3,4,5等。 等级0表示：表示关机 等级1表示：单用户模式 等级2表示：无网络连接的多用户命令行模式 等级3表示：有网络连接的多用户命令行模式 等级4表示：不可用 等级5表示：带图形界面的多用户模式 等级6表示：重新启动 例如： 12[root@localhost ~]# chkconfig --level 5 httpd on注意：正在将请求转发到“systemctl enable httpd.service” （三）列出service启动信息： 1# chkconfig --list [name] 如果不指定name，会列出所有services的信息。 每个service每个运行级别都会有一个启动和停止脚本；当切换运行级别时，init不会重启已经启动的service，也不会重新停止已经停止的service。 例如： 12345678910[root@localhost ~]# chkconfig --list注意：该输出结果只显示 SysV 服务，并不包含原生 systemd 服务。SysV 配置数据可能被原生 systemd 配置覆盖。 如果您想列出 systemd 服务,请执行 'systemctl list-unit-files'。 欲查看对特定 target 启用的服务请执行 'systemctl list-dependencies [target]'。netconsole 0:关 1:关 2:关 3:关 4:关 5:关 6:关network 0:关 1:关 2:开 3:开 4:开 5:开 6:关rhnsd 0:关 1:关 2:开 3:开 4:开 5:开 6:关 总结：service命令的功能基本都被systemct取代。直接使用systemctl命令即可。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux笔记，Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（12）Spring JDBC框架和事务管理]]></title>
    <url>%2F2018%2F08%2F05%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89Spring-JDBC%E6%A1%86%E6%9E%B6%E5%92%8C%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spring JDBC框架JDBC框架概述：在使用普通的 JDBC 数据库时，就会很麻烦的写不必要的代码来处理异常，打开和关闭数据库连接等。但 Spring JDBC 框架负责所有的低层细节，从开始打开连接，准备和执行 SQL 语句，处理异常，处理事务，到最后关闭连接。 所以当从数据库中获取数据时，你所做的是定义连接参数，指定要执行的 SQL 语句，每次迭代完成所需的工作。 Spring JDBC 提供几种方法和数据库中相应的不同的类与接口。我将给出使用 JdbcTemplate 类框架的经典和最受欢迎的方法。这是管理所有数据库通信和异常处理的中央框架类。 JdbcTemplate类型：JdbcTemplate 类执行 SQL 查询、更新语句和存储过程调用，执行迭代结果集和提取返回参数值。它也捕获 JDBC 异常并转换它们到 org.springframework.dao 包中定义的通用类、更多的信息、异常层次结构。 JdbcTemplate 类的实例是线程安全配置的。所以你可以配置 JdbcTemplate 的单个实例，然后将这个共享的引用安全地注入到多个 DAOs 中。 使用 JdbcTemplate 类时常见的做法是在你的 Spring 配置文件中配置数据源，然后共享数据源 bean 依赖注入到 DAO 类中，并在数据源的设值函数中创建了 JdbcTemplate。 1234567&lt;bean id="dataSource"class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/jsp_db"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt;&lt;/bean&gt; 数据访问对象（DAO）：DAO 代表常用的数据库交互的数据访问对象。DAOs 提供一种方法来读取数据并将数据写入到数据库中，它们应该通过一个接口显示此功能，应用程序的其余部分将访问它们。 在 Spring 中，数据访问对象(DAO)支持很容易用统一的方法使用数据访问技术，如 JDBC、Hibernate、JPA 或者 JDO。 Spring JDBC 示例:目标：通过Spring JDBC 框架，来实现创建一个数据表。 123456CREATE TABLE Student( ID INT NOT NULL AUTO_INCREMENT, NAME VARCHAR(20) NOT NULL, AGE INT NOT NULL, PRIMARY KEY (ID)); StudentDAO.java 123456789101112131415161718192021222324package jdbc;import java.util.List;import javax.sql.DataSource;public interface StudentDAO &#123; //用于初始化数据库连接的方法 public void setDataSource(DataSource dateSource); //这是用来在学生表中创建一条记录的方法。 public void create(String name, Integer age); //这是用于列出学生表中与通过的学生ID相对应的的记录的方法。 public Student getStudent(Integer id); //这是用来列出学生表中的所有记录的方法。 public List&lt;Student&gt; listStudents(); //这是用于删除学生表中与通过的学生id相对应的记录的方法。 public void delete(Integer id); //这是用来将一条记录更新到学生表中的方法。 public void update(Integer id, Integer age);&#125; Student.java 12345678910111213141516171819202122232425package jdbc;public class Student &#123; private Integer age; private String name; private Integer id; public void setAge(Integer age) &#123; this.age = age; &#125; public Integer getAge() &#123; return age; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public Integer getId() &#123; return id; &#125;&#125; StudentMapper.java 1234567891011121314package jdbc;import java.sql.ResultSet;import java.sql.SQLException;import org.springframework.jdbc.core.RowMapper;public class StudentMapper implements RowMapper&lt;Student&gt; &#123; public Student mapRow(ResultSet rs, int rowNum) throws SQLException &#123; Student student = new Student(); student.setId(rs.getInt("id")); student.setName(rs.getString("name")); student.setAge(rs.getInt("age")); return student; &#125;&#125; 下面是为定义的 DAO 接口 StudentDAO 的实现类文件 StudentJDBCTemplate.java： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package jdbc;import java.util.List;import javax.sql.DataSource;import org.springframework.jdbc.core.JdbcTemplate;public class StudentJDBCTemplate implements StudentDAO&#123; private DataSource dataSource; private JdbcTemplate jdbcTemplateObject; @Override public void setDataSource(DataSource dataSource) &#123; this.dataSource = dataSource; this.jdbcTemplateObject = new JdbcTemplate(dataSource); &#125; @Override public void create(String name, Integer age) &#123; String SQL = "insert into Student (name, age) values (?, ?)"; jdbcTemplateObject.update(SQL, name, age); System.out.println("创建记录名：" + name + "年龄：" + age); return; &#125; @Override public Student getStudent(Integer id) &#123; String SQL = "select * from Student where id = ?"; Student student = jdbcTemplateObject.queryForObject(SQL, new Object[]&#123;id&#125;, new StudentMapper()); return student; &#125; @Override public List&lt;Student&gt; listStudents() &#123; String SQL = "select * from Student"; List &lt;Student&gt; students = jdbcTemplateObject.query(SQL, new StudentMapper()); return students; &#125; @Override public void delete(Integer id) &#123; String SQL = "delete from Student where id = ?"; jdbcTemplateObject.update(SQL, id); System.out.println("删除ID为 : " + id + " 的记录！" ); return; &#125; @Override public void update(Integer id, Integer age) &#123; String SQL = "update Student set age = ? where id = ?"; jdbcTemplateObject.update(SQL, age, id); System.out.println("更新记录的学生ID为 = " + id ); return; &#125;&#125; MainApp.java 1234567891011121314151617181920212223242526272829303132333435package jdbc;import java.util.List;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("JDBC.xml"); StudentJDBCTemplate studentJDBCTemplate = (StudentJDBCTemplate)context.getBean("studentJDBCTemplate"); System.out.println("------创建记录--------" ); studentJDBCTemplate.create("xiaoming", 11); studentJDBCTemplate.create("xiaoli", 2); studentJDBCTemplate.create("xiaozhang", 15); System.out.println(); System.out.println("------列出所有记录--------" ); List&lt;Student&gt; students = studentJDBCTemplate.listStudents(); for (Student record : students) &#123; System.out.print("ID : " + record.getId() ); System.out.print(", Name : " + record.getName() ); System.out.println(", Age : " + record.getAge()); &#125; System.out.println("----更新ID=2的记录 -----" ); studentJDBCTemplate.update(2, 20); System.out.println("----列出ID=2的记录 -----" ); Student student = studentJDBCTemplate.getStudent(2); System.out.print("ID : " + student.getId() ); System.out.print(", Name : " + student.getName() ); System.out.println(", Age : " + student.getAge()); &#125;&#125; 配置文件 JDBC.xml 的内容 : 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd "&gt; &lt;!-- Initialization for data source --&gt; &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/jsp_db?useSSL=false"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/bean&gt; &lt;!-- Definition for studentJDBCTemplate bean --&gt; &lt;bean id="studentJDBCTemplate" class="jdbc.StudentJDBCTemplate"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt;&lt;/beans&gt; 运行结果： 123456789101112131415------创建记录--------创建记录名：xiaoming年龄：11创建记录名：xiaoli年龄：2创建记录名：xiaozhang年龄：15------列出所有记录--------ID : 1, Name : xiaoming, Age : 11ID : 2, Name : xiaoli, Age : 20ID : 3, Name : xiaozhang, Age : 15 ----更新ID=2的记录 -----更新记录的学生ID为 = 2 ----列出ID=2的记录 -----ID : 2, Name : xiaoli, Age : 20 Spring事务管理事物管理：一个数据库事务是一个被视为单一的工作单元的操作序列。这些操作应该要么完整地执行，要么完全不执行。事务管理是一个重要组成部分，RDBMS 面向企业应用程序，以确保数据完整性和一致性。事务的概念可以描述为具有以下四个关键属性说成是 ACID： 原子性：事务应该当作一个单独单元的操作，这意味着整个序列操作要么是成功，要么是失败的。 一致性：这表示数据库的引用完整性的一致性，表中唯一的主键等。 隔离性：可能同时处理很多有相同的数据集的事务，每个事务应该与其他事务隔离，以防止数据损坏。 持久性：一个事务一旦完成全部操作后，这个事务的结果必须是永久性的，不能因系统故障而从数据库中删除。 一个真正的 RDBMS 数据库系统将为每个事务保证所有的四个属性。使用 SQL 发布到数据库中的事务的简单视图如下： 使用 begin transaction 命令开始事务。 使用 SQL 查询语句执行各种删除、更新或插入操作。 如果所有的操作都成功，则执行提交操作，否则回滚所有操作。 Spring 框架在不同的底层事务管理 APIs 的顶部提供了一个抽象层。Spring 的事务支持旨在通过添加事务能力到 POJOs 来提供给 EJB 事务一个选择方案。Spring 支持编程式和声明式事务管理。EJBs 需要一个应用程序服务器，但 Spring 事务管理可以在不需要应用程序服务器的情况下实现。 局部事物和全局事物：局部事务是特定于一个单一的事务资源，如一个 JDBC 连接，而全局事务可以跨多个事务资源事务，如在一个分布式系统中的事务。 局部事务管理在一个集中的计算环境中是有用的，该计算环境中应用程序组件和资源位于一个单位点，而事务管理只涉及到一个运行在一个单一机器中的本地数据管理器。局部事务更容易实现。 全局事务管理需要在分布式计算环境中，所有的资源都分布在多个系统中。在这种情况下事务管理需要同时在局部和全局范围内进行。分布式或全局事务跨多个系统执行，它的执行需要全局事务管理系统和所有相关系统的局部数据管理人员之间的协调。 Spring支持两种类型的事物管理： 编程式事务管理 ：这意味着你在编程的帮助下有管理事务。这给了你极大的灵活性，但却很难维护。 声明式事务管理 ：这意味着你从业务代码中分离事务管理。你仅仅使用注释或 XML 配置来管理事务。 声明式事务管理比编程式事务管理更可取，尽管它不如编程式事务管理灵活，但它允许你通过代码控制事务。但作为一种横切关注点，声明式事务管理可以使用 AOP 方法进行模块化。Spring 支持使用 Spring AOP 框架的声明式事务管理。 Spring事物抽象：Spring 事务抽象的关键是由 org.springframework.transaction.PlatformTransactionManager 接口定义，如下所示： 123456public interface PlatformTransactionManager &#123; TransactionStatus getTransaction(TransactionDefinition definition); throws TransactionException; void commit(TransactionStatus status) throws TransactionException; void rollback(TransactionStatus status) throws TransactionException;&#125; 序号 方法 &amp; 描述 1 TransactionStatus getTransaction(TransactionDefinition definition)根据指定的传播行为，该方法返回当前活动事务或创建一个新的事务。 2 void commit(TransactionStatus status)该方法提交给定的事务和关于它的状态。 3 void rollback(TransactionStatus status)该方法执行一个给定事务的回滚。 TransactionDefinition 是在 Spring 中事务支持的核心接口，它的定义如下： 1234567public interface TransactionDefinition &#123; int getPropagationBehavior(); int getIsolationLevel(); String getName(); int getTimeout(); boolean isReadOnly();&#125; 序号 方法 &amp; 描述 1 int getPropagationBehavior()该方法返回传播行为。Spring 提供了与 EJB CMT 类似的所有的事务传播选项。 2 int getIsolationLevel()该方法返回该事务独立于其他事务的工作的程度。 3 String getName()该方法返回该事务的名称。 4 int getTimeout()该方法返回以秒为单位的时间间隔，事务必须在该时间间隔内完成。 5 boolean isReadOnly()该方法返回该事务是否是只读的。 下面是隔离级别的可能值: 序号 隔离 &amp; 描述 1 TransactionDefinition.ISOLATION_DEFAULT这是默认的隔离级别。 2 TransactionDefinition.ISOLATION_READ_COMMITTED表明能够阻止误读；可以发生不可重复读和虚读。 3 TransactionDefinition.ISOLATION_READ_UNCOMMITTED表明可以发生误读、不可重复读和虚读。 4 TransactionDefinition.ISOLATION_REPEATABLE_READ表明能够阻止误读和不可重复读；可以发生虚读。 5 TransactionDefinition.ISOLATION_SERIALIZABLE表明能够阻止误读、不可重复读和虚读。 下面是传播类型的可能值: 序号 传播 &amp; 描述 1 TransactionDefinition.PROPAGATION_MANDATORY支持当前事务；如果不存在当前事务，则抛出一个异常。 2 TransactionDefinition.PROPAGATION_NESTED如果存在当前事务，则在一个嵌套的事务中执行。 3 TransactionDefinition.PROPAGATION_NEVER不支持当前事务；如果存在当前事务，则抛出一个异常。 4 TransactionDefinition.PROPAGATION_NOT_SUPPORTED不支持当前事务；而总是执行非事务性。 5 TransactionDefinition.PROPAGATION_REQUIRED支持当前事务；如果不存在事务，则创建一个新的事务。 6 TransactionDefinition.PROPAGATION_REQUIRES_NEW创建一个新事务，如果存在一个事务，则把当前事务挂起。 7 TransactionDefinition.PROPAGATION_SUPPORTS支持当前事务；如果不存在，则执行非事务性。 8 TransactionDefinition.TIMEOUT_DEFAULT使用默认超时的底层事务系统，或者如果不支持超时则没有。 TransactionStatus 接口为事务代码提供了一个简单的方法来控制事务的执行和查询事务状态。 1234567public interface TransactionStatus extends SavepointManager &#123; boolean isNewTransaction(); boolean hasSavepoint(); void setRollbackOnly(); boolean isRollbackOnly(); boolean isCompleted();&#125; 序号 方法 &amp; 描述 1 boolean hasSavepoint()该方法返回该事务内部是否有一个保存点，也就是说，基于一个保存点已经创建了嵌套事务。 2 boolean isCompleted()该方法返回该事务是否完成，也就是说，它是否已经提交或回滚。 3 boolean isNewTransaction()在当前事务时新的情况下，该方法返回 true。 4 boolean isRollbackOnly()该方法返回该事务是否已标记为 rollback-only。 5 void setRollbackOnly()该方法设置该事务为 rollback-only 标记。 Spring编程式事物管理：编程式事务管理方法允许你在对你的源代码编程的帮助下管理事务。这给了你极大地灵活性，但是它很难维护。 首先得创建两张表： Student表： 123456CREATE TABLE Student( ID INT NOT NULL AUTO_INCREMENT, NAME VARCHAR(20) NOT NULL, AGE INT NOT NULL, PRIMARY KEY (ID)); 第二个表是 Marks，用来存储基于年份的学生的标记。这里 SID 是 Student 表的外键。 12345CREATE TABLE Marks( SID INT NOT NULL, MARKS INT NOT NULL, YEAR INT NOT NULL); 直接使用 PlatformTransactionManager 来实现编程式方法从而实现事务。要开始一个新事务，你需要有一个带有适当的 transaction 属性的 TransactionDefinition 的实例。这个例子中，我们使用默认的 transaction 属性简单的创建了 DefaultTransactionDefinition 的一个实例。 当 TransactionDefinition 创建后，你可以通过调用 getTransaction() 方法来开始你的事务，该方法会返回 TransactionStatus 的一个实例。 TransactionStatus 对象帮助追踪当前的事务状态，并且最终，如果一切运行顺利，你可以使用 PlatformTransactionManager 的 commit() 方法来提交这个事务，否则的话，你可以使用 rollback() 方法来回滚整个操作。 下面是数据访问对象接口文件 StudentDAO.java 的内容： 12345678910111213141516package transaction;import java.util.List;import javax.sql.DataSource;public interface StudentDAO &#123; //这是用于初始化数据库资源(即连接)的方法。 public void setDataSource(DataSource ds); //这是用来在学生和标记表中创建一条记录的方法。 public void create(String name, Integer age, Integer marks, Integer year); //这是用来列出学生和标记表中的所有记录的方法 public List&lt;StudentMarks&gt; listStudents();&#125; StudentMarks.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package transaction;public class StudentMarks &#123; private Integer age; private String name; private Integer id; private Integer marks; private Integer year; private Integer sid; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public Integer getMarks() &#123; return marks; &#125; public void setMarks(Integer marks) &#123; this.marks = marks; &#125; public Integer getYear() &#123; return year; &#125; public void setYear(Integer year) &#123; this.year = year; &#125; public Integer getSid() &#123; return sid; &#125; public void setSid(Integer sid) &#123; this.sid = sid; &#125; &#125; StudentMarksMapper.java 123456789101112131415161718192021package transaction;import java.sql.ResultSet;import java.sql.SQLException;import org.springframework.jdbc.core.RowMapper;public class StudentMarksMapper implements RowMapper&lt;StudentMarks&gt; &#123; @Override public StudentMarks mapRow(ResultSet rs, int rowNum) throws SQLException &#123; StudentMarks studentMarks = new StudentMarks(); studentMarks.setId(rs.getInt("id")); studentMarks.setAge(rs.getInt("age")); studentMarks.setName(rs.getString("name")); studentMarks.setMarks(rs.getInt("marks")); studentMarks.setYear(rs.getInt("year")); studentMarks.setSid(rs.getInt("sid")); return studentMarks; &#125;&#125; 下面是定义的 DAO 接口 StudentDAO 实现类文件 StudentJDBCTemplate.java： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package transaction;import java.util.List;import javax.sql.DataSource;import org.springframework.dao.DataAccessException;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.transaction.PlatformTransactionManager;import org.springframework.transaction.TransactionDefinition;import org.springframework.transaction.TransactionStatus;import org.springframework.transaction.support.DefaultTransactionDefinition;public class StudentJDBCTemplate implements StudentDAO &#123; private DataSource dataSource; private JdbcTemplate jdbcTemplateObject; private PlatformTransactionManager transactionManager; @Override public void setDataSource(DataSource dataSource) &#123; this.dataSource = dataSource; this.jdbcTemplateObject = new JdbcTemplate(dataSource); &#125; public void setTransactionManager( PlatformTransactionManager transactionManager) &#123; this.transactionManager = transactionManager; &#125; @Override public void create(String name, Integer age, Integer marks, Integer year)&#123; TransactionDefinition def = new DefaultTransactionDefinition(); TransactionStatus status = transactionManager.getTransaction(def); try &#123; String SQL1 = "insert into Student (name, age) values (?, ?)"; jdbcTemplateObject.update( SQL1, name, age); // 获取要在标记表中使用的最新学生ID. String SQL2 = "select max(id) from Student"; int sid = jdbcTemplateObject.queryForObject(SQL2, Integer.class); String SQL3 = "insert into Marks(sid, marks, year) " + "values (?, ?, ?)"; jdbcTemplateObject.update( SQL3, sid, marks, year); System.out.println("Created Name = " + name + ", Age = " + age); transactionManager.commit(status); &#125; catch (DataAccessException e) &#123; System.out.println("Error in creating record, rolling back"); transactionManager.rollback(status); throw e; &#125; return; &#125; @Override public List&lt;StudentMarks&gt; listStudents() &#123; String SQL = "select * from Student, Marks where Student.id=Marks.sid"; List &lt;StudentMarks&gt; studentMarks = jdbcTemplateObject.query(SQL, new StudentMarksMapper()); return studentMarks; &#125;&#125; MainApp.java 123456789101112131415161718192021222324252627package transaction;import java.util.List;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import transaction.StudentJDBCTemplate;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("transaction.xml"); StudentJDBCTemplate studentJDBCTemplate = (StudentJDBCTemplate)context.getBean("studentJDBCTemplate"); System.out.println("------创建记录--------" ); studentJDBCTemplate.create("Zara", 11, 99, 2010); studentJDBCTemplate.create("Nuha", 20, 97, 2010); studentJDBCTemplate.create("Ayan", 25, 100, 2011); System.out.println("------列出所有记录--------" ); List&lt;StudentMarks&gt; studentMarks = studentJDBCTemplate.listStudents(); for (StudentMarks record : studentMarks) &#123; System.out.print("ID : " + record.getId() ); System.out.print(", Name : " + record.getName() ); System.out.print(", Marks : " + record.getMarks()); System.out.print(", Year : " + record.getYear()); System.out.println(", Age : " + record.getAge()); &#125; &#125;&#125; 配置文件：transacation.xml 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd "&gt; &lt;!-- Initialization for data source --&gt; &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/jsp_db?useSSL=false"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/bean&gt; &lt;!-- Initialization for TransactionManager --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- Definition for studentJDBCTemplate bean --&gt; &lt;bean id="studentJDBCTemplate" class="transaction.StudentJDBCTemplate"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;property name="transactionManager" ref="transactionManager" /&gt; &lt;/bean&gt;&lt;/beans&gt; 程序运行结果： 12345678------创建记录--------Created Name = Zara, Age = 11Created Name = Nuha, Age = 20Created Name = Ayan, Age = 25------列出所有记录--------ID : 1, Name : Zara, Marks : 99, Year : 2010, Age : 11ID : 2, Name : Nuha, Marks : 97, Year : 2010, Age : 20ID : 3, Name : Ayan, Marks : 100, Year : 2011, Age : 25 Spring声明式事务管理：声明式事务管理方法允许你在配置的帮助下而不是源代码硬编程来管理事务。这意味着你可以将事务管理从事务代码中隔离出来。你可以只使用注释或基于配置的 XML 来管理事务。 bean 配置会指定事务型方法。下面是与声明式事务相关的步骤： 我们使用标签，它创建一个事务处理的建议，同时，我们定义一个匹配所有方法的切入点，我们希望这些方法是事务型的并且会引用事务型的建议。 如果在事务型配置中包含了一个方法的名称，那么创建的建议在调用方法之前就会在事务中开始进行。 目标方法会在 try / catch 块中执行。 如果方法正常结束，AOP 建议会成功的提交事务，否则它执行回滚操作。 StudentDAO.java 12345678910111213141516package transaction;import java.util.List;import javax.sql.DataSource;public interface StudentDAO &#123; //这是用于初始化数据库资源(即连接)的方法。 public void setDataSource(DataSource ds); //这是用来在学生和标记表中创建一条记录的方法。 public void create(String name, Integer age, Integer marks, Integer year); //这是用来列出学生和标记表中的所有记录的方法 public List&lt;StudentMarks&gt; listStudents();&#125; StudentMarks.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package transaction;public class StudentMarks &#123; private Integer age; private String name; private Integer id; private Integer marks; private Integer year; private Integer sid; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public Integer getMarks() &#123; return marks; &#125; public void setMarks(Integer marks) &#123; this.marks = marks; &#125; public Integer getYear() &#123; return year; &#125; public void setYear(Integer year) &#123; this.year = year; &#125; public Integer getSid() &#123; return sid; &#125; public void setSid(Integer sid) &#123; this.sid = sid; &#125;&#125; StudentMarksMapper.java 123456789101112131415161718192021package transaction;import java.sql.ResultSet;import java.sql.SQLException;import org.springframework.jdbc.core.RowMapper;public class StudentMarksMapper implements RowMapper&lt;StudentMarks&gt; &#123; @Override public StudentMarks mapRow(ResultSet rs, int rowNum) throws SQLException &#123; StudentMarks studentMarks = new StudentMarks(); studentMarks.setId(rs.getInt("id")); studentMarks.setAge(rs.getInt("age")); studentMarks.setName(rs.getString("name")); studentMarks.setMarks(rs.getInt("marks")); studentMarks.setYear(rs.getInt("year")); studentMarks.setSid(rs.getInt("sid")); return studentMarks; &#125;&#125; StudentJDBCTemplate.java： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package transaction;import java.util.List;import javax.sql.DataSource;import org.springframework.dao.DataAccessException;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.transaction.PlatformTransactionManager;import org.springframework.transaction.TransactionDefinition;import org.springframework.transaction.TransactionStatus;import org.springframework.transaction.support.DefaultTransactionDefinition;public class StudentJDBCTemplate implements StudentDAO &#123; private DataSource dataSource; private JdbcTemplate jdbcTemplateObject; private PlatformTransactionManager transactionManager; @Override public void setDataSource(DataSource dataSource) &#123; this.dataSource = dataSource; this.jdbcTemplateObject = new JdbcTemplate(dataSource); &#125; public void setTransactionManager( PlatformTransactionManager transactionManager) &#123; this.transactionManager = transactionManager; &#125; @Override public void create(String name, Integer age, Integer marks, Integer year)&#123; try &#123; String SQL1 = "insert into Student (name, age) values (?, ?)"; jdbcTemplateObject.update( SQL1, name, age); //获取要在标记表中使用的最新学生ID。 String SQL2 = "select max(id) from Student"; int sid = jdbcTemplateObject.queryForObject(SQL2, Integer.class ); String SQL3 = "insert into Marks(sid, marks, year) " + "values (?, ?, ?)"; jdbcTemplateObject.update( SQL3, sid, marks, year); System.out.println("Created Name = " + name + ", Age = " + age); // 来模拟异常 throw new RuntimeException("simulate Error condition") ; &#125; catch (DataAccessException e) &#123; System.out.println("创建记录时的错误, 回滚"); throw e; &#125; &#125; @Override public List&lt;StudentMarks&gt; listStudents() &#123; String SQL = "select * from Student, Marks where Student.id=Marks.sid"; List &lt;StudentMarks&gt; studentMarks = jdbcTemplateObject.query(SQL, new StudentMarksMapper()); return studentMarks; &#125;&#125; MainApp.java 1234567891011121314151617181920212223242526package transaction;import java.util.List;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("transaction2.xml"); StudentDAO studentJDBCTemplate = (StudentDAO)context.getBean("studentJDBCTemplate"); System.out.println("------创建记录--------" ); studentJDBCTemplate.create("Zara", 11, 99, 2010); studentJDBCTemplate.create("Nuha", 20, 97, 2010); studentJDBCTemplate.create("Ayan", 25, 100, 2011); System.out.println("------列出所有记录--------" ); List&lt;StudentMarks&gt; studentMarks = studentJDBCTemplate.listStudents(); for (StudentMarks record : studentMarks) &#123; System.out.print("ID : " + record.getId() ); System.out.print(", Name : " + record.getName() ); System.out.print(", Marks : " + record.getMarks()); System.out.print(", Year : " + record.getYear()); System.out.println(", Age : " + record.getAge()); &#125; &#125;&#125; 配置文件transcation2.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd"&gt; &lt;!-- Initialization for data source --&gt; &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/jsp_db?useSSL=false"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/bean&gt; &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="create"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;aop:config&gt; &lt;aop:pointcut id="createOperation" expression="execution(* transaction2.StudentJDBCTemplate.create(..))"/&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="createOperation"/&gt; &lt;/aop:config&gt; &lt;!-- Initialization for TransactionManager --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- Definition for studentJDBCTemplate bean --&gt; &lt;bean id="studentJDBCTemplate" class="transaction2.StudentJDBCTemplate"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;/beans&gt; 运行结果： 123------创建记录--------Created Name = Zara, Age = 11Exception in thread "main" java.lang.RuntimeException: simulate Error condition]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java学习笔记</tag>
        <tag>JDBC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（11）Spring AOP]]></title>
    <url>%2F2018%2F08%2F05%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89Spring-AOP%2F</url>
    <content type="text"><![CDATA[AOP简介##AOP的概念： AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 它是一种思想，可在不改变程序源码的情况下为程序添加额外的功能。 AOP的发展阶段： 静态AOP：Aspect形式， 通过特定的编译器，将实现后的Aspect编译并织入系统的静态类中。 动态AOP：AOP的织入过程在系统运行开始只有进行，而不是预先编译到系统中。 AOP的主要意图：允许通过分离应用的业务逻辑与系统级服务进行内聚性的开发。应用对象值实现业务逻辑即可，并不负责它的系统级关注点。 AOP的主要应用：日志记录、跟踪、监控和优化，性能统计、优化，安全、权限控制，应用系统的异常捕捉及处理，事务处理，缓存，持久化，懒加载（Lazy loading），内容传递，调试，资源池，同步等等。 AOP术语： 连接点：程序执行的某个特定位置，比如类初始化前，初始化后，方法调用前，方法调用后等等 切点：通过切点来定位特定的连接点 。 增强：织入到目标类连接点上的一端程序代码。 目标对象：增强逻辑的织入目标类。 引介：引介是一种特殊的增强，他为类添加一些属性和方法。 织入：将增强添加对目标类的具体连接点的上的过程。 代理：一个类被AOP织入增强后，会产生一个结果类，该类融合了原类和增强逻辑的代理类。 切面:又切点和增强组成，既包括了横切逻辑的定义，也包括了连接点的定义。 AOP的实现者： AspectJ： AspectJ是目前最完善的AOP语言，对Java编程语言的进行了扩展，定义了AOP语法，能够在编译期间提供横切代码的织入。AspectJ提供了两种横切实现机制，一种称为动态横切（Dynamic Crosscutting），另一种称为静态横切（Static Crosscutting）。 AspectWerkz： 基于Java的简单、动态和轻量级的AOP框架，支持运行期或类装载期织入横切代码，它拥有一个特殊的类装载器。它与AspectJ项目已经合并，第一个发布版本是AspectJ5:扩展AspectJ语言，以基于注解的方式支持类似AspectJ的代码风格。 JBoss AOP： JBoss是一个开源的符合J2EE规范的应用服务器，作为J2EE规范的补充，JBoss中引入了AOP框架，为普通Java类提供了J2EE服务，而无需遵循EJB规范。JBoss通过类载入时，使用Javassist对字节码操作实现动态AOP框架。 Spring AOP： Spring AOP使用纯Java实现，不需要专门的编译过程，不需要特殊的类装载器，它在运行期通过代理方式向目标类织入增强代码。Spring并不尝试提供最完整的AOP实现，主要侧重于提供一种和Spring IoC容器整合的AOP实现，以解决企业级开发中常见问题。 AOP的实现方法利用Proxy 实现AOP功能 ：采用Proxy类方法，基本流程为：主函数–&gt;代理–&gt;目标对象的方法。对于Proxy类有一个使用前提，就是目标对象必须要实现接口，否则不能使用这个方法。实现AOP功能步骤如下： 创建接口：StudentInterface.java 创建接口实现类：Student.java 创建代理工厂类：ProxyFactory.java 利用Proxy实现AOP功能的总结如下： 目标对象必须实现接口 返回创建的代理对象 重写invoke()方法 限制条件放在invoke()方法 利用CGLib 实现AOP功能 ：CGLib(Code Generation Library)是一个开源项目,它是一个强大的，高性能，高质量的Code生成类库，它可以在运行期扩展Java类与实现Java接口。实现AOP功能步骤如下所示： 引入Jar文件 创建实体类 创建CGLIB代理类 创建入口类进行测试 利用Spring注解方式实现AOP功能：利用Spring注解方式来实现前置通知，后置通知，例外通知以及环绕通知等。实现AOP功能步骤如下： 引入Jar文件 配置AOP命名空间 创建目标对象类 创建切面 在配置文件中配置切面 创建入口类进行测试 利用Spring XML配置方式实现AOP功能：利用Spring XML文件配置方式实现AOP功能步骤如下： 引入Jar文件 配置AOP命名空间 创建目标对象类 创建切面 在配置文件中配置 创建入口类进行测试 Spring AOP的增强类型：1 前置增强顾名思义就是在目标方法执行前织入增强。BeforeAdvice表示前置增强。属于Spring提供的增强所以属于方法级增强。MethodBeforeAdvice为目前可用前置增强。 2 后置增强顾名思义就是在目标方法执行后织入增强。AfterReturningAdvice表示后置增强。属于Spring提供的增强所以属于方法级增强。 3 环绕赠强MethodInterceptor是前置增强和后置增强的综合，在目标方法执行前后都织入增强。可以用该增强替换前置增强和后置增强 4 异常抛出增强ThrowsAdvice表示在目标方法抛出异常时实施增强 5 引介增强IntroductionInterceptor在目标类中添加属性和行为]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（10）Spring Bean配置]]></title>
    <url>%2F2018%2F08%2F04%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89Spring-Bean%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Spring Beans自动装配Beans自动装配：Spring 容器可以在不使用&lt;constructor-arg&gt;和&lt;property&gt; 元素的情况下自动装配相互协作的 bean 之间的关系，这有助于减少编写一个大的基于 Spring 的应用程序的 XML 配置的数量。 自动装配模式：下列自动装配模式，它们可用于指示 Spring 容器为来使用自动装配进行依赖注入。你可以使用&lt;bean&gt;元素的 autowire 属性为一个 bean 定义指定自动装配模式。 模式 描述 no 这是默认的设置，它意味着没有自动装配，你应该使用显式的bean引用来连线。你不用为了连线做特殊的事。 byName 由属性名自动装配。Spring 容器看到在 XML 配置文件中 bean 的自动装配的属性设置为 byName。然后尝试匹配，并且将它的属性与在配置文件中被定义为相同名称的 beans 的属性进行连接。 byType 由属性数据类型自动装配。Spring 容器看到在 XML 配置文件中 bean 的自动装配的属性设置为 byType。然后如果它的类型匹配配置文件中的一个确切的 bean 名称，它将尝试匹配和连接属性的类型。如果存在不止一个这样的 bean，则一个致命的异常将会被抛出。 constructor 类似于 byType，但该类型适用于构造函数参数类型。如果在容器中没有一个构造函数参数类型的 bean，则一个致命错误将会发生。 autodetect Spring首先尝试通过 constructor 使用自动装配来连接，如果它不执行，Spring 尝试通过 byType 来自动装配。 可以使用 byType 或者 constructor 自动装配模式来连接数组和其他类型的集合。 自动装配的局限性：当自动装配始终在同一个项目中使用时，它的效果最好。如果通常不使用自动装配，它可能会使开发人员混淆的使用它来连接只有一个或两个 bean 定义。不过，自动装配可以显著减少需要指定的属性或构造器参数，但你应该在使用它们之前考虑到自动装配的局限性和缺点。 限制 描述 重写的可能性 你可以使用总是重写自动装配的 &lt;constructor-arg>和 &lt;property> 设置来指定依赖关系。 原始数据类型 你不能自动装配所谓的简单类型包括基本类型，字符串和类。 混乱的本质 自动装配不如显式装配精确，所以如果可能的话尽可能使用显式装配。 Spring自动装配”byName”:这种模式由属性名称指定自动装配。Spring 容器看作 beans，在 XML 配置文件中 beans 的 auto-wire 属性设置为 byName。然后，它尝试将它的属性与配置文件中定义为相同名称的 beans 进行匹配和连接。如果找到匹配项，它将注入这些 beans，否则，它将抛出异常。 例如，在配置文件中，如果一个 bean 定义设置为自动装配 byName，并且它包含 spellChecker 属性（即，它有一个 setSpellChecker(…) 方法），那么 Spring 就会查找定义名为 spellChecker 的 bean，并且用它来设置这个属性。你仍然可以使用 标签连接其余的属性。下面的例子将说明这个概念。 示例： 下面是在正常情况下的配置文件 Beans.xml 文件： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for textEditor bean --&gt; &lt;bean id="textEditor" class="autowire.TextEditor"&gt; &lt;property name="spellChecker" ref="spellChecker" /&gt; &lt;property name="name" value="Generic Text Editor" /&gt; &lt;/bean&gt; &lt;!-- Definition for spellChecker bean --&gt; &lt;bean id="spellChecker" class="autowire.SpellChecker"&gt; &lt;/bean&gt;&lt;/beans&gt; 但是，如果你要使用自动装配 “byName”，那么你的 XML 配置文件将成为如下： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for textEditor bean --&gt; &lt;bean id="textEditor" class="autowire.TextEditor" autowire="byName"&gt; &lt;property name="name" value="Generic Text Editor" /&gt; &lt;/bean&gt; &lt;!-- Definition for spellChecker bean --&gt; &lt;bean id="spellChecker" class="autowire.SpellChecker"&gt; &lt;/bean&gt;&lt;/beans&gt; Spring自动装配”byType”:这种模式由属性类型指定自动装配。Spring 容器看作 beans，在 XML 配置文件中 beans 的 autowire 属性设置为 byType。然后，如果它的 type 恰好与配置文件中 beans 名称中的一个相匹配，它将尝试匹配和连接它的属性。如果找到匹配项，它将注入这些 beans，否则，它将抛出异常。 例如，在配置文件中，如果一个 bean 定义设置为自动装配 byType，并且它包含 SpellChecker 类型的 spellChecker 属性，那么 Spring 就会查找定义名为 SpellChecker 的 bean，并且用它来设置这个属性。你仍然可以使用 &lt;property> 标签连接其余属性。 示例： 下面是在正常情况下的配置文件 Beans.xml 文件： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for textEditor bean --&gt; &lt;bean id="textEditor" class="autowire.TextEditor"&gt; &lt;property name="spellChecker" ref="spellChecker" /&gt; &lt;property name="name" value="Generic Text Editor" /&gt; &lt;/bean&gt; &lt;!-- Definition for spellChecker bean --&gt; &lt;bean id="spellChecker" class="autowire.SpellChecker"&gt; &lt;/bean&gt;&lt;/beans&gt; 但是，如果你要使用自动装配 “byType”，那么你的 XML 配置文件将成为如下： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for textEditor bean --&gt; &lt;bean id="textEditor" class="autowire.TextEditor" autowire="byType"&gt; &lt;property name="name" value="Generic Text Editor" /&gt; &lt;/bean&gt; &lt;!-- Definition for spellChecker bean --&gt; &lt;bean id="SpellChecker" class="autowire.SpellChecker"&gt; &lt;/bean&gt;&lt;/beans&gt; Spring由构造函数自动装配：这种模式与 byType 非常相似，但它应用于构造器参数。Spring 容器看作 beans，在 XML 配置文件中 beans 的 autowire 属性设置为 constructor。然后，它尝试把它的构造函数的参数与配置文件中 beans 名称中的一个进行匹配和连线。如果找到匹配项，它会注入这些 bean，否则，它会抛出异常。 例如，在配置文件中，如果一个 bean 定义设置为通过构造函数自动装配，而且它有一个带有 SpellChecker类型的参数之一的构造函数，那么 Spring 就会查找定义名为 SpellChecker 的 bean，并用它来设置构造函数的参数。你仍然可以使用 &lt;constructor-arg> 标签连接其余属性。 实例： TextEditor.java 12345678910111213141516171819202122package autowire;public class TextEditor &#123; private SpellChecker spellChecker; private String name; public TextEditor(SpellChecker spellChecker, String name) &#123; this.spellChecker = spellChecker; this.name = name; &#125; public SpellChecker getSpellChecker() &#123; return spellChecker; &#125; public String getName() &#123; return name; &#125; public void spellCheck() &#123; spellChecker.checkSpelling(); &#125;&#125; SpellChecker.java 1234567891011package autowire;public class SpellChecker &#123; public SpellChecker() &#123; System.out.println("Inside SpellChecker constructor."); &#125; public void checkSpelling() &#123; System.out.println("Inside checkSpelling." ); &#125;&#125; MainApp.java 12345678910111213package autowire;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml"); TextEditor te = (TextEditor)context.getBean("textEditor"); te.spellCheck(); &#125;&#125; 下面是在正常情况下的配置文件 Beans.xml 文件： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for textEditor bean --&gt; &lt;bean id="textEditor" class="autowire.TextEditor"&gt; &lt;constructor-arg ref="spellChecker" /&gt; &lt;constructor-arg value="Generic Text Editor"/&gt; &lt;/bean&gt; &lt;!-- Definition for spellChecker bean --&gt; &lt;bean id="spellChecker" class="autowire.SpellChecker"&gt; &lt;/bean&gt;&lt;/beans&gt; 但是，如果你要使用自动装配 “by constructor”，那么你的 XML 配置文件将成为如下： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for textEditor bean --&gt; &lt;bean id="textEditor" class="autowire.TextEditor" autowire="constructor"&gt; &lt;constructor-arg value="Generic Text Editor"/&gt; &lt;/bean&gt; &lt;!-- Definition for spellChecker bean --&gt; &lt;bean id="SpellChecker" class="autowire.SpellChecker"&gt; &lt;/bean&gt;&lt;/beans&gt; Spirng基于注解的配置从 Spring 2.5 开始就可以使用注解来配置依赖注入。而不是采用 XML 来描述一个 bean 连线，你可以使用相关类，方法或字段声明的注解，将 bean 配置移动到组件类本身。 在 XML 注入之前进行注解注入，因此后者的配置将通过两种方式的属性连线被前者重写。 注解连线在默认情况下在 Spring 容器中不打开。因此，在可以使用基于注解的连线之前，我们将需要在我们的 Spring 配置文件中启用它。所以如果你想在 Spring 应用程序中使用的任何注解，可以考虑到下面的配置文件。 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd"&gt; &lt;context:annotation-config/&gt; &lt;!-- bean definitions go here --&gt;&lt;/beans&gt; 一旦 被配置后，你就可以开始注解你的代码，表明 Spring 应该自动连接值到属性，方法和构造函数。让我们来看看几个重要的注解，并且了解它们是如何工作的： 序号 注解 &amp; 描述 1 @Required@Required 注解应用于 bean 属性的 setter 方法。 2 @Autowired@Autowired 注解可以应用到 bean 属性的 setter 方法，非 setter 方法，构造函数和属性。 3 @Qualifier通过指定确切的将被连线的 bean，@Autowired 和 @Qualifier 注解可以用来删除混乱。 4 JSR-250 AnnotationsSpring 支持 JSR-250 的基础的注解，其中包括了 @Resource，@PostConstruct 和 @PreDestroy 注解。 Spring @Required注释：@Required 注释应用于 bean 属性的 setter 方法，它表明受影响的 bean 属性在配置时必须放在 XML 配置文件中，否则容器就会抛出一个 BeanInitializationException 异常。下面显示的是一个使用 @Required 注释的示例。 示例： Student.java 123456789101112131415161718192021222324252627package annotation;import org.springframework.beans.factory.annotation.Required;public class Student &#123; private Integer age; private String name; public Integer getAge() &#123; return age; &#125; @Required public void setAge(Integer age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; @Required public void setName(String name) &#123; this.name = name; &#125; &#125; MainApp.java 1234567891011121314package annotation;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("Student.xml"); Student student = (Student) context.getBean("student"); System.out.println("Name : " + student.getName() ); System.out.println("Age : " + student.getAge() ); &#125;&#125; Student.xml 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd"&gt; &lt;context:annotation-config/&gt; &lt;!-- Definition for student bean --&gt; &lt;bean id="student" class="annotation.Student"&gt; &lt;property name="name" value="Zara" /&gt; &lt;property name="age" value="11" /&gt; &lt;/bean&gt;&lt;/beans&gt; Spring @Autowired注释：@Autowired 注释对在哪里和如何完成自动连接提供了更多的细微的控制。 @Autowired 注释可以在 setter 方法中被用于自动连接 bean，就像 @Autowired 注释，容器，一个属性或者任意命名的可能带有多个参数的方法。 Setter方法中的@autowired： 可以在 XML 文件中的 setter 方法中使用 @Autowired 注释来除去 元素。当 Spring遇到一个在 setter 方法中使用的 @Autowired 注释，它会在方法中视图执行 byType 自动连接。 属性中的@autowired： 可以在属性中使用 @Autowired 注释来除去 setter 方法。当时使用 为自动连接属性传递的时候，Spring 会将这些传递过来的值或者引用自动分配给那些属性。 构造函数中的@Autowired: 可以在构造函数中使用 @Autowired。一个构造函数@Autowired 说明当创建 bean 时，即使在 XML 文件中没有使用元素配置 bean ，构造函数也会被自动连接。 @Autowired的（required=false）选项： 默认情况下，@Autowired 注释意味着依赖是必须的，它类似于 @Required 注释，然而，你可以使用 @Autowired的 （required=false） 选项关闭默认行为。 @Autowired(required=false) Spring @Qualifier注释：可能会有这样一种情况，当你创建多个具有相同类型的 bean 时，并且想要用一个属性只为它们其中的一个进行装配，在这种情况下，你可以使用 @Qualifier 注释和 @Autowired 注释通过指定哪一个真正的 bean 将会被装配来消除混乱。 示例： Student.java 1234567891011121314151617181920212223package annotation;public class Student &#123; private Integer age; private String name; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; Profile.java 12345678910111213141516171819202122package annotation;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;public class Profile &#123; @Autowired //在属性中使用 **@Autowired** 注释来除去 setter 方法。 @Qualifier("student2") //指定Bean private Student student; public Profile()&#123; System.out.println("Inside Profile constructor." ); &#125; public void printAge() &#123; System.out.println("Age : " + student.getAge() ); &#125; public void printName() &#123; System.out.println("Name : " + student.getName() ); &#125;&#125; MainApp.java 1234567891011121314package annotation;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("Student.xml"); Profile profile = (Profile)context.getBean("profile"); profile.printName(); profile.printAge(); &#125;&#125; Student.xml 1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd"&gt; &lt;context:annotation-config/&gt; &lt;bean id="profile" class="annotation.Profile" &gt; &lt;/bean&gt; &lt;!-- Definition for student bean --&gt; &lt;bean id="student1" class="annotation.Student"&gt; &lt;property name="name" value="Zara" /&gt; &lt;property name="age" value="11"/&gt; &lt;/bean&gt; &lt;bean id="student2" class="annotation.Student"&gt; &lt;property name="name" value="join" /&gt; &lt;property name="age" value="13"/&gt; &lt;/bean&gt;&lt;/beans&gt; Spring JSR-250注释：Spring还使用基于 JSR-250 注释，它包括 @PostConstruct， @PreDestroy 和 @Resource 注释。 @PostConstruct 和 @PreDestroy 注释： 为了定义一个 bean 的安装和卸载，我们使用 init-method 和/或 destroy-method 参数简单的声明一下 。init-method 属性指定了一个方法，该方法在 bean 的实例化阶段会立即被调用。同样地，destroy-method 指定了一个方法，该方法只在一个 bean 从容器中删除之前被调用。 你可以使用 @PostConstruct 注释作为初始化回调函数的一个替代，@PreDestroy 注释作为销毁回调函数的一个替代。 @Resource 注释： 可以在字段中或者 setter 方法中使用 @Resource 注释，它和在 Java EE 5 中的运作是一样的。@Resource 注释使用一个 ‘name’ 属性，该属性以一个 bean 名称的形式被注入。你可以说，它遵循 by-name 自动连接语义。 Spring基于Java的配置：基于 Java 的配置选项，可以使在不用配置 XML 的情况下编写大多数的 Spring，但是一些有帮助的基于 Java 的注解，解释如下： @Configuration 和 @Bean 注解带有 @Configuration 的注解类表示这个类可以使用 Spring IoC 容器作为 bean 定义的来源。@Bean 注解告诉 Spring，一个带有 @Bean 的注解方法将返回一个对象，该对象应该被注册为在 Spring 应用程序上下文中的 bean。 示例： HelloWorldConfig.java 123456789101112package annotation;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class HelloWorldConfig &#123; @Bean public HelloWorld helloWorld() &#123; return new HelloWorld(); &#125;&#125; HelloWorld.java 12345678910111213package annotation;public class HelloWorld &#123; private String message; public void setMessage(String message)&#123; this.message = message; &#125; public void getMessage()&#123; System.out.println("Your Message : " + message); &#125;&#125; MainApp.java 12345678910111213141516package annotation;import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class MainApp3 &#123; public static void main(String[] args) &#123; ApplicationContext ctx = new AnnotationConfigApplicationContext(HelloWorldConfig.class); HelloWorld helloWorld = ctx.getBean(HelloWorld.class); helloWorld.setMessage("Hello World!"); helloWorld.getMessage(); &#125;&#125; 注入Bean的依赖性：当 @Beans 依赖对方时，表达这种依赖性非常简单，只要有一个 bean 方法调用另一个。如下所示： 12345678910111213package com.tutorialspoint;import org.springframework.context.annotation.*;@Configurationpublic class AppConfig &#123; @Bean public Foo foo() &#123; return new Foo(bar()); &#125; @Bean public Bar bar() &#123; return new Bar(); &#125;&#125; 这里，foo Bean 通过构造函数注入来接收参考基准。 @Import注释：@import 注解允许从另一个配置类中加载 @Bean 定义。考虑 ConfigA 类，如下所示： 1234567@Configurationpublic class ConfigA &#123; @Bean public A a() &#123; return new A(); &#125;&#125; 你可以在另一个 Bean 声明中导入上述 Bean 声明，如下所示： 12345678@Configuration@Import(ConfigA.class)public class ConfigB &#123; @Bean public B a() &#123; return new A(); &#125;&#125; 现在，当实例化上下文时，不需要同时指定 ConfigA.class 和 ConfigB.class，只有 ConfigB 类需要提供，如下所示： 1234567public static void main(String[] args) &#123; ApplicationContext ctx = new AnnotationConfigApplicationContext(ConfigB.class); // now both beans A and B will be available... A a = ctx.getBean(A.class); B b = ctx.getBean(B.class);&#125; 生命周期回调：@Bean 注解支持指定任意的初始化和销毁的回调方法，就像在 bean 元素中 Spring 的 XML 的初始化方法和销毁方法的属性： 12345678910111213141516public class Foo &#123; public void init() &#123; // initialization logic &#125; public void cleanup() &#123; // destruction logic &#125;&#125;@Configurationpublic class AppConfig &#123; @Bean(initMethod = "init", destroyMethod = "cleanup" ) public Foo foo() &#123; return new Foo(); &#125;&#125; 指定 Bean 的范围： 默认范围是单实例，但是你可以重写带有 @Scope 注解的该方法，如下所示： 12345678@Configurationpublic class AppConfig &#123; @Bean @Scope("prototype") public Foo foo() &#123; return new Foo(); &#125;&#125; Spring中的事件处理：Spring 的核心是 ApplicationContext，它负责管理 beans 的完整生命周期。当加载 beans 时，ApplicationContext 发布某些类型的事件。例如，当上下文启动时，ContextStartedEvent 发布，当上下文停止时，ContextStoppedEvent 发布。 通过 ApplicationEvent 类和 ApplicationListener 接口来提供在 ApplicationContext 中处理事件。如果一个 bean 实现 ApplicationListener，那么每次 ApplicationEvent 被发布到 ApplicationContext 上，那个 bean 会被通知。 Spring 提供了以下的标准事件： 序号 Spring 内置事件 &amp; 描述 1 ContextRefreshedEvent ApplicationContext 被初始化或刷新时，该事件被发布。这也可以在 ConfigurableApplicationContext 接口中使用 refresh() 方法来发生。 2 ContextStartedEvent 当使用 ConfigurableApplicationContext 接口中的 start() 方法启动 ApplicationContext 时，该事件被发布。你可以调查你的数据库，或者你可以在接受到这个事件后重启任何停止的应用程序。 3 ContextStoppedEvent 当使用 ConfigurableApplicationContext 接口中的 stop() 方法停止 ApplicationContext 时，发布这个事件。你可以在接受到这个事件后做必要的清理的工作。 4 ContextClosedEvent 当使用 ConfigurableApplicationContext 接口中的 close() 方法关闭 ApplicationContext 时，该事件被发布。一个已关闭的上下文到达生命周期末端；它不能被刷新或重启。 5 RequestHandledEvent 这是一个 web-specific 事件，告诉所有 bean HTTP 请求已经被服务。 由于 Spring 的事件处理是单线程的，所以如果一个事件被发布，直至并且除非所有的接收者得到的该消息，该进程被阻塞并且流程将不会继续。因此，如果事件处理被使用，在设计应用程序时应注意。 监听上下文事件：为了监听上下文事件，一个 bean 应该实现只有一个方法 onApplicationEvent() 的 ApplicationListener 接口。因此，我们写一个例子来看看事件是如何传播的，以及如何可以用代码来执行基于某些事件所需的任务。 HelloWorld.java 12345678910111213package annotation;public class HelloWorld &#123; private String message; public void setMessage(String message)&#123; this.message = message; &#125; public void getMessage()&#123; System.out.println("Your Message : " + message); &#125;&#125; CStartEventHandler.java 123456789101112package annotation;import org.springframework.context.ApplicationListener;import org.springframework.context.event.ContextStartedEvent;public class CStartEventHandler implements ApplicationListener&lt;ContextStartedEvent&gt; &#123; @Override public void onApplicationEvent(ContextStartedEvent arg0) &#123; System.out.println("ContextStartedEvent Received"); &#125;&#125; CStopEventHandler.java 12345678910111213package annotation;import org.springframework.context.ApplicationListener;import org.springframework.context.event.ContextStoppedEvent;public class CStopEventHandler implements ApplicationListener&lt;ContextStoppedEvent&gt; &#123; @Override public void onApplicationEvent(ContextStoppedEvent arg0) &#123; System.out.println("ContextStoppedEvent Received"); &#125;&#125; MainApp4.java 1234567891011121314151617package annotation;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp4 &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = new ClassPathXmlApplicationContext("Event.xml"); context.start(); HelloWorld obj = (HelloWorld)context.getBean("helloWorld"); obj.getMessage(); context.stop(); &#125;&#125; Event.xml 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="helloWorld" class="annotation.HelloWorld"&gt; &lt;property name="message" value="Hello World!"/&gt; &lt;/bean&gt; &lt;bean id="cStartEventHandler" class="annotation.CStartEventHandler"/&gt; &lt;bean id="cStopEventHandler" class="annotation.CStopEventHandler"/&gt;&lt;/beans&gt; 运行结果： 123ContextStartedEvent ReceivedYour Message : Hello World!ContextStoppedEvent Received Spring中的自定义事件：这个是 CustomEvent.java 文件的内容： 12345678910package annotation;import org.springframework.context.ApplicationEvent;public class CustomEvent extends ApplicationEvent&#123; public CustomEvent(Object source) &#123; super(source); &#125; public String toString() &#123; return "My Custom Event"; &#125;&#125; 下面是 CustomEventPublisher.java 文件的内容： 12345678910111213141516171819202122232425262728293031package annotation;import org.springframework.context.ApplicationEventPublisher;import org.springframework.context.ApplicationEventPublisherAware;public class CustomEventPublisher implements ApplicationEventPublisherAware &#123; private ApplicationEventPublisher publisher; public void setApplicationEventPublisher (ApplicationEventPublisher publisher)&#123; this.publisher = publisher; &#125; public void publish() &#123; CustomEvent ce = new CustomEvent(this); publisher.publishEvent(ce); &#125;&#125;package com.tutorialspoint;import org.springframework.context.ApplicationEventPublisher;import org.springframework.context.ApplicationEventPublisherAware;public class CustomEventPublisher implements ApplicationEventPublisherAware &#123; private ApplicationEventPublisher publisher; public void setApplicationEventPublisher (ApplicationEventPublisher publisher)&#123; this.publisher = publisher; &#125; public void publish() &#123; CustomEvent ce = new CustomEvent(this); publisher.publishEvent(ce); &#125;&#125; 下面是 CustomEventHandler.java 文件的内容： 12345678910111213package annotation;import org.springframework.context.ApplicationListener;import org.springframework.context.event.ContextStoppedEvent;public class CStopEventHandler implements ApplicationListener&lt;ContextStoppedEvent&gt; &#123; @Override public void onApplicationEvent(ContextStoppedEvent arg0) &#123; System.out.println("ContextStoppedEvent Received"); &#125;&#125; 下面是 MainApp.java 文件的内容： 12345678910111213141516package annotation;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp5 &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = new ClassPathXmlApplicationContext("Custom.xml"); CustomEventPublisher cvp = (CustomEventPublisher) context.getBean("customEventPublisher"); cvp.publish(); cvp.publish(); &#125;&#125; 下面是配置文件Custom.xml： 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="customEventHandler" class="annotation.CustomEventHandler"/&gt; &lt;bean id="customEventPublisher" class="annotation.CustomEventPublisher"/&gt;&lt;/beans&gt; 程序运行结果： 12My Custom EventMy Custom Event 不同配置方式的比较 基于XML配置 基于注解配置 基于Java类配置 Bean定义 在XML文件中通过&lt;bean>元素定义Bean 在Bean实现类处通过注解@Component等定义Bean 在标注了@Configuration的Java类中，在类方法上标注@Bean定义Bean Bean名称 通过&lt;Bean>的id或name属性定义 通过注解的value属性定义，如@Component（”userDao”） 通过@Bean的name属性定义，如@Bean（”userDao”） Bean注入 通过&lt;property>子元素或通过p命名空间的动态属性注入 通过标出@autowired，按类型匹配自动注入，可配合使用@Qualifier按名称匹配注入 1. 方法处通过@autowired是方法入参绑定Bean。 2，通过调用配置类的@bean方法进行注入 Bean生命过程方法 通过&lt;bean>的init-method和destory-method属性指定Bean实现类方法名 通过在目标方法上标注@postConstruct和@PreDestroy注解指定 通过@Bean的initMethod或destoryMethod指定相应方法 Bean作用范围 通过&lt;bean>的Scope属性指定 通过在类定义出标注@Scope指定 通过Bean方法定义出标签@Scope指定 Bean延迟初始化 通过&lt;bena>的lazy-init属性指定，默认为default 通过在类定义标注@lazy指定，如@Lazy（true） 通过在Bean方法定义处标注@Lazy指定 三种的使用场景： 基于XML的配置： 第三方类库：如DataSource、JdbcTemplate等。 命名空间，如aop，context等。 基于注解的配置： Bean的实现类是当前项目开发的，可直接在Java类中使用注解配置。 基于Java类的配置： 对于实例化Bean的逻辑比较复杂，则比较使用与基于Java类配置的方式。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>java学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（9）Spring基础]]></title>
    <url>%2F2018%2F08%2F02%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89Spring%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Spring概述Spring概述：Spring 是最受欢迎的企业级 Java 应用程序开发框架，数以百万的来自世界各地的开发人员使用 Spring 框架来创建性能好、易于测试、可重用的代码。 Spring 框架是一个开源的 Java 平台，它最初是由 Rod Johnson 编写的，并且于 2003 年 6 月首次在 Apache 2.0 许可下发布。 Spring 是轻量级的框架，其基础版本只有 2 MB 左右的大小。 Spring 框架的核心特性是可以用于开发任何 Java 应用程序，但是在 Java EE 平台上构建 web 应用程序是需要扩展的。 Spring 框架的目标是使 J2EE 开发变得更容易使用，通过启用基于 POJO 编程模型来促进良好的编程实践。 使用Spring框架的好处：下面列出的是使用 Spring 框架主要的好处： Spring 可以使开发人员使用 POJOs 开发企业级的应用程序。只使用 POJOs 的好处是你不需要一个 EJB 容器产品，比如一个应用程序服务器，但是你可以选择使用一个健壮的 servlet 容器，比如 Tomcat 或者一些商业产品。 Spring 在一个单元模式中是有组织的。即使包和类的数量非常大，你只要担心你需要的，而其它的就可以忽略了。 Spring 不会让你白费力气做重复工作，它真正的利用了一些现有的技术，像ORM 框架、日志框架、JEE、Quartz 和 JDK 计时器，其他视图技术。 测试一个用 Spring 编写的应用程序很容易，因为环境相关的代码被移动到这个框架中。此外，通过使用 JavaBean-style POJOs，它在使用依赖注入注入测试数据时变得更容易。 Spring 的 web 框架是一个设计良好的 web MVC 框架，它为比如 Structs 或者其他工程上的或者不怎么受欢迎的 web 框架提供了一个很好的供替代的选择。 Spring 对JavaEE开发中非常难用的一些API（JDBC、JavaMail、远程调用等），都提供了封装，使这些API应用难度大大降低。 轻量级的 IOC 容器往往是轻量级的，例如，特别是当与 EJB 容器相比的时候。这有利于在内存和 CPU 资源有限的计算机上开发和部署应用程序。 Spring提供了一致的事务管理接口，可向下扩展到（使用一个单一的数据库，例如）本地事务并扩展到全局事务（例如，使用 JTA）。 依赖注入（DI）：Spring 最认同的技术是控制反转的依赖注入（DI）模式。控制反转（IoC）是一个通用的概念，它可以用许多不同的方式去表达，依赖注入仅仅是控制反转的一个具体的例子。 当编写一个复杂的 Java 应用程序时，应用程序类应该尽可能的独立于其他的 Java 类来增加这些类可重用可能性，当进行单元测试时，可以使它们独立于其他类进行测试。依赖注入（或者有时被称为配线）有助于将这些类粘合在一起，并且在同一时间让它们保持独立。 到底什么是依赖注入？让我们将这两个词分开来看一看。这里将依赖关系部分转化为两个类之间的关联。例如，类 A 依赖于类 B。现在，让我们看一看第二部分，注入。所有这一切都意味着类 B 将通过 IoC 被注入到类 A 中。 依赖注入可以以向构造函数传递参数的方式发生，或者通过使用 setter 方法 post-construction。 面向方面的程序设计（AOP）：Spring 框架的一个关键组件是面向方面的程序设计（AOP）框架。一个程序中跨越多个点的功能被称为横切关注点，这些横切关注点在概念上独立于应用程序的业务逻辑。有各种各样常见的很好的关于方面的例子，比如日志记录、声明性事务、安全性，和缓存等等。 在 OOP 中模块化的关键单元是类，而在 AOP 中模块化的关键单元是方面。AOP 帮助你将横切关注点从它们所影响的对象中分离出来，然而依赖注入帮助你将你的应用程序对象从彼此中分离出来。 Spring 框架的 AOP 模块提供了面向方面的程序设计实现，可以定义诸如方法拦截器和切入点等，从而使实现功能的代码彻底的解耦出来。使用源码级的元数据，可以用类似于.Net属性的方式合并行为信息到代码中。 Spring体系结构体系结构：Spring 有可能成为所有企业应用程序的一站式服务点，然而，Spring 是模块化的，允许你挑选和选择适用于你的模块，不必要把剩余部分也引入。下面的部分对在 Spring 框架中所有可用的模块给出了详细的介绍。 Spring 框架提供约 20 个模块，可以根据应用程序的要求来使用。 图：Spring结构 核心容器：核心容器由spring-core，spring-beans，spring-context，spring-context-support和spring-expression（SpEL，Spring表达式语言，Spring Expression Language）等模块组成，它们的细节如下： spring-core模块提供了框架的基本组成部分，包括 IoC 和依赖注入功能。 spring-beans 模块提供 BeanFactory，工厂模式的微妙实现，它移除了编码式单例的需要，并且可以把配置和依赖从实际编码逻辑中解耦。 context模块建立在由core和 beans 模块的基础上建立起来的，它以一种类似于JNDI注册的方式访问对象。Context模块继承自Bean模块，并且添加了国际化（比如，使用资源束）、事件传播、资源加载和透明地创建上下文（比如，通过Servelet容器）等功能。Context模块也支持Java EE的功能，比如EJB、JMX和远程调用等。ApplicationContext接口是Context模块的焦点。spring-context-support提供了对第三方库集成到Spring上下文的支持，比如缓存（EhCache, Guava, JCache）、邮件（JavaMail）、调度（CommonJ, Quartz）、模板引擎（FreeMarker, JasperReports, Velocity）等。 spring-expression模块提供了强大的表达式语言，用于在运行时查询和操作对象图。它是JSP2.1规范中定义的统一表达式语言的扩展，支持set和get属性值、属性赋值、方法调用、访问数组集合及索引的内容、逻辑算术运算、命名变量、通过名字从Spring IoC容器检索对象，还支持列表的投影、选择以及聚合等。 数据访问/集成：数据访问/集成层包括 JDBC，ORM，OXM，JMS 和事务处理模块，它们的细节如下： （注：JDBC=Java Data Base Connectivity，ORM=Object Relational Mapping，OXM=Object XML Mapping，JMS=Java Message Service） JDBC 模块提供了JDBC抽象层，它消除了冗长的JDBC编码和对数据库供应商特定错误代码的解析。 ORM 模块提供了对流行的对象关系映射API的集成，包括JPA、JDO和Hibernate等。通过此模块可以让这些ORM框架和spring的其它功能整合，比如前面提及的事务管理。 OXM 模块提供了对OXM实现的支持，比如JAXB、Castor、XML Beans、JiBX、XStream等。 JMS 模块包含生产（produce）和消费（consume）消息的功能。从Spring 4.1开始，集成了spring-messaging模块。。 事务模块为实现特殊接口类及所有的 POJO 支持编程式和声明式事务管理。（注：编程式事务需要自己写beginTransaction()、commit()、rollback()等事务管理方法，声明式事务是通过注解或配置由spring自动处理，编程式事务粒度更细） Web：Web 层由 Web，Web-MVC，Web-Socket 和 Web-Portlet 组成，它们的细节如下： Web 模块提供面向web的基本功能和面向web的应用上下文，比如多部分（multipart）文件上传功能、使用Servlet监听器初始化IoC容器等。它还包括HTTP客户端以及Spring远程调用中与web相关的部分。。 Web-MVC 模块为web应用提供了模型视图控制（MVC）和REST Web服务的实现。Spring的MVC框架可以使领域模型代码和web表单完全地分离，且可以与Spring框架的其它所有功能进行集成。 Web-Socket 模块为 WebSocket-based 提供了支持，而且在 web 应用程序中提供了客户端和服务器端之间通信的两种方式。 Web-Portlet 模块提供了用于Portlet环境的MVC实现，并反映了spring-webmvc模块的功能。 其他：还有其他一些重要的模块，像 AOP，Aspects，Instrumentation，Web 和测试模块，它们的细节如下： AOP 模块提供了面向方面的编程实现，允许你定义方法拦截器和切入点对代码进行干净地解耦，从而使实现功能的代码彻底的解耦出来。使用源码级的元数据，可以用类似于.Net属性的方式合并行为信息到代码中。 Aspects 模块提供了与 AspectJ 的集成，这是一个功能强大且成熟的面向切面编程（AOP）框架。 Instrumentation 模块在一定的应用服务器中提供了类 instrumentation 的支持和类加载器的实现。 Messaging 模块为 STOMP 提供了支持作为在应用程序中 WebSocket 子协议的使用。它也支持一个注解编程模型，它是为了选路和处理来自 WebSocket 客户端的 STOMP 信息。 测试模块支持对具有 JUnit 或 TestNG 框架的 Spring 组件的测试。 Spring环境配置 安装 Apache Commons Logging API 从 http://commons.apache.org/logging/ 下载 Apache Commons Logging API 的最新版本。 安装Spring框架库： 从 http://repo.spring.io/release/org/springframework/spring 下载最新版本的 Spring 框架的二进制文件。 在编写Spring程序时，将这两个文件中的jar包都导入到Java工程中，添加到构建路径中即可。 Spring IoC容器Ioc容器：Spring 容器是 Spring 框架的核心。容器将创建对象，把它们连接在一起，配置它们，并管理他们的整个生命周期从创建到销毁。Spring 容器使用依赖注入（DI）来管理组成一个应用程序的组件。这些对象被称为 Spring Beans。 通过阅读配置元数据提供的指令，容器知道对哪些对象进行实例化，配置和组装。配置元数据可以通过 XML，Java 注释或 Java 代码来表示。下图是 Spring 如何工作的高级视图。 Spring IoC 容器利用 Java 的 POJO 类和配置元数据来生成完全配置和可执行的系统或应用程序。 图：Spring工作的高级视图 Spring 提供了以下两种不同类型的容器。 Spring BeanFactory 容器 它是最简单的容器，给 DI 提供了基本的支持，它用 org.springframework.beans.factory.BeanFactory 接口来定义。BeanFactory 或者相关的接口，如 BeanFactoryAware，InitializingBean，DisposableBean，在 Spring 中仍然存在具有大量的与 Spring 整合的第三方框架的反向兼容性的目的。 Spring ApplicationContext 容器 该容器添加了更多的企业特定的功能，例如从一个属性文件中解析文本信息的能力，发布应用程序事件给感兴趣的事件监听器的能力。该容器是由 org.springframework.context.ApplicationContext 接口定义。 ApplicationContext 容器包括 BeanFactory 容器的所有功能，所以通常建议超过 BeanFactory。BeanFactory 仍然可以用于轻量级的应用程序，如移动设备或基于 applet 的应用程序，其中它的数据量和速度是显著。 Java反射机制：Java语言允许通过程序化的方式间接对Class的对象实例操作。Class文件由类装载器装载后，在JVM中将形成一份描述Class结构的元信息对象，通过该对象可以获知Class的结构信息，如构造函数、属性和方法。 Spring BeanFactory 容器：这是一个最简单的容器，它主要的功能是为依赖注入 （DI） 提供支持，这个容器接口在 org.springframework.beans.factory.BeanFactor 中被定义。 BeanFactory 和相关的接口，比如BeanFactoryAware、 DisposableBean、InitializingBean，仍旧保留在 Spring 中，主要目的是向后兼容已经存在的和那些 Spring 整合在一起的第三方框架。 在 Spring 中，有大量对 BeanFactory 接口的实现。其中，最常被使用的是 XmlBeanFactory 类。这个容器从一个 XML 文件中读取配置元数据，由这些元数据来生成一个被配置化的系统或者应用。 在资源宝贵的移动设备或者基于 applet 的应用当中， BeanFactory 会被优先选择。否则，一般使用的是 ApplicationContext，除非你有更好的理由选择 BeanFactory。 例子： 123456789import org.springframework.core.io.ClassPathResource;public class MainApp &#123; public static void main(String[] args) &#123; XmlBeanFactory factory = new XmlBeanFactory (new ClassPathResource("Beans.xml")); HelloWorld obj = (HelloWorld) factory.getBean("helloWorld"); obj.getMessage(); &#125;&#125; 在该程序当中，我们需要注意以下两点： 第一步利用框架提供的 XmlBeanFactory() API 去生成工厂 bean 以及利用 ClassPathResource() API 去加载在路径 CLASSPATH 下可用的 bean 配置文件。XmlBeanFactory() API 负责创建并初始化所有的对象，即在配置文件中提到的 bean。 第二步利用第一步生成的 bean 工厂对象的 getBean() 方法得到所需要的 bean。 这个方法通过配置文件中的 bean ID 来返回一个真正的对象，该对象最后可以用于实际的对象。一旦得到这个对象，就可以利用这个对象来调用任何方法。 Spring ApplicationContext 容器：Application Context 是 spring 中较高级的容器。和 BeanFactory 类似，它可以加载配置文件中定义的 bean，将所有的 bean 集中在一起，当有请求的时候分配 bean。 另外，它增加了企业所需要的功能，比如，从属性文件中解析文本信息和将事件传递给所指定的监听器。这个容器在 org.springframework.context.ApplicationContext interface 接口中定义。 ApplicationContext 包含 BeanFactory 所有的功能，一般情况下，相对于 BeanFactory，ApplicationContext 会更加优秀。当然，BeanFactory 仍可以在轻量级应用中使用，比如移动设备或者基于 applet 的应用程序。 最常被使用的 ApplicationContext 接口实现： FileSystemXmlApplicationContext：该容器从 XML 文件中加载已被定义的 bean。在这里，需要提供给构造器 XML 文件的完整路径。 ClassPathXmlApplicationContext：该容器从 XML 文件中加载已被定义的 bean。在这里，你不需要提供 XML 文件的完整路径，只需正确配置 CLASSPATH 环境变量即可，因为，容器会从 CLASSPATH 中搜索 bean 配置文件。 WebXmlApplicationContext：该容器会在一个 web 应用程序的范围内加载在 XML 文件中已被定义的 bean。 例子： 1234567891011package com.tutorialspoint;import org.springframework.context.ApplicationContext;import org.springframework.context.support.FileSystemXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new FileSystemXmlApplicationContext ("C:/Users/ZARA/workspace/HelloSpring/src/Beans.xml"); HelloWorld obj = (HelloWorld) context.getBean("helloWorld"); obj.getMessage(); &#125;&#125; 在该程序当中，我们需要注意以下两点： 第一步生成工厂对象。加载完指定路径下 bean 配置文件后，利用框架提供的 FileSystemXmlApplicationContext API 去生成工厂 bean。FileSystemXmlApplicationContext 负责生成和初始化所有的对象，比如，所有在 XML bean 配置文件中的 bean。 第二步利用第一步生成的上下文中的 getBean() 方法得到所需要的 bean。 这个方法通过配置文件中的 bean ID 来返回一个真正的对象。一旦得到这个对象，就可以利用这个对象来调用任何方法。 Spring Bean定义：被称作 bean 的对象是构成应用程序的支柱也是由 Spring IoC 容器管理的。bean 是一个被实例化，组装，并通过 Spring IoC 容器所管理的对象。这些 bean 是由用容器提供的配置元数据创建的。 bean 定义包含称为配置元数据的信息，下述容器也需要知道配置元数据： 如何创建一个 bean bean 的生命周期的详细信息 bean 的依赖关系 上述所有的配置元数据转换成一组构成每个 bean 定义的下列属性。 属性 描述 class 这个属性是强制性的，并且指定用来创建 bean 的 bean 类。 name 这个属性指定唯一的 bean 标识符。在基于 XML 的配置元数据中，你可以使用 ID 和/或 name 属性来指定 bean 标识符。 scope 这个属性指定由特定的 bean 定义创建的对象的作用域 constructor-arg 它是用来注入依赖关系的 properties 它是用来注入依赖关系的 autowiring mode 它是用来注入依赖关系的 lazy-initialization mode 延迟初始化的 bean 告诉 IoC 容器在它第一次被请求时，而不是在启动时去创建一个 bean 实例。 initialization 方法 在 bean 的所有必需的属性被容器设置之后，调用回调方法。 destruction 方法 当包含该 bean 的容器被销毁时，使用回调方法。 Spring配置元数据： Spring IoC 容器完全由实际编写的配置元数据的格式解耦。有下面三个重要的方法把配置元数据提供给 Spring 容器： 基于 XML 的配置文件。 基于注解的配置 基于 Java 的配置 以下是一个基于 XML 配置文件的例子，这个配置文件中有不同的 bean 定义，包括延迟初始化，初始化方法和销毁方法的： 123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- A simple bean definition --&gt; &lt;bean id="..." class="..."&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt; &lt;!-- A bean definition with lazy init set on --&gt; &lt;bean id="..." class="..." lazy-init="true"&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt; &lt;!-- A bean definition with initialization method --&gt; &lt;bean id="..." class="..." init-method="..."&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt; &lt;!-- A bean definition with destruction method --&gt; &lt;bean id="..." class="..." destroy-method="..."&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt; &lt;!-- more bean definitions go here --&gt;&lt;/beans&gt; Bean的作用域：当在 Spring 中定义一个 bean 时，你必须声明该 bean 的作用域的选项。例如，为了强制 Spring 在每次需要时都产生一个新的 bean 实例，你应该声明 bean 的作用域的属性为 prototype。同理，如果你想让 Spring 在每次需要时都返回同一个bean实例，你应该声明 bean 的作用域的属性为 singleton。 Spring 框架支持以下五个作用域，如果你使用 web-aware ApplicationContext 时，其中三个是可用的。 作用域 描述 singleton 在spring IoC容器仅存在一个Bean实例，Bean以单例方式存在，默认值 prototype 每次从容器中调用Bean时，都返回一个新的实例，即每次调用getBean()时，相当于执行newXxxBean() request 每次HTTP请求都会创建一个新的Bean，该作用域仅适用于WebApplicationContext环境 session 同一个HTTP Session共享一个Bean，不同Session使用不同的Bean，仅适用于WebApplicationContext环境 global-session 一般用于Portlet应用环境，改作用于仅适用于WebApplicationContext环境 singleton作用域： 当一个bean的作用域为Singleton，那么Spring IoC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。 Singleton是单例类型，就是在创建起容器时就同时自动创建了一个bean的对象，不管你是否使用，他都存在了，每次获取到的对象都是同一个对象。注意，Singleton作用域是Spring中的缺省作用域。 prototype作用域： 当一个bean的作用域为Prototype，表示一个bean定义对应多个对象实例。Prototype作用域的bean会导致在每次对该bean请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）时都会创建一个新的bean实例。 Prototype是原型类型，它在我们创建容器的时候并没有实例化，而是当我们获取bean的时候才会去创建一个对象，而且我们每次获取到的对象都不是同一个对象。根据经验，对有状态的bean应该使用prototype作用域，而对无状态的bean则应该使用singleton作用域。 Spring Bean生命周期：理解 Spring bean 的生命周期很容易。当一个 bean 被实例化时，它可能需要执行一些初始化使它转换成可用状态。同样，当 bean 不再需要，并且从容器中移除时，可能需要做一些清除工作。 为了定义安装和拆卸一个 bean，我们只要声明带有 init-method 和/或 destroy-method 参数的 。init-method 属性指定一个方法，在实例化 bean 时，立即调用该方法。同样，destroy-method 指定一个方法，只有从容器中移除 bean 之后，才能调用该方法。 初始化回调 org.springframework.beans.factory.InitializingBean 接口指定一个单一的方法： 1void afterPropertiesSet() throws Exception; 因此，你可以简单地实现上述接口和初始化工作可以在 afterPropertiesSet() 方法中执行，如下所示： 12345public class ExampleBean implements InitializingBean &#123; public void afterPropertiesSet() &#123; // do some initialization work &#125;&#125; 在基于 XML 的配置元数据的情况下，你可以使用 init-method 属性来指定带有 void 无参数方法的名称。例如： 12&lt;bean id="exampleBean" class="examples.ExampleBean" init-method="init"/&gt; 下面是类的定义： 12345public class ExampleBean &#123; public void init() &#123; // do some initialization work &#125;&#125; 销毁回调 org.springframework.beans.factory.DisposableBean 接口指定一个单一的方法： 1void destroy() throws Exception; 因此，你可以简单地实现上述接口并且结束工作可以在 destroy() 方法中执行，如下所示： 12345public class ExampleBean implements DisposableBean &#123; public void destroy() &#123; // do some destruction work &#125;&#125; 在基于 XML 的配置元数据的情况下，你可以使用 destroy-method 属性来指定带有 void 无参数方法的名称。例如： 12&lt;bean id="exampleBean" class="examples.ExampleBean" destroy-method="destroy"/&gt; 下面是类的定义： 12345public class ExampleBean &#123; public void destroy() &#123; // do some destruction work &#125;&#125; 如果你在非 web 应用程序环境中使用 Spring 的 IoC 容器；例如在丰富的客户端桌面环境中；那么在 JVM 中你要注册关闭 hook。这样做可以确保正常关闭，为了让所有的资源都被释放，可以在单个 beans 上调用 destroy 方法。 建议不要使用 InitializingBean 或者 DisposableBean 的回调方法，因为 XML 配置在命名方法上提供了极大的灵活性。 默认的初始化和销毁方法 如果你有太多具有相同名称的初始化或者销毁方法的 Bean，那么你不需要在每一个 bean 上声明初始化方法和销毁方法。框架使用 元素中的 default-init-method 和 default-destroy-method 属性提供了灵活地配置这种情况。 123456789101112&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd" default-init-method="init" default-destroy-method="destroy"&gt; &lt;bean id="..." class="..."&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt;&lt;/beans&gt; Spring Bean 后置处理器：BeanPostProcessor 接口定义回调方法，你可以实现该方法来提供自己的实例化逻辑，依赖解析逻辑等。你也可以在 Spring 容器通过插入一个或多个 BeanPostProcessor 的实现来完成实例化，配置和初始化一个bean之后实现一些自定义逻辑回调方法。 你可以配置多个 BeanPostProcessor接口，通过设置 BeanPostProcessor 实现的 Ordered 接口提供的 order 属性来控制这些 BeanPostProcessor 接口的执行顺序。 BeanPostProcessor 可以对 bean（或对象）实例进行操作，这意味着 Spring IoC 容器实例化一个 bean 实例，然后 BeanPostProcessor 接口进行它们的工作。 ApplicationContext 会自动检测由 BeanPostProcessor 接口的实现定义的 bean，注册这些 bean 为后置处理器，然后通过在容器中创建 bean，在适当的时候调用它。 实例： HelloWorld.java 123456789101112131415161718192021package com.tutorialspoint;public class HelloWorld &#123; private String message; public void getMessage() &#123; System.out.println("Your Message:" + message); &#125; public void setMessage(String message) &#123; this.message = message; &#125; public void init() &#123; System.out.println("Bean的初始化方法！"); &#125; public void destroy() &#123; System.out.println("Bean的销毁方法！"); &#125;&#125; 这是实现 BeanPostProcessor 的非常简单的例子，它在任何 bean 的初始化的之前和之后输入该 bean 的名称。你可以在初始化 bean 的之前和之后实现更复杂的逻辑，因为你有两个访问内置 bean 对象的后置处理程序的方法。 这里是 InitHelloWorld.java 文件的内容： 123456789101112131415161718package com.tutorialspoint;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.BeanPostProcessor;public class InitHelloWorld implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("Bean初始化之前:" + beanName); return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("Bean初始化之后:" + beanName); return bean; &#125; &#125; 下面是 MainApp.java 文件的内容。在这里，你需要注册一个在 AbstractApplicationContext 类中声明的关闭 hook 的 registerShutdownHook() 方法。它将确保正常关闭，并且调用相关的 destroy 方法。 123456789101112131415package com.tutorialspoint;import org.springframework.context.support.AbstractApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; AbstractApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml"); HelloWorld obj = (HelloWorld)context.getBean("helloWorld"); obj.getMessage(); context.registerShutdownHook(); &#125;&#125; 下面是 init 和 destroy 方法需要的配置文件 Beans.xml 文件： 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="helloWorld" class="com.tutorialspoint.HelloWorld" init-method="init" destroy-method="destroy"&gt; &lt;property name="message" value="Hello World!"/&gt; &lt;/bean&gt; &lt;bean class="com.tutorialspoint.InitHelloWorld" /&gt; &lt;/beans&gt; 程序运行结果如下： 12345678910八月 02, 2018 11:43:31 上午 org.springframework.context.support.AbstractApplicationContext prepareRefresh信息: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@1eb44e46: startup date [Thu Aug 02 11:43:31 CST 2018]; root of context hierarchy八月 02, 2018 11:43:31 上午 org.springframework.beans.factory.xml.XmlBeanDefinitionReader loadBeanDefinitions信息: Loading XML bean definitions from class path resource [Beans.xml]Bean初始化之前:helloWorldBean的初始化方法！Bean初始化之后:helloWorldYour Message:Hello World!Bean的销毁方法！ Spring Bean定义继承：bean 定义可以包含很多的配置信息，包括构造函数的参数，属性值，容器的具体信息例如初始化方法，静态工厂方法名，等等。 子 bean 的定义继承父定义的配置数据。子定义可以根据需要重写一些值，或者添加其他值。 Spring Bean 定义的继承与 Java 类的继承无关，但是继承的概念是一样的。你可以定义一个父 bean 的定义作为模板和其他子 bean 就可以从父 bean 中继承所需的配置。 当你使用基于 XML 的配置元数据时，通过使用父属性，指定父 bean 作为该属性的值来表明子 bean 的定义。 Bean定义模板： 父 bean 自身不能被实例化，因为它是不完整的，而且它也被明确地标记为抽象的。当一个定义是抽象的，它仅仅作为一个纯粹的模板 bean 定义来使用的，充当子定义的父定义使用。 12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="beanTeamplate" abstract="true"&gt; &lt;property name="message1" value="Hello World!"/&gt; &lt;property name="message2" value="Hello Second World!"/&gt; &lt;property name="message3" value="Namaste India!"/&gt; &lt;/bean&gt; &lt;bean id="helloIndia" class="com.tutorialspoint.HelloIndia" parent="beanTeamplate"&gt; &lt;property name="message1" value="Hello India!"/&gt; &lt;property name="message3" value="Namaste India!"/&gt; &lt;/bean&gt;&lt;/beans&gt; Spring依赖注入##依赖注入： 每个基于应用程序的 java 都有几个对象，这些对象一起工作来呈现出终端用户所看到的工作的应用程序。当编写一个复杂的 Java 应用程序时，应用程序类应该尽可能独立于其他 Java 类来增加这些类重用的可能性，并且在做单元测试时，测试独立于其他类的独立性。依赖注入（或有时称为布线）有助于把这些类粘合在一起，同时保持他们独立。 假设你有一个包含文本编辑器组件的应用程序，并且你想要提供拼写检查。标准代码看起来是这样的： 123456public class TextEditor &#123; private SpellChecker spellChecker; public TextEditor() &#123; spellChecker = new SpellChecker(); &#125;&#125; 在这里我们所做的就是创建一个 TextEditor 和 SpellChecker 之间的依赖关系。在控制反转的场景中，我们反而会做这样的事情： 123456public class TextEditor &#123; private SpellChecker spellChecker; public TextEditor(SpellChecker spellChecker) &#123; this.spellChecker = spellChecker; &#125;&#125; 在这里，TextEditor 不应该担心 SpellChecker 的实现。SpellChecker 将会独立实现，并且在 TextEditor 实例化的时候将提供给 TextEditor，整个过程是由 Spring 框架的控制。 在这里，我们已经从 TextEditor 中删除了全面控制，并且把它保存到其他地方（即 XML 配置文件），且依赖关系（即 SpellChecker 类）通过类构造函数被注入到 TextEditor 类中。因此，控制流通过依赖注入（DI）已经“反转”，因为你已经有效地委托依赖关系到一些外部系统。 依赖注入的第二种方法是通过 TextEditor 类的 Setter 方法，我们将创建 SpellChecker 实例，该实例将被用于调用 setter 方法来初始化 TextEditor 的属性。 因此，DI 主要有两种变体和下面的两个子章将结合实例涵盖它们： 序号 依赖注入类型 &amp; 描述 1 Constructor-based dependency injection当容器调用带有多个参数的构造函数类时，实现基于构造函数的 DI，每个代表在其他类中的一个依赖关系。 2 Setter-based dependency injection基于 setter 方法的 DI 是通过在调用无参数的构造函数或无参数的静态工厂方法实例化 bean 之后容器调用 beans 的 setter 方法来实现的。 你可以混合这两种方法，基于构造函数和基于 setter 方法的 DI，然而使用有强制性依存关系的构造函数和有可选依赖关系的 setter是一个好的做法。 代码是 DI 原理的清洗机，当对象与它们的依赖关系被提供时，解耦效果更明显。对象不查找它的依赖关系，也不知道依赖关系的位置或类，而这一切都由 Spring 框架控制的。 Spring基于构造函数的依赖注入：当容器调用带有一组参数的类构造函数时，基于构造函数的 DI 就完成了，其中每个参数代表一个对其他类的依赖 。 构造函数参数解析： 如果存在不止一个参数时，当把参数传递给构造函数时，可能会存在歧义。要解决这个问题，那么构造函数的参数在 bean 定义中的顺序就是把这些参数提供给适当的构造函数的顺序就可以了。考虑下面的类: 123456package x.y;public class Foo &#123; public Foo(Bar bar, Baz baz) &#123; // ... &#125;&#125; 下述配置文件工作顺利： 123456789&lt;beans&gt; &lt;bean id="foo" class="x.y.Foo"&gt; &lt;constructor-arg ref="bar"/&gt; &lt;constructor-arg ref="baz"/&gt; &lt;/bean&gt; &lt;bean id="bar" class="x.y.Bar"/&gt; &lt;bean id="baz" class="x.y.Baz"/&gt;&lt;/beans&gt; 让我们再检查一下我们传递给构造函数不同类型的位置。考虑下面的类： 123456package x.y;public class Foo &#123; public Foo(int year, String name) &#123; // ... &#125;&#125; 如果你使用 type 属性显式的指定了构造函数参数的类型，容器也可以使用与简单类型匹配的类型。例如： 12345678&lt;beans&gt; &lt;bean id="exampleBean" class="examples.ExampleBean"&gt; &lt;constructor-arg type="int" value="2001"/&gt; &lt;constructor-arg type="java.lang.String" value="Zara"/&gt; &lt;/bean&gt;&lt;/beans&gt; 最后并且也是最好的传递构造函数参数的方式，使用 index 属性来显式的指定构造函数参数的索引。下面是基于索引为 0 的例子，如下所示： 12345678&lt;beans&gt; &lt;bean id="exampleBean" class="examples.ExampleBean"&gt; &lt;constructor-arg index="0" value="2001"/&gt; &lt;constructor-arg index="1" value="Zara"/&gt; &lt;/bean&gt;&lt;/beans&gt; 最后，如果你想要向一个对象传递一个引用，你需要使用 标签的 ref 属性，如果你想要直接传递值，那么你应该使用如上所示的 value 属性。 示例： TextEditor类： 123456789101112package di;public class TextEditor &#123; private SpellChecker spellChecker; public TextEditor(SpellChecker spellChecker) &#123; System.out.println("TextEditor的构造函数." ); this.spellChecker = spellChecker; &#125; public void spellCheck() &#123; spellChecker.checkSpelling(); &#125;&#125; 另一个依赖文件SpellCkecker.java: 1234567891011package di;public class SpellChecker &#123; public SpellChecker()&#123; System.out.println("SpellChecker的构造函数." ); &#125; public void checkSpelling() &#123; System.out.println("checkSpelling的实现" ); &#125; &#125; 以下是 MainApp.java 文件的内容： 123456789101112package di;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainApp &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml"); TextEditor te = (TextEditor) context.getBean("textEditor"); te.spellCheck(); &#125;&#125; 下面是配置文件 Beans.xml 的内容，它有基于构造函数注入的配置： 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for textEditor bean --&gt; &lt;bean id="textEditor" class="di.TextEditor"&gt; &lt;constructor-arg ref="spellChecker"/&gt; &lt;/bean&gt; &lt;!-- Definition for spellChecker bean --&gt; &lt;bean id="spellChecker" class="di.SpellChecker"&gt; &lt;/bean&gt;&lt;/beans&gt; 运行结果： 123SpellChecker的构造函数.TextEditor的构造函数.checkSpelling的实现 Spring基于设值函数的依赖注入：当容器调用一个无参的构造函数或一个无参的静态 factory 方法来初始化你的 bean 后，通过容器在你的 bean 上调用设值函数，基于设值函数的 DI 就完成了。 使用 p-namespace 实现 XML 配置： 如果你有许多的设值函数方法，那么在 XML 配置文件中使用 p-namespace 是非常方便的。让我们查看一下区别： 以带有 标签的标准 XML 配置文件为例： 1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="john-classic" class="com.example.Person"&gt; &lt;property name="name" value="John Doe"/&gt; &lt;property name="spouse" ref="jane"/&gt; &lt;/bean&gt; &lt;bean name="jane" class="com.example.Person"&gt; &lt;property name="name" value="John Doe"/&gt; &lt;/bean&gt;&lt;/beans&gt; 上述 XML 配置文件可以使用 p-namespace 以一种更简洁的方式重写，如下所示： 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="john-classic" class="com.example.Person" p:name="John Doe" p:spouse-ref="jane"/&gt; &lt;/bean&gt; &lt;bean name="jane" class="com.example.Person" p:name="John Doe"/&gt; &lt;/bean&gt;&lt;/beans&gt; 在这里，你不应该区别指定原始值和带有 p-namespace 的对象引用。-ref 部分表明这不是一个直接的值，而是对另一个 bean 的引用。 Spring注入内部Beans：正如你所知道的 Java 内部类是在其他类的范围内被定义的，同理，inner beans 是在其他 bean 的范围内定义的 bean。因此在 或 元素内 元素被称为内部bean，如下所示。 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;bean id="outerBean" class="..."&gt; &lt;property name="target"&gt; &lt;bean id="innerBean" class="..."/&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; Spring注入集合：你已经看到了如何使用 value 属性来配置基本数据类型和在你的 bean 配置文件中使用&lt;property&gt;标签的 ref 属性来配置对象引用。这两种情况下处理奇异值传递给一个 bean。 现在如果你想传递多个值，如 Java Collection 类型 List、Set、Map 和 Properties，应该怎么做呢。为了处理这种情况，Spring 提供了四种类型的集合的配置元素，如下所示： 元素 描述 &lt; list> 它有助于连线，如注入一列值，允许重复。 &lt;set> 它有助于连线一组值，但不能重复。 &lt;map> 它可以用来注入名称-值对的集合，其中名称和值可以是任何类型。 &lt;props> 它可以用来注入名称-值对的集合，其中名称和值都是字符串类型。 你可以使用&lt;list&gt;或&lt;set&gt;来连接任何 java.util.Collection 的实现或数组。 你会遇到两种情况（a）传递集合中直接的值（b）传递一个 bean 的引用作为集合的元素。 示例： JavaCollection.java 123456789101112131415161718192021222324252627282930313233343536373839404142package di;import java.util.List;import java.util.Map;import java.util.Properties;import java.util.Set;public class JavaCollection &#123; List addressList; Set addressSet; Map addressMap; Properties addressProp; public List getAddressList() &#123; System.out.println("List Elements:" + addressList); return addressList; &#125; public void setAddressList(List addressList) &#123; this.addressList = addressList; &#125; public Set getAddressSet() &#123; System.out.println("Set Elements:" + addressList); return addressSet; &#125; public void setAddressSet(Set addressSet) &#123; this.addressSet = addressSet; &#125; public Map getAddressMap() &#123; System.out.println("Map Elements:" + addressList); return addressMap; &#125; public void setAddressMap(Map addressMap) &#123; this.addressMap = addressMap; &#125; public Properties getAddressProp() &#123; System.out.println("Prop Elements:" + addressList); return addressProp; &#125; public void setAddressProp(Properties addressProp) &#123; this.addressProp = addressProp; &#125; &#125; MainApp.java 12345678910111213141516package di;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Mina &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("Beans.xml"); JavaCollection jc = (JavaCollection)context.getBean("javaCollection"); jc.getAddressList(); jc.getAddressSet(); jc.getAddressMap(); jc.getAddressProp(); &#125;&#125; Beans.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Definition for javaCollection --&gt; &lt;bean id="javaCollection" class="com.tutorialspoint.JavaCollection"&gt; &lt;!-- results in a setAddressList(java.util.List) call --&gt; &lt;property name="addressList"&gt; &lt;list&gt; &lt;value&gt;INDIA&lt;/value&gt; &lt;value&gt;Pakistan&lt;/value&gt; &lt;value&gt;USA&lt;/value&gt; &lt;value&gt;USA&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- results in a setAddressSet(java.util.Set) call --&gt; &lt;property name="addressSet"&gt; &lt;set&gt; &lt;value&gt;INDIA&lt;/value&gt; &lt;value&gt;Pakistan&lt;/value&gt; &lt;value&gt;USA&lt;/value&gt; &lt;value&gt;USA&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!-- results in a setAddressMap(java.util.Map) call --&gt; &lt;property name="addressMap"&gt; &lt;map&gt; &lt;entry key="1" value="INDIA"/&gt; &lt;entry key="2" value="Pakistan"/&gt; &lt;entry key="3" value="USA"/&gt; &lt;entry key="4" value="USA"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!-- results in a setAddressProp(java.util.Properties) call --&gt; &lt;property name="addressProp"&gt; &lt;props&gt; &lt;prop key="one"&gt;INDIA&lt;/prop&gt; &lt;prop key="two"&gt;Pakistan&lt;/prop&gt; &lt;prop key="three"&gt;USA&lt;/prop&gt; &lt;prop key="four"&gt;USA&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 程序运行结果： 1234List Elements:[INDIA, Pakistan, USA, USA]Set Elements:[INDIA, Pakistan, USA, USA]Map Elements:[INDIA, Pakistan, USA, USA]Prop Elements:[INDIA, Pakistan, USA, USA] 注入Bean引用： 下面的 Bean 定义将帮助你理解如何注入 bean 的引用作为集合的元素。甚至你可以将引用和值混合在一起，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd"&gt; &lt;!-- Bean Definition to handle references and values --&gt; &lt;bean id="..." class="..."&gt; &lt;!-- Passing bean reference for java.util.List --&gt; &lt;property name="addressList"&gt; &lt;list&gt; &lt;ref bean="address1"/&gt; &lt;ref bean="address2"/&gt; &lt;value&gt;Pakistan&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- Passing bean reference for java.util.Set --&gt; &lt;property name="addressSet"&gt; &lt;set&gt; &lt;ref bean="address1"/&gt; &lt;ref bean="address2"/&gt; &lt;value&gt;Pakistan&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!-- Passing bean reference for java.util.Map --&gt; &lt;property name="addressMap"&gt; &lt;map&gt; &lt;entry key="one" value="INDIA"/&gt; &lt;entry key ="two" value-ref="address1"/&gt; &lt;entry key ="three" value-ref="address2"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 为了使用上面的 bean 定义，你需要定义 setter 方法，它们应该也能够是用这种方式来处理引用。 注入 null 和空字符串的值: 如果你需要传递一个空字符串作为值，那么你可以传递它，如下所示： 123&lt;bean id="..." class="exampleBean"&gt; &lt;property name="email" value=""/&gt;&lt;/bean&gt; 前面的例子相当于 Java 代码：exampleBean.setEmail(“”)。 如果你需要传递一个 NULL 值，那么你可以传递它，如下所示： 123&lt;bean id="..." class="exampleBean"&gt; &lt;property name="email"&gt;&lt;null/&gt;&lt;/property&gt;&lt;/bean&gt; 前面的例子相当于 Java 代码：exampleBean.setEmail(null)。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Java学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（8）JSP高级]]></title>
    <url>%2F2018%2F07%2F30%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89JSP%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[JSP标准标签库（JSTL）##JSP标准标签库简介： JSP标准标签库（JSTL）是一个JSP标签集合，它封装了JSP应用的通用核心功能。 JSTL支持通用的、结构化的任务，比如迭代，条件判断，XML文档操作，国际化标签，SQL标签。 除了这些，它还提供了一个框架来使用集成JSTL的自定义标签。 根据JSTL标签所提供的功能，可以将其分为5个类别。 核心标签 格式化标签 SQL 标签 XML 标签 JSTL 函数 JSTL库安装：Apache Tomcat安装JSTL 库步骤如下： 从Apache的标准标签库中下载的二进包(jakarta-taglibs-standard-current.zip)。 官方下载地址：http://archive.apache.org/dist/jakarta/taglibs/standard/binaries/ 本站下载地址：jakarta-taglibs-standard-1.1.2.zip 下载jakarta-taglibs-standard-1.1.2.zip 包并解压，将jakarta-taglibs-standard-1.1.2/lib/下的两个jar文件：standard.jar和jstl.jar文件拷贝到/WEB-INF/lib/下。 接下来我们在 web.xml 文件中添加以下配置： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app version="2.4" xmlns="http://java.sun.com/xml/ns/j2ee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd"&gt; &lt;jsp-config&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/fmt&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/fmt.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/fmt-rt&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/fmt-rt.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/core&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/c.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/core-rt&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/c-rt.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/sql&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/sql.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/sql-rt&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/sql-rt.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/x&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/x.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;taglib&gt; &lt;taglib-uri&gt;http://java.sun.com/jstl/x-rt&lt;/taglib-uri&gt; &lt;taglib-location&gt;/WEB-INF/x-rt.tld&lt;/taglib-location&gt; &lt;/taglib&gt; &lt;/jsp-config&gt;&lt;/web-app&gt; 使用任何库，必须在每个JSP文件中的头部包含&lt;taglib>标签。 核心标签：核心标签是最常用的JSTL标签。引用核心标签库的语法如下： 12&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt; 标签 描述 &lt; c:out&gt; 用于在JSP中显示数据，就像&lt;%= … &gt; &lt; c:set&gt; 用于保存数据 &lt; c:remove&gt; 用于删除数据 &lt; c:catch&gt; 用来处理产生错误的异常状况，并且将错误信息储存起来 &lt; c:if&gt; 与我们在一般程序中用的if一样 &lt; c:choose&gt; 本身只当做&lt; c:when&gt;和&lt; c:otherwise&gt;的父标签 &lt; c:when&gt; &lt; c:choose&gt;的子标签，用来判断条件是否成立 &lt; c:otherwise&gt; &lt; c:choose&gt;的子标签，接在&lt; c:when&gt;标签后，当&lt; c:when&gt;标签判断为false时被执行 &lt; c:import&gt; 检索一个绝对或相对 URL，然后将其内容暴露给页面 &lt; c:forEach&gt; 基础迭代标签，接受多种集合类型 &lt; c:forTokens&gt; 根据指定的分隔符来分隔内容并迭代输出 &lt; c:param&gt; 用来给包含或重定向的页面传递参数 &lt; c:redirect&gt; 重定向至一个新的URL. &lt; c:url&gt; 使用可选的查询参数来创造一个URL 格式化标签：JSTL格式化标签用来格式化并输出文本、日期、时间、数字。引用格式化标签库的语法如下： 12&lt;%@ taglib prefix="fmt" uri="http://java.sun.com/jsp/jstl/fmt" %&gt; 标签 描述 &lt; fmt:formatNumber&gt; 使用指定的格式或精度格式化数字 &lt; fmt:parseNumber&gt; 解析一个代表着数字，货币或百分比的字符串 &lt; fmt:parseDate&gt; 使用指定的风格或模式格式化日期和时间 &lt; fmt:setLocale&gt; 解析一个代表着日期或时间的字符串 &lt; fmt:bundle&gt; 绑定资源 &lt; fmt:setLocale&gt; 指定地区 &lt; fmt:setBundle&gt; 绑定资源 &lt; fmt:timeZone&gt; 指定时区 &lt; fmt:setTimeZone&gt; 指定时区 &lt; fmt:message&gt; 显示资源配置文件信息 &lt; fmt:requestEnconding&gt; 设置request的字符编码 SQL标签：JSTL SQL标签库提供了与关系型数据库（Oracle，MySQL，SQL Server等等）进行交互的标签。引用SQL标签库的语法如下： 12&lt;%@ taglib prefix="sql" uri="http://java.sun.com/jsp/jstl/sql" %&gt; 标签 描述 &lt; sql:setDataSource&gt; 指定数据源 &lt; sql:query&gt; 运行SQL查询语句 &lt; sql:update&gt; 运行SQL更新语句 &lt; sql:param&gt; 将SQL语句中的参数设为指定值 &lt; sql:dateParam&gt; 将SQL语句中的日期参数设为指定的java.util.Date 对象值 &lt; sql:transaction&gt; 在共享数据库连接中提供嵌套的数据库行为元素，将所有语句以一个事务的形式来运行 XML 标签JSTL XML标签库提供了创建和操作XML文档的标签。引用XML标签库的语法如下： 12&lt;%@ taglib prefix="x" uri="http://java.sun.com/jsp/jstl/xml" %&gt; 在使用xml标，必须将XML 和 XPath 的相关包拷贝至你的 Tomcat 安装目录\lib下: XercesImpl.jar 下载地址： http://www.apache.org/dist/xerces/j/ xalan.jar 下载地址： http://xml.apache.org/xalan-j/index.html 标签 描述 &lt;x:out&gt; 与&lt;%= … &gt;,类似，不过只用于XPath表达式 &lt;x:parse&gt; 解析 XML 数据 &lt;x:set&gt; 设置XPath表达式 &lt;x:if&gt; 判断XPath表达式，若为真，则执行本体中的内容，否则跳过本体 &lt;x:forEach&gt; 迭代XML文档中的节点 &lt;x:choose&gt; &lt;x:when&gt;和&lt;x:otherwise&gt;的父标签 &lt;x:when&gt; &lt;x:choose&gt;的子标签，用来进行条件判断 &lt;x:otherwise&gt; &lt;x:choose&gt;的子标签，当&lt;x:when&gt;判断为false时被执行 x:transform&gt; 将XSL转换应用在XML文档中 x:param 与&lt;x:transform&gt;共同使用，用于设置XSL样式表 JSTL函数JSTL包含一系列标准函数，大部分是通用的字符串处理函数。引用JSTL函数库的语法如下： 12&lt;%@ taglib prefix="fn" uri="http://java.sun.com/jsp/jstl/functions" %&gt; 函数 描述 fn:contains() 测试输入的字符串是否包含指定的子串 fn:containsIgnoreCase() 测试输入的字符串是否包含指定的子串，大小写不敏感 fn:endsWith() 测试输入的字符串是否以指定的后缀结尾 fn:escapeXml() 跳过可以作为XML标记的字符 fn:indexOf() 返回指定字符串在输入字符串中出现的位置 fn:join() 将数组中的元素合成一个字符串然后输出 fn:length() 返回字符串长度 fn:replace() 将输入字符串中指定的位置替换为指定的字符串然后返回 fn:split() 将字符串用指定的分隔符分隔然后组成一个子字符串数组并返回 fn:startsWith() 测试输入字符串是否以指定的前缀开始 fn:substring() 返回字符串的子集 fn:substringAfter() 返回字符串在指定子串之后的子集 fn:substringBefore() 返回字符串在指定子串之前的子集 fn:toLowerCase() 将字符串中的字符转为小写 fn:toUpperCase() 将字符串中的字符转为大写 fn:trim() 移除首位的空白符 JSP连接数据库SELECT操作实例：123456789101112131415161718192021222324252627282930313233343536373839&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.io.*,java.util.*,java.sql.*"%&gt;&lt;%@ page import="javax.servlet.http.*,javax.servlet.*" %&gt;&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c"%&gt;&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/sql" prefix="sql"%&gt; &lt;html&gt;&lt;head&gt;&lt;title&gt;SELECT 操作&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;sql:setDataSource var="snapshot" driver="com.mysql.jdbc.Driver" url="jdbc:mysql://localhost:3306/jsp_db" user="root" password="123456"/&gt; &lt;sql:query dataSource="$&#123;snapshot&#125;" var="result"&gt;SELECT * from websites;&lt;/sql:query&gt;&lt;h1&gt;JSP 数据库实例 - 菜鸟教程&lt;/h1&gt;&lt;table border="1" width="100%"&gt;&lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;密码&lt;/th&gt; &lt;th&gt;邮箱&lt;/th&gt;&lt;/tr&gt;&lt;c:forEach var="row" items="$&#123;result.rows&#125;"&gt;&lt;tr&gt; &lt;td&gt;&lt;c:out value="$&#123;row.id&#125;"/&gt;&lt;/td&gt; &lt;td&gt;&lt;c:out value="$&#123;row.name&#125;"/&gt;&lt;/td&gt; &lt;td&gt;&lt;c:out value="$&#123;row.password&#125;"/&gt;&lt;/td&gt; &lt;td&gt;&lt;c:out value="$&#123;row.email&#125;"/&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/c:forEach&gt;&lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 运行结果： 图：Select操作 INSERT操作实例：12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.io.*,java.util.*,java.sql.*"%&gt;&lt;%@ page import="javax.servlet.http.*,javax.servlet.*" %&gt;&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c"%&gt;&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/sql" prefix="sql"%&gt; &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;JSP数据库 INSERT操作&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;sql:setDataSource var="snapshot" driver="com.mysql.jdbc.Driver" url="jdbc:mysql://localhost:3306/jsp_db" user="root" password="123456"/&gt;&lt;sql:update dataSource="$&#123;snapshot&#125;" var="result"&gt;INSERT INTO tbl_user (name, password, email)VALUES("xiaoli", "123984", "731507579@qq.com");&lt;/sql:update&gt;&lt;sql:query dataSource="$&#123;snapshot&#125;" var="result"&gt;SELECT * from tbl_user;&lt;/sql:query&gt;&lt;h1&gt;JSP数据库 Insert实例&lt;/h1&gt;&lt;table border="1" width="100%"&gt;&lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;密码&lt;/th&gt; &lt;th&gt;邮箱&lt;/th&gt;&lt;/tr&gt;&lt;c:forEach var="row" items="$&#123;result.rows&#125;"&gt;&lt;tr&gt; &lt;td&gt;&lt;c:out value="$&#123;row.id&#125;"/&gt;&lt;/td&gt; &lt;td&gt;&lt;c:out value="$&#123;row.name&#125;"/&gt;&lt;/td&gt; &lt;td&gt;&lt;c:out value="$&#123;row.password&#125;"/&gt;&lt;/td&gt; &lt;td&gt;&lt;c:out value="$&#123;row.email&#125;"/&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/c:forEach&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 运行结果： 图：insert实例 JSP JavaBeanJavaBean是特殊的Java类，使用J ava语言书写，并且遵守JavaBean API规范。 接下来给出的是JavaBean与其它Java类相比而言独一无二的特征： 提供一个默认的无参构造函数。 需要被序列化并且实现了Serializable接口。 可能有一系列可读写属性。 可能有一系列的”getter”或”setter”方法。 JavaBean属性：一个JavaBean对象的属性应该是可访问的。这个属性可以是任意合法的Java数据类型，包括自定义Java类。 一个JavaBean对象的属性可以是可读写，或只读，或只写。JavaBean对象的属性通过JavaBean实现类中提供的两个方法来访问： 方法 描述 getPropertyName() 举例来说，如果属性的名称为myName，那么这个方法的名字就要写成getMyName()来读取这个属性。这个方法也称为访问器。 setPropertyName() 举例来说，如果属性的名称为myName，那么这个方法的名字就要写成setMyName()来写入这个属性。这个方法也称为写入器。 一个只读的属性只提供getPropertyName()方法，一个只写的属性只提供setPropertyName()方法。 JavaBean程序示例：这是StudentBean.java文件： 123456789101112131415161718192021222324252627282930package com.runoob;public class StudentsBean implements java.io.Serializable&#123; private String firstName = null; private String lastName = null; private int age = 0; public StudentsBean() &#123; &#125; public String getFirstName()&#123; return firstName; &#125; public String getLastName()&#123; return lastName; &#125; public int getAge()&#123; return age; &#125; public void setFirstName(String firstName)&#123; this.firstName = firstName; &#125; public void setLastName(String lastName)&#123; this.lastName = lastName; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 访问JavaBean： jsp:useBean 标签可以在JSP中声明一个JavaBean，然后使用。声明后，JavaBean对象就成了脚本变量，可以通过脚本元素或其他自定义标签来访问。jsp:useBean标签的语法格式如下： 1&lt;jsp:useBean id="bean 的名字" scope="bean 的作用域" typeSpec/&gt; 其中，根据具体情况，scope的值可以是page，request，session或application。id值可任意只要不和同一JSP文件中其它jsp:useBean中id值一样就行了。 访问 JavaBean 对象的属性： 在 jsp:useBean 标签主体中使用 jsp:getProperty/ 标签来调用 getter 方法，使用 jsp:setProperty/ 标签来调用 setter 方法，语法格式如下： 123456&lt;jsp:useBean id="id" class="bean 编译的类" scope="bean 作用域"&gt; &lt;jsp:setProperty name="bean 的 id" property="属性名" value="value"/&gt; &lt;jsp:getProperty name="bean 的 id" property="属性名"/&gt; ...........&lt;/jsp:useBean&gt; name属性指的是Bean的id属性。property属性指的是想要调用的getter或setter方法。 接下来给出使用以上语法进行属性访问的一个简单例子： 123456789101112131415161718192021222324252627282930&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;get 和 set 属性实例&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;jsp:useBean id="students" class="com.runoob.StudentsBean"&gt; &lt;jsp:setProperty name="students" property="firstName" value="小强"/&gt; &lt;jsp:setProperty name="students" property="lastName" value="王"/&gt; &lt;jsp:setProperty name="students" property="age" value="10"/&gt;&lt;/jsp:useBean&gt;&lt;p&gt;学生名字: &lt;jsp:getProperty name="students" property="firstName"/&gt;&lt;/p&gt;&lt;p&gt;学生姓氏: &lt;jsp:getProperty name="students" property="lastName"/&gt;&lt;/p&gt;&lt;p&gt;学生年龄: &lt;jsp:getProperty name="students" property="age"/&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; JSP自定义标签自定义标签是用户定义的JSP语言元素。当JSP页面包含一个自定义标签时将被转化为servlet，标签转化为对被 称为tag handler的对象的操作，即当servlet执行时Web container调用那些操作。 JSP标签扩展可以让你创建新的标签并且可以直接插入到一个JSP页面。 JSP 2.0规范中引入Simple Tag Handlers来编写这些自定义标记。 你可以继承SimpleTagSupport类并重写的doTag()方法来开发一个最简单的自定义标签。 创建”Hello”标签接下来，我们想创建一个自定义标签叫作ex:Hello，标签格式为： 1&lt;ex:Hello /&gt; 要创建自定义的JSP标签，你首先必须创建处理标签的Java类。所以，让我们创建一个HelloTag类，如下所示： 12345678910111213package servlet;import javax.servlet.jsp.tagext.*;import javax.servlet.jsp.*;import java.io.*;public class HelloTag extends SimpleTagSupport &#123; public void doTag() throws JspException, IOException &#123; JspWriter out = getJspContext().getOut(); out.println("Hello Custom Tag!"); &#125;&#125; 以下代码重写了doTag()方法，方法中使用了getJspContext()方法来获取当前的JspContext对象，并将”Hello Custom Tag!”传递给JspWriter对象。 编译以上类，并将其复制到环境变量CLASSPATH目录中。最后创建如下标签库：&lt;Tomcat安装目录&gt;webapps\ROOT\WEB-INF\custom.tld。 12345678910&lt;taglib&gt; &lt;tlib-version&gt;1.0&lt;/tlib-version&gt; &lt;jsp-version&gt;2.0&lt;/jsp-version&gt; &lt;short-name&gt;Example TLD&lt;/short-name&gt; &lt;tag&gt; &lt;name&gt;Hello&lt;/name&gt; &lt;tag-class&gt;com.runoob.HelloTag&lt;/tag-class&gt; &lt;body-content&gt;empty&lt;/body-content&gt; &lt;/tag&gt;&lt;/taglib&gt; 接下来，我们就可以在JSP文件中使用Hello标签： 123456789&lt;%@ taglib prefix="ex" uri="WEB-INF/custom.tld"%&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;A sample custom tag&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;ex:Hello/&gt; &lt;/body&gt;&lt;/html&gt; 以上程序输出结果为： 1Hello Custom Tag! JSP表达式语言JSP表达式语言（EL）使得访问存储在JavaBean中的数据变得非常简单。JSP EL既可以用来创建算术表达式也可以用来创建逻辑表达式。在JSP EL表达式内可以使用整型数，浮点数，字符串，常量true、false，还有null。 一个简单的语法典型的，当您需要在JSP标签中指定一个属性值时，只需要简单地使用字符串即可： 1&lt;jsp:setProperty name="box" property="perimeter" value="100"/&gt; JSP EL允许您指定一个表达式来表示属性值。一个简单的表达式语法如下： 1$&#123;expr&#125; 其中，expr指的是表达式。在JSP EL中通用的操作符是 . 和 {} 。这两个操作符允许您通过内嵌的JSP对象访问各种各样的JavaBean属性。 举例来说，上面的jsp:setProperty标签可以使用表达式语言改写成如下形式： 12&lt;jsp:setProperty name=&quot;box&quot; property=&quot;perimeter&quot; value=&quot;$&#123;2*box.width+2*box.height&#125;&quot;/&gt; 当JSP编译器在属性中见到”${}”格式后，它会产生代码来计jsp算这个表达式，并且产生一个替代品来代替表达式的值。 您也可以在标签的模板文本中使用表达式语言。比如jsp:text标签简单地将其主体中的文本插入到JSP输出中： 123&lt;jsp:text&gt;&lt;h1&gt;Hello JSP!&lt;/h1&gt;&lt;/jsp:text&gt; 现在，在jsp:text标签主体中使用表达式，就像这样： 123&lt;jsp:text&gt;Box Perimeter is: $&#123;2*box.width + 2*box.height&#125;&lt;/jsp:text&gt; 在EL表达式中可以使用圆括号来组织子表达式。比如${(1 + 2) 3}等于9，但是${1 + (2 3)} 等于7。 想要停用对EL表达式的评估的话，需要使用page指令将isELIgnored属性值设为true： 1&lt;%@ page isELIgnored ="true|false" %&gt; 这样，EL表达式就会被忽略。若设为false，则容器将会计算EL表达式。 EL中的基础操作符EL表达式支持大部分Java所提供的算术和逻辑操作符： 操作符 描述 . 访问一个Bean属性或者一个映射条目 [] 访问一个数组或者链表的元素 ( ) 组织一个子表达式以改变优先级 + 加 - 减或负 * 乘 / or div 除 % or mod 取模 == or eq 测试是否相等 != or ne 测试是否不等 &lt; or lt 测试是否小于 &gt; or gt 测试是否大于 &lt;= or le 测试是否小于等于 &gt;= or ge 测试是否大于等于 &amp;&amp; or and 测试逻辑与 \ \ or or 测试逻辑或 ! or not 测试取反 empty 测试是否空值]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
        <tag>JSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（7）JSP基础]]></title>
    <url>%2F2018%2F07%2F28%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89JSP%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JSP简介什么是JSP？JSP全称Java Server Pages，是一种动态网页开发技术。它使用JSP标签在HTML网页中插入Java代码。标签通常以&lt;%开头以%&gt;结束。 JSP是一种Java servlet，主要用于实现Java web应用程序的用户界面部分。网页开发者们通过结合HTML代码、XHTML代码、XML元素以及嵌入JSP操作和命令来编写JSP。 JSP通过网页表单获取用户输入数据、访问数据库及其他数据源，然后动态地创建网页。 JSP标签有多种功能，比如访问数据库、记录用户选择信息、访问JavaBeans组件等，还可以在不同的网页中传递控制信息和共享信息。 为什么使用JSP？JSP程序与CGI程序有着相似的功能，但和CGI程序相比，JSP程序有如下优势： 性能更加优越，因为JSP可以直接在HTML网页中动态嵌入元素而不需要单独引用CGI文件。 服务器调用的是已经编译好的JSP文件，而不像CGI/Perl那样必须先载入解释器和目标脚本。 JSP 基于Java Servlet API，因此，JSP拥有各种强大的企业级Java API，包括JDBC，JNDI，EJB，JAXP等等。 JSP页面可以与处理业务逻辑的 Servlet 一起使用，这种模式被Java servlet 模板引擎所支持。 最后，JSP是Java EE不可或缺的一部分，是一个完整的企业级应用平台。这意味着JSP可以用最简单的方式来实现最复杂的应用。 JSP的优势： 与ASP相比：JSP有两大优势。首先，动态部分用Java编写，而不是VB或其他MS专用语言，所以更加强大与易用。第二点就是JSP易于移植到非MS平台上。 与纯 Servlet 相比：JSP可以很方便的编写或者修改HTML网页而不用去面对大量的println语句。 与SSI相比：SSI无法使用表单数据、无法进行数据库链接。 与JavaScript相比：虽然JavaScript可以在客户端动态生成HTML，但是很难与服务器交互，因此不能提供复杂的服务，比如访问数据库和图像处理等等。 与静态HTML相比：静态HTML不包含动态信息。 JSP结构网络服务器需要一个 JSP 引擎，也就是一个容器来处理 JSP 页面。容器负责截获对 JSP 页面的请求。 JSP 容器与 Web 服务器协同合作，为JSP的正常运行提供必要的运行环境和其他服务，并且能够正确识别专属于 JSP 网页的特殊元素。 下图显示了 JSP 容器和 JSP 文件在 Web 应用中所处的位置。 图：JSP结构 JSP处理：以下步骤表明了 Web 服务器是如何使用JSP来创建网页的： 就像其他普通的网页一样，您的浏览器发送一个 HTTP 请求给服务器。 Web 服务器识别出这是一个对 JSP 网页的请求，并且将该请求传递给 JSP 引擎。通过使用 URL或者 .jsp 文件来完成。 JSP 引擎从磁盘中载入 JSP 文件，然后将它们转化为 Servlet。这种转化只是简单地将所有模板文本改用 println() 语句，并且将所有的 JSP 元素转化成 Java 代码。 JSP 引擎将 Servlet 编译成可执行类，并且将原始请求传递给 Servlet 引擎。 Web 服务器的某组件将会调用 Servlet 引擎，然后载入并执行 Servlet 类。在执行过程中，Servlet 产生 HTML 格式的输出并将其内嵌于 HTTP response 中上交给 Web 服务器。 Web 服务器以静态 HTML 网页的形式将 HTTP response 返回到您的浏览器中。 最终，Web 浏览器处理 HTTP response 中动态产生的HTML网页，就好像在处理静态网页一样。 以上提及到的步骤可以用下图来表示： 图：JSP处理流程图 一般情况下，JSP 引擎会检查 JSP 文件对应的 Servlet 是否已经存在，并且检查 JSP 文件的修改日期是否早于 Servlet。如果 JSP 文件的修改日期早于对应的 Servlet，那么容器就可以确定 JSP 文件没有被修改过并且 Servlet 有效。这使得整个流程与其他脚本语言（比如 PHP）相比要高效快捷一些。 总的来说，JSP 网页就是用另一种方式来编写 Servlet 而不用成为 Java 编程高手。除了解释阶段外，JSP 网页几乎可以被当成一个普通的 Servlet 来对待。 JSP生命周期JSP生命周期；理解JSP底层功能的关键就是去理解它们所遵守的生命周期。 JSP生命周期就是从创建到销毁的整个过程，类似于servlet生命周期，区别在于JSP生命周期还包括将JSP文件编译成servlet。 以下是JSP生命周期中所走过的几个阶段： 编译阶段： servlet容器编译servlet源文件，生成servlet类 初始化阶段： 加载与JSP对应的servlet类，创建其实例，并调用它的初始化方法 执行阶段： 调用与JSP对应的servlet实例的服务方法 销毁阶段： 调用与JSP对应的servlet实例的销毁方法，然后销毁servlet实例 很明显，JSP生命周期的四个主要阶段和servlet生命周期非常相似，下面给出图示： 图：JSP的生命周期 JSP编译：当浏览器请求JSP页面时，JSP引擎会首先去检查是否需要编译这个文件。如果这个文件没有被编译过，或者在上次编译后被更改过，则编译这个JSP文件。 编译的过程包括三个步骤： 解析JSP文件。 将JSP文件转为servlet。 编译servlet。 JSP初始化：容器载入JSP文件后，它会在为请求提供任何服务前调用jspInit()方法。如果您需要执行自定义的JSP初始化任务，复写jspInit()方法就行了，就像下面这样： 123public void jspInit()&#123; // 初始化代码&#125; 一般来讲程序只初始化一次，servlet也是如此。通常情况下您可以在jspInit()方法中初始化数据库连接、打开文件和创建查询表。 JSP执行：这一阶段描述了JSP生命周期中一切与请求相关的交互行为，直到被销毁。 当JSP网页完成初始化后，JSP引擎将会调用_jspService()方法。 _jspService()方法需要一个HttpServletRequest对象和一个HttpServletResponse对象作为它的参数，就像下面这样： 12345void _jspService(HttpServletRequest request, HttpServletResponse response)&#123; // 服务端处理代码&#125; _jspService()方法在每个request中被调用一次并且负责产生与之相对应的response，并且它还负责产生所有7个HTTP方法的回应，比如GET、POST、DELETE等等。 JSP清理：SP生命周期的销毁阶段描述了当一个JSP网页从容器中被移除时所发生的一切。 jspDestroy()方法在JSP中等价于servlet中的销毁方法。当您需要执行任何清理工作时复写jspDestroy()方法，比如释放数据库连接或者关闭文件夹等等。 jspDestroy()方法的格式如下： 1234public void jspDestroy()&#123; // 清理代码&#125; JSP生命周期代码实例：123456789101112131415161718192021222324252627282930313233343536373839404142&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;JSP生命周期实例&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;%! private int initVar=0; private int serviceVar=0; private int destroyVar=0;%&gt; &lt;%! public void jspInit()&#123; initVar++; System.out.println("jspInit():JSP被初始化了" + initVar + "次"); &#125; public void jspDestroy()&#123; destroyVar++; System.out.println("jspDestroy(): JSP被销毁了"+ destroyVar +"次"); &#125;%&gt; &lt;% serviceVar++; System.out.println("_jspService(): JSP共响应了" + serviceVar + "次请求"); String content1 = "初始化次数 : " + initVar; String content2 = "响应客户请求次数 : " + serviceVar; String content3 = "销毁次数 : " + destroyVar; %&gt;&lt;h1&gt;JSP测试实例&lt;/h1&gt;&lt;p&gt;&lt;%=content1 %&gt;&lt;/p&gt;&lt;p&gt;&lt;%=content2 %&gt;&lt;/p&gt;&lt;p&gt;&lt;%=content3 %&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 运行结果： 图：JSP生命周期测试实例 JSP语法脚本程序：脚本程序可以包含任意量的Java语句、变量、方法或表达式，只要它们在脚本语言中是有效的。 脚本程序的语法格式： 1&lt;% 代码片段 %&gt; 或者，您也可以编写与其等价的XML语句，就像下面这样： 123&lt;jsp:scriptlet&gt; 代码片段&lt;/jsp:scriptlet&gt; 任何文本、HTML标签、JSP元素必须写在脚本程序的外面。 JSP程序示例： 123456789&lt;html&gt;&lt;head&gt;&lt;title&gt;Hello World&lt;/title&gt;&lt;/head&gt;&lt;body&gt;Hello World!&lt;br/&gt;&lt;%out.println("Your IP address is " + request.getRemoteAddr());%&gt;&lt;/body&gt;&lt;/html&gt; 如果我们要在页面正常显示中文，我们需要在 JSP 文件头部添加以下代码：&lt;&gt; 12&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt; JSP声明：一个声明语句可以声明一个或多个变量、方法，供后面的Java代码使用。在JSP文件中，必须先声明这些变量和方法然后才能使用它们。 JSP声明的语法格式： 1&lt;%! declaration; [ declaration; ]+ ... %&gt; 或者，您也可以编写与其等价的XML语句，就像下面这样： 123&lt;jsp:declaration&gt; 代码片段&lt;/jsp:declaration&gt; 程序示例： 123&lt;%! int i = 0; %&gt; &lt;%! int a, b, c; %&gt; &lt;%! Circle a = new Circle(2.0); %&gt; JSP表达式：一个JSP表达式中包含的脚本语言表达式，先被转化成String，然后插入到表达式出现的地方。 由于表达式的值会被转化成String，所以您可以在一个文本行中使用表达式而不用去管它是否是HTML标签。 表达式元素中可以包含任何符合Java语言规范的表达式，但是不能使用分号来结束表达式。 JSP表达式的语法格式： 1&lt;%= 表达式 %&gt; 同样，您也可以编写与之等价的XML语句： 123&lt;jsp:expression&gt; 表达式&lt;/jsp:expression&gt; 程序示例： 1234567891011121314&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;JSP语法测试&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt; 今天的日期是:&lt;%= (new java.util.Date()).toLocaleString() %&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 程序运行结果： 今天的日期是:2018-7-28 15:17:40 JSP注释：JSP注释主要有两个作用：为代码作注释以及将某段代码注释掉。 JSP注释的语法格式： 123456789101112131415&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;%-- 该部分注释在网页中不会被显示--%&gt; &lt;p&gt; 今天的日期是: &lt;%= (new java.util.Date()).toLocaleString()%&gt;&lt;/p&gt;&lt;/body&gt; &lt;/html&gt; 运行后得到以下结果： 1今天的日期是: 2016-6-25 13:41:26 不同情况下使用注释的语法规则： 语法 描述 &lt;%– 注释 –%&gt; JSP注释，注释内容不会被发送至浏览器甚至不会被编译 HTML注释，通过浏览器查看网页源代码时可以看见注释内容 &lt;\% 代表静态 &lt;%常量 %> 代表静态 %&gt; 常量 \’ 在属性中使用的单引号 \” 在属性中使用的双引号 JSP指令：JSP指令用来设置与整个JSP页面相关的属性。 JSP指令语法格式： 1&lt;%@ directive attribute="value" %&gt; 这里有三种指令标签： 指令 描述 &lt;%@ page … %&gt; 定义页面的依赖属性，比如脚本语言、error页面、缓存需求等等 &lt;%@ include … %&gt; 包含其他文件 &lt;%@ taglib … %&gt; 引入标签库的定义，可以是自定义标签 JSP行为：SP行为标签使用XML语法结构来控制servlet引擎。它能够动态插入一个文件，重用JavaBean组件，引导用户去另一个页面，为Java插件产生相关的HTML等等。 行为标签只有一种语法格式，它严格遵守XML标准： 1&lt;jsp:action_name attribute="value" /&gt; 行为标签基本上是一些预先就定义好的函数，下表罗列出了一些可用的JSP行为标签：： 语法 描述 jsp:include 用于在当前页面中包含静态或动态资源 jsp:useBean 寻找和初始化一个JavaBean组件 jsp:setProperty 设置 JavaBean组件的值 jsp:getProperty 将 JavaBean组件的值插入到 output中 jsp:forward 从一个JSP文件向另一个文件传递一个包含用户请求的request对象 jsp:plugin 用于在生成的HTML页面中包含Applet和JavaBean对象 jsp:element 动态创建一个XML元素 jsp:attribute 定义动态创建的XML元素的属性 jsp:body 定义动态创建的XML元素的主体 jsp:text 用于封装模板数据 JSP隐含对象：JSP支持九个自动定义的变量，江湖人称隐含对象。这九个隐含对象的简介见下表： 对象 描述 request HttpServletRequest类的实例 response HttpServletResponse类的实例 out PrintWriter类的实例，用于把结果输出至网页上 session HttpSession类的实例 application ServletContext类的实例，与应用上下文有关 config ServletConfig类的实例 pageContext PageContext类的实例，提供对JSP页面所有对象以及命名空间的访问 page 类似于Java类中的this关键字 Exception Exception类的对象，代表发生错误的JSP页面中对应的异常对象 控制流语句JSP提供对Java语言的全面支持。您可以在JSP程序中使用Java API甚至建立Java代码块，包括判断语句和循环语句等等。 判断语句If…else块，请看下面这个例子： 123456789101112131415161718&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%! int day = 3; %&gt; &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;IF...ELSE 实例&lt;/h3&gt;&lt;% if (day == 1 | day == 7) &#123; %&gt; &lt;p&gt;今天是周末&lt;/p&gt;&lt;% &#125; else &#123; %&gt; &lt;p&gt;今天不是周末&lt;/p&gt;&lt;% &#125; %&gt;&lt;/body&gt; &lt;/html&gt; 运行后得到以下结果： 12IF...ELSE 实例今天不是周末 现在来看看switch…case块，与if…else块有很大的不同，它使用out.println()，并且整个都装在脚本程序的标签中，就像下面这样： 12345678910111213141516171819202122232425262728293031323334353637&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%! int day = 3; %&gt; &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;SWITCH...CASE 实例&lt;/h3&gt;&lt;% switch(day) &#123;case 0: out.println("星期天"); break;case 1: out.println("星期一"); break;case 2: out.println("星期二"); break;case 3: out.println("星期三"); break;case 4: out.println("星期四"); break;case 5: out.println("星期五"); break;default: out.println("星期六");&#125;%&gt;&lt;/body&gt; &lt;/html&gt; 浏览器访问，运行后得出以下结果： 123SWITCH...CASE 实例星期三 循环语句在JSP程序中可以使用Java的三个基本循环类型：for，while，和 do…while。 让我们来看看for循环的例子，以下输出的不同字体大小的”菜鸟教程”： 123456789101112131415161718&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%! int fontSize; %&gt; &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;For 循环实例&lt;/h3&gt;&lt;%for ( fontSize = 1; fontSize &lt;= 3; fontSize++)&#123; %&gt; &lt;font color="green" size="&lt;%= fontSize %&gt;"&gt; 菜鸟教程 &lt;/font&gt;&lt;br /&gt;&lt;%&#125;%&gt;&lt;/body&gt; &lt;/html&gt; JSP 字面量JSP语言定义了以下几个字面量： 布尔值(boolean)：true 和 false; 整型(int)：与 Java 中的一样; 浮点型(float)：与 Java 中的一样; 字符串(string)：以单引号或双引号开始和结束; Null：null。 JSP指令JSP指令：SP指令用来设置整个JSP页面相关的属性，如网页的编码方式和脚本语言。 语法格式如下： 1&lt;%@ directive attribute="value" %&gt; 指令可以有很多个属性，它们以键值对的形式存在，并用逗号隔开。 JSP中的三种指令标签： 指令 描述 &lt;%@ page … %&gt; 定义网页依赖属性，比如脚本语言、error页面、缓存需求等等 &lt;%@ include … %&gt; 包含其他文件 &lt;%@ taglib … %&gt; 引入标签库的定义 Page指令：Page指令为容器提供当前页面的使用说明。一个JSP页面可以包含多个page指令。 Page指令的语法格式： 1&lt;%@ page attribute="value" %&gt; 等价的XML格式： 1&lt;jsp:directive.page attribute="value" /&gt; 下表列出与Page指令相关的属性： 属性 描述 buffer 指定out对象使用缓冲区的大小 autoFlush 控制out对象的 缓存区 contentType 指定当前JSP页面的MIME类型和字符编码 errorPage 指定当JSP页面发生异常时需要转向的错误处理页面 isErrorPage 指定当前页面是否可以作为另一个JSP页面的错误处理页面 extends 指定servlet从哪一个类继承 import 导入要使用的Java类 info 定义JSP页面的描述信息 isThreadSafe 指定对JSP页面的访问是否为线程安全 language 定义JSP页面所用的脚本语言，默认是Java session 指定JSP页面是否使用session isELIgnored 指定是否执行EL表达式 isScriptingEnabled 确定脚本元素能否被使用 Include指令：JSP可以通过include指令来包含其他文件。被包含的文件可以是JSP文件、HTML文件或文本文件。包含的文件就好像是该JSP文件的一部分，会被同时编译执行。 Include指令的语法格式如下： 1&lt;%@ include file="文件相对 url 地址" %&gt; include 指令中的文件名实际上是一个相对的 URL 地址。 如果您没有给文件关联一个路径，JSP编译器默认在当前路径下寻找。 等价的XML语法： 1&lt;jsp:directive.include file="文件相对 url 地址" /&gt; Taglib指令：JSP API允许用户自定义标签，一个自定义标签库就是自定义标签的集合。 Taglib指令引入一个自定义标签集合的定义，包括库路径、自定义标签。 Taglib指令的语法： 1&lt;%@ taglib uri="uri" prefix="prefixOfTag" %&gt; uri属性确定标签库的位置，prefix属性指定标签库的前缀。 等价的XML语法： 1&lt;jsp:directive.taglib uri="uri" prefix="prefixOfTag" /&gt; JSP动作元素与JSP指令元素不同的是，JSP动作元素在请求处理阶段起作用。JSP动作元素是用XML语法写成的。 利用JSP动作可以动态地插入文件、重用JavaBean组件、把用户重定向到另外的页面、为Java插件生成HTML代码。 动作元素只有一种语法，它符合XML标准： 1&lt;jsp:action_name attribute="value" /&gt; 动作元素基本上都是预定义的函数，JSP规范定义了一系列的标准动作，它用JSP作为前缀，可用的标准动作元素如下： 语法 描述 jsp:include 在页面被请求的时候引入一个文件。 jsp:useBean 寻找或者实例化一个JavaBean。 jsp:setProperty 设置JavaBean的属性。 jsp:getProperty 输出某个JavaBean的属性。 jsp:forward 把请求转到一个新的页面。 jsp:plugin 根据浏览器类型为Java插件生成OBJECT或EMBED标记。 jsp:element 定义动态XML元素 jsp:attribute 设置动态定义的XML元素属性。 jsp:body 设置动态定义的XML元素内容。 jsp:text 在JSP页面和文档中使用写入文本的模板 常见的属性: 所有的动作要素都有两个属性：id属性和scope属性。 id属性： id属性是动作元素的唯一标识，可以在JSP页面中引用。动作元素创建的id值可以通过PageContext来调用。 scope属性： 该属性用于识别动作元素的生命周期。 id属性和scope属性有直接关系，scope属性定义了相关联id对象的寿命。 scope属性有四个可能的值： (a) page, (b)request, (c)session, 和 (d) application。 JSP隐式对象JSP隐式对象是JSP容器为每个页面提供的Java对象，开发者可以直接使用它们而不用显式声明。JSP隐式对象也被称为预定义变量。 JSP所支持的九大隐式对象： 对象 描述 request HttpServletRequest 接口的实例 response HttpServletResponse 接口的实例 out JspWriter类的实例，用于把结果输出至网页上 session HttpSession类的实例 application ServletContext类的实例，与应用上下文有关 config ServletConfig类的实例 pageContext PageContext类的实例，提供对JSP页面所有对象以及命名空间的访问 page 类似于Java类中的this关键字 Exception Exception类的对象，代表发生错误的JSP页面中对应的异常对象 request对象 request对象是javax.servlet.http.HttpServletRequest 类的实例。每当客户端请求一个JSP页面时，JSP引擎就会制造一个新的request对象来代表这个请求。 request对象提供了一系列方法来获取HTTP头信息，cookies，HTTP方法等等。 response对象 response对象是javax.servlet.http.HttpServletResponse类的实例。当服务器创建request对象时会同时创建用于响应这个客户端的response对象。 response对象也定义了处理HTTP头模块的接口。通过这个对象，开发者们可以添加新的cookies，时间戳，HTTP状态码等等。 out对象 out对象是 javax.servlet.jsp.JspWriter 类的实例，用来在response对象中写入内容。 最初的JspWriter类对象根据页面是否有缓存来进行不同的实例化操作。可以在page指令中使用buffered=’false’属性来轻松关闭缓存。 JspWriter类包含了大部分java.io.PrintWriter类中的方法。不过，JspWriter新增了一些专为处理缓存而设计的方法。还有就是，JspWriter类会抛出IOExceptions异常，而PrintWriter不会。 下表列出了我们将会用来输出boolean，char，int，double，String，object等类型数据的重要方法： 方法 描述 out.print(dataType dt) 输出Type类型的值 out.println(dataType dt) 输出Type类型的值然后换行 out.flush() 刷新输出流 session对象 session对象是 javax.servlet.http.HttpSession 类的实例。和Java Servlets中的session对象有一样的行为。 session对象用来跟踪在各个客户端请求间的会话。 application对象 application对象直接包装了servlet的ServletContext类的对象，是javax.servlet.ServletContext 类的实例。 这个对象在JSP页面的整个生命周期中都代表着这个JSP页面。这个对象在JSP页面初始化时被创建，随着jspDestroy()方法的调用而被移除。 通过向application中添加属性，则所有组成您web应用的JSP文件都能访问到这些属性。 config对象 config对象是 javax.servlet.ServletConfig 类的实例，直接包装了servlet的ServletConfig类的对象。 这个对象允许开发者访问Servlet或者JSP引擎的初始化参数，比如文件路径等。 以下是config对象的使用方法，不是很重要，所以不常用： 1config.getServletName(); 它返回包含在&lt;servlet-name>元素中的servlet名字，注意，&lt;servlet-name>元素在 WEB-INF\web.xml 文件中定义。 pageContext 对象 pageContext对象是javax.servlet.jsp.PageContext 类的实例，用来代表整个JSP页面。 这个对象主要用来访问页面信息，同时过滤掉大部分实现细节。 这个对象存储了request对象和response对象的引用。application对象，config对象，session对象，out对象可以通过访问这个对象的属性来导出。 pageContext对象也包含了传给JSP页面的指令信息，包括缓存信息，ErrorPage URL,页面scope等。 PageContext类定义了一些字段，包括PAGE_SCOPE，REQUEST_SCOPE，SESSION_SCOPE， APPLICATION_SCOPE。它也提供了40余种方法，有一半继承自javax.servlet.jsp.JspContext 类。 其中一个重要的方法就是removeArribute()，它可接受一个或两个参数。比如，pageContext.removeArribute(“attrName”)移除四个scope中相关属性，但是下面这种方法只移除特定scope中的相关属性： 1pageContext.removeAttribute("attrName", PAGE_SCOPE); page 对象 这个对象就是页面实例的引用。它可以被看做是整个JSP页面的代表。 page 对象就是this对象的同义词。 exception 对象 exception 对象包装了从先前页面中抛出的异常信息。它通常被用来产生对出错条件的适当响应。 JSP的功能JSP客户端请求：HTTP信息头示例： 在这个例子中，我们会使用HttpServletRequest类的getHeaderNames()方法来读取HTTP信息头。这个方法以枚举的形式返回当前HTTP请求的头信息。 获取Enumeration对象后，用标准的方式来遍历Enumeration对象，用hasMoreElements()方法来确定什么时候停止，用nextElement()方法来获得每个参数的名字。 123456789101112131415161718192021222324252627&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.io.*,java.util.*" %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;HTTP 头部请求实例&lt;/h2&gt;&lt;table width="100%" border="1" align="center"&gt;&lt;tr bgcolor="#949494"&gt;&lt;th&gt;Header Name&lt;/th&gt;&lt;th&gt;Header Value(s)&lt;/th&gt;&lt;/tr&gt;&lt;% Enumeration headerNames = request.getHeaderNames(); while(headerNames.hasMoreElements()) &#123; String paramName = (String)headerNames.nextElement(); out.print("&lt;tr&gt;&lt;td&gt;" + paramName + "&lt;/td&gt;\n"); String paramValue = request.getHeader(paramName); out.println("&lt;td&gt; " + paramValue + "&lt;/td&gt;&lt;/tr&gt;\n"); &#125;%&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; JSP服务器响应：接下来的例子使用setIntHeader()方法和setRefreshHeader()方法来模拟一个数字时钟： 123456789101112131415161718192021222324252627282930&lt;%@page import="java.util.GregorianCalendar"%&gt;&lt;%@page import="java.util.Calendar"%&gt;&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;JSP服务器响应&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;自动刷新实例&lt;/h2&gt;&lt;% //设置每隔5秒自动刷新 response.setIntHeader("Refresh", 5); //获取当前时间 Calendar calendar = new GregorianCalendar(); String am_pm; int hour = calendar.get(Calendar.HOUR); int minute = calendar.get(Calendar.MINUTE); int second = calendar.get(Calendar.SECOND); if(calendar.get(Calendar.AM_PM) == 0) am_pm = "AM"; else am_pm = "PM"; String CurrentTime = hour + ":" + minute + ":" + second + " " + am_pm; out.println("当前时间：" + CurrentTime + "\n");%&gt;&lt;/body&gt;&lt;/html&gt; JSP过滤器：JSP 和 Servlet 中的过滤器都是 Java 类。 过滤器可以动态地拦截请求和响应，以变换或使用包含在请求或响应中的信息。 可以将一个或多个过滤器附加到一个 Servlet 或一组 Servlet。过滤器也可以附加到 JavaServer Pages (JSP) 文件和 HTML 页面。 过滤器是可用于 Servlet 编程的 Java 类，可以实现以下目的： 在客户端的请求访问后端资源之前，拦截这些请求。 在服务器的响应发送回客户端之前，处理这些响应。 过滤器通过 Web 部署描述符（web.xml）中的 XML 标签来声明，然后映射到您的应用程序的部署描述符中的 Servlet 名称或 URL 模式。 当 Web 容器启动 Web 应用程序时，它会为您在部署描述符中声明的每一个过滤器创建一个实例。 Filter 的执行顺序与在 web.xml 配置文件中的配置顺序一致，一般把 Filter 配置在所有的 Servlet 之前。 JSP过滤器同Servlet过滤器。 Filter 的基本工作原理 1、Filter 程序是一个实现了特殊接口的 Java 类，与 Servlet 类似，也是由 Servlet 容器进行调用和执行的。 2、当在 web.xml 注册了一个 Filter 来对某个 Servlet 程序进行拦截处理时，它可以决定是否将请求继续传递给 Servlet 程序，以及对请求和响应消息是否进行修改。 3、当 Servlet 容器开始调用某个 Servlet 程序时，如果发现已经注册了一个 Filter 程序来对该 Servlet 进行拦截，那么容器不再直接调用 Servlet 的 service 方法，而是调用 Filter 的 doFilter 方法，再由 doFilter 方法决定是否去激活 service 方法。 4、但在 Filter.doFilter 方法中不能直接调用 Servlet 的 service 方法，而是调用 FilterChain.doFilter 方法来激活目标 Servlet 的 service 方法，FilterChain 对象时通过 Filter.doFilter 方法的参数传递进来的。 5、只要在 Filter.doFilter 方法中调用 FilterChain.doFilter 方法的语句前后增加某些程序代码，这样就可以在 Servlet 进行响应前后实现某些特殊功能。 6、如果在 Filter.doFilter 方法中没有调用 FilterChain.doFilter 方法，则目标 Servlet 的 service 方法不会被执行，这样通过 Filter 就可以阻止某些非法的访问请求。 JSP Cookie：设置Cooki： 1234567891011121314151617181920212223242526272829303132333435363738&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.net.*" %&gt;&lt;% // 编码，解决中文乱码 String str = URLEncoder.encode(request.getParameter("name"),"utf-8"); // 设置 name 和 url cookie Cookie name = new Cookie("name", str); Cookie url = new Cookie("url", request.getParameter("url")); // 设置cookie过期时间为24小时。 name.setMaxAge(60*60*24); url.setMaxAge(60*60*24); // 在响应头部添加cookie response.addCookie( name ); response.addCookie( url );%&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;设置 Cookie&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;设置 Cookie&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;网站名:&lt;/b&gt; &lt;%= request.getParameter("name")%&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;网址:&lt;/b&gt; &lt;%= request.getParameter("url")%&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 读取Cookie： 12345678910111213141516171819202122232425262728293031&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.net.*" %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;获取 Cookie&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% Cookie cookie = null; Cookie[] cookies = null; // 获取cookies的数据,是一个数组 cookies = request.getCookies(); if( cookies != null )&#123; out.println("&lt;h2&gt; 查找 Cookie 名与值&lt;/h2&gt;"); for (int i = 0; i &lt; cookies.length; i++)&#123; cookie = cookies[i]; out.print("参数名 : " + cookie.getName()); out.print("&lt;br&gt;"); out.print("参数值: " + URLDecoder.decode(cookie.getValue(), "utf-8") +" &lt;br&gt;"); out.print("------------------------------------&lt;br&gt;"); &#125; &#125;else&#123; out.println("&lt;h2&gt;没有发现 Cookie&lt;/h2&gt;"); &#125;%&gt;&lt;/body&gt;&lt;/html&gt; 删除Cookie： 123456789101112131415161718192021222324252627282930313233343536&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.net.*" %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;&lt;title&gt;获取 Cookie&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% Cookie cookie = null; Cookie[] cookies = null; // 获取当前域名下的cookies，是一个数组 cookies = request.getCookies(); if( cookies != null )&#123; out.println("&lt;h2&gt; 查找 Cookie 名与值&lt;/h2&gt;"); for (int i = 0; i &lt; cookies.length; i++)&#123; cookie = cookies[i]; if((cookie.getName( )).compareTo("name") == 0 )&#123; cookie.setMaxAge(0); response.addCookie(cookie); out.print("删除 Cookie: " + cookie.getName( ) + "&lt;br/&gt;"); &#125; out.print("参数名 : " + cookie.getName()); out.print("&lt;br&gt;"); out.print("参数值: " + URLDecoder.decode(cookie.getValue(), "utf-8") +" &lt;br&gt;"); out.print("------------------------------------&lt;br&gt;"); &#125; &#125;else&#123; out.println("&lt;h2&gt;没有发现 Cookie&lt;/h2&gt;"); &#125;%&gt;&lt;/body&gt;&lt;/html&gt; JSP Session跟踪：Session对象：JSP利用servlet提供的HttpSession接口来识别一个用户，存储这个用户的所有访问信息。 默认情况下，JSP允许会话跟踪，一个新的HttpSession对象将会自动地为新的客户端实例化。禁止会话跟踪需要显式地关掉它，通过将page指令中session属性值设为false来实现，就像下面这样： 1&lt;%@ page session="false" %&gt; JSP引擎将隐含的session对象暴露给开发者。由于提供了session对象，开发者就可以方便地存储或检索数据。 JSP应用：这个例子描述了如何使用HttpSession对象来获取创建时间和最后一次访问时间。我们将会为request对象关联一个新的session对象，如果这个对象尚未存在的话。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.io.*,java.util.*" %&gt;&lt;% // 获取session创建时间 Date createTime = new Date(session.getCreationTime()); // 获取最后访问页面的时间 Date lastAccessTime = new Date(session.getLastAccessedTime()); String title = "再次访问菜鸟教程实例"; Integer visitCount = new Integer(0); String visitCountKey = new String("visitCount"); String userIDKey = new String("userID"); String userID = new String("ABCD"); // 检测网页是否由新的访问用户 if (session.isNew())&#123; title = "访问菜鸟教程实例"; session.setAttribute(userIDKey, userID); session.setAttribute(visitCountKey, visitCount); &#125; else &#123; visitCount = (Integer)session.getAttribute(visitCountKey); visitCount += 1; userID = (String)session.getAttribute(userIDKey); session.setAttribute(visitCountKey, visitCount); &#125;%&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Session 跟踪&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Session 跟踪&lt;/h1&gt;&lt;table border="1" align="center"&gt; &lt;tr bgcolor="#949494"&gt; &lt;th&gt;Session 信息&lt;/th&gt; &lt;th&gt;值&lt;/th&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;id&lt;/td&gt; &lt;td&gt;&lt;% out.print( session.getId()); %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;创建时间&lt;/td&gt; &lt;td&gt;&lt;% out.print(createTime); %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;最后访问时间&lt;/td&gt; &lt;td&gt;&lt;% out.print(lastAccessTime); %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;用户 ID&lt;/td&gt; &lt;td&gt;&lt;% out.print(userID); %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;访问次数&lt;/td&gt; &lt;td&gt;&lt;% out.print(visitCount); %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 运行结果： 图：Session跟踪 删除Session数据： 当处理完一个用户的会话数据后，您可以有如下选择： 移除一个特定的属性： 调用public void removeAttribute(String name) 方法来移除指定的属性。 删除整个会话： 调用public void invalidate() 方法来使整个session无效。 设置会话有效期： 调用 public void setMaxInactiveInterval(int interval) 方法来设置session超时。 登出用户： 支持servlet2.4版本的服务器，可以调用 logout()方法来登出用户，并且使所有相关的session无效。 配置web.xml文件： 如果使用的是Tomcat，可以向下面这样配置web.xml文件： 123&lt;session-config&gt; &lt;session-timeout&gt;15&lt;/session-timeout&gt;&lt;/session-config&gt; 超时以分钟为单位，Tomcat中的默认的超时时间是30分钟。 Servlet中的getMaxInactiveInterval( ) 方法以秒为单位返回超时时间。如果在web.xml中配置的是15分钟，则getMaxInactiveInterval( ) 方法将会返回900。 JSP点击量统计：该实例将介绍如何使用JSP来计算特定页面访问的总人数。如果你要计算你网站使用页面的总点击量，那么你就必须将该代码放在所有的JSP页面上。 1234567891011121314151617181920212223242526272829&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;%@ page import="java.io.*,java.util.*" %&gt;&lt;html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;访问量统计&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% Integer hitsCount = (Integer)application.getAttribute("hitCounter"); if( hitsCount ==null || hitsCount == 0 )&#123; /* 第一次访问 */ out.println("欢迎访问菜鸟教程!"); hitsCount = 1; &#125;else&#123; /* 返回访问值 */ out.println("欢迎再次访问菜鸟教程!"); hitsCount += 1; &#125; application.setAttribute("hitCounter", hitsCount);%&gt;&lt;p&gt;页面访问量为: &lt;%= hitsCount%&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
        <tag>JSP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记(6)Servlet]]></title>
    <url>%2F2018%2F07%2F16%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89Servlet%2F</url>
    <content type="text"><![CDATA[Servlet简介Servlet是什么？Servlet的全称是 Server Applet，顾名思义，就是用 Java 编写的服务器端程序。 Servlet 是一个 Java Web开发标准，狭义的Servlet是指Java语言实现的一个接口，广义的Servlet是指任何实现了这个Servlet接口的类，一般情况下，人们将Servlet理解为后者。 Java Servlet 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序之间的中间层。 使用 Servlet，您可以收集来自网页表单的用户输入，呈现来自数据库或者其他源的记录，还可以动态创建网页。 Java Servlet 通常情况下与使用 CGI（Common Gateway Interface，公共网关接口）实现的程序可以达到异曲同工的效果。但是相比于 CGI，Servlet 有以下几点优势： 性能明显更好。 Servlet 在 Web 服务器的地址空间内执行。这样它就没有必要再创建一个单独的进程来处理每个客户端请求。 Servlet 是独立于平台的，因为它们是用 Java 编写的。 服务器上的 Java 安全管理器执行了一系列限制，以保护服务器计算机上的资源。因此，Servlet 是可信的。 Java 类库的全部功能对 Servlet 来说都是可用的。它可以通过 sockets 和 RMI 机制与 applets、数据库或其他软件进行交互。 Servlet架构： 图：Servlet架构图 Servlet任务：Servlet 执行以下主要任务： 读取客户端（浏览器）发送的显式的数据。这包括网页上的 HTML 表单，或者也可以是来自 applet 或自定义的 HTTP 客户端程序的表单。 读取客户端（浏览器）发送的隐式的 HTTP 请求数据。这包括 cookies、媒体类型和浏览器能理解的压缩格式等等。 处理数据并生成结果。这个过程可能需要访问数据库，执行 RMI 或 CORBA 调用，调用 Web 服务，或者直接计算得出对应的响应。 发送显式的数据（即文档）到客户端（浏览器）。该文档的格式可以是多种多样的，包括文本文件（HTML 或 XML）、二进制文件（GIF 图像）、Excel 等。 发送隐式的 HTTP 响应到客户端（浏览器）。这包括告诉浏览器或其他客户端被返回的文档类型（例如 HTML），设置 cookies 和缓存参数，以及其他类似的任务。 Servlet包：Java Servlet 是运行在带有支持 Java Servlet 规范的解释器的 web 服务器上的 Java 类。 Servlet 可以使用 javax.servlet 和 javax.servlet.http 包创建，它是 Java 企业版的标准组成部分，Java 企业版是支持大型开发项目的 Java 类库的扩展版本。 Servlet生命周期Servlet 生命周期可被定义为从创建直到毁灭的整个过程。以下是 Servlet 遵循的过程： Servlet 通过调用 init () 方法进行初始化。 Servlet 调用 service() 方法来处理客户端的请求。 Servlet 通过调用 destroy() 方法终止（结束）。 最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。 init()方法：nit 方法被设计成只调用一次。它在第一次创建 Servlet 时被调用，在后续每次用户请求时不再调用。因此，它是用于一次性初始化，就像 Applet 的 init 方法一样。 Servlet 创建于用户第一次调用对应于该 Servlet 的 URL 时，但是您也可以指定 Servlet 在服务器第一次启动时被加载。 当用户调用一个 Servlet 时，就会创建一个 Servlet 实例，每一个用户请求都会产生一个新的线程，适当的时候移交给 doGet 或 doPost 方法。init() 方法简单地创建或加载一些数据，这些数据将被用于 Servlet 的整个生命周期。 init 方法的定义如下： 123public void init() throws ServletException &#123; // 初始化代码...&#125; service()方法：service() 方法是执行实际任务的主要方法。Servlet 容器（即 Web 服务器）调用 service() 方法来处理来自客户端（浏览器）的请求，并把格式化的响应写回给客户端。 每次服务器接收到一个 Servlet 请求时，服务器会产生一个新的线程并调用服务。service() 方法检查 HTTP 请求类型（GET、POST、PUT、DELETE 等），并在适当的时候调用 doGet、doPost、doPut，doDelete 等方法。 下面是该方法的特征： 1234public void service(ServletRequest request, ServletResponse response) throws ServletException, IOException&#123;&#125; service() 方法由容器调用，service 方法在适当的时候调用 doGet、doPost、doPut、doDelete 等方法。所以，您不用对 service() 方法做任何动作，您只需要根据来自客户端的请求类型来重写 doGet() 或 doPost() 即可。 doGet() 和 doPost() 方法是每次服务请求中最常用的方法。下面是这两种方法的特征。 doGet()方法： GET 请求来自于一个 URL 的正常请求，或者来自于一个未指定 METHOD 的 HTML 表单，它由 doGet() 方法处理。 12345public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // Servlet 代码&#125; doPost()方法： POST 请求来自于一个特别指定了 METHOD 为 POST 的 HTML 表单，它由 doPost() 方法处理。 12345public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // Servlet 代码&#125; destroy()方法：destroy() 方法只会被调用一次，在 Servlet 生命周期结束时被调用。destroy() 方法可以让您的 Servlet 关闭数据库连接、停止后台线程、把 Cookie 列表或点击计数器写入到磁盘，并执行其他类似的清理活动。 在调用 destroy() 方法之后，servlet 对象被标记为垃圾回收。destroy 方法定义如下所示： 123public void destroy() &#123; // 终止化代码...&#125; 架构图：下图显示了一个典型的 Servlet 生命周期方案。 第一个到达服务器的 HTTP 请求被委派到 Servlet 容器。 Servlet 容器在调用 service() 方法之前加载 Servlet。 然后 Servlet 容器处理由多个线程产生的多个请求，每个线程执行一个单一的 Servlet 实例的 service() 方法。 图：servlet架构图 Servlet实例Servlet 是服务 HTTP 请求并实现 javax.servlet.Servlet 接口的 Java 类。Web 应用程序开发人员通常编写 Servlet 来扩展 javax.servlet.http.HttpServlet，并实现 Servlet 接口的抽象类专门用来处理 HTTP 请求。 动态Web开发的工程目录结构： 图：目录结构 上图中各个目录解析： deployment descriptor：部署的描述。 Web App Libraries：自己加的包可以放在里面。 build：放入编译之后的文件。 WebContent:放进写入的页面。 Hello Word实例程序：123456789101112131415161718192021222324252627282930313233// 导入必需的 java 库import java.io.*;import javax.servlet.*;import javax.servlet.http.*;// 扩展 HttpServlet 类public class HelloServlet extends HttpServlet &#123; private String message; public void init() throws ServletException &#123; // 执行必需的初始化 message = "Hello World"; &#125; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 设置响应内容类型 response.setContentType("text/html"); // 实际的逻辑是在这里 PrintWriter out = response.getWriter(); out.println("&lt;h1&gt;" + message + "&lt;/h1&gt;"); &#125; public void destroy() &#123; // 什么也不做 &#125;&#125; 写好servlet代码后，还需要在web.xml文件中创建映射关系： 12345678910111213&lt;web-app&gt; &lt;servlet&gt; &lt;description&gt;&lt;/description&gt; &lt;display-name&gt;HelloServlet&lt;/display-name&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;jsp-file&gt;/servlet.jsp&lt;/jsp-file&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/servlet/HelloServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet&gt;&lt;/web-app&gt; 启动Tomcat服务器后，即可在浏览器中输入 http://localhost:8080/TomcatTest/HelloServlet即可在页面上输出Hello Word。 Servlet表单数据很多情况下，需要传递一些信息，从浏览器到 Web 服务器，最终到后台程序。浏览器使用两种方法可将这些信息传递到 Web 服务器，分别为 GET 方法和 POST 方法。 GET方法：GET 方法向页面请求发送已编码的用户信息。页面和已编码的信息中间用 ? 字符分隔，如下所示： 1http://www.test.com/hello?key1=value1&amp;key2=value2 GET 方法是默认的从浏览器向 Web 服务器传递信息的方法，它会产生一个很长的字符串，出现在浏览器的地址栏中。如果您要向服务器传递的是密码或其他的敏感信息，请不要使用 GET 方法。GET 方法有大小限制：请求字符串中最多只能有 1024 个字符。 这些信息使用 QUERY_STRING 头传递，并可以通过 QUERY_STRING 环境变量访问，Servlet 使用 doGet() 方法处理这种类型的请求。 POST方法：另一个向后台程序传递信息的比较可靠的方法是 POST 方法。POST 方法打包信息的方式与 GET 方法基本相同，但是 POST 方法不是把信息作为 URL 中 ? 字符后的文本字符串进行发送，而是把这些信息作为一个单独的消息。消息以标准输出的形式传到后台程序，您可以解析和使用这些标准输出。Servlet 使用 doPost() 方法处理这种类型的请求。 使用Servlet读取表单数据：Servlet 处理表单数据，这些数据会根据不同的情况使用不同的方法自动解析： getParameter()：您可以调用 request.getParameter() 方法来获取表单参数的值。 getParameterValues()：如果参数出现一次以上，则调用该方法，并返回多个值，例如复选框。 getParameterNames()：如果您想要得到当前请求中的所有参数的完整列表，则调用该方法。 读取所有表单参数：以下是通用的实例，使用 HttpServletRequest 的 getParameterNames() 方法读取所有可用的表单参数。该方法返回一个枚举，其中包含未指定顺序的参数名。 一旦我们有一个枚举，我们可以以标准方式循环枚举，使用 hasMoreElements() 方法来确定何时停止，使用 nextElement() 方法来获取每个参数的名称。 ReadParams.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package servlet;import java.io.IOException;import java.io.PrintWriter;import java.util.Enumeration;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.jasper.tagplugins.jstl.core.Out;/** * Servlet implementation class ReadParams */@WebServlet("/ReadParams")public class ReadParams extends HttpServlet &#123; private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public ReadParams() &#123; super(); // TODO Auto-generated constructor stub &#125; /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //设置响应内容类型 response.setContentType("text/html;charset=UTF-8"); PrintWriter out = response.getWriter(); String title = "读取所有表单数据"; String docType = "&lt;!doctype html public \"-//w3c//dtd html 4.0 " + "transitional//en\"&gt;\n"; out.println(docType + "&lt;html&gt;\n" + "&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt;" + title + "&lt;/title&gt;&lt;/head&gt;\n" + "&lt;body bgcolor=\"#f0f0f0\"&gt;\n" + "&lt;h1 align=\"center\"&gt;" + title + "&lt;/h1&gt;\n" + "&lt;table width=\"100%\" border=\"1\" align=\"center\"&gt;\n" + "&lt;tr bgcolor=\"#949494\"&gt;\n" + "&lt;th&gt;参数名称&lt;/th&gt;&lt;th&gt;参数值&lt;/th&gt;\n"+ "&lt;/tr&gt;\n"); Enumeration paramNames = request.getParameterNames(); while(paramNames.hasMoreElements()) &#123; String paramName = (String)paramNames.nextElement(); out.print("&lt;tr&gt;&lt;td&gt;" + paramName + "&lt;/td&gt;\n"); String[] paramValues = request.getParameterValues(paramName); // 读取单个值的数据 if (paramValues.length == 1) &#123; String paramValue = paramValues[0]; if (paramValue.length() == 0) out.println("&lt;td&gt;&lt;i&gt;没有值&lt;/i&gt;&lt;/td&gt;"); else out.println("&lt;td&gt;" + paramValue + "&lt;/td&gt;"); &#125; else &#123; // 读取多个值的数据 out.println("&lt;td&gt;&lt;ul&gt;"); for(int i=0; i &lt; paramValues.length; i++) &#123; out.println("&lt;li&gt;" + paramValues[i]); &#125; out.println("&lt;/ul&gt;&lt;/td&gt;"); &#125; out.print("&lt;/tr&gt;"); &#125; out.println("\n&lt;/table&gt;\n&lt;/body&gt;&lt;/html&gt;"); &#125; /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // TODO Auto-generated method stub doGet(request, response); &#125;&#125; 设置表单：checkbox.html 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;菜鸟教程&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="CheckBox" method="POST" target="_blank"&gt;&lt;input type="checkbox" name="runoob" checked="checked" /&gt; 菜鸟教程&lt;input type="checkbox" name="google" /&gt; 谷歌&lt;input type="checkbox" name="taobao" checked="checked" /&gt; 淘宝&lt;input type="submit" value="选择站点" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 在web.xml中添加 12345678&lt;servlet&gt; &lt;servlet-name&gt;ReadParams&lt;/servlet-name&gt; &lt;servlet-class&gt;servlet.ReadParams&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;ReadParams&lt;/servlet-name&gt; &lt;url-pattern&gt;/servlet/ReadParams&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 运行结果： 图：读取多个参数 Servlet客户端请求##Http头部： 当浏览器请求网页时，它会向 Web 服务器发送特定信息，这些信息不能被直接读取，因为这些信息是作为 HTTP 请求的头的一部分进行传输的。 以下是来自于浏览器端的重要头信息 头信息 描述 Accept 这个头信息指定浏览器或其他客户端可以处理的 MIME 类型。值 image/png 或 image/jpeg是最常见的两种可能值。 Accept-Charset 这个头信息指定浏览器可以用来显示信息的字符集。例如 ISO-8859-1。 Accept-Encoding 这个头信息指定浏览器知道如何处理的编码类型。值 gzip 或 compress 是最常见的两种可能值。 Accept-Language 这个头信息指定客户端的首选语言，在这种情况下，Servlet 会产生多种语言的结果。例如，en、en-us、ru 等。 Authorization 这个头信息用于客户端在访问受密码保护的网页时识别自己的身份。 Connection 这个头信息指示客户端是否可以处理持久 HTTP 连接。持久连接允许客户端或其他浏览器通过单个请求来检索多个文件。值 Keep-Alive 意味着使用了持续连接。 Content-Length 这个头信息只适用于 POST 请求，并给出 POST 数据的大小（以字节为单位）。 Cookie 这个头信息把之前发送到浏览器的 cookies 返回到服务器。 Host 这个头信息指定原始的 URL 中的主机和端口。 If-Modified-Since 这个头信息表示只有当页面在指定的日期后已更改时，客户端想要的页面。如果没有新的结果可以使用，服务器会发送一个 304 代码，表示 Not Modified 头信息。 If-Unmodified-Since 这个头信息是 If-Modified-Since 的对立面，它指定只有当文档早于指定日期时，操作才会成功。 Referer 这个头信息指示所指向的 Web 页的 URL。例如，如果您在网页 1，点击一个链接到网页 2，当浏览器请求网页 2 时，网页 1 的 URL 就会包含在 Referer 头信息中。 User-Agent 这个头信息识别发出请求的浏览器或其他客户端，并可以向不同类型的浏览器返回不同的内容。 读取HTTP头的方法：下面的方法可用在 Servlet 程序中读取 HTTP 头。这些方法通过 HttpServletRequest 对象可用。 序号 方法 &amp; 描述 1 Cookie[] getCookies() 返回一个数组，包含客户端发送该请求的所有的 Cookie 对象。 2 Enumeration getAttributeNames() 返回一个枚举，包含提供给该请求可用的属性名称。 3 Enumeration getHeaderNames() 返回一个枚举，包含在该请求中包含的所有的头名。 4 Enumeration getParameterNames() 返回一个 String 对象的枚举，包含在该请求中包含的参数的名称。 5 HttpSession getSession() 返回与该请求关联的当前 session 会话，或者如果请求没有 session 会话，则创建一个。 6 HttpSession getSession(boolean create) 返回与该请求关联的当前 HttpSession，或者如果没有当前会话，且创建是真的，则返回一个新的 session 会话。 7 Locale getLocale() 基于 Accept-Language 头，返回客户端接受内容的首选的区域设置。 8 Object getAttribute(String name) 以对象形式返回已命名属性的值，如果没有给定名称的属性存在，则返回 null。 9 ServletInputStream getInputStream() 使用 ServletInputStream，以二进制数据形式检索请求的主体。 10 String getAuthType() 返回用于保护 Servlet 的身份验证方案的名称，例如，”BASIC” 或 “SSL”，如果JSP没有受到保护则返回 null。 11 String getCharacterEncoding() 返回请求主体中使用的字符编码的名称。 12 String getContentType() 返回请求主体的 MIME 类型，如果不知道类型则返回 null。 13 String getContextPath() 返回指示请求上下文的请求 URI 部分。 14 String getHeader(String name) 以字符串形式返回指定的请求头的值。 15 String getMethod() 返回请求的 HTTP 方法的名称，例如，GET、POST 或 PUT。 16 String getParameter(String name) 以字符串形式返回请求参数的值，或者如果参数不存在则返回 null。 17 String getPathInfo() 当请求发出时，返回与客户端发送的 URL 相关的任何额外的路径信息。 18 String getProtocol() 返回请求协议的名称和版本。 19 String getQueryString() 返回包含在路径后的请求 URL 中的查询字符串。 20 String getRemoteAddr() 返回发送请求的客户端的互联网协议（IP）地址。 21 String getRemoteHost() 返回发送请求的客户端的完全限定名称。 22 String getRemoteUser() 如果用户已通过身份验证，则返回发出请求的登录用户，或者如果用户未通过身份验证，则返回 null。 23 String getRequestURI() 从协议名称直到 HTTP 请求的第一行的查询字符串中，返回该请求的 URL 的一部分。 24 String getRequestedSessionId() 返回由客户端指定的 session 会话 ID。 25 String getServletPath() 返回调用 JSP 的请求的 URL 的一部分。 26 String[] getParameterValues(String name) 返回一个字符串对象的数组，包含所有给定的请求参数的值，如果参数不存在则返回 null。 27 boolean isSecure() 返回一个布尔值，指示请求是否使用安全通道，如 HTTPS。 28 int getContentLength() 以字节为单位返回请求主体的长度，并提供输入流，或者如果长度未知则返回 -1。 29 int getIntHeader(String name) 返回指定的请求头的值为一个 int 值。 30 int getServerPort() 返回接收到这个请求的端口号。 31 int getParameterMap() 将参数封装成 Map 类型。 Http头请求实例：下面的实例使用 HttpServletRequest 的 getHeaderNames() 方法读取 HTTP 头信息。该方法返回一个枚举，包含与当前的 HTTP 请求相关的头信息。 一旦我们有一个枚举，我们可以以标准方式循环枚举，使用 hasMoreElements() 方法来确定何时停止，使用 nextElement() 方法来获取每个参数的名称。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package servlet;import java.io.IOException;import java.io.PrintWriter;import java.util.Enumeration;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * Servlet implementation class DisplayHeader */@WebServlet("/DisplayHeader")public class DisplayHeader extends HttpServlet &#123; private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public DisplayHeader() &#123; super(); &#125; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 设置响应内容类型 response.setContentType("text/html;charset=UTF-8"); PrintWriter out = response.getWriter(); String title = "HTTP Header 请求实例 - 菜鸟教程实例"; String docType = "&lt;!DOCTYPE html&gt; \n"; out.println(docType + "&lt;html&gt;\n" + "&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt;" + title + "&lt;/title&gt;&lt;/head&gt;\n"+ "&lt;body bgcolor=\"#f0f0f0\"&gt;\n" + "&lt;h1 align=\"center\"&gt;" + title + "&lt;/h1&gt;\n" + "&lt;table width=\"100%\" border=\"1\" align=\"center\"&gt;\n" + "&lt;tr bgcolor=\"#949494\"&gt;\n" + "&lt;th&gt;Header 名称&lt;/th&gt;&lt;th&gt;Header 值&lt;/th&gt;\n"+ "&lt;/tr&gt;\n"); Enumeration HeaderNmames = request.getHeaderNames(); while(HeaderNmames.hasMoreElements()) &#123; String paramName = (String)HeaderNmames.nextElement(); out.print("&lt;tr&gt;&lt;td&gt;" + paramName + "&lt;/td&gt;\n"); String paramValue = request.getHeader(paramName); out.println("&lt;td&gt; " + paramValue + "&lt;/td&gt;&lt;/tr&gt;\n"); &#125; out.println("&lt;/table&gt;\n&lt;/body&gt;&lt;/html&gt;"); &#125; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125;&#125; 在web.xml中添加： 123456789&lt;servlet&gt; &lt;servlet-name&gt;DisplayHeader&lt;/servlet-name&gt; &lt;servlet-class&gt;servlet.DisplayHeader&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DisplayHeader&lt;/servlet-name&gt; &lt;url-pattern&gt;/servlet/DisplayHeader&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet&gt; 现在，调用上面的 Servlet，访问 http://localhost:8080/TomcatTest/DisplayHeader 会产生以下结果： 图：读取http头部信息 Servlet服务器HTTP响应##Http响应头部： 图：Http请求和响应报文头 下表总结了从 Web 服务器端返回到浏览器的最有用的 HTTP 1.1 响应报头， 头信息 描述 Allow 这个头信息指定服务器支持的请求方法（GET、POST 等）。 Cache-Control 这个头信息指定响应文档在何种情况下可以安全地缓存。可能的值有：public、private 或 no-cache 等。Public 意味着文档是可缓存，Private 意味着文档是单个用户私用文档，且只能存储在私有（非共享）缓存中，no-cache 意味着文档不应被缓存。 Connection 这个头信息指示浏览器是否使用持久 HTTP 连接。值 close 指示浏览器不使用持久 HTTP 连接，值 keep-alive 意味着使用持久连接。 Content-Disposition 这个头信息可以让您请求浏览器要求用户以给定名称的文件把响应保存到磁盘。 Content-Encoding 在传输过程中，这个头信息指定页面的编码方式。 Content-Language 这个头信息表示文档编写所使用的语言。例如，en、en-us、ru 等。 Content-Length 这个头信息指示响应中的字节数。只有当浏览器使用持久（keep-alive）HTTP 连接时才需要这些信息。 Content-Type 这个头信息提供了响应文档的 MIME（Multipurpose Internet Mail Extension）类型。 Expires 这个头信息指定内容过期的时间，在这之后内容不再被缓存。 Last-Modified 这个头信息指示文档的最后修改时间。然后，客户端可以缓存文件，并在以后的请求中通过 If-Modified-Since 请求头信息提供一个日期。 Location 这个头信息应被包含在所有的带有状态码的响应中。在 300s 内，这会通知浏览器文档的地址。浏览器会自动重新连接到这个位置，并获取新的文档。 Refresh 这个头信息指定浏览器应该如何尽快请求更新的页面。您可以指定页面刷新的秒数。 Retry-After 这个头信息可以与 503（Service Unavailable 服务不可用）响应配合使用，这会告诉客户端多久就可以重复它的请求。 Set-Cookie 这个头信息指定一个与页面关联的 cookie。 设置HTTP响应报头的方法：下面的方法可用于在 Servlet 程序中设置 HTTP 响应报头。这些方法通过 HttpServletResponse 对象可用。 序号 方法 &amp; 描述 1 String encodeRedirectURL(String url) 为 sendRedirect 方法中使用的指定的 URL 进行编码，或者如果编码不是必需的，则返回 URL 未改变。 2 String encodeURL(String url) 对包含 session 会话 ID 的指定 URL 进行编码，或者如果编码不是必需的，则返回 URL 未改变。 3 boolean containsHeader(String name) 返回一个布尔值，指示是否已经设置已命名的响应报头。 4 boolean isCommitted() 返回一个布尔值，指示响应是否已经提交。 5 void addCookie(Cookie cookie) 把指定的 cookie 添加到响应。 6 void addDateHeader(String name, long date) 添加一个带有给定的名称和日期值的响应报头。 7 void addHeader(String name, String value) 添加一个带有给定的名称和值的响应报头。 8 void addIntHeader(String name, int value) 添加一个带有给定的名称和整数值的响应报头。 9 void flushBuffer() 强制任何在缓冲区中的内容被写入到客户端。 10 void reset() 清除缓冲区中存在的任何数据，包括状态码和头。 11 void resetBuffer() 清除响应中基础缓冲区的内容，不清除状态码和头。 12 void sendError(int sc) 使用指定的状态码发送错误响应到客户端，并清除缓冲区。 13 void sendError(int sc, String msg) 使用指定的状态发送错误响应到客户端。 14 void sendRedirect(String location) 使用指定的重定向位置 URL 发送临时重定向响应到客户端。 15 void setBufferSize(int size) 为响应主体设置首选的缓冲区大小。 16 void setCharacterEncoding(String charset) 设置被发送到客户端的响应的字符编码（MIME 字符集）例如，UTF-8。 17 void setContentLength(int len) 设置在 HTTP Servlet 响应中的内容主体的长度，该方法设置 HTTP Content-Length 头。 18 void setContentType(String type) 如果响应还未被提交，设置被发送到客户端的响应的内容类型。 19 void setDateHeader(String name, long date) 设置一个带有给定的名称和日期值的响应报头。 20 void setHeader(String name, String value) 设置一个带有给定的名称和值的响应报头。 21 void setIntHeader(String name, int value) 设置一个带有给定的名称和整数值的响应报头。 22 void setLocale(Locale loc) 如果响应还未被提交，设置响应的区域。 23 void setStatus(int sc) 为该响应设置状态码。 HTTP头响应实例–自动刷新：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package servlet;import java.io.IOException;import java.io.PrintWriter;import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.Date;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * Servlet implementation class Refresh */@WebServlet("/Refresh")public class Refresh extends HttpServlet &#123; private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public Refresh() &#123; super(); &#125; /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // 设置刷新自动加载时间为 1 秒 response.setIntHeader("Refresh", 1); // 设置响应内容类型 response.setContentType("text/html;charset=UTF-8"); //使用默认时区和语言环境获得一个日历 Calendar cale = Calendar.getInstance(); //将Calendar类型转换成Date类型 Date tasktime=cale.getTime(); //设置日期输出的格式 SimpleDateFormat df=new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); //格式化输出 String nowTime = df.format(tasktime); PrintWriter out = response.getWriter(); String title = "自动刷新 Header 设置 - 菜鸟教程实例"; String docType = "&lt;!DOCTYPE html&gt;\n"; out.println(docType + "&lt;html&gt;\n" + "&lt;head&gt;&lt;title&gt;" + title + "&lt;/title&gt;&lt;/head&gt;\n"+ "&lt;body bgcolor=\"#f0f0f0\"&gt;\n" + "&lt;h1 align=\"center\"&gt;" + title + "&lt;/h1&gt;\n" + "&lt;p&gt;当前时间是：" + nowTime + "&lt;/p&gt;\n"); &#125; /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125;&#125; 添加web.xml配置： 12345678&lt;servlet&gt; &lt;servlet-name&gt;Refresh&lt;/servlet-name&gt; &lt;servlet-class&gt;servlet.Refresh&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;Refresh&lt;/servlet-name&gt; &lt;url-pattern&gt;/servlet/Refresh&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 运行后，每隔1秒页面都会刷新一次。 Servlet HTTP状态码HTTP常见状态码： 代码 消息 描述 100 Continue 只有请求的一部分已经被服务器接收，但只要它没有被拒绝，客户端应继续该请求。 101 Switching Protocols 服务器切换协议。 200 OK 请求成功。 201 Created 该请求是完整的，并创建一个新的资源。 202 Accepted 该请求被接受处理，但是该处理是不完整的。 203 Non-authoritative Information 204 No Content 205 Reset Content 206 Partial Content 300 Multiple Choices 链接列表。用户可以选择一个链接，进入到该位置。最多五个地址。 301 Moved Permanently 所请求的页面已经转移到一个新的 URL。 302 Found 所请求的页面已经临时转移到一个新的 URL。 303 See Other 所请求的页面可以在另一个不同的 URL 下被找到。 304 Not Modified 305 Use Proxy 306 Unused 在以前的版本中使用该代码。现在已不再使用它，但代码仍被保留。 307 Temporary Redirect 所请求的页面已经临时转移到一个新的 URL。 400 Bad Request 服务器不理解请求。 401 Unauthorized 所请求的页面需要用户名和密码。 402 Payment Required 您还不能使用该代码。 403 Forbidden 禁止访问所请求的页面。 404 Not Found 服务器无法找到所请求的页面。. 405 Method Not Allowed 在请求中指定的方法是不允许的。 406 Not Acceptable 服务器只生成一个不被客户端接受的响应。 407 Proxy Authentication Required 在请求送达之前，您必须使用代理服务器的验证。 408 Request Timeout 请求需要的时间比服务器能够等待的时间长，超时。 409 Conflict 请求因为冲突无法完成。 410 Gone 所请求的页面不再可用。 411 Length Required “Content-Length” 未定义。服务器无法处理客户端发送的不带 Content-Length 的请求信息。 412 Precondition Failed 请求中给出的先决条件被服务器评估为 false。 413 Request Entity Too Large 服务器不接受该请求，因为请求实体过大。 414 Request-url Too Long 服务器不接受该请求，因为 URL 太长。当您转换一个 “post” 请求为一个带有长的查询信息的 “get” 请求时发生。 415 Unsupported Media Type 服务器不接受该请求，因为媒体类型不被支持。 417 Expectation Failed 500 Internal Server Error 未完成的请求。服务器遇到了一个意外的情况。 501 Not Implemented 未完成的请求。服务器不支持所需的功能。 502 Bad Gateway 未完成的请求。服务器从上游服务器收到无效响应。 503 Service Unavailable 未完成的请求。服务器暂时超载或死机。 504 Gateway Timeout 网关超时。 505 HTTP Version Not Supported 服务器不支持”HTTP协议”版本。 设置HTTP状态码的方法：下面的方法可用于在 Servlet 程序中设置 HTTP 状态码。这些方法通过 HttpServletResponse 对象可用。 序号 方法 &amp; 描述 1 public void setStatus ( int statusCode ) 该方法设置一个任意的状态码。setStatus 方法接受一个 int（状态码）作为参数。如果您的反应包含了一个特殊的状态码和文档，请确保在使用 PrintWriter 实际返回任何内容之前调用 setStatus。 2 public void sendRedirect(String url) 该方法生成一个 302 响应，连同一个带有新文档 URL 的 Location 头。 3 public void sendError(int code, String message) 该方法发送一个状态码（通常为 404），连同一个在 HTML 文档内部自动格式化并发送到客户端的短消息。 Servlet过滤器Servlet 过滤器可以动态地拦截请求和响应，以变换或使用包含在请求或响应中的信息。 可以将一个或多个 Servlet 过滤器附加到一个 Servlet 或一组 Servlet。Servlet 过滤器也可以附加到 JavaServer Pages (JSP) 文件和 HTML 页面。调用 Servlet 前调用所有附加的 Servlet 过滤器。 Servlet 过滤器是可用于 Servlet 编程的 Java 类，可以实现以下目的： 在客户端的请求访问后端资源之前，拦截这些请求。 在服务器的响应发送回客户端之前，处理这些响应。 根据规范建议的各种类型的过滤器： 身份验证过滤器（Authentication Filters）。 数据压缩过滤器（Data compression Filters）。 加密过滤器（Encryption Filters）。 触发资源访问事件过滤器。 图像转换过滤器（Image Conversion Filters）。 日志记录和审核过滤器（Logging and Auditing Filters）。 MIME-TYPE 链过滤器（MIME-TYPE Chain Filters）。 标记化过滤器（Tokenizing Filters）。 XSL/T 过滤器（XSL/T Filters），转换 XML 内容。 过滤器通过 Web 部署描述符（web.xml）中的 XML 标签来声明，然后映射到您的应用程序的部署描述符中的 Servlet 名称或 URL 模式。 当 Web 容器启动 Web 应用程序时，它会为您在部署描述符中声明的每一个过滤器创建一个实例。 Filter的执行顺序与在web.xml配置文件中的配置顺序一致，一般把Filter配置在所有的Servlet之前。 Servlet过滤器方法：过滤器是一个实现了 javax.servlet.Filter 接口的 Java 类。javax.servlet.Filter 接口定义了三个方法： 序号 方法 &amp; 描述 1 public void doFilter (ServletRequest, ServletResponse, FilterChain) 该方法完成实际的过滤操作，当客户端请求方法与过滤器设置匹配的URL时，Servlet容器将先调用过滤器的doFilter方法。FilterChain用户访问后续过滤器。 2 public void init(FilterConfig filterConfig) web 应用程序启动时，web 服务器将创建Filter 的实例对象，并调用其init方法，读取web.xml配置，完成对象的初始化功能，从而为后续的用户请求作好拦截的准备工作（filter对象只会创建一次，init方法也只会执行一次）。开发人员通过init方法的参数，可获得代表当前filter配置信息的FilterConfig对象。 3 public void destroy() Servlet容器在销毁过滤器实例前调用该方法，在该方法中释放Servlet过滤器占用的资源。 FilterConfig 使用 Filter 的 init 方法中提供了一个 FilterConfig 对象。 如 web.xml 文件配置如下： 12345678&lt;filter&gt; &lt;filter-name&gt;LogFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.runoob.test.LogFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;Site&lt;/param-name&gt; &lt;param-value&gt;菜鸟教程&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; 在 init 方法使用 FilterConfig 对象获取参数： 123456public void init(FilterConfig config) throws ServletException &#123; // 获取初始化参数 String site = config.getInitParameter("Site"); // 输出初始化参数 System.out.println("网站名称: " + site); &#125; 过滤器实例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package servlet;import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.annotation.WebFilter;import jdk.nashorn.internal.runtime.regexp.joni.Config;/** * Servlet Filter implementation class LogFilter */@WebFilter("/LogFilter")public class LogFilter implements Filter &#123; /** * Default constructor. */ public LogFilter() &#123; // TODO Auto-generated constructor stub &#125; public void init(FilterConfig fConfig) throws ServletException &#123; // 获取初始化参数 String site = fConfig.getInitParameter("Site"); // 输出初始化参数 System.out.println("网站名称: " + site); &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; //输出站点名称 System.out.println("站点网址: http://www.runoob.com" ); //在过滤链上传递请求 chain.doFilter(request, response); &#125; /** * @see Filter#destroy() */ public void destroy() &#123; /* 在 Filter 实例被 Web 容器从服务移除之前调用 */ &#125;&#125; 在Web.xml中添加Servlet的过滤器映射： 123456789101112&lt;filter&gt; &lt;filter-name&gt;LogFilter&lt;/filter-name&gt; &lt;filter-class&gt;servlet.LogFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;Site&lt;/param-name&gt; &lt;param-value&gt;菜鸟教程&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;LogFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 上述过滤器适用于所有的 Servlet，因为我们在配置中指定 /* 。如果您只想在少数的 Servlet 上应用过滤器，您可以指定一个特定的 Servlet 路径。 使用多个过滤器：使用多个过滤器时，web.xml 中的 filter-mapping 元素的顺序决定了 Web 容器应用过滤器到 Servlet 的顺序。若要反转过滤器的顺序，您只需要在 web.xml 文件中反转 filter-mapping 元素即可。 web.xml配置各节点说明：&lt; filter>指定一个过滤器。 &lt; filter-name>用于为过滤器指定一个名字，该元素的内容不能为空。 &lt; filter-class>元素用于指定过滤器的完整的限定类名。 &lt; init-param>元素用于为过滤器指定初始化参数，它的子元素&lt; param-name>指定参数的名字，&lt;param-value>指定参数的值。 在过滤器中，可以使用FilterConfig接口对象来访问初始化参数。 &lt;filter-mapping>元素用于设置一个 Filter 所负责拦截的资源。一个Filter拦截的资源可通过两种方式来指定：Servlet 名称和资源访问的请求路径 &lt;filter-name>子元素用于设置filter的注册名称。该值必须是在&lt;filter>元素中声明过的过滤器的名字 &lt;url-pattern>设置 filter 所拦截的请求路径(过滤器关联的URL样式) &lt;servlet-name>指定过滤器所拦截的Servlet名称。 &lt;dispatcher>指定过滤器所拦截的资源被 Servlet 容器调用的方式，可以是REQUEST,INCLUDE,FORWARD和ERROR之一，默认REQUEST。用户可以设置多个&lt;dispatcher>子元素用来指定 Filter 对资源的多种调用方式进行拦截。 &lt;dispatcher>子元素可以设置的值及其意义 REQUEST：当用户直接访问页面时，Web容器将会调用过滤器。如果目标资源是通过RequestDispatcher的include()或forward()方法访问时，那么该过滤器就不会被调用。 INCLUDE：如果目标资源是通过RequestDispatcher的include()方法访问时，那么该过滤器将被调用。除此之外，该过滤器不会被调用。 FORWARD：如果目标资源是通过RequestDispatcher的forward()方法访问时，那么该过滤器将被调用，除此之外，该过滤器不会被调用。 ERROR：如果目标资源是通过声明式异常处理机制调用时，那么该过滤器将被调用。除此之外，过滤器不会被调用。 Servlet Cookie处理Cookie 是存储在客户端计算机上的文本文件，并保留了各种跟踪信息。Java Servlet 显然支持 HTTP Cookie。 识别返回用户包括三个步骤： 服务器脚本向浏览器发送一组 Cookie。例如：姓名、年龄或识别号码等。 浏览器将这些信息存储在本地计算机上，以备将来使用。 当下一次浏览器向 Web 服务器发送任何请求时，浏览器会把这些 Cookie 信息发送到服务器，服务器将使用这些信息来识别用户。 Cookie 剖析Cookie 通常设置在 HTTP 头信息中（虽然 JavaScript 也可以直接在浏览器上设置一个 Cookie）。设置 Cookie 的 Servlet 会发送如下的头信息： 1234567HTTP/1.1 200 OKDate: Fri, 04 Feb 2000 21:03:38 GMTServer: Apache/1.3.9 (UNIX) PHP/4.0b3Set-Cookie: name=xyz; expires=Friday, 04-Feb-07 22:03:38 GMT; path=/; domain=runoob.comConnection: closeContent-Type: text/html 正如您所看到的，Set-Cookie 头包含了一个名称值对、一个 GMT 日期、一个路径和一个域。名称和值会被 URL 编码。expires 字段是一个指令，告诉浏览器在给定的时间和日期之后”忘记”该 Cookie。 如果浏览器被配置为存储 Cookie，它将会保留此信息直到到期日期。如果用户的浏览器指向任何匹配该 Cookie 的路径和域的页面，它会重新发送 Cookie 到服务器。浏览器的头信息可能如下所示： 123456789GET / HTTP/1.0Connection: Keep-AliveUser-Agent: Mozilla/4.6 (X11; I; Linux 2.2.6-15apmac ppc)Host: zink.demon.co.uk:1126Accept: image/gif, */*Accept-Encoding: gzipAccept-Language: enAccept-Charset: iso-8859-1,*,utf-8Cookie: name=xyz Servlet 就能够通过请求方法 request.getCookies() 访问 Cookie，该方法将返回一个 Cookie 对象的数组。 Servlet Cookie 方法以下是在 Servlet 中操作 Cookie 时可使用的有用的方法列表。 序号 方法 &amp; 描述 1 public void setDomain(String pattern) 该方法设置 cookie 适用的域，例如 runoob.com。 2 public String getDomain() 该方法获取 cookie 适用的域，例如 runoob.com。 3 public void setMaxAge(int expiry) 该方法设置 cookie 过期的时间（以秒为单位）。如果不这样设置，cookie 只会在当前 session 会话中持续有效。 4 public int getMaxAge() 该方法返回 cookie 的最大生存周期（以秒为单位），默认情况下，-1 表示 cookie 将持续下去，直到浏览器关闭。 5 public String getName() 该方法返回 cookie 的名称。名称在创建后不能改变。 6 public void setValue(String newValue) 该方法设置与 cookie 关联的值。 7 public String getValue() 该方法获取与 cookie 关联的值。 8 public void setPath(String uri) 该方法设置 cookie 适用的路径。如果您不指定路径，与当前页面相同目录下的（包括子目录下的）所有 URL 都会返回 cookie。 9 public String getPath() 该方法获取 cookie 适用的路径。 10 public void setSecure(boolean flag) 该方法设置布尔值，表示 cookie 是否应该只在加密的（即 SSL）连接上发送。 11 public void setComment(String purpose) 设置cookie的注释。该注释在浏览器向用户呈现 cookie 时非常有用。 12 public String getComment() 获取 cookie 的注释，如果 cookie 没有注释则返回 null。 通过 Servlet 设置 Cookie通过 Servlet 设置 Cookie 包括三个步骤： (1) 创建一个 Cookie 对象：您可以调用带有 cookie 名称和 cookie 值的 Cookie 构造函数，cookie 名称和 cookie 值都是字符串。 1Cookie cookie = new Cookie("key","value"); 请记住，无论是名字还是值，都不应该包含空格或以下任何字符： 1[ ] ( ) = , &quot; / ? @ : ; (2) 设置最大生存周期：您可以使用 setMaxAge 方法来指定 cookie 能够保持有效的时间（以秒为单位）。下面将设置一个最长有效期为 24 小时的 cookie。 1cookie.setMaxAge(60*60*24); (3) 发送 Cookie 到 HTTP 响应头：您可以使用 response.addCookie 来添加 HTTP 响应头中的 Cookie，如下所示： 1response.addCookie(cookie); Servlet Session跟踪HTTP 是一种”无状态”协议，这意味着每次客户端检索网页时，客户端打开一个单独的连接到 Web 服务器，服务器会自动不保留之前客户端请求的任何记录。 但是仍然有以下三种方式来维持 Web 客户端和 Web 服务器之间的 session 会话： Cookies一个 Web 服务器可以分配一个唯一的 session 会话 ID 作为每个 Web 客户端的 cookie，对于客户端的后续请求可以使用接收到的 cookie 来识别。 这可能不是一个有效的方法，因为很多浏览器不支持 cookie，所以我们建议不要使用这种方式来维持 session 会话。 隐藏的表单字段一个 Web 服务器可以发送一个隐藏的 HTML 表单字段，以及一个唯一的 session 会话 ID，如下所示： 1&lt;input type="hidden" name="sessionid" value="12345"&gt; 该条目意味着，当表单被提交时，指定的名称和值会被自动包含在 GET 或 POST 数据中。每次当 Web 浏览器发送回请求时，session_id 值可以用于保持不同的 Web 浏览器的跟踪。 这可能是一种保持 session 会话跟踪的有效方式，但是点击常规的超文本链接（）不会导致表单提交，因此隐藏的表单字段也不支持常规的 session 会话跟踪。 URL 重写您可以在每个 URL 末尾追加一些额外的数据来标识 session 会话，服务器会把该 session 会话标识符与已存储的有关 session 会话的数据相关联。 URL 重写是一种更好的维持 session 会话的方式，它在浏览器不支持 cookie 时能够很好地工作，但是它的缺点是会动态生成每个 URL 来为页面分配一个 session 会话 ID，即使是在很简单的静态 HTML 页面中也会如此。 HttpSession 对象除了上述的三种方式，Servlet 还提供了 HttpSession 接口，该接口提供了一种跨多个页面请求或访问网站时识别用户以及存储有关用户信息的方式。 Servlet 容器使用这个接口来创建一个 HTTP 客户端和 HTTP 服务器之间的 session 会话。会话持续一个指定的时间段，跨多个连接或页面请求。 您会通过调用 HttpServletRequest 的公共方法 getSession() 来获取 HttpSession 对象，如下所示： 1HttpSession session = request.getSession(); 你需要在向客户端发送任何文档内容之前调用 request.getSession()。下面总结了 HttpSession 对象中可用的几个重要的方法： 序号 方法 &amp; 描述 1 public Object getAttribute(String name) 该方法返回在该 session 会话中具有指定名称的对象，如果没有指定名称的对象，则返回 null。 2 public Enumeration getAttributeNames() 该方法返回 String 对象的枚举，String 对象包含所有绑定到该 session 会话的对象的名称。 3 public long getCreationTime() 该方法返回该 session 会话被创建的时间，自格林尼治标准时间 1970 年 1 月 1 日午夜算起，以毫秒为单位。 4 public String getId() 该方法返回一个包含分配给该 session 会话的唯一标识符的字符串。 5 public long getLastAccessedTime() 该方法返回客户端最后一次发送与该 session 会话相关的请求的时间自格林尼治标准时间 1970 年 1 月 1 日午夜算起，以毫秒为单位。 6 public int getMaxInactiveInterval() 该方法返回 Servlet 容器在客户端访问时保持 session 会话打开的最大时间间隔，以秒为单位。 7 public void invalidate() 该方法指示该 session 会话无效，并解除绑定到它上面的任何对象。 8 public boolean isNew() 如果客户端还不知道该 session 会话，或者如果客户选择不参入该 session 会话，则该方法返回 true。 9 public void removeAttribute(String name) 该方法将从该 session 会话移除指定名称的对象。 10 public void setAttribute(String name, Object value) 该方法使用指定的名称绑定一个对象到该 session 会话。 11 public void setMaxInactiveInterval(int interval) 该方法在 Servlet 容器指示该 session 会话无效之前，指定客户端请求之间的时间，以秒为单位。 Servlet数据库访问123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111package servlet;import java.io.IOException;import java.io.PrintWriter;import java.sql.Connection;import java.sql.DriverManager;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet("/DatabaseAccess")public class DatabaseAccess extends HttpServlet &#123; private static final long serialVersionUID = 1L; //JDBC驱动名称及数据库URL static final String JDBC_DRIVER = "com.mysql.jdbc.Driver"; static final String DB_URL = "jdbc:mysql://localhost:3306/jsp_db"; //数据库的用户名与密码 static final String USER = "root"; static final String PASS = "123456"; public DatabaseAccess() &#123; super(); &#125; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; Connection conn = null; Statement stat = null; //设置响应内容类型 response.setContentType("text/html;charset=UTF-8"); PrintWriter out = response.getWriter(); String title = "Servlet Mysql 测试 - 菜鸟教程"; String docType = "&lt;!DOCTYPE html&gt;\n"; out.println(docType + "&lt;html&gt;\n" + "&lt;head&gt;&lt;title&gt;" + title + "&lt;/title&gt;&lt;/head&gt;\n" + "&lt;body bgcolor=\"#f0f0f0\"&gt;\n" + "&lt;h1 align=\"center\"&gt;" + title + "&lt;/h1&gt;\n"); try &#123; //注册JDBC驱动器 Class.forName(JDBC_DRIVER); //打开一个连接 conn = DriverManager.getConnection(DB_URL, USER, PASS); //执行SQL查询 stat = conn.createStatement(); String sql = "SELECT * FROM tbl_user"; stat.executeQuery(sql); ResultSet rs = stat.getResultSet(); //展开结果 while(rs.next())&#123; // 通过字段检索 int id = rs.getInt("id"); String name = rs.getString("name"); String password = rs.getString("password"); String email = rs.getString("email"); // 输出数据 out.println("ID: " + id); out.println(", 姓名: " + name); out.println(", 密码: " + password); out.println(", 邮箱: " + email); out.print("&lt;br /&gt;"); &#125; out.println("&lt;/body&gt;&lt;/html&gt;"); //完成后关闭 rs.close(); stat.close(); conn.close(); &#125; catch(SQLException se) &#123; // 处理 JDBC 错误 se.printStackTrace(); &#125; catch(Exception e) &#123; // 处理 Class.forName 错误 e.printStackTrace(); &#125;finally&#123; // 最后是用于关闭资源的块 try&#123; if(stat!=null) stat.close(); &#125;catch(SQLException se2)&#123; &#125; try&#123; if(conn!=null) conn.close(); &#125;catch(SQLException se)&#123; se.printStackTrace(); &#125; &#125; &#125; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125;&#125; 运行结果： 图：访问数据库 参考自：菜鸟教程，W3cschool，极客学院。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
        <tag>Servlet</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（5）JDBC]]></title>
    <url>%2F2018%2F07%2F11%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89JDBC%2F</url>
    <content type="text"><![CDATA[JDBC简介JDBC简介：JDBC代表Java数据库连接(Java Database Connectivity)，它是用于Java编程语言和数据库之间的数据库无关连接的标准Java API，换句话说：JDBC是用于在Java语言编程中与数据库连接的API。 JDBC库包括通常与数据库使用相关，如下面提到的每个任务的API - 连接到数据库 创建SQL或MySQL语句 在数据库中执行SQL或MySQL查询 查看和修改结果记录 从根本上说，JDBC是一个规范，它提供了一整套接口，允许以一种可移植的访问底层数据库API。 Java可以用它来编写不同类型的可执行文件，如 - Java应用程序 Java Applet Java Servlets Java ServerPages(JSP) 企业级JavaBeans(EJB) 所有这些不同的可执行文件都能够使用JDBC驱动程序来访问数据库，并用于存储数据到数据库中。 JDBC提供与ODBC相同的功能，允许Java程序包含与数据库无关的代码(同样的代码，只需要指定使用的数据库类型，不需要重修改数据库查询或操作代码)。 JDBC架构：JDBC API支持用于数据库访问的两层和三层处理模型，但通常，JDBC体系结构由两层组成： JDBC API：提供应用程序到JDBC管理器连接。 JDBC驱动程序API：支持JDBC管理器到驱动程序连接。 JDBC API使用驱动程序管理器并指定数据库的驱动程序来提供与异构数据库的透明连接。 JDBC驱动程序管理器确保使用正确的驱动程序来访问每个数据源。 驱动程序管理器能够支持连接到多个异构数据库的多个并发驱动程序。 以下是架构图，它显示了驱动程序管理器相对于JDBC驱动程序和Java应用程序的位置 - 图：JDBC架构图 常见的JDBC组件：JDBC API提供以下接口和类 ： DriverManager：此类管理数据库驱动程序列表。 使用通信子协议将来自java应用程序的连接请求与适当的数据库驱动程序进行匹配。在JDBC下识别某个子协议的第一个驱动程序将用于建立数据库连接。 Driver：此接口处理与数据库服务器的通信。我们很少会直接与Driver对象进行交互。 但会使用DriverManager对象来管理这种类型的对象。 它还提取与使用Driver对象相关的信息。 Connection：此接口具有用于联系数据库的所有方法。 连接(Connection)对象表示通信上下文，即，与数据库的所有通信仅通过连接对象。 Statement：使用从此接口创建的对象将SQL语句提交到数据库。 除了执行存储过程之外，一些派生接口还接受参数。 ResultSet：在使用Statement对象执行SQL查询后，这些对象保存从数据库检索的数据。 它作为一个迭代器并可移动ResultSet对象查询的数据。 SQLException：此类处理数据库应用程序中发生的任何错误。 在编程前需要下载来连接数据库的库：Connector/J。 它里面包含了上面的这些类。 JDBC驱动程序类型：JDBC驱动程序是什么？JDBC驱动程序在JDBC API中实现定义的接口，用于与数据库服务器进行交互。 例如，使用JDBC驱动程序，可以通过发送SQL或数据库命令，然后使用Java接收结果来打开数据库连接并与数据库进行交互。 JDK附带的Java.sql包包含各种类，其类的行为被定义，实现在第三方驱动程序中完成。 第三方供应商在其数据库驱动程序中实现java.sql.Driver接口。 JDBC驱动程序类型：JDBC驱动程序实现因Java运行的各种操作系统和硬件平台而异。 Sun将实现类型分为四种类型，分别为1,2,3和4类型，如下所述： 类型1：JDBC-ODBC桥驱动程序 在类型1驱动程序中，JDBC桥接器用于访问安装在每台客户机上的ODBC驱动程序。 使用ODBC需要在系统上配置表示目标数据库的数据源名称(DSN)。 当Java第一次出现时，这是一个驱动程序，因为大多数数据库仅支持ODBC访问，但现在这种类型的驱动程序仅推荐用于实验性使用或没有其他替代方案时使用。 图：类型1 架构图 类型2：JDBC本地API 在类型2驱动程序中，JDBC API调用将转换为本地C/C++ API调用，这是数据库唯一的。 这些驱动程序通常由数据库供应商提供，并以与JDBC-ODBC桥接相同的方式使用。 必须在每个客户机上安装供应商特定的驱动程序。 如果要更改数据库，则必须更改原生API，因为它特定于数据库，并且现在大部分已经过时，但是使用类型2驱动程序实现了一些扩展功能的开发，它消除了ODBC的开销。 图:Oracle调用接口(OCI)驱动程序是类型2驱动程序的示例。 类型3：JDBC-Net纯Java 在类型3驱动程序中，使用三层方法访问数据库。 JDBC客户端使用标准网络套接字与中间件应用程序服务器进行通信。 套接字信息随后由中间件应用服务器转换成DBMS所需的调用格式，并转发到数据库服务器。 这种驱动程序是非常灵活的，因为它不需要在客户端上安装代码，一个驱动程序实际上可以提供多个数据库的访问。 图：类型3 架构 可以将应用程序服务器视为JDBC“代理”，它会调用客户端应用程序。 因此，我们需要了解应用程序服务器的配置，才能有效地使用此驱动程序类型。 应用程序服务器可能会使用类型1,2或4驱动程序与数据库通信，了解细微差别对理解JDBC是有帮助的。 类型4：100％纯Java 在类型4驱动程序中，基于纯Java的驱动程序通过套接字连接与供应商的数据库直接通信。 这是数据库可用的最高性能驱动程序，通常由供应商自己提供。 这种驱动是非常灵活的，不需要在客户端或服务器上安装特殊的软件。 此外，这些驱动程序可以动态下载。 图：类型4 架构 MySQL Connector/J驱动程序是类型4驱动程序。 由于其网络协议的专有性质，数据库供应商通常提供类型4驱动程序。 怎么选择驱动程序： 如果在访问一种类型的数据库，例如Oracle，Sybase或IBM DB2，则首选驱动程序类型为类型4。 如果Java应用程序同时访问多种类型的数据库，则类型3是首选驱动程序。 类型2驱动程序在数据库不可用的类型3或类型4驱动程序的情况下使用。 类型1驱动程序不被视为部署级驱动程序，通常仅用于开发和测试目的。 JDBC编程JDBC SQL语法：有关MySQL的语法：可以参考MySQL学习笔记。 创建JDBC应用程序的一般步骤：构建JDBC应用程序涉及以下六个步骤 - 导入包：需要包含包含数据库编程所需的JDBC类的包。 大多数情况下，使用import java.sql.*就足够了。 注册JDBC驱动程序：需要初始化驱动程序，以便可以打开与数据库的通信通道。 打开一个连接：需要使用DriverManager.getConnection()方法创建一个Connection对象，它表示与数据库的物理连接。 执行查询：需要使用类型为Statement的对象来构建和提交SQL语句到数据库。 从结果集中提取数据：需要使用相应的ResultSet.getXXX()方法从结果集中检索数据。 清理环境：需要明确地关闭所有数据库资源，而不依赖于JVM的垃圾收集。 JDBC数据库连接：建立JDBC连接所涉及的编程相当简单。 以下是基本的四个步骤 - 导入JDBC包：使用Java语言的import语句在Java代码开头位置导入所需的类。 注册JDBC驱动程序：使JVM将所需的驱动程序实现加载到内存中，从而可以满足JDBC请求。 数据库URL配置：创建一个正确格式化的地址，指向要连接到的数据库(如：MySQL,Oracle和MSSQL等等)。 创建连接对象：最后，调用DriverManager对象的getConnection()方法来建立实际的数据库连接。 注册驱动程序的方法：方法1：Class.forName() 注册驱动程序最常见的方法是使用Java的Class.forName()方法，将驱动程序的类文件动态加载到内存中，并将其自动注册。这个方法是推荐使用的方法，因为它使驱动程序注册可配置和便携。 以下示例使用Class.forName()注册Oracle驱动程序 - 1234567try &#123; Class.forName("oracle.jdbc.driver.OracleDriver");&#125;catch(ClassNotFoundException ex) &#123; System.out.println("Error: unable to load driver class!"); System.exit(1);&#125; 使用JDBC驱动程序连接MySQL数据库的示例代码片段 - 1234Class.forName("com.mysql.jdbc.Driver");Connection conn = null;conn = DriverManager.getConnection("jdbc:mysql://hostname:port/db_name","db_username", "db_password");conn.close(); 使用getInstance()方法来解决不合规的JVM，但是必须编写两个额外的异常，如下所示： 12345678910111213try &#123; Class.forName("oracle.jdbc.driver.OracleDriver").newInstance();&#125;catch(ClassNotFoundException ex) &#123; System.out.println("Error: unable to load driver class!"); System.exit(1);catch(IllegalAccessException ex) &#123; System.out.println("Error: access problem while loading!"); System.exit(2);catch(InstantiationException ex) &#123; System.out.println("Error: unable to instantiate driver!"); System.exit(3);&#125; 方法2 - DriverManager.registerDriver() 第二种方法是使用静态DriverManager.registerDriver()方法来注册驱动程序。 如果使用的是非JDK兼容的JVM(如Microsoft提供的)，则应使用registerDriver()方法。 以下示例使用registerDriver()注册Oracle驱动程序 - 12345678try &#123; Driver myDriver = new oracle.jdbc.driver.OracleDriver(); DriverManager.registerDriver( myDriver );&#125;catch(ClassNotFoundException ex) &#123; System.out.println("Error: unable to load driver class!"); System.exit(1);&#125; 数据库URL配置：加载驱动程序后，可以使用DriverManager.getConnection()方法建立连接。 为了方便参考，这里列出三个重载的DriverManager.getConnection()方法 - getConnection(String url) getConnection(String url, Properties prop) getConnection(String url, String user, String password) 这里每个格式都需要一个数据库URL。 数据库URL是指向数据库的地址。 制定数据库URL是建立连接相关联的大多数错误问题发生的地方。 下表列出了常用的JDBC驱动程序名称和数据库URL。 RDBMS JDBC驱动程序名称 URL格式 MySQL com.mysql.jdbc.Driver jdbc:mysql://hostname/databaseName ORACLE oracle.jdbc.driver.OracleDriver jdbc:oracle:thin:@hostname:portNumber:databaseName PostgreSQL org.postgresql.Driver jdbc:postgresql://hostname:port/dbname DB2 com.ibm.db2.jdbc.net.DB2Driver jdbc:db2:hostname:port Number/databaseName Sybase com.sybase.jdbc.SybDriver jdbc:sybase:Tds:hostname: portNumber/databaseName URL格式的所有突出部分都是静态的，只需要根据数据库设置更改对应的部分。 JDBC Statements类：当获得了与数据库的连接后，就可以与数据库进行交互了。 JDBC Statement，CallableStatement和PreparedStatement接口定义了可用于发送SQL或PL/SQL命令，并从数据库接收数据的方法和属性。 它们还定义了有助于在Java和SQL数据类型的数据类型差异转换的方法。下表提供了每个接口定义，以及使用这些接口的目的的总结。 接口 推荐使用 Statement 用于对数据库进行通用访问，在运行时使用静态SQL语句时很有用。 Statement接口不能接受参数。 PreparedStatement 当计划要多次使用SQL语句时使用。PreparedStatement接口在运行时接受输入参数。 CallableStatement 当想要访问数据库存储过程时使用。CallableStatement接口也可以接受运行时输入参数。 Statement对象1. 创建Statement对象 在使用Statement对象执行SQL语句之前，需要使用Connection对象的createStatement()方法创建一个Statement对象，如以下示例所示： 1234567891011Statement stmt = null;try &#123; stmt = conn.createStatement( ); . . .&#125;catch (SQLException e) &#123; . . .&#125;finally &#123; . . .&#125; 在创建Statement对象后，可以使用它来执行一个SQL语句，它有三个执行方法可以执行。它们分别是 - boolean execute (String SQL) ： 如果可以检索到ResultSet对象，则返回一个布尔值true; 否则返回false。使用此方法执行SQLDDL语句或需要使用真正的动态SQL，可使用于执行创建数据库，创建表的SQL语句等等。 int executeUpdate (String SQL): 返回受SQL语句执行影响的行数。使用此方法执行预期会影响多行的SQL语句，例如:INSERT，UPDATE或DELETE语句。 ResultSet executeQuery(String SQL)：返回一个ResultSet对象。 当您希望获得结果集时，请使用此方法，就像使用SELECT语句一样。 2.关闭Statement对象 就像关闭一个Connection对象一样，以保存数据库资源一样，由于同样的原因，还应该关闭Statement对象。 一个简单的调用close()方法将执行该作业(工作)。 如果先关闭Connection对象，它也会关闭Statement对象。 但是，应该始终显式关闭Statement对象，以确保正确的清理顺序。 1234567891011Statement stmt = null;try &#123; stmt = conn.createStatement( ); . . .&#125;catch (SQLException e) &#123; . . .&#125;finally &#123; stmt.close();&#125; PreparedStatement对象PreparedStatement接口扩展了Statement接口，它添加了比Statement对象更好一些优点的功能。 此语句可以动态地提供/接受参数。 2.1 创建PreparedStatement对象123456789101112PreparedStatement pstmt = null;try &#123; String SQL = "Update Employees SET age = ? WHERE id = ?"; pstmt = conn.prepareStatement(SQL); . . .&#125;catch (SQLException e) &#123; . . .&#125;finally &#123; . . .&#125; JDBC中的所有参数都由 ? 符号作为占位符，这被称为参数标记。 在执行SQL语句之前，必须为每个参数(占位符)提供值。 setXXX()方法将值绑定到参数，其中XXX表示要绑定到输入参数的值的Java数据类型。 如果忘记提供绑定值，则将会抛出一个SQLException。 每个参数标记是它其顺序位置引用。第一个标记表示位置1，下一个位置2等等。 该方法与Java数组索引不同(它不从0开始)。 所有Statement对象与数据库交互的方法(a)execute()，(b)executeQuery()和(c)executeUpdate()也可以用于PreparedStatement对象。 但是，这些方法被修改为可以使用输入参数的SQL语句。 2.关闭PreparedStatement对象 就像关闭Statement对象一样，由于同样的原因(节省数据库系统资源)，也应该关闭PreparedStatement对象。 简单的调用close()方法将执行关闭。 如果先关闭Connection对象，它也会关闭PreparedStatement对象。 但是，应该始终显式关闭PreparedStatement对象，以确保以正确顺序清理资源。 123456789101112PreparedStatement pstmt = null;try &#123; String SQL = "Update Employees SET age = ? WHERE id = ?"; pstmt = conn.prepareStatement(SQL); . . .&#125;catch (SQLException e) &#123; . . .&#125;finally &#123; pstmt.close();&#125; CallableStatement对象类似Connection对象创建Statement和PreparedStatement对象一样，它还可以使用同样的方式创建CallableStatement对象，该对象将用于执行对数据库存储过程的调用。 3.1. 创建CallableStatement对象假设需要执行以下Oracle存储过程 - 1234567CREATE OR REPLACE PROCEDURE getEmpName (EMP_ID IN NUMBER, EMP_FIRST OUT VARCHAR) ASBEGIN SELECT first INTO EMP_FIRST FROM Employees WHERE ID = EMP_ID;END; 注意：上面的存储过程是针对Oracle编写的，但是如果您使用MySQL数据库，可使用以下方式来编写MySQL相同的存储过程，如下在EMP数据库中创建它 - 123456789101112DELIMITER $$DROP PROCEDURE IF EXISTS `EMP`.`getEmpName` $$CREATE PROCEDURE `EMP`.`getEmpName` (IN EMP_ID INT, OUT EMP_FIRST VARCHAR(255))BEGIN SELECT first INTO EMP_FIRST FROM Employees WHERE ID = EMP_ID;END $$DELIMITER ; 存在三种类型的参数：IN，OUT和INOUT。 PreparedStatement对象只使用IN参数。CallableStatement对象可以使用上面三个参数类型。 以下是上面三种类型参数的定义 - 参数 描述 IN 创建SQL语句时其参数值是未知的。 使用setXXX()方法将值绑定到IN参数。 OUT 由SQL语句返回的参数值。可以使用getXXX()方法从OUT参数中检索值。 INOUT 提供输入和输出值的参数。使用setXXX()方法绑定变量并使用getXXX()方法检索值。 以下代码片段显示了如何使用Connection.prepareCall()方法根据上述存储过程来实例化一个CallableStatement对象 - 123456789101112CallableStatement cstmt = null;try &#123; String strSQL = "&#123;call getEmpName (?, ?)&#125;"; cstmt = conn.prepareCall (SQL); . . .&#125;catch (SQLException e) &#123; . . .&#125;finally &#123; . . .&#125; String变量strSQL表示存储过程，带有两个参数占位符。 使用CallableStatement对象就像使用PreparedStatement对象一样。 在执行语句之前，必须将值绑定到所有参数，否则将抛出一个SQLException异常。 如果有IN参数，只需遵循适用于PreparedStatement对象的相同规则和技术; 使用与绑定的Java数据类型相对应的setXXX()方法。 使用OUT和INOUT参数时，必须使用一个额外的CallableStatement对象方法registerOutParameter()。 registerOutParameter()方法将JDBC数据类型绑定到存储过程并返回预期数据类型。 当调用存储过程，可以使用适当的getXXX()方法从OUT参数中检索该值。 此方法将检索到的SQL类型的值转换为对应的Java数据类型。 关闭CallableStatement对象 就像关闭其他Statement对象一样，由于同样的原因(节省数据库系统资源)，还应该关闭CallableStatement对象。 简单的调用close()方法将执行关闭CallableStatement对象。 如果先关闭Connection对象，它也会关闭CallableStatement对象。 但是，应该始终显式关闭CallableStatement对象，以确保按正确顺序的清理资源。 123456789101112CallableStatement cstmt = null;try &#123; String SQL = "&#123;call getEmpName (?, ?)&#125;"; cstmt = conn.prepareCall (SQL); . . .&#125;catch (SQLException e) &#123; . . .&#125;finally &#123; cstmt.close();&#125; JDBC结果集：SQL语句执行后从数据库查询读取数据，返回的数据放在结果集中。 SELECT语句用于从数据库中选择行并在结果集中查看它们的标准方法。 java.sql.ResultSet接口表示数据库查询的结果集。 ResultSet对象维护指向结果集中当前行的游标。 术语“结果集”是指包含在ResultSet对象中的行和列数据。 ResultSet接口的方法可以分为三类： 浏览方法：用于移动光标。 获取方法：用于查看光标指向的当前行的列中的数据。 更新方法：用于更新当前行的列中的数据。 然后在基础数据库中更新数据。 光标可以基于ResultSet的属性移动。当创建生成ResultSet的相应Statement时，将指定这些属性。 JDBC提供以下连接方法来创建具有所需ResultSet的语句 - createStatement(int RSType, int RSConcurrency); prepareStatement(String SQL, int RSType, int RSConcurrency); prepareCall(String sql, int RSType, int RSConcurrency); 第一个参数表示ResultSet对象的类型，第二个参数是两个ResultSet常量之一，用于指定结果集是只读还是可更新。 浏览结果集 ResultSet接口中有几种涉及移动光标的方法，包括 - 编号 方法 描述 1 public void beforeFirst() throws SQLException 将光标移动到第一行之前 2 public void afterLast() throws SQLException 将光标移动到最后一行之后。 3 public boolean first() throws SQLException 将光标移动到第一行。 4 public void last() throws SQLException 将光标移动到最后一行。 5 public boolean absolute(int row) throws SQLException 将光标移动到指定的行。 6 public boolean relative(int row) throws SQLException 从当前指向的位置，将光标向前或向后移动给定行数。 7 public boolean previous() throws SQLException 将光标移动到上一行。 如果上一行关闭结果集，此方法返回false。 8 public boolean next() throws SQLException 将光标移动到下一行。 如果结果集中没有更多行，则此方法返回false。 9 public int getRow() throws SQLException 返回光标指向的行号。 10 public void moveToInsertRow() throws SQLException 将光标移动到结果集中的特殊行，该行可用于将新行插入数据库。当前光标位置被记住。 11 public void moveToCurrentRow() throws SQLException 如果光标当前位于插入行，则将光标移回当前行; 否则，此方法什么也不做 JDBC事务：如果JDBC连接处于自动提交模式，默认情况下，则每个SQL语句在完成后都会提交到数据库。 对于简单的应用程序可能没有问题，但是有三个原因需要考虑是否关闭自动提交并管理自己的事务 - 提高性能 保持业务流程的完整性 使用分布式事务 事务能够控制何时更改提交并应用于数据库。 它将单个SQL语句或一组SQL语句视为一个逻辑单元，如果任何语句失败，整个事务将失败。 要启用手动事务支持，而不是使用JDBC驱动程序默认使用的自动提交模式，请调用Connection对象的setAutoCommit()方法。 如果将布尔的false传递给setAutoCommit()，则关闭自动提交。 也可以传递一个布尔值true来重新打开它。 例如，如果有一个名为conn的Connection对象，请将以下代码关闭自动提交 - 1conn.setAutoCommit(false); 提交和回滚 完成更改后，若要提交更改，那么可在连接对象上调用commit()方法，如下所示： 1conn.commit( ); 否则，要使用连接名为conn的数据库回滚更新，请使用以下代码 - 1conn.rollback( ); 使用保存点 新的JDBC 3.0新添加了Savepoint接口提供了额外的事务控制能力。大多数现代DBMS支持其环境中的保存点，如Oracle的PL/SQL。 设置保存点(Savepoint)时，可以在事务中定义逻辑回滚点。 如果通过保存点(Savepoint)发生错误时，则可以使用回滚方法来撤消所有更改或仅保存保存点之后所做的更改。 Connection对象有两种新的方法可用来管理保存点 - setSavepoint(String savepointName): - 定义新的保存点，它还返回一个Savepoint对象。 releaseSavepoint(Savepoint savepointName): - 删除保存点。要注意，它需要一个Savepoint对象作为参数。 该对象通常是由setSavepoint()方法生成的保存点。 有一个rollback (String savepointName)方法，它将使用事务回滚到指定的保存点。 JDBC异常：异常处理允许我们以受控的方式处理异常情况，而不是直接退出程序，例如程序定义的错误。 发生异常时可以抛出异常。术语“异常”表示当前的程序执行停止，并且被重定向到最近的适用的catch子句。如果没有适用的catch子句存在，则程序的执行结束。 JDBC异常处理与Java异常处理非常相似，但对于JDBC，要处理的最常见异常是java.sql.SQLException。 SQLException方法 驱动程序和数据库中都会发生SQLException。 发生这种异常时，SQLException类型的对象将被传递给catch子句。 传递的SQLException对象具有以下可用于检索有关异常信息的方法 - 方法 描述 getErrorCode( ) 获取与异常关联的错误代码。 getMessage( ) 获取驱动程序处理的错误的JDBC驱动程序的错误消息，或获取数据库错误的Oracle错误代码和消息。 getSQLState( ) 获取XOPEN SQLstate字符串。 对于JDBC驱动程序错误，不会从此方法返回有用的信息。 对于数据库错误，返回五位数的XOPEN SQLstate代码。 此方法可以返回null。 getNextException( ) 获取异常链中的下一个Exception对象。 printStackTrace( ) 打印当前异常或可抛出的异常，并将其追溯到标准错误流。 printStackTrace(PrintStream s) 将此throwable及其回溯打印到指定的打印流。 printStackTrace(PrintWriter w) 打印这个throwable，它是回溯到指定的打印器(PrintWriter)。 JDBC批处理：批量处理允许将相关的SQL语句分组到批处理中，并通过对数据库的一次调用来提交它们，一次执行完成与数据库之间的交互。 一次向数据库发送多个SQL语句时，可以减少通信开销，从而提高性能。 不需要JDBC驱动程序来支持此功能。应该使用DatabaseMetaData.supportsBatchUpdates()方法来确定目标数据库是否支持批量更新处理。如果JDBC驱动程序支持此功能，该方法将返回true。 Statement，PreparedStatement和CallableStatement的addBatch()方法用于将单个语句添加到批处理。 executeBatch()用于执行组成批量的所有语句。 executeBatch()返回一个整数数组，数组的每个元素表示相应更新语句的更新计数。 就像将批处理语句添加到处理中一样，可以使用clearBatch()方法删除它们。此方法将删除所有使用addBatch()方法添加的语句。 但是，无法指定选择某个要删除的语句。 使用Statement对象进行批处理 以下是使用Statement对象的批处理的典型步骤序列 - 使用createStatement()方法创建Statement对象。 使用setAutoCommit()将自动提交设置为false。 使用addBatch()方法在创建的Statement对象上添加SQL语句到批处理中。 在创建的Statement对象上使用executeBatch()方法执行所有SQL语句。 最后，使用commit()方法提交所有更改。 使用PrepareStatement对象进行批处理 以下是使用PrepareStatement对象进行批处理的典型步骤顺序 - 使用占位符创建SQL语句。 使用prepareStatement()方法创建PrepareStatement对象。 使用setAutoCommit()将自动提交设置为false。 使用addBatch()方法在创建的Statement对象上添加SQL语句到批处理中。 在创建的Statement对象上使用executeBatch()方法执行所有SQL语句。 最后，使用commit()方法提交所有更改。 JDBC编程示例查询数据：在实验前，事先建立好了两张表，tbl_user,和tbl_address。通过JDBC变量是查询下面两张表的数据。 1234567891011121314151617181920212223242526mysql&gt; show tables;+------------------+| Tables_in_jsp_db |+------------------+| tbl_address || tbl_user |+------------------+2 rows in set (0.00 sec)mysql&gt; select * from tbl_user;+----+-----------+----------+----------------------+| id | name | password | email |+----+-----------+----------+----------------------+| 1 | xiaoming | 123456 | xiaoming@gmeail.com || 2 | xiaozhang | 123456 | xiaozhang@gmeail.com |+----+-----------+----------+----------------------+2 rows in set (0.00 sec)mysql&gt; select * from tbl_address;+----+----------+---------+---------+| id | city | country | user_id |+----+----------+---------+---------+| 1 | beijing | china | 1 || 2 | tianjing | china | 2 |+----+----------+---------+---------+2 rows in set (0.00 sec) 配置dbconfig.properties: 1234driver=com.mysql.jdbc.Driverdburl=jdbc:mysql://localhost:3306/jsp_db?useSSL=falseuser=rootpassword=123456 连接实体： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package JDBC.util;import java.io.InputStream;import java.sql.Connection;import java.sql.DriverManager;import java.util.Properties;public class ConnectionFactory &#123; private static String driver; private static String dburl; private static String user; private static String password; private static final ConnectionFactory factory = new ConnectionFactory(); private Connection conn; static &#123; Properties prop = new Properties(); try &#123; InputStream in = ConnectionFactory.class.getClassLoader(). getResourceAsStream("dbconfig.properties"); prop.load(in); &#125; catch (Exception e) &#123; System.out.println("========配置文件读取错误========"); &#125; driver = prop.getProperty("driver"); dburl = prop.getProperty("dburl"); user = prop.getProperty("user"); password = prop.getProperty("password"); &#125; private ConnectionFactory() &#123; &#125; public static ConnectionFactory getInstance() &#123; return factory; &#125; public Connection makeConnection() &#123; try &#123; Class.forName(driver); conn = DriverManager.getConnection(dburl, user, password); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return conn; &#125;&#125; JDBC.entity： 1234567891011121314package JDBC.entity;public abstract class IdEntity &#123; protected int id; public int getId() &#123; return id; &#125; public int setId(int id) &#123; return this.id = id; &#125;&#125; 12345678910111213141516171819202122232425262728293031package JDBC.entity;public class User extends IdEntity &#123; private String name; private String password; private String emial; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getEmial() &#123; return emial; &#125; public void setEmial(String emial) &#123; this.emial = emial; &#125; @Override public String toString() &#123; return "User [name=" + name + ", password=" + password + ", " + "emial=" + emial + ", id=" + id + "]"; &#125;&#125; 123456789101112131415161718192021222324252627282930313233package JDBC.entity;public class Address extends IdEntity&#123; private String city; private String country; private int userId; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getCountry() &#123; return country; &#125; public void setCountry(String country) &#123; this.country = country; &#125; public int getUserId() &#123; return userId; &#125; public void setUserId(int i) &#123; this.userId = i; &#125; @Override public String toString() &#123; return "Address [city=" + city + ", country=" + country + ", " + "userId=" + userId + ", id=" + id + "]"; &#125;&#125; JDBC.test: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package JDBC;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import JDBC.entity.Address;import JDBC.entity.User;import JDBC.util.ConnectionFactory;public class JDBCtest &#123; public static void main(String[] args) throws SQLException &#123; ConnectionFactory cf = ConnectionFactory.getInstance(); Connection conn = cf.makeConnection(); String sql_user = "SELECT * FROM tbl_user"; Statement stat = conn.createStatement(); PreparedStatement ps = null; Address address = new Address(); User user = new User(); try &#123; stat.executeQuery(sql_user); ResultSet re_user = stat.getResultSet(); String sql_address = "SELECT * FROM tbl_address WhERE user_id = ?"; while(re_user.next())&#123; user.setPassword(re_user.getString("password")); user.setId(re_user.getInt("id")); user.setName(re_user.getString("name")); user.setEmial(re_user.getString("email")); System.out.println(user.toString()); ps = conn.prepareStatement(sql_address); ps.setInt(1, user.getId()); ps.execute(); ResultSet re_address = ps.getResultSet(); if(re_address.next()) &#123; address.setId(re_address.getInt("id")); address.setCity(re_address.getString("city")); address.setCountry(re_address.getString("country")); address.setUserId(re_address.getInt("user_id")); System.out.println(address.toString()); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 程序运行结果： 123Address [city=beijing, country=china, userId=1, id=1]User [name=xiaozhang, password=123456, emial=xiaozhang@gmeail.com, id=2]Address [city=tianjing, country=china, userId=2, id=2]]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
        <tag>数据库</tag>
        <tag>JDBC</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL学习笔记（2）高级操作]]></title>
    <url>%2F2018%2F07%2F09%2FMySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[MySQL UNION：MySQL UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。 语法：MySQL UNION 操作符语法格式： 1234567SELECT expression1, expression2, ... expression_nFROM tables[WHERE conditions]UNION [ALL | DISTINCT]SELECT expression1, expression2, ... expression_nFROM tables[WHERE conditions]; 参数： expression1, expression2, … expression_n: 要检索的列。 tables: 要检索的数据表。 WHERE conditions: 可选， 检索条件。 DISTINCT: 可选，删除结果集中重复的数据。默认情况下 UNION 操作符已经删除了重复数据，所以 DISTINCT 修饰符对结果没啥影响。 ALL: 可选，返回所有结果集，包含重复数据。 使用示例： 实验表： 1234567891011121314151617181920mysql&gt; select * from student1;+----+-----+--------+-----+-----+| id | num | name | sex | age |+----+-----+--------+-----+-----+| 1 | 100 | 小明 | 男 | 20 || 2 | 101 | 小红 | 女 | 24 || 3 | 102 | 小刘 | 女 | 23 || 4 | 103 | 程兴旺 | 男 | 21 |+----+-----+--------+-----+-----+3 rows in set (0.00 sec)mysql&gt; select * from student;+----+------+------+-----+------+----------+| id | num | name | age | sex | class |+----+------+------+-----+------+----------+| 1 | NULL | 张三 | 19 | 男 | NULL || 2 | NULL | 李四 | 25 | 男 | NULL || 6 | 200 | 刘慧 | 23 | 女 | 对口一班 |+----+------+------+-----+------+----------+3 rows in set (0.00 sec) 实验1：从两张表中选取不同的年龄：（默认情况下会删除重复的数据） 123456789101112131415mysql&gt; select age from student -&gt; union -&gt; select age from student1 -&gt; order by age;+-----+| age |+-----+| 19 || 20 || 21 || 23 || 24 || 25 |+-----+6 rows in set (0.00 sec) 注释：UNION 只会选取不同的值。请使用 UNION ALL 来选取重复的值！ 实验2：选择所有的年龄，包括重复的。 123456789101112131415161718mysql&gt; select age from student -&gt; union ALL -&gt; select age from student1 -&gt; order by age;+-----+| age |+-----+| 19 || 20 || 21 || 23 || 23 || 24 || 25 |+-----+7 rows in set (0.00 sec)mysql&gt; 实验3：选择出两张表中所有男性的信息。使用where语句的union。 123456789101112131415mysql&gt; select num, name, age ,sex from student -&gt; where sex=&apos;男&apos; -&gt; union all -&gt; select num, name, age ,sex from student1 -&gt; where sex=&apos;男&apos; -&gt; ;+------+--------+-----+------+| num | name | age | sex |+------+--------+-----+------+| NULL | 张三 | 19 | 男 || NULL | 李四 | 25 | 男 || 100 | 小明 | 20 | 男 || 103 | 程兴旺 | 21 | 男 |+------+--------+-----+------+4 rows in set (0.00 sec) MySQL排序：如果需要对读取的数据进行排序，就可以使用 MySQL 的 ORDER BY 子句来设定想按哪个字段哪种方式来进行排序，再返回搜索结果。 语法：以下是 SQL SELECT 语句使用 ORDER BY 子句将查询数据排序后再返回数据： 12SELECT field1, field2,...fieldN table_name1, table_name2...ORDER BY field1, [field2...] [ASC [DESC]] 可以使用任何字段来作为排序的条件，从而返回排序后的查询结果。 可以设定多个字段来排序。 可以使用 ASC 或 DESC 关键字来设置查询结果是按升序或降序排列。 默认情况下，它是按升序排列。 可以添加 WHERE…LIKE 子句来设置条件。 使用示例： 按年龄升序进行排序： 12345678910111213141516171819mysql&gt; select * from student order by age;+----+------+------+-----+------+----------+| id | num | name | age | sex | class |+----+------+------+-----+------+----------+| 1 | NULL | 张三 | 19 | 男 | NULL || 6 | 200 | 刘慧 | 23 | 女 | 对口一班 || 2 | NULL | 李四 | 25 | 男 | NULL |+----+------+------+-----+------+----------+3 rows in set (0.00 sec)mysql&gt; select * from student order by age desc;+----+------+------+-----+------+----------+| id | num | name | age | sex | class |+----+------+------+-----+------+----------+| 2 | NULL | 李四 | 25 | 男 | NULL || 6 | 200 | 刘慧 | 23 | 女 | 对口一班 || 1 | NULL | 张三 | 19 | 男 | NULL |+----+------+------+-----+------+----------+3 rows in set (0.00 sec) MySQL GROUP BY语句：GROUP BY 语句根据一个或多个列对结果集进行分组。 在分组的列上可以使用 COUNT, SUM, AVG,等函数。 GROUP BY 语法： 1234SELECT column_name, function(column_name)FROM table_nameWHERE column_name operator valueGROUP BY column_name; 使用示例： 将student1表中男女分组，并统计男女各有多少人。 12345678mysql&gt; select sex, count(*) from student1 group by sex;+-----+----------+| sex | count(*) |+-----+----------+| 女 | 2 || 男 | 2 |+-----+----------+2 rows in set (0.00 sec) MySQL连接的使用：可以使用JOIN在两个或多个表中查询数据。 JOIN 按照功能大致分为如下三类： INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。 LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。 RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。 MySQL NULL值处理：我们已经知道 MySQL 使用 SQL SELECT 命令及 WHERE 子句来读取数据表中的数据,但是当提供的查询条件字段为 NULL 时，该命令可能就无法正常工作。 为了处理这种情况，MySQL提供了三大运算符: IS NULL: 当列的值是 NULL,此运算符返回 true。 IS NOT NULL: 当列的值不为 NULL, 运算符返回 true。 &lt;=&gt;: 比较操作符（不同于=运算符），当比较的的两个值为 NULL 时返回 true。 关于 NULL 的条件比较运算是比较特殊的。不能使用 = NULL 或 != NULL 在列中查找 NULL 值 。 在 MySQL 中，NULL 值与任何其它值的比较（即使是 NULL）永远返回 false，即 NULL = NULL 返回false 。 MySQL 中处理 NULL 使用 IS NULL 和 IS NOT NULL 运算符。 使用示例： 12345678910111213141516mysql&gt; select * from student where num is null;+----+------+------+-----+------+-------+| id | num | name | age | sex | class |+----+------+------+-----+------+-------+| 1 | NULL | 张三 | 19 | 男 | NULL || 2 | NULL | 李四 | 25 | 男 | NULL |+----+------+------+-----+------+-------+2 rows in set (0.00 sec)mysql&gt; select * from student where num is not null;+----+------+------+-----+------+----------+| id | num | name | age | sex | class |+----+------+------+-----+------+----------+| 6 | 200 | 刘慧 | 23 | 女 | 对口一班 |+----+------+------+-----+------+----------+1 row in set (0.00 sec) MySQL 正则表达式：MySQL中使用 REGEXP 操作符来进行正则表达式匹配。 下表中的正则模式可应用于 REGEXP 操作符中。 模式 描述 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\n’ 或 ‘\r’ 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\n’ 或 ‘\r’ 之前的位置。 . 匹配除 “\n” 之外的任何单个字符。要匹配包括 ‘\n’ 在内的任何字符，请使用象 ‘[.\n]’ 的模式。 […] 字符集合。匹配所包含的任意一个字符。例如， ‘[abc]’ 可以匹配 “plain” 中的 ‘a’。 [^…] 负值字符集合。匹配未包含的任意字符。例如， ‘[^abc]’ 可以匹配 “plain” 中的’p’。 p1 \ p2\ p3 匹配 p1 或 p2 或 p3。例如，’z\ food’ 能匹配 “z” 或 “food”。’(z\ f)ood’ 则匹配 “zood” 或 “food”。 * 匹配前面的子表达式零次或多次。例如，zo 能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。 使用示例： 12345678910mysql&gt; select name from student1 where name regexp &apos;^小&apos;;#匹配以name中以“小”字开头的姓名。+------+| name |+------+| 小明 || 小红 || 小刘 |+------+3 rows in set (0.00 sec) MySQL事务：MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 一般来说，事务是必须满足4个条件（ACID）：：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 事务控制语句： BEGIN或START TRANSACTION；显式地开启一个事务； COMMIT；也可以使用COMMIT WORK，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改成为永久性的； ROLLBACK；有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier；SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT； RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier；把事务回滚到标记点； SET TRANSACTION；用来设置事务的隔离级别。InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。 MYSQL 事务处理主要有两种方法： 1、用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 2、直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 MySQL索引：MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。 索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。 创建索引时，需要确保该索引是应用在SQL 查询语句的条件(一般作为 WHERE 子句的条件)。 实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。 上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 建立索引会占用磁盘空间的索引文件。 普通索引：创建索引： 这是最基本的索引，它没有任何限制。它有以下几种创建方式： 1CREATE INDEX indexName ON mytable(username(length)); 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引) 1ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定 123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引的语法 1DROP INDEX [indexName] ON mytable; 唯一索引：它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式： 创建索引 1CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构 1ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定 123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 使用ALTER 命令添加和删除索引有四种方式来添加数据表的索引： ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。 ALTER TABLE tbl_name ADD UNIQUE index_name (column_list): 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。 ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。 ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):该语句指定了索引为 FULLTEXT ，用于全文索引。 使用 ALTER 命令添加和删除主键主键只能作用于一个列上，添加主键索引时，需要确保该主键默认不为空（NOT NULL）。实例如下： 123mysql&gt; alter table student add primary key (id);Query OK, 6 rows affected (0.02 sec)Records: 6 Duplicates: 0 Warnings: 0 你也可以使用 ALTER 命令删除主键： 123mysql&gt; alter table student drop primary key;Query OK, 6 rows affected (0.02 sec)Records: 6 Duplicates: 0 Warnings: 0 删除主键时只需指定PRIMARY KEY，但在删除索引时，必须知道索引名。 显示索引信息可以使用 SHOW INDEX 命令来列出表中的相关的索引信息。可以通过添加 \G 来格式化输出信息。 尝试以下实例: 1mysql&gt; SHOW INDEX FROM table_name; \G MySQL临时表：MySQL 临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。 临时表在MySQL 3.23版本中添加，如果你的MySQL版本低于 3.23版本就无法使用MySQL的临时表。不过现在一般很少有再使用这么低版本的MySQL数据库服务了。 如果使用了其他MySQL客户端程序连接MySQL数据库服务器来创建临时表，那么只有在关闭客户端程序时才会销毁临时表，当然也可以手动销毁。 使用示例： 12345create temporary Table test（`id` int not null）;#创建临时表drop Table test；#手动删除临时表，默认当断开与数据库的连接后，临时表就会自动销毁。 当你使用 SHOW TABLES命令显示数据表列表时，将无法看到 临时表。 如果退出当前MySQL会话，再使用 SELECT命令来读取原先创建的临时表数据，那会发现数据库中没有该表的存在，因为在退出时该临时表已经被销毁了。 MySQL 复制表：如果我们需要完全的复制MySQL的数据表，包括表的结构，索引，默认值等。 如果仅仅使用CREATE TABLE … SELECT 命令，是无法实现的。 完整的复制MySQL数据表，步骤如下： 使用 SHOW CREATE TABLE 命令获取创建数据表(CREATE TABLE) 语句，该语句包含了原数据表的结构，索引等。 ​ 复制以下命令显示的SQL语句，修改数据表名，并执行SQL语句，通过以上命令 将完全的复制数据表结构。 如果你想复制表的内容，你就可以使用INSERT INTO … SELECT 语句来实现。 使用示例： 获取数据表完整的结构： 1234567891011121314151617mysql&gt; show create table student \G;*************************** 1. row *************************** Table: studentCreate Table: CREATE TABLE `student` ( `id` int(11) NOT NULL, `num` int(11), `name` varchar(20) NOT NULL, `age` int(11) NOT NULL, `sex` varchar(10) DEFAULT NULL, `class` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`), KEY `index_1` (`num`)) ENGINE=MyISAM AUTO_INCREMENT=10 DEFAULT CHARSET=utf81 row in set (0.00 sec)ERROR:No query specified 修改sql数据表表明，并执行sql语句。 1234567891011mysql&gt; CREATE TABLE `student2` ( -&gt; `id` int(11) NOT NULL, -&gt; `num` int(11), -&gt; `name` varchar(20) NOT NULL, -&gt; `age` int(11) NOT NULL, -&gt; `sex` varchar(10) DEFAULT NULL, -&gt; `class` varchar(20) DEFAULT NULL, -&gt; PRIMARY KEY (`id`), -&gt; KEY `index_1` (`num`) -&gt; ) ENGINE=MyISAM AUTO_INCREMENT=10 DEFAULT CHARSET=utf8;Query OK, 0 rows affected (0.01 sec) 执行完第二步骤后，将在数据库中创建新的克隆表student2。 如果想拷贝数据表的数据你可以使用INSERT INTO… SELECT 语句来实现。 其他复制表的方式：第一、只复制表结构到新表 create table 新表 select * from 旧表 where 1=2 #这也可以按条件复制一部分数据 或者 create table 新表 like 旧表 #只复制表的结构 第二、复制表结构及数据到新表 create table新表 select * from 旧表 MySQL中\G的意思：查询结果按列打印\G 放到sql语句后,可以使每个字段打印到单独的行。 \g相当于；，结尾号。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051mysql&gt; select * from student1;+----+-----+--------+-----+-----+| id | num | name | sex | age |+----+-----+--------+-----+-----+| 1 | 100 | 小明 | 男 | 20 || 2 | 101 | 小红 | 女 | 24 || 3 | 102 | 小刘 | 女 | 23 || 4 | 103 | 程兴旺 | 男 | 21 |+----+-----+--------+-----+-----+4 rows in set (0.00 sec)mysql&gt; select * from student1 \G;*************************** 1. row *************************** id: 1 num: 100name: 小明 sex: 男 age: 20*************************** 2. row *************************** id: 2 num: 101name: 小红 sex: 女 age: 24*************************** 3. row *************************** id: 3 num: 102name: 小刘 sex: 女 age: 23*************************** 4. row *************************** id: 4 num: 103name: 程兴旺 sex: 男 age: 214 rows in set (0.00 sec)ERROR:No query specifiedmysql&gt; select * from student1 \g+----+-----+--------+-----+-----+| id | num | name | sex | age |+----+-----+--------+-----+-----+| 1 | 100 | 小明 | 男 | 20 || 2 | 101 | 小红 | 女 | 24 || 3 | 102 | 小刘 | 女 | 23 || 4 | 103 | 程兴旺 | 男 | 21 |+----+-----+--------+-----+-----+4 rows in set (0.00 sec) MySQL 元数据：如果想知道MySQL以下三种信息： 查询结果信息： SELECT, UPDATE 或 DELETE语句影响的记录数。 数据库和数据表的信息： 包含了数据库及数据表的结构信息。 MySQL服务器信息： 包含了数据库服务器的当前状态，版本号等。 在MySQL的命令提示符中，可以很容易的获取以上服务器信息。 命令 描述 SELECT VERSION( ) 服务器版本信息 SELECT DATABASE( ) 当前数据库名 (或者返回空) SELECT USER( ) 当前用户名 SHOW STATUS 服务器状态 SHOW VARIABLES 服务器配置变量 MySQL 序列使用：MySQL序列是一组整数：1, 2, 3, …，由于一张数据表只能有一个字段自增主键， 如果你想实现其他字段也实现自动增加，就可以使用MySQL序列来实现。 使用aoto_increament： MySQL中最简单使用序列的方法就是使用 MySQL AUTO_INCREMENT 来定义列。 获取aoto_increament的值： 在MySQL的客户端中可以使用 SQL中的LAST_INSERT_ID( ) 函数来获取最后的插入表中的自增列的值。 1234567mysql&gt; select last_insert_id();+------------------+| last_insert_id() |+------------------+| 9 |+------------------+1 row in set (0.00 sec) 重置序列： 如果删除了数据表中的多条记录，并希望对剩下数据的AUTO_INCREMENT列进行重新排列，那么可以通过删除自增的列，然后重新添加来实现。 不过该操作要非常小心，如果在删除的同时又有新记录添加，有可能会出现数据混乱。 1234mysql&gt; ALTER TABLE tablename DROP id;mysql&gt; ALTER TABLE tablename -&gt; ADD id INT UNSIGNED NOT NULL AUTO_INCREMENT FIRST, -&gt; ADD PRIMARY KEY (id); 设置序列的开始值： 一般情况下序列的开始值为1，但如果需要指定一个开始值100，可以通过以下语句来实现： 12345678mysql&gt; CREATE TABLE tablename -&gt; ( -&gt; id INT UNSIGNED NOT NULL AUTO_INCREMENT, -&gt; PRIMARY KEY (id), -&gt; name VARCHAR(30) NOT NULL, -&gt; date DATE NOT NULL, -&gt; origin VARCHAR(30) NOT NULL)engine=innodb auto_increment=100 charset=utf8; 或者创建表后指定。 1ALTER TABLE tablename AUTO_INCREMENT = 100; MySQL 处理重复数据：有些 MySQL 数据表中可能存在重复的记录，有些情况我们允许重复数据的存在，但有时候我们也需要删除这些重复的数据。 防止表中出现重复的数据： 可以在MySQL数据表中设置指定的字段为PRIMARY KEY（主键） 或者UNIQUE（唯一）索引来保证数据的唯一性。 当有想要两个字段都不能有重复时，可以设置双主键模式来保证数据的唯一性。如果设置了双主键，那么那个键的默认值不能为NULL，可设置为NOT NULL。 如果设置了唯一索引，那么在插入重复数据时，SQL语句将无法执行成功,并抛出错。 NSERT IGNORE INTO与INSERT INTO的区别就是INSERT IGNORE会忽略数据库中已经存在的数据，如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。这样就可以保留数据库中已经存在数据，达到在间隙中插入数据的目的。 INSERT IGNORE INTO当插入数据时，在设置了记录的唯一性后，如果插入重复数据，将不返回错误，只以警告形式返回。 而REPLACE INTO into如果存在primary 或 unique相同的记录，则先删除掉。再插入新记录。 另一种设置数据的唯一性方法是添加一个UNIQUE索引，如下所示： 1234567CREATE TABLE person_tbl( first_name CHAR(20) NOT NULL, last_name CHAR(20) NOT NULL, sex CHAR(10) UNIQUE (last_name, first_name)); 统计重复数据：般情况下，查询重复的值，请执行以下操作： 确定哪一列包含的值可能会重复。 在列选择列表使用COUNT(*)列出的那些列。 在GROUP BY子句中列出的列。 1234567891011121314151617181920212223mysql&gt; select * from test;+----+| id |+----+| 10 || 20 || 20 || 20 || 30 || 30 |+----+6 rows in set (0.00 sec)mysql&gt; select id, count(*) as counts from test -&gt; group by id;+----+--------+| id | counts |+----+--------+| 10 | 1 || 20 | 3 || 30 | 2 |+----+--------+3 rows in set (0.00 sec) 过滤重复数据：如果需要读取不重复的数据可以在 SELECT 语句中使用 DISTINCT 关键字来过滤重复数据。 123456789mysql&gt; select distinct id from test;+----+| id |+----+| 10 || 20 || 30 |+----+3 rows in set (0.00 sec) 也可以使用group by来读取数据表中不重复的数据： 123456789mysql&gt; select id from test group by id;+----+| id |+----+| 10 || 20 || 30 |+----+3 rows in set (0.00 sec) 删除重复数据：12345678910111213mysql&gt; create table test1 select id from test group by id;Query OK, 3 rows affected (0.06 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; select * from test1;+----+| id |+----+| 10 || 20 || 30 |+----+3 rows in set (0.00 sec) 相当于创建一个新的表，复制不重复的数据。然后可以删除原来的表，并将新创建的表更名为原来的表。从而达到删除重复数据的目的。 也可以在数据表中添加 INDEX（索引） 和 PRIMAY KEY（主键）这种简单的方法来删除表中的重复记录。方法如下： 12mysql&gt; ALTER IGNORE TABLE person_tbl -&gt; ADD PRIMARY KEY (last_name, first_name); MySQL 及 SQL注入：所谓SQL注入，就是通过把SQL命令插入到Web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。 我们永远不要信任用户的输入，我们必须认定用户输入的数据都是不安全的，我们都需要对用户输入的数据进行过滤处理。 MySQL导出数据：MySQL中你可以使用SELECT…INTO OUTFILE语句来简单的导出数据到文本文件上。 使用 SELECT … INTO OUTFILE 语句导出数据以下实例中我们将数据表 runoob_tbl 数据导出到 /tmp/runoob.txt 文件中: 12mysql&gt; SELECT * FROM runoob_tbl -&gt; INTO OUTFILE &apos;/tmp/runoob.txt&apos;; 可以通过命令选项来设置数据输出的指定格式，以下实例为导出 CSV 格式： 123mysql&gt; SELECT * FROM passwd INTO OUTFILE &apos;/tmp/runoob.txt&apos; -&gt; FIELDS TERMINATED BY &apos;,&apos; ENCLOSED BY &apos;&quot;&apos; -&gt; LINES TERMINATED BY &apos;\r\n&apos;; 在下面的例子中，生成一个文件，各值用逗号隔开。这种格式可以被许多程序使用。 1234SELECT a,b,a+b INTO OUTFILE &apos;/tmp/result.text&apos;FIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&apos;LINES TERMINATED BY &apos;\n&apos;FROM test_table; SELECT … INTO OUTFILE 语句有以下属性: LOAD DATA INFILE是SELECT … INTO OUTFILE的逆操作，SELECT句法。为了将一个数据库的数据写入一个文件，使用SELECT … INTO OUTFILE，为了将文件读回数据库，使用LOAD DATA INFILE。 SELECT…INTO OUTFILE ‘file_name’形式的SELECT可以把被选择的行写入一个文件中。该文件被创建到服务器主机上，因此必须拥有FILE权限，才能使用此语法。 输出不能是一个已存在的文件。防止文件数据被篡改。 需要有一个登陆服务器的账号来检索文件。否则 SELECT … INTO OUTFILE 不会起任何作用。 在UNIX中，该文件被创建后是可读的，权限由MySQL服务器所拥有。这意味着，虽然你就可以读取该文件，但可能无法将其删除。 导出表作为原始数据mysqldump 是 mysql 用于转存储数据库的实用程序。它主要产生一个 SQL 脚本，其中包含从头重新创建数据库所必需的命令 CREATE TABLE INSERT 等。 使用 mysqldump 导出数据需要使用 –tab 选项来指定导出文件指定的目录，该目标必须是可写的。 以下实例将数据表 runoob_tbl 导出到 /tmp 目录中： 123$ mysqldump -u root -p --no-create-info \ --tab=/tmp RUNOOB runoob_tblpassword ****** 导出 SQL 格式的数据导出 SQL 格式的数据到指定文件，如下所示： 12$ mysqldump -u root -p RUNOOB runoob_tbl &gt; dump.txtpassword ****** 如果需要导出整个数据库的数据，可以使用以下命令： 12$ mysqldump -u root -p RUNOOB &gt; database_dump.txtpassword ****** 如果需要备份所有数据库，可以使用以下命令： 12$ mysqldump -u root -p --all-databases &gt; database_dump.txtpassword ****** –all-databases 选项在 MySQL 3.23.12 及以后版本加入。 该方法可用于实现数据库的备份策略。 将数据表及数据库拷贝至其他主机如果需要将数据拷贝至其他的 MySQL 服务器上, 你可以在 mysqldump 命令中指定数据库名及数据表。 在源主机上执行以下命令，将数据备份至 dump.txt 文件中: 12$ mysqldump -u root -p database_name table_name &gt; dump.txtpassword ***** 如果完整备份数据库，则无需使用特定的表名称。 如果需要将备份的数据库导入到MySQL服务器中，可以使用以下命令，使用以下命令你需要确认数据库已经创建： 12345$ mysql -u root -p database_name &lt; dump.txtpassword *****#你也可以使用以下命令将导出的数据直接导入到远程的服务器上，但请确保两台服务器是相通的，是可以相互访问的：&lt;/p&gt;$ mysqldump -u root -p database_name \ | mysql -h other-host.com database_name 以上命令中使用了管道来将导出的数据导入到指定的远程主机上。 MySQL导入数据：1、mysql 命令导入使用 mysql 命令导入语法格式为： 1mysql -u用户名 -p密码 &lt; 要导入的数据库数据(runoob.sql) 实例： 1# mysql -uroot -p123456 &lt; runoob.sql 以上命令将将备份的整个数据库 runoob.sql 导入。 2、source 命令导入source 命令导入数据库需要先登录到数库终端： 1234mysql&gt; create database abc; # 创建数据库mysql&gt; use abc; # 使用已创建的数据库 mysql&gt; set names utf8; # 设置编码mysql&gt; source /home/abc/abc.sql # 导入备份数据库 3、使用 LOAD DATA 导入数据MySQL 中提供了LOAD DATA INFILE语句来插入数据。 以下实例中将从当前目录中读取文件 dump.txt ，将该文件中的数据插入到当前数据库的 mytbl 表中。 1mysql&gt; LOAD DATA LOCAL INFILE &apos;dump.txt&apos; INTO TABLE mytbl; 如果指定LOCAL关键词，则表明从客户主机上按路径读取文件。如果没有指定，则文件在服务器上按路径读取文件。 你能明确地在LOAD DATA语句中指出列值的分隔符和行尾标记，但是默认标记是定位符和换行符。 两个命令的 FIELDS 和 LINES 子句的语法是一样的。两个子句都是可选的，但是如果两个同时被指定，FIELDS 子句必须出现在 LINES 子句之前。 如果用户指定一个 FIELDS 子句，它的子句 （TERMINATED BY、[OPTIONALLY] ENCLOSED BY 和 ESCAPED BY) 也是可选的，不过，用户必须至少指定它们中的一个。 123mysql&gt; LOAD DATA LOCAL INFILE &apos;dump.txt&apos; INTO TABLE mytbl -&gt; FIELDS TERMINATED BY &apos;:&apos; -&gt; LINES TERMINATED BY &apos;\r\n&apos;; LOAD DATA 默认情况下是按照数据文件中列的顺序插入数据的，如果数据文件中的列与插入表中的列不一致，则需要指定列的顺序。 如，在数据文件中的列顺序是 a,b,c，但在插入表的列顺序为b,c,a，则数据导入语法如下： 12mysql&gt; LOAD DATA LOCAL INFILE &apos;dump.txt&apos; -&gt; INTO TABLE mytbl (b, c, a); 4、使用 mysqlimport 导入数据mysqlimport客户端提供了LOAD DATA INFILEQL语句的一个命令行接口。mysqlimport的大多数选项直接对应LOAD DATA INFILE子句。 从文件 dump.txt 中将数据导入到 mytbl 数据表中, 可以使用以下命令： 12$ mysqlimport -u root -p --local database_name dump.txtpassword ***** mysqlimport命令可以指定选项来设置指定格式,命令语句格式如下： 123$ mysqlimport -u root -p --local --fields-terminated-by=&quot;:&quot; \ --lines-terminated-by=&quot;\r\n&quot; database_name dump.txtpassword ***** mysqlimport 语句中使用 –columns 选项来设置列的顺序： 123$ mysqlimport -u root -p --local --columns=b,c,a \ database_name dump.txtpassword ***** mysqlimport的常用选项介绍 选项 功能 -d or –delete 新数据导入数据表中之前删除数据数据表中的所有信息 -f or –force 不管是否遇到错误，mysqlimport将强制继续插入数据 -i or –ignore mysqlimport跳过或者忽略那些有相同唯一 关键字的行， 导入文件中的数据将被忽略。 -l or -lock-tables 数据被插入之前锁住表，这样就防止了， 你在更新数据库时，用户的查询和更新受到影响。 -r or -replace 这个选项与－i选项的作用相反；此选项将替代 表中有相同唯一关键字的记录。 –fields-enclosed- by= char 指定文本文件中数据的记录时以什么括起的， 很多情况下 数据以双引号括起。 默认的情况下数据是没有被字符括起的。 –fields-terminated- by=char 指定各个数据的值之间的分隔符，在句号分隔的文件中， 分隔符是句号。您可以用此选项指定数据之间的分隔符。 默认的分隔符是跳格符（Tab） –lines-terminated- by=str 此选项指定文本文件中行与行之间数据的分隔字符串 或者字符。 默认的情况下mysqlimport以newline为行分隔符。 您可以选择用一个字符串来替代一个单个的字符： 一个新行或者一个回车。 mysqlimport命令常用的选项还有-v 显示版本（version）， -p 提示输入密码（password）等。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>正则表达式</tag>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL学习笔记（1）基础操作]]></title>
    <url>%2F2018%2F07%2F08%2FMySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[数据库简介什么是数据库：数据库（Database）是按照数据结构来组织、存储和管理数据的仓库， 每个数据库都有一个或多个不同的API用于创建，访问，管理，搜索和复制所保存的数据。 我们也可以将数据存储在文件中，但是在文件中读写数据速度相对较慢。 所以，现在我们使用关系型数据库管理系统（RDBMS）来存储和管理的大数据量。所谓的关系型数据库，是建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据。 RDBMS即关系数据库管理系统(Relational Database Management System)的特点： 数据以表格的形式出现 每行为各种记录名称 每列为记录名称所对应的数据域 许多的行和列组成一张表单 若干的表单组成database RDBMS术语： 数据库: 数据库是一些关联表的集合。 数据表: 表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格。 列: 一列(数据元素) 包含了相同的数据, 例如邮政编码的数据。 行：一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据。 冗余：存储两倍数据，冗余降低了性能，但提高了数据的安全性。 主键：主键是唯一的。一个数据表中只能包含一个主键。你可以使用主键来查询数据。 外键：外键用于关联两个表。 复合键：复合键（组合键）将多个列作为一个索引键，一般用于复合索引。 索引：使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构。类似于书籍的目录。 参照完整性: 参照的完整性要求关系中不允许引用不存在的实体。与实体完整性是关系模型必须满足的完整性约束条件，目的是保证数据的一致性。 MySQL数据库简介：MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 公司。MySQL 是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。 MySQL 是开源的，所以你不需要支付额外的费用。 MySQL 支持大型的数据库。可以处理拥有上千万条记录的大型数据库。 MySQL 使用标准的SQL数据语言形式。 MySQL 可以运行于多个系统上，并且支持多种语言。这些编程语言包括C、C++、Python、Java、Perl、PHP、Eiffel、Ruby和Tcl等。 MySQL 对PHP有很好的支持，PHP是目前最流行的Web开发语言。 MySQL 支持大型数据库，支持5000万条记录的数据仓库，32位系统表文件最大可支持4GB，64位系统支持最大的表文件为8TB。 MySQL 是可以定制的，采用了GPL（General Public License）协议，你可以修改源码来开发自己的 MySQL 系统。 MySQL管理启动和关闭MySQL服务器：在windows中，启动mysql服务器的命令为：net start mysql 在Linux中，启动mysql服务器的命令为：service mysql start/stop/restart 用户管理：创建用户：命令： 1create user &apos;username&apos;@&apos;host&apos; identified by &apos;password&apos;; 另一种创建用户的方法： 1234grant select, insert, update, delete, create,drop on tutorials.* to &apos;hive&apos;@&apos;localhost&apos; identified by &apos;hive123&apos;; 说明： username：创建的用户名 host：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符%。 password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器 注意: MySQL 的SQL语句以分号 (;) 作为结束标识。 例如： 1create user &apos;hive&apos;@&apos;localhost&apos; identified by &apos;hive123&apos;; 授权：命令： 1grant privileges on databasename.tablename to &apos;username&apos;@&apos;host&apos;; 说明: privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL databasename：数据库名 tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用*表示，如*.* 所有的权限为： ​ Alter 修改表和索引 Create 创建数据库和表 Delete 删除表中已有的记录 Drop 抛弃（删除）数据库和表 INDEX 创建或抛弃索引 Insert 向表中插入新行 REFERENCE 未用 Select 检索表中的记录 Update 修改现存表记录 FILE 读或写服务器上的文件 PROCESS 查看服务器中执行的线程信息或杀死线程 RELOAD 重载授权表或清空日志、主机缓存或表缓存。 SHUTDOWN 关闭服务器 ALL 所有；ALL PRIVILEGES同义词 USAGE 特殊的“无权限”权限 例如： 1grant ALL on *.* to &apos;hive&apos;@&apos;localhost&apos;; 注意： 用以上命令授权的用户不能给其它用户授权，如果想让该用户可以授权，用以下命令: 12&gt; GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos; WITH GRANT OPTION;&gt; 设置与更改用户密码：命令： 1SET PASSWORD FOR &apos;username&apos;@&apos;host&apos; = PASSWORD(&apos;newpassword&apos;); 如果是当前登陆用户用: 1SET PASSWORD = PASSWORD(&quot;newpassword&quot;); 例子: 1set password for &apos;hive&apos;@&apos;localhost&apos;=password(&apos;hive&apos;); 撤销用户权限：命令： 1revoke privilege on databasename.tablename FROM &apos;username&apos;@&apos;host&apos;; 例如； 1revoke all on *.* from &apos;hive&apos;@&apos;localhost&apos;; 删除用户：1drop user &apos;hive&apos;@&apos;localhost&apos;; 注意：在创建对用户管理后，必须执行flush privileges 命令， 这个命令执行后会重新载入授权表。如果你不使用该命令，你就无法使用新创建的用户来连接mysql服务器，除非你重启mysql服务器。 管理MySQL的命令：切换数据库视图： use database_name选择要操作的Mysql数据库，使用该命令后所有Mysql命令都只针对该数据库。 12mysql&gt; use mysql;Database changed 列出所有的数据库： show databases; 列出 MySQL 数据库管理系统的数据库列表。 12345678910mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec) 列出所有的表： show tables; 显示指定数据库的所有表，使用该命令前需要使用 use 命令来选择要操作的数据库。 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || engine_cost || event || func || general_log || gtid_executed || help_category || help_keyword || help_relation || help_topic || innodb_index_stats || innodb_table_stats || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || server_cost || servers || slave_master_info || slave_relay_log_info || slave_worker_info || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+31 rows in set (0.00 sec) 显示数据表信息： show columns from tablename 显示数据表的属性，属性类型，主键信息 ，是否为 NULL，默认值等其他信息。 12345678mysql&gt; show columns from db;+-----------------------+---------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-----------------------+---------------+------+-----+---------+-------+| Host | char(60) | NO | PRI | | || Db | char(64) | NO | PRI | | || User | char(32) | NO | PRI | | |...... 显示数据表的索引信息： show index from tablename 显示数据表的详细索引信息，包括PRIMARY KEY（主键）。 显示数数库管理系统的性能及统计信息： show table status from dababases; 该命令将输出Mysql数据库管理系统的性能及统计信息。 1234mysql&gt; SHOW TABLE STATUS FROM RUNOOB; # 显示数据库 RUNOOB 中所有表的信息mysql&gt; SHOW TABLE STATUS from RUNOOB LIKE &apos;runoob%&apos;; # 表名以runoob开头的表的信息mysql&gt; SHOW TABLE STATUS from RUNOOB LIKE &apos;runoob%&apos;\G; # 加上 \G，查询结果按列打印 数据库常用基本操作创建数据库：使用create命令创建数据库： 12mysql&gt; create database test_db;Query OK, 1 row affected (0.01 sec) 用 mysqladmin 创建数据库 root用户拥有最高权限，可以使用 mysql mysqladmin 命令来创建数据库。 12C:\Users\曹世宏&gt;mysqladmin -u root -p create testdbEnter password: ****** 删除数据库：使用drop命令删除数据库： 12mysql&gt; drop database test_db;Query OK, 0 rows affected (0.00 sec) 使用mysqladmin删除数据库： 1234567C:\Users\曹世宏&gt;mysqladmin -u root -p drop testdbEnter password: ******Dropping the database is potentially a very bad thing to do.Any data stored in the database will be destroyed.Do you really want to drop the &apos;testdb;&apos; database [y/N] yDatabase &quot;testdb&quot; dropped 选择数据库：123456mysql&gt; create database test_db;Query OK, 1 row affected (0.00 sec)mysql&gt; use test_db;Database changedmysql&gt; 执行以上命令后，就已经成功选择了 test_db 数据库，在后续的操作中都会在 该数据库中执行。 注意:所有的数据库名，表名，表字段都是区分大小写的。 数据类型：MySQL中定义数据字段的类型对数据库的优化是非常重要的。 MySQL支持多种类型，大致可以分为三类：数值、日期/时间和字符串(字符)类型。 数值类型： MySQL支持所有标准SQL数值数据类型。 这些类型包括严格数值数据类型(INTEGER、SMALLINT、DECIMAL和NUMERIC)，以及近似数值数据类型(FLOAT、REAL和DOUBLE PRECISION)。 关键字INT是INTEGER的同义词，关键字DEC是DECIMAL的同义词。 BIT数据类型保存位字段值，并且支持MyISAM、MEMORY、InnoDB和BDB表。 作为SQL标准的扩展，MySQL也支持整数类型TINYINT、MEDIUMINT和BIGINT。下面的表显示了需要的每个整数类型的存储和范围。 类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT（tinyint） 1 字节 (-128，127) (0，255) 小整数值 SMALLINT(smallint) 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT(mediumint) 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 FLOAT 4 字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度浮点数值 DOUBLE 8 字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度浮点数值 DECIMAL(decimal) 对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 日期和时间类型： 表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。 每个时间类型有一个有效值范围和一个”零”值，当指定不合法的MySQL不能表示的值时使用”零”值。 型 大小(字节) 范围 格式 用途 DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:00/2038结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 字符串类型：字符串类型指CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM和SET。 类型 大小 用途 CHAR 0-255字节 定长字符串 VARCHAR 0-65535 字节 变长字符串 TINYBLOB 0-255字节 不超过 255 个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65 535字节 二进制形式的长文本数据 TEXT 0-65 535字节 长文本数据 MEDIUMBLOB 0-16 777 215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16 777 215字节 中等长度文本数据 LONGBLOB 0-4 294 967 295字节 二进制形式的极大文本数据 LONGTEXT 0-4 294 967 295字节 极大文本数据 CHAR 和 VARCHAR 类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。 BINARY 和 VARBINARY 类似于 CHAR 和 VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值值。 BLOB 是一个二进制大对象，可以容纳可变数量的数据。有 4 种 BLOB 类型：TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB。它们区别在于可容纳存储范围不同。 有 4 种 TEXT 类型：TINYTEXT、TEXT、MEDIUMTEXT 和 LONGTEXT。对应的这 4 种 BLOB 类型，可存储的最大长度不同，可根据实际情况选择。 创建数据表：创建MySQL数据表需要以下信息： 表名 表字段名 定义每个表字段 语法：以下为创建MySQL数据表的SQL通用语法： 1CREATE TABLE table_name (column_name column_type); 例如：创建一个student表，id为主键，有name，sex，age。 1234567create table if not exists `student` ( `id` int unsigned auto_increment, `name` varchar(20) not null, `sex` varchar(5) not null, `age` int not null, primary key (`id`) )engine=InnoDB default charset=utf8; 如果你不想字段为 NULL 可以设置字段的属性为 NOT NULL， 在操作数据库时如果输入该字段的数据为NULL ，就会报错。 AUTO_INCREMENT定义列为自增的属性，一般用于主键，数值会自动加1。 PRIMARY KEY关键字用于定义列为主键。 您可以使用多列来定义主键，列间以逗号分隔。 ENGINE 设置存储引擎，CHARSET 设置编码。 删除数据表：1234567891011mysql&gt; show tables;+-------------------+| Tables_in_test_db |+-------------------+| student || teacher |+-------------------+2 rows in set (0.00 sec)mysql&gt; drop TABLE `teacher`;Query OK, 0 rows affected (0.02 sec) 插入数据：MySQL 表中使用 INSERT INTO SQL语句来插入数据。 语法:以下为向MySQL数据表插入数据通用的INSERT INTO SQL语法： 123INSERT INTO table_name ( field1, field2,...fieldN ) VALUES ( value1, value2,...valueN ); 如果数据是字符型，必须使用单引号或者双引号，如：”value”。 例如： 12345mysql&gt; INSERT INTO student -&gt; (name, sex, age) -&gt; VALUES -&gt; (&quot;张三&quot;, &quot;男&quot;, 19);Query OK, 1 row affected (0.01 sec) 读取数据表： 123456789mysql&gt; select * from student;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 1 | 张三 | 男 | 19 || 2 | 李四 | 男 | 20 || 3 | 王五 | 女 | 22 |+----+------+-----+-----+5 rows in set (0.00 sec) 查询数据：MySQL 数据库使用SQL SELECT语句来查询数据。 语法：以下为在MySQL数据库中查询数据通用的 SELECT 语法： 1234SELECT column_name,column_nameFROM table_name[WHERE Clause][LIMIT N][ OFFSET M] 查询语句中可以使用一个或者多个表，表之间使用逗号(,)分割，并使用WHERE语句来设定查询条件。 SELECT 命令可以读取一条或者多条记录。 你可以使用星号（*）来代替其他字段，SELECT语句会返回表的所有字段数据 你可以使用 WHERE 语句来包含任何条件。 你可以使用 LIMIT 属性来设定返回的记录数。 你可以通过OFFSET指定SELECT语句开始查询的数据偏移量。默认情况下偏移量为0。 查询示例： 12345678910111213141516171819mysql&gt; select * from student;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 1 | 张三 | 男 | 19 || 2 | 李四 | 男 | 20 || 3 | 王五 | 女 | 22 |+----+------+-----+-----+3 rows in set (0.00 sec)mysql&gt; select name from student ;+------+| name |+------+| 张三 || 李四 || 王五 |+------+3 rows in set (0.00 sec) MySQL WHERE 子句：如需有条件地从表中选取数据，可将 WHERE 子句添加到 SELECT 语句中。 语法：以下是 SQL SELECT 语句使用 WHERE 子句从数据表中读取数据的通用语法： 12SELECT field1, field2,...fieldN FROM table_name1, table_name2...[WHERE condition1 [AND [OR]] condition2..... 查询语句中可以使用一个或者多个表，表之间使用逗号, 分割，并使用WHERE语句来设定查询条件。 可以在 WHERE 子句中指定任何条件。 可以使用 AND 或者 OR 指定一个或多个条件。 WHERE 子句也可以运用于 SQL 的 DELETE 或者 UPDATE 命令。 WHERE 子句类似于程序语言中的 if 条件，根据 MySQL 表中的字段值来读取指定的数据。 以下为操作符列表，可用于 WHERE 子句中。 下表中实例假定 A 为 10, B 为 20 操作符 描述 实例 = 等号，检测两个值是否相等，如果相等返回true (A = B) 返回false。 &lt;&gt;, != 不等于，检测两个值是否相等，如果不相等返回true (A != B) 返回 true。 &gt; 大于号，检测左边的值是否大于右边的值, 如果左边的值大于右边的值返回true (A &gt; B) 返回false。 &lt; 小于号，检测左边的值是否小于右边的值, 如果左边的值小于右边的值返回true (A &lt; B) 返回 true。 &gt;= 大于等于号，检测左边的值是否大于或等于右边的值, 如果左边的值大于或等于右边的值返回true (A &gt;= B) 返回false。 &lt;= 小于等于号，检测左边的值是否小于于或等于右边的值, 如果左边的值小于或等于右边的值返回true (A &lt;= B) 返回 true。 如果我们想再 MySQL 数据表中读取指定的数据，WHERE 子句是非常有用的。 使用主键来作为 WHERE 子句的条件查询是非常快速的。 如果给定的条件在表中没有任何匹配的记录，那么查询不会返回任何数据。 使用示例: 1234567891011121314151617181920212223mysql&gt; select * from student where id=2;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 2 | 李四 | 男 | 20 |+----+------+-----+-----+1 row in set (0.00 sec)mysql&gt; select * from student where name=&quot;张三&quot;;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 1 | 张三 | 男 | 19 |+----+------+-----+-----+1 row in set (0.00 sec)mysql&gt; select * from student where age&gt;=20;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 2 | 李四 | 男 | 20 || 3 | 王五 | 女 | 22 |+----+------+-----+-----+2 rows in set (0.00 sec) MySQL UPDATE查询：如果我们需要修改或更新 MySQL 中的数据，我们可以使用 SQL UPDATE 命令来操作。 语法：以下是 UPDATE 命令修改 MySQL 数据表数据的通用 SQL 语法： 12UPDATE table_name SET field1=new-value1, field2=new-value2[WHERE Clause] 可以同时更新一个或多个字段。 可以在 WHERE 子句中指定任何条件。 可以在一个单独表中同时更新数据。 当你需要更新数据表中指定行的数据时 WHERE 子句是非常有用的。 使用示例： 12345678910111213mysql&gt; update student set age=25 where name=&quot;李四&quot;;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from student;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 1 | 张三 | 男 | 19 || 2 | 李四 | 男 | 25 || 3 | 王五 | 女 | 22 |+----+------+-----+-----+3 rows in set (0.00 sec) MySQL DELETE 语句：可以使用 SQL 的 DELETE FROM 命令来删除 MySQL 数据表中的记录。 语法：以下是 SQL DELETE 语句从 MySQL 数据表中删除数据的通用语法： 1DELETE FROM table_name [WHERE Clause] 如果没有指定 WHERE 子句，MySQL 表中的所有记录将被删除。 可以在 WHERE 子句中指定任何条件 可以在单个表中一次性删除记录。 当想删除数据表中指定的记录时 WHERE 子句是非常有用的。 使用示例： 1234567891011mysql&gt; delete from student where id=3;Query OK, 1 row affected (0.01 sec)mysql&gt; select * from student;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 1 | 张三 | 男 | 19 || 2 | 李四 | 男 | 25 |+----+------+-----+-----+2 rows in set (0.00 sec) MySQL LIKE 子句：当要获取包含某字符串的记录是，可以使用like子句。 SQL LIKE 子句中使用百分号 %字符来表示任意字符，类似于UNIX或正则表达式中的星号 *。 如果没有使用百分号 %, LIKE 子句与等号 = 的效果是一样的。 语法：以下是 SQL SELECT 语句使用 LIKE 子句从数据表中读取数据的通用语法： 123SELECT field1, field2,...fieldN FROM table_nameWHERE field1 LIKE condition1 [AND [OR]] filed2 = &apos;somevalue&apos; 可以在 WHERE 子句中指定任何条件。 可以在 WHERE 子句中使用LIKE子句。 可以使用LIKE子句代替等号 =。 LIKE 通常与 % 一同使用，类似于一个元字符的搜索。 可以使用 AND 或者 OR 指定一个或多个条件。 可以在 DELETE 或 UPDATE 命令中使用 WHERE…LIKE 子句来指定条件。 使用示例： 1234567891011121314mysql&gt; select * from student where name like &apos;%三&apos; ;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 1 | 张三 | 男 | 19 |+----+------+-----+-----+1 row in set (0.00 sec)mysql&gt; select * from student where age like &quot;%5&quot;;+----+------+-----+-----+| id | name | sex | age |+----+------+-----+-----+| 2 | 李四 | 男 | 25 |+----+------+-----+-----+1 row in set (0.00 sec) MySQL ALTER 命令：当我们需要修改数据表名或者修改数据表字段时，就需要使用到MySQL ALTER命令。 删除，添加或修改表字段：使用ALTER命令及DROP子句来删除表中的列字段；操作如下： 如果数据表中只剩余一个字段则无法使用DROP来删除字段。 12345678910111213141516171819202122232425mysql&gt; show columns from student;+-------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || sex | varchar(5) | NO | | NULL | || age | int(11) | NO | | NULL | |+-------+------------------+------+-----+---------+----------------+4 rows in set (0.00 sec)mysql&gt; alter TABLE student Drop sex;#删除表的sex列。Query OK, 0 rows affected (0.12 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show columns from student;+-------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || age | int(11) | NO | | NULL | |+-------+------------------+------+-----+---------+----------------+3 rows in set (0.00 sec) MySQL 中使用 ADD 子句来向数据表中添加列，如下实例在表 student中添加 class字段，并定义数据类型: 添加的列会自动添加到数据表字段得末尾。如果你需要指定新增字段的位置，可以使用MySQL提供的关键字 FIRST (设定位第一列)， AFTER 字段名（设定位于某个字段之后）。 FIRST 和 AFTER 关键字只占用于 ADD 子句，所以如果想重置数据表字段的位置就需要先使用 DROP 删除字段然后使用 ADD 来添加字段并设置位置。 123456789101112131415mysql&gt; alter table student add class varchar(30);#添加class列。Query OK, 0 rows affected (0.11 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show columns from student;+-------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || age | int(11) | NO | | NULL | || class | varchar(30) | YES | | NULL | |+-------+------------------+------+-----+---------+----------------+4 rows in set (0.00 sec) 123456789101112131415mysql&gt; alter table student ADD number int after id;Query OK, 0 rows affected (0.12 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show columns from student;+--------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+--------+------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || number | int(11) | YES | | NULL | || name | varchar(20) | NO | | NULL | || age | int(11) | NO | | NULL | || class | varchar(30) | YES | | NULL | |+--------+------------------+------+-----+---------+----------------+5 rows in set (0.00 sec) 修改字段类型及名称：如果需要修改字段类型及名称, 可以在ALTER命令中使用 MODIFY 或 CHANGE 子句 。 123456789101112131415161718192021mysql&gt; alter table student modify class char(20);#修改class的字段类型为char（20）Query OK, 2 rows affected (0.10 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; alter table student change number num int;#修改number名称为num；Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show columns from student;+-------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || num | int(11) | YES | | NULL | || name | varchar(20) | NO | | NULL | || age | int(11) | NO | | NULL | || class | char(20) | YES | | NULL | |+-------+------------------+------+-----+---------+----------------+5 rows in set (0.00 sec) 使用change子句是，在CHARGE关键字之后，紧跟着要修改的字段名，然后指定字段名及类型。 ALTER TABLE对Null值和默认值的影响：当修改字段时，可以指定是否包含值或者是否设置默认值。 12345678910111213141516ysql&gt; alter table student modify num INT NULL DEFAULT 100;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show columns from student;+-------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || num | int(11) | YES | | 100 | || name | varchar(20) | NO | | NULL | || age | int(11) | NO | | NULL | || class | varchar(20) | YES | | NULL | |+-------+------------------+------+-----+---------+----------------+5 rows in set (0.00 sec)mysql&gt; ALTER TABLE testalter_tbl -&gt; MODIFY j BIGINT NOT NULL DEFAULT 100; 如果不设置默认值，MySQL会自动设置该字段默认为 NULL。 修改字段默认值：可以使用 ALTER 来修改字段的默认值，尝试以下实例： 123456789101112131415mysql&gt; alter table student alter num set default 200;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show columns from student;+-------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || num | int(11) | YES | | 200 | || name | varchar(20) | NO | | NULL | || age | int(11) | NO | | NULL | || class | varchar(20) | YES | | NULL | |+-------+------------------+------+-----+---------+----------------+5 rows in set (0.00 sec) 也可以使用 ALTER 命令及 DROP子句来删除字段的默认值，如下实例： 123mysql&gt; alter table student alter num drop default;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0 修改数据表类型，可以使用 ALTER 命令及 TYPE 子句来完成。尝试以下实例，我们将表 student 的类型修改为 MYISAM ： 注意：查看数据表类型可以使用 SHOW TABLE STATUS 语句。 123456789101112131415161718192021222324252627mysql&gt; alter table student engine=myisam;Query OK, 2 rows affected (0.05 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; show table status like &apos;student&apos;\G;*************************** 1. row *************************** Name: student Engine: MyISAM Version: 10 Row_format: Dynamic Rows: 2 Avg_row_length: 24 Data_length: 48Max_data_length: 281474976710655 Index_length: 2048 Data_free: 0 Auto_increment: 6 Create_time: 2018-07-08 23:04:34 Update_time: 2018-07-08 23:04:34 Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment:1 row in set (0.00 sec)ERROR:No query specified 修改表名：如果需要修改数据表的名称，可以在 ALTER TABLE 语句中使用 RENAME 子句来实现。 12345678910mysql&gt; alter table student rename to students;Query OK, 0 rows affected (0.01 sec)mysql&gt; show tables;+-------------------+| Tables_in_test_db |+-------------------+| students |+-------------------+1 row in set (0.00 sec) ALTER 命令还可以用来创建及删除MySQL数据表的索等。 学习MySQL参考资料来源自：http://www.runoob.com/mysql/mysql-tutorial.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的数据备份工具rsync]]></title>
    <url>%2F2018%2F07%2F06%2FLinux%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7rsync%2F</url>
    <content type="text"><![CDATA[rsync简介：rsync命令（ Remote Sync）是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。rsync使用所谓的“rsync算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 它的特性如下： 可以镜像保存整个目录树和文件系统。 可以很容易做到保持原来文件的权限、时间、软硬链接等等。 无须特殊权限即可安装。 快速：第一次同步时 rsync 会复制全部内容，但在下一次只传输修改过的文件。rsync 在传输数据的过程中可以实行压缩及解压缩操作，因此可以使用更少的带宽。 安全：可以使用scp、ssh等方式来传输文件，当然也可以通过直接的socket连接。 支持匿名传输，以方便进行网站镜象。 rsync语法：语法123456rsync [OPTION]... SRC DESTrsync [OPTION]... SRC [USER@]host:DESTrsync [OPTION]... [USER@]HOST:SRC DESTrsync [OPTION]... [USER@]HOST::SRC DESTrsync [OPTION]... SRC [USER@]HOST::DESTrsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] 对应于以上六种命令格式，rsync有六种不同的工作模式： 拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号”:”分隔符时就启动这种工作模式。如：rsync -a /data /backup 使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号”:”分隔符时启动该模式。如：rsync -avz *.c foo:src 使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号”:”分隔符时启动该模式。如：rsync -avz foo:src/bar /data 从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含”::”分隔符时启动该模式。如：rsync -av root@192.168.78.192::www /databack 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含”::”分隔符时启动该模式。如：rsync -av /databack root@192.168.78.192::www 列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。如：rsync -v rsync://192.168.78.192/www 选项12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061-v, --verbose 详细模式输出。-q, --quiet 精简输出模式。-c, --checksum 打开校验开关，强制对文件传输进行校验。-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。-r, --recursive 对子目录以递归模式处理。-R, --relative 使用相对路径信息。-b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。--backup-dir 将备份文件(如~filename)存放在在目录下。-suffix=SUFFIX 定义备份文件前缀。-u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。-l, --links 保留软链接。-L, --copy-links 想对待常规文件一样处理软链结。--copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结。--safe-links 忽略指向SRC路径目录树以外的链结。-H, --hard-links 保留硬链结。-p, --perms 保持文件权限。-o, --owner 保持文件属主信息。-g, --group 保持文件属组信息。-D, --devices 保持设备文件信息。-t, --times 保持文件时间信息。-S, --sparse 对稀疏文件进行特殊处理以节省DST的空间。-n, --dry-run现实哪些文件将被传输。-w, --whole-file 拷贝文件，不进行增量检测。-x, --one-file-system 不要跨越文件系统边界。-B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节。-e, --rsh=command 指定使用rsh、ssh方式进行数据同步。--rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。--existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。--delete 删除那些DST中SRC没有的文件。--delete-excluded 同样删除接收端那些被该选项指定排除的文件。--delete-after 传输结束以后再删除。--ignore-errors 及时出现IO错误也进行删除。--max-delete=NUM 最多删除NUM个文件。--partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。--force 强制删除目录，即使不为空。--numeric-ids 不将数字的用户和组id匹配为用户名和组名。--timeout=time ip超时时间，单位为秒。-I, --ignore-times 不跳过那些有同样的时间和长度的文件。--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。-T --temp-dir=DIR 在DIR中创建临时文件。--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。-P 等同于 --partial。--progress 显示备份过程。-z, --compress 对备份的文件在传输时进行压缩处理。--exclude=PATTERN 指定排除不需要传输的文件模式。--include=PATTERN 指定不排除而需要传输的文件模式。--exclude-from=FILE 排除FILE中指定模式的文件。--include-from=FILE 不排除FILE指定模式匹配的文件。--version 打印版本信息。--address 绑定到特定的地址。--config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。--port=PORT 指定其他的rsync服务端口。--blocking-io 对远程shell使用阻塞IO。-stats 给出某些文件的传输状态。--progress 在传输时现实传输过程。--log-format=formAT 指定日志文件格式。--password-file=FILE 从FILE中得到密码。--bwlimit=KBPS 限制I/O带宽，KBytes per second。-h, --help 显示帮助信息。 常用的有-a，-V –delete –exclude。 常用选项的实例：（1）首先建立目录以及文件： 123456789101112[root@localhost ~]# mkdir rsync[root@localhost ~]# cd rsync[root@localhost rsync]# mkdir test1[root@localhost rsync]# cd test1[root@localhost test1]# touch 1 2 3[root@localhost test1]# ln -s /root/123.txt ./123.txt[root@localhost test1]# ls -l总用量 0-rw-r--r-- 1 root root 0 7月 6 13:37 1lrwxrwxrwx 1 root root 13 7月 6 13:57 123.txt -&gt; /root/123.txt-rw-r--r-- 1 root root 0 7月 6 13:37 2-rw-r--r-- 1 root root 0 7月 6 13:37 3 （2）使用-a选项： -a, –archive 归档模式，表示以递归方式传输文件，并保持所有文件属性 12345[root@localhost rsync]# rsync -a test1 test2[root@localhost rsync]# ls test2test1[root@localhost rsync]# ls test2/test1/1 123.txt 2 3 这里有一个问题，就是本来想把test1目录直接拷贝成test2目录，可结果rsync却新建了test2目录然后把test1放到test2当中。为了避免这样的情况发生，可以这样做: 12345678[root@localhost rsync]# rm -rf test2[root@localhost rsync]# rsync -a test1/ test2/[root@localhost rsync]# ls -l test2/总用量 0-rw-r--r-- 1 root root 0 7月 6 13:37 1lrwxrwxrwx 1 root root 13 7月 6 13:57 123.txt -&gt; /root/123.txt-rw-r--r-- 1 root root 0 7月 6 13:37 2-rw-r--r-- 1 root root 0 7月 6 13:37 3 加一个斜杠就好了，所以建议在使用rsync备份目录时要养成加斜杠的习惯。在上面讲了-a选项等同于-rlptgoD，而且 -a 还可以和 --no-OPTIN一并使用。下面看看-l选项的作用: -l, –links 保留软链接。 -v, –verbose 详细模式输出。 1234567891011[root@localhost rsync]# rsync -av --no-l test1/ test2/sending incremental file listcreated directory test2./1skipping non-regular file "123.txt"23sent 200 bytes received 72 bytes 544.00 bytes/sectotal size is 13 speedup is 0.05 使用-v选项看来就是方便呀，上例告诉我们跳过了非普通文件123.txt，其实123.txt是一个软连接文件，如果不使用-l选项则不理会软连接文件的。虽然加上-l选项会把软连接文件给拷贝过去，但是软连接的目标文件却没有拷贝过去，有时候咱们指向拷贝软连接文件所指向的目标文件，那这时候该怎么办呢？ （3）使用-L选项： -L, –copy-links 想对待常规文件一样处理软链结。 1234567891011121314151617[root@localhost rsync]# rsync -avL test1/ test2/sending incremental file listcreated directory test2./1123.txt23sent 231 bytes received 91 bytes 644.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls -l test2/总用量 0-rw-r--r-- 1 root root 0 7月 6 13:37 1lrwxrwxrwx 1 root root 13 7月 6 13:57 123.txt-rw-r--r-- 1 root root 0 7月 6 13:37 2-rw-r--r-- 1 root root 0 7月 6 13:37 3 加上 -L 选项就可以把SRC中软连接的目标文件给拷贝到DST. （4）使用-u选项： -u, –update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。 首先查看一下test1/1 和test2/1的创建时间（肯定是一样的），然后使用touch修改一下test2/1的创建时间（此时test2/1要比test1/1的创建时间晚了一些），如果不加-u选项的话，会把test2/1的创建时间变成和test1/1的创建时间一样。 123[root@localhost rsync]# ll test1/1 test2/1-rw-r--r-- 1 root root 0 6月 10 12:58 test1/1-rw-r--r-- 1 root root 0 6月 10 12:58 test2/1 两者之间的创建时间是一样的，下面修改test2/1 的创建时间，然后不加-u同步: 123456[root@localhost rsync]# touch test2/1[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:20 test2/1[root@localhost rsync]# rsync -a test1/1 test2/[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 12:58 test2/1 test2/1 的创建时间又变成和test1/1的创建时间一样了。下面加上 -u 再看看结果是怎么样的: 1234567891011121314[root@localhost rsync]# touch test2/1[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:31 test2/1[root@localhost rsync]# rsync -avu test1/ test2/sending incremental file list./123.txt -&gt; /root/123.txtsent 100 bytes received 18 bytes 236.00 bytes/sectotal size is 13 speedup is 0.11[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:31 test2/1[root@localhost rsync]# ll test1/1-rw-r--r-- 1 root root 0 6月 10 12:58 test1/1 加上-u 选项后，不会再把 test1/1 同步为 test2/1 了。 （5）使用–delete选项： –delete 删除那些DST中SRC没有的文件。 首先删除test1/123.txt: 123[root@localhost rsync]# rm -f test1/123.txt[root@localhost rsync]# ls test1/1 2 3 然后把test1/ 目录 同步到 test2/ 目录下: 123456789[root@localhost rsync]# rsync -av test1/ test2/sending incremental file list./1sent 94 bytes received 34 bytes 256.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 123.txt 2 3 test2/目录并没有删除掉123.txt, 下面加上 --delete 选项: 12345678[root@localhost rsync]# rsync -av --delete test1/ test2/sending incremental file listdeleting 123.txtsent 52 bytes received 12 bytes 128.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 2 3 test2/ 目录里的123.txt也被删除了，这就是 --delete 选项的用处。还有一种情况就是如果在DST增加文件了，而SRC当中没有这些文件，同步时加上 --delete 选项后同样会删除新增的文件: 12345678910[root@localhost rsync]# touch test2/4[root@localhost rsync]# ls test1/1 2 3[root@localhost rsync]# ls test2/1 2 3 4[root@localhost rsync]# rsync -a --delete test1/ test2/[root@localhost rsync]# ls test1/1 2 3[root@localhost rsync]# ls test2/1 2 3 （6）使用–exclude选项： –exclude=PATTERN 指定排除不需要传输的文件模式。 –progress 在传输时现实传输过程。 123456[root@localhost rsync]# touch test1/4[root@localhost rsync]# rsync -a --exclude="4" test1/ test2/[root@localhost rsync]# ls test1/1 2 3 4[root@localhost rsync]# ls test2/1 2 3 另外还可以使用匹配字符 * 12345678910111213[root@localhost rsync]# touch test1/1.txt test1/2.txt[root@localhost rsync]# ls test1/1 1.txt 2 2.txt 3 4[root@localhost rsync]# rsync -a --progress --exclude="*.txt" test1/ test2/sending incremental file list./4 0 100% 0.00kB/s 0:00:00 (xfer#1, to-check=0/5)sent 104 bytes received 34 bytes 276.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 2 3 4 上例中，也连带着使用了 --progress 选项，这个主要是用来观察rsync同步过程的状态的。最后简单总结一下，平时使用rsync同步数据的时候，使用-a选项基本上就可以达到我们想要的效果了，只是有时候会有个别的需求，会用到 -a --no-OPTION, -u, -L, --delete, --exclude 以及 progress 这些选项。 rsync应用实例：（1）通过ssh的方式：1234567891011[root@localhost rsync]# rsync -avL test1/ 192.168.171.128:/tmp/test2/sending incremental file listcreated directory /tmp/test2./1123.txt23sent 278 bytes received 128 bytes 812.00 bytes/sectotal size is 10 speedup is 0.02 这种方式就是前面介绍的第二种方式了，是通过ssh拷贝的数据，需要输入192.168.171.128 那台机器root账户的密码。当然也可以使用第三种方式拷贝: 1234567891011[root@localhost rsync]# rsync -avL www@192.168.171.128:/tmp/test2/ /tmp/test3/receiving incremental file listcreated directory /tmp/test3./1123.txt23sent 103 bytes received 282 bytes 770.00 bytes/sectotal size is 10 speedup is 0.03 以上两种方式如果写到脚本里，备份起来就有麻烦了，因为要输入密码，脚本本来就是自动的，不可能做到的。但是不代表没有解决办法。那就是通过密钥验证，密钥不设立密码就ok了。 上面操作都没有输入密码，因为我已经做好了免认证。免认证登录操作如下： 在操作之前我们先讲明主机信息： 192.168.171.129 （主机名[root@localhost ~]）和 192.168.171.128 （主机名root@ubuntu:）。我在两台主机之间做了ssh登录免认证。将对方的公钥文件都保存在自己的主机上。 首先确认一下两台主机上是否有这个文件 /root/.ssh/id_rsa.pub: 12[root@localhost ~]# ssh-keygenGenerating public/private rsa key pair. 因为之前生成过密钥对，所以这个文件已经存在了，如果您的Linux不存在这个文件，请按照如下方法生成: 123456789[root@localhost ~]# ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:3b:74:af:e8:08:ac:99:30:3f:ef:84:7a:a0:a6:3d:89 root@localhost 在这个过程中会有一些交互的过程，它首先提示要输入这个密钥的密码，出于安全考虑应该定义个密码，但是我们的目的就是为了自动化同步数据，所以这里不输入任何密码，直接按回车，即密码为空。最后则生成了私钥(/root/.ssh/id_rsa)和公钥文件(/root/.ssh/id_rsa.pub) 把公钥文件的内容拷贝到目标机器上: 12[root@localhost ~]# cat .ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDDxysdnnem+g5qA/3St3cubGjyT8D+u0SkpNT8z9F9mgSf8THCaZBh3I8urgJ4XfmIajj+Cz0LFd3UrB0HUt7BO1xUP36W4PbOeGei25W2qhRJIEn/RdwtUHkApWd6I43JdlPJNmy+9JgvXb6eOxUn8UgsBn13D0mOtBuE5uWQOcKDYi4DvqD5xVGhBNVvOvSS1Puvu9xygbf5H2l4fwih57hr7YTki/5DcMvdH0YkGbmOjLBHkqQZg6ZjzGuCGtIEh4yGghKoV1oPaYoCcXNKmQo48FjomUyyTrRxkRH4pAq6ckml22lxCe0av7Qu9yK2phUW+3Bo0AT8fSoJQ5EJ root@localhost 复制主机localhost的/root/.ssh/id_rsa.pub文件内容，并粘贴到主机Ubuntu的 ~/.ssh/authorized_keys中: 1[root@ubuntu ~]# vim .ssh/authorized_keys 在这一步也许您会遇到.ssh目录不存在的问题，可以手动创建，并修改目录权限为700也可以执行ssh-keygen命令生成这个目录。保存.ssh/authorized_keys文件后，就可以在localhost主机上不用输入密码就能ssh登录Ubuntu主机。然后可以用相同的方法把Ubuntu的公钥复制到localhost主机上。 然后可进行如下rsync操作： 1234567891011[root@localhost ~]# rsync -av rsync/test1/ 192.168.171.128:/tmp/test4/sending incremental file listcreated directory /tmp/test2./1123.txt23sent 278 bytes received 128 bytes 812.00 bytes/sectotal size is 10 speedup is 0.02 （2） 通过后台服务的方式这种方式可以理解成这样，在远程主机上建立一个rsync的服务器，在服务器上配置好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器。配置rsync服务器的步骤： 在实验中我将192.168.171.128，主机名Ubuntu作为rsync服务器。192.168.171.129作为客户端。 建立并配置rsync的配置文件 /etc/rsyncd.conf 1234567891011121314151617root@ubuntu:/# cat /etc/rsyncd.conf port=873log file=/var/log/rsync.logpid file=/var/run/rsyncd.pidaddress=192.168.171.128[root]path=/root/rsyncuse chroot=truemax connections=4read only=nolist=trueuid=rootgid=rootauth users=rootsecrets file=/etc/rsyncd.passwdhosts allow=192.168.171.129 其中配置文件分为两部分：全部配置部分和模块配置部分，全局部分就是几个参数而已，就像rsyncd.conf中port, log file, pid file, address这些都属于全局配置，而[root]以下部分就是模块配置部分了。一个配置文件中可以有多个模块，模块名自定义。其实模块中的一些参数例如use chroot, max connections, udi, gid, auth users, secrets file以及hosts allow都可以配置成全局的参数。下面就简单解释一下这些参数的意义： port 指定在哪个端口启动rsyncd服务，默认是873 log file 指定日志文件 pid file 指定pid文件，这个文件的作用涉及到服务的启动以及停止等进程管理操作 address 指定启动rsyncd服务的IP，假如你的机器有多个IP，就可以指定其中一个启动rsyncd服务，默认是在全部IP上启动 [test] 指定模块名，自定义 path 指定数据存放的路径 use chroot true|false 默认是true，意思是在传输文件以前首先chroot到path参数所指定的目录下。这样做的原因是实现额外的安全防护，但是缺点是需要以roots权限，并且不能备份指向外部的符号连接所指向的目录文件。默认情况下chroot值为true，如果你的数据当中有软连接文件的话建议设置成false。 max connections 指定最大的连接数，默认是0即没有限制 read only ture|false 如果为true则不能上传到该模块指定的路径下 list 指定当用户查询该服务器上的可用模块时，该模块是否被列出，设定为true则列出，false则隐藏 uid/gid 指定传输文件时，以哪个用户/组的身份传输 auth users 指定传输时要使用的用户名 secrets file 指定密码文件，该参数连同上面的参数如果不指定则不使用密码验证，注意该密码文件的权限一定要是600 hosts allow 指定被允许连接该模块的主机，可以是IP或者网段，如果是多个，之间用空格隔开 编辑secrets file，保存后要赋予600权限，如果权限不对，不能完成同步 123root@ubuntu:/# cat /etc/rsyncd.passwd root:test123root@ubuntu:/# chmod 600 /etc/rsyncd.passwd 启动rsyncd服务 1root@ubuntu:~# rsync --daemon --config=/etc/rsyncd.conf 启动后，可以查看一下日志，并查看端口是否启动: 1234root@ubuntu:~# cat /var/log/rsync.log 2018/07/06 16:44:15 [4178] rsyncd version 3.1.1 starting, listening on port 873root@ubuntu:~# netstat -lnp | grep 873tcp 0 0 192.168.171.128:873 0.0.0.0:* LISTEN 4178/rsync 如果想开机启动，请把 rsync --daemon --confg=/etc/rsyncd.conf 写入到/etc/rc.d/rc.local文件。 到另一台机器上测试 12345678910[root@localhost ~]# rsync -avL root@192.168.171.128::root/test/ /tmp/Password: receiving incremental file list./123sent 84 bytes received 200 bytes 63.11 bytes/sectotal size is 0 speedup is 0.00 刚刚提到有一个选项叫做 “use chroot” 默认为true，如果是true，同步的文件中如果有软连接，则会有问题，首先在主机Ubuntu的/root/rsync/test/ 目录下创建一个软连接文件: 12345root@ubuntu:~/rsync/test# ln -s /root/test.txt test.txtroot@ubuntu:~/rsync/test# ls1 2 3 test.txtroot@ubuntu:~/rsync/test# ll test.txt lrwxrwxrwx 1 root root 14 7月 6 17:01 test.txt -&gt; /root/test.txt 然后再到主机localhost上，同步: 123456789[root@localhost ~]# rsync -avL root@192.168.171.128::root/test/ /tmp/Password: receiving incremental file listsymlink has no referent: "/test/test.txt" (in root)./sent 27 bytes received 146 bytes 49.43 bytes/sectotal size is 0 speedup is 0.00rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1650) [generator=3.1.2] 可以看到，如果设置 “use chroot” 为true则同步软连接文件会有问题，下面把主机Ubuntu的rsync配置文件修改一下，把true改为false: 1234567891011121314151617root@ubuntu:~# cat /etc/rsyncd.conf port=873log file=/var/log/rsync.logpid file=/var/run/rsyncd.pidaddress=192.168.171.128[root]path=/root/rsyncuse chroot=falsemax connections=4read only=nolist=trueuid=rootgid=rootauth users=rootsecrets file=/etc/rsyncd.passwdhosts allow=192.168.171.0/24 然后再到主机localhost上再次执行同步: 1234567[root@localhost ~]# rsync -avL root@192.168.171.128::root/test/ /tmp/Password: receiving incremental file listtest.txtsent 43 bytes received 1,755 bytes 513.71 bytes/sectotal size is 1,600 speedup is 0.89 因为rsync有一个特定机制，配置文件时即时生效的，所以修改完配置文件后不用重启服务。 上面的例子中，都需要输入密码，这样同样也不能写入脚本中自动执行，其实这种方式也是可以不用手动输入密码的，它有两种实现方式。 第一种，指定密码文件 在客户端上，也就是主机localhost上，编辑一个密码文件:加入root的密码 123[root@localhost ~]# vim /etc/pass[root@localhost ~]# cat /etc/passtest123 修改密码文件的权限: 1[root@localhost ~]# chmod 600 /etc/pass 在同步的时候，指定一下密码文件，就可以省去输入密码的步骤了: 123456[root@localhost ~]# rsync -avL root@192.168.171.128::root/test/ /tmp/ --password-file=/etc/passreceiving incremental file list./sent 27 bytes received 115 bytes 94.67 bytes/sectotal size is 1,600 speedup is 11.27 第二种：在rsync服务器端不指定用户 在服务端也就是主机Ubuntu上修改配置文件rsyncd.conf, 去掉关于认证账户的配置项(auth user 和 secrets file这两行): 12345678910111213141516171819root@ubuntu:~# sed -i 's/auth users/#auth users/;s/secrets file/#secrets file/' /etc/rsyncd.confroot@ubuntu:~# cat /etc/rsyncd.conf port=873log file=/var/log/rsync.logpid file=/var/run/rsyncd.pidaddress=192.168.171.128[root]path=/root/rsyncuse chroot=falsemax connections=4read only=nolist=trueuid=rootgid=root#auth users=root#secrets file=/etc/rsyncd.passwdhosts allow=192.168.171.0/24root@ubuntu:~# 上面的这个命令是把 “auth users” 和 “secrets file” 两行的最前面加一个 “#”, 这样就把这两行注释掉，使其失去意义。然后我们再到客户端主机localhost上测试: 12345[root@localhost ~]# rsync -avL root@192.168.171.128::root/test/ /tmp/receiving incremental file listsent 20 bytes received 108 bytes 256.00 bytes/sectotal size is 1,600 speedup is 12.50 注意，这里不用再加root这个用户了，默认是以root的身份拷贝的，现在已经不需要输入密码了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统日常管理]]></title>
    <url>%2F2018%2F07%2F03%2FLinux%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%B8%B8%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[监控系统的状态：w：查看当前系统负载： Linux w命令用于显示目前登入系统的用户信息。 执行这项指令可得知目前登入系统的用户有哪些人，以及他们正在执行的程序。 单独执行 w 指令会显示所有的用户，也可指定用户名称，仅显示某位用户的相关信息。 语法：w \[ - fhlsuV ][用户名称] 参数说明： -f (from): 开启或关闭显示用户从何处登入系统。 -h (no-header): 不显示各栏位的标题信息列。 -l : 使用详细格式列表，此为预设值。 -s (short): 使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。 -i(ip-addr): 显示IP地址代替主机名。 -u(no-current): 忽略执行程序的名称，以及该程序耗费CPU时间的信息。 -V (version): 显示版本信息。 使用实例： 显示当前用户： 1234[root@cao ~]# w //显示当前用户，不显示登录位置 21:55:19 up 16:33, 1 user, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAThadoop pts/1 192.168.171.1 21:50 7.00s 0.08s 0.26s sshd: hadoop [priv 第一行从左面开始显示的信息依次为：时间，系统运行时间，登录用户数，平均负载。第二行开始以及下面所有的行，告诉我们的信息是，当前登录的都有哪些用户，以及他们是从哪里登录的等等。 我们最应该关注的应该是第一行中的 ‘load average:’ 后面的三个数值。 第一个数值表示1分钟内系统的平均负载值；第二个数值表示5分钟内系统的平均负载值；第三个数值表示15分钟系统的平均负载值。这个值的意义是，单位时间段内CPU活动进程数。当然这个值越大就说明服务器压力越大。一般情况下这个值只要不超过服务器的cpu数量就没有关系，如果服务器cpu数量为8，那么这个值若小于8，就说明当前服务器没有压力，否则就要关注一下了。 查看cpu信息： 可通过cat /proc/cpuinfo 查看cpu的信息。 可以使用这个命令： grep -c &#39;processor&#39; /proc/cpuinfo 而如何看几颗物理cpu 1234567891011121314151617181920[root@cao ~]# cat /proc/cpuinfoprocessor : 0vendor_id : GenuineIntelcpu family : 6model : 78model name : Intel(R) Core(TM) i5-6200U CPU @ 2.30GHzstepping : 3microcode : 0xbacpu MHz : 2400.002cache size : 3072 KBphysical id : 0siblings : 2core id : 0cpu cores : 2apicid : 0initial apicid : 0fpu : yesfpu_exception : yescpuid level : 22wp : yes 不显示登录位置： 1234[root@cao ~]# w -f 21:56:47 up 16:34, 1 user, load average: 0.00, 0.01, 0.05USER TTY LOGIN@ IDLE JCPU PCPU WHAThadoop pts/1 21:50 7.00s 0.08s 0.26s sshd: hadoop [priv] 以精简模式显示： 1234[root@cao ~]# w -s 21:57:27 up 16:35, 1 user, load average: 0.00, 0.01, 0.05USER TTY FROM IDLE WHAThadoop pts/1 192.168.171.1 7.00s sshd: hadoop [priv] vmstat监控系统的状态：vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、IO读写、CPU活动等进行监视。它是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。 语法：vmstat(选项)(参数) 选项： -a（active）：显示活动内页；-f（forks）：显示启动后创建的进程总数；-m（slabs）：显示slab信息；-n（one-header）：头信息仅显示一次；-s（stats）：以表格方式显示事件计数器和内存状态；-d（disk）：报告磁盘状态；-p（partition）：显示指定的硬盘分区状态；-S（unit）：输出信息的单位。 参数 （delay）事件间隔：状态信息刷新的时间间隔； （count）次数：显示报告的 使用实例： 不加任何参数。vmstat命令只输出一条记录，这个数据是自系统上次重启之后到现在的平均数值。 1234[root@cao ~]# vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st1 0 0 795972 2116 612752 0 0 2 1 20 18 0 0 100 0 0 字段说明： Procs（显示进程相关信息） r: 运行队列中进程数量，这个值也可以判断是否需要增加CPU。（长期大于1） b:表示等待资源的进程数，比如等待I/O, 内存等，这列的值如果长时间大于1，则需要关注一下了； Memory（内存相关信息） swpd: 使用虚拟内存大小，如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。 free: 空闲物理内存大小。 buff: 用作缓冲的内存大小，（即将写入磁盘的）。 cache: 用作缓存的内存大小，（从磁盘中读取的）；如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小。 Swap（内存交换情况） si: 每秒从交换区写到内存的大小，由磁盘调入内存。 so: 每秒写入交换区的内存大小，由内存调入磁盘。 注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 IO（现在的Linux版本块的大小为1kb）磁盘使用情况 bi: 每秒读取的块数 bo: 每秒写入的块数 注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。 system（系统 显示采集间隔内发生的中断次数） in: 每秒中断数，包括时钟中断。 cs: 每秒上下文切换数。 注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 CPU（以百分比表示） us: 用户进程执行时间百分比(user time) us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time) sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 wa: IO等待时间百分比 wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 id: 空闲时间百分比 一般关注r b si so bi bo wa。 使用 vmstat 查看系统状态的时候，通常都是使用这样的形式来看的: 1[root@localhost ~]# vmstat 1 5 或者: 1[root@localhost ~]# vmstat 1 前面表示，每隔一秒钟打印一次状态，共打印5次，而后面的表示每隔1秒打印一次状态，一直打印，除非我们按 Ctrl + c 结束。 显示活动与非活动的内存： 图：显示活动与非活动的内存 显示各种事件计数器表和内存统计信息，这显示不重复。 123456789101112131415161718192021222324252627[root@cao ~]# vmstat -s 1865308 K total memory 454440 K used memory 500496 K active memory 285084 K inactive memory 796020 K free memory 2116 K buffer memory 612732 K swap cache 2097148 K total swap 0 K used swap 2097148 K free swap 8641 non-nice user cpu ticks 73 nice user cpu ticks 24467 system cpu ticks 24617409 idle cpu ticks 1999 IO-wait cpu ticks 0 IRQ cpu ticks 814 softirq cpu ticks 0 stolen cpu ticks 528466 pages paged in 159234 pages paged out 0 pages swapped in 0 pages swapped out 5039370 interrupts 4392272 CPU context switches 1530566527 boot time 21873 forks top显示进程所占系统资源：top命令用于实时显示 process 的动态。 语法 1top [-] [d delay] [q] [c] [S] [s] [i] [n] [b] 参数说明： d（delay time） : 改变显示的更新速度，或是在交谈式指令列( interactive command)按 s。 q : 没有任何延迟的显示速度，如果使用者是有 superuser 的权限，则 top 将会以最高的优先序执行。 c（commadn line） : 切换显示模式，共有两种模式，一是只显示执行档的名称，另一种是显示完整的路径与名称S : 累积模式，会将己完成或消失的子行程 ( dead child process ) 的 CPU time 累积起来。 s（Secure mode） : 安全模式，将交谈式指令取消, 避免潜在的危机。 i （Idle tasks）: 不显示任何闲置 (idle) 或无用 (zombie) 的行程。 n : 更新的次数，完成后将会退出 top b （Bold hilite）: 批次档模式，搭配 “n” 参数一起使用，可以用来将 top 的结果输出到档案内 这个命令用于动态监控进程所占系统资源，每隔3秒变一次。这个命令的特点是把占用系统资源（CPU，内存，磁盘IO等）最高的进程放到最前面。top命令打印出了很多信息，包括系统负载（loadaverage）、进程数（Tasks）、cpu使用情况、内存使用情况以及交换分区使用情况。其实上面这些内容可以通过其他命令来查看，所以用top重点查看的还是下面的进程使用系统资源详细状况。这部分东西反映的东西还是比较多的，不过需要您关注的也就是几项：%CPU, %MEM, COMMAND 这些项目所代表的意义，RES 这一项为进程所占内存大小，而 %MEM 为使用内存百分比。在 top 状态下，按 “shift + m”, 可以按照内存使用大小排序。按数字 ‘1’ 可以列出各颗cpu的使用状态。 图：top命令显示结果 以累积模式显示程序信息 1# top -S 设置信息更新次数 123top -n 2//表示更新两次后终止更新显示 设置信息更新时间 123# top -d 3//表示更新周期为3秒 显示指定的进程信息 123# top -p 139//显示进程号为139的进程信息，CPU、内存占用率等 显示更新十次后退出 1top -n 10 将更新显示二次的结果输入到名称为 top.log 的档案里 1top -n 2 -b &lt; top.log 常用的一个命令 top -bn1 它表示非动态打印系统资源使用情况，可以用在shell脚本中. sar 监控系统状态：sar （System Activity Reporter系统活动情况报告）命令很强大，它可以监控系统所有资源状态，比如平均负载、网卡流量、磁盘状态、内存使用等等。它不同于其他系统状态监控工具的地方在于，它可以打印历史信息，可以显示当天从零点开始到当前时刻的系统状态信息。如果您系统没有安装这个命令，请使用 yum install -y sysstat 命令安装。初次使用sar命令会报错，那是因为sar工具还没有生成相应的数据库文件（时时监控就不会了，因为不用去查询那个库文件）。它的数据库文件在 “/var/log/sa/” 目录下，默认保存一个月。 语法：sar [ 选项 ][ &lt;时间间隔&gt; [ &lt;次数&gt; ] ] 常用选项： -o file表示将命令结果以二进制格式存放在文件中，file 是文件名。 -A：所有报告的总和 -u：输出CPU使用情况的统计信息 -v：输出inode、文件和其他内核表的统计信息 -d：输出每一个块设备的活动信息 -r：输出内存和交换空间的统计信息 -b：显示I/O和传送速率的统计信息 -q：查看历史负载 -a：文件读写情况 -c：输出进程统计信息，每秒创建的进程数 -R：输出内存页面的统计信息 -y：终端设备活动情况 -w：输出系统交换活动信息 -n ：报告网络状态。 使用实例： 查看网卡流量：sar -n DEV,这是显示流量历史。可通过sar -n DEV 1 5 查看实时流量。 图：查看网卡流量信息 IFACE这列表示设备名称，rxpck/s 表示每秒进入收取的包的数量，txpck/s 表示每秒发送出去的包的数量，rxbyt/s 表示每秒收取的数据量（单位Byte），txbyt/s表示每秒发送的数据量。后面几列不需要关注。如果有一天所管理的服务器丢包非常严重，那么就应该看一看这个网卡流量是否异常了，如果rxpck/s 那一列的数值大于4000，或者rxbyt/s那列大于5,000,000则很有可能是被攻击了，正常的服务器网卡流量不会高于这么多，除非是自己在拷贝数据。 另外也可以使用命令 sar -n DEV -f /var/log/sa/sa24 查看看某一天的网卡流量历史，使用-f选项，后面跟文件名，如果系统是Redhat或者CentOS那么sar的库文件一定是在/var/log/sa/目录下的。 CPU资源监控： 例如，每3秒采样一次，连续采样3次，观察CPU 的使用情况，并将采样结果以二进制形式存入当前目录下的文件test中，需键入如下命令：sar -u -o test 3 3 图：sar -u查看cpu使用情况 输出项说明： CPU：all 表示统计信息为所有 CPU 的平均值。 %user：显示在用户级别(application)运行使用 CPU 总时间的百分比。 %nice：显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比。 %system：在核心级别(kernel)运行所使用 CPU 总时间的百分比。 %iowait：显示用于等待I/O操作占用 CPU 总时间的百分比。 %steal：管理程序(hypervisor)为另一个虚拟进程提供服务而等待虚拟 CPU 的百分比。 %idle：显示 CPU 空闲时间占用 CPU 总时间的百分比。 若 %iowait 的值过高，表示硬盘存在I/O瓶颈 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量 若 %idle 的值持续低于1，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU 。 如果要查看二进制文件test中的内容，需键入如下sar命令： sar -u -f test 内存和交换空间监控： 例如，每3秒采样一次，连续采样3次，监控内存分页： 图：内存信息 输出项说明： kbmemfree：这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间. kbmemused：这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间. %memused：这个值是kbmemused和内存总量(不包括swap)的一个百分比. kbbuffers和kbcached：这两个值就是free命令中的buffer和cache. kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap). %commit：这个值是kbcommit与内存总量(包括swap)的一个百分比. free查看内存使用状况：free指令会显示内存的使用情况，包括实体内存，虚拟的交换文件内存，共享内存区段，以及系统核心使用的缓冲区等。 语法：free [-bkmotV][-s &lt;间隔秒数&gt;] 参数说明： -b (bytes): 以Byte为单位显示内存使用情况。 -k (Kilo): 以KB为单位显示内存使用情况。 -m (mega): 以MB为单位显示内存使用情况。 -s&lt;间隔秒数&gt; 持续观察内存使用状况。 -h（human）：以可阅读的方式显示。 -t (total): 显示内存总和列。 -V(version): 显示版本信息。 使用示例： 显示内存使用情况： 图；内存使用情况 以总和的形式显示内存使用信息： 图：以总和的形式显示内存信息 ps查看系统进程： ps命令用于显示当前进程 (process) 的状态。 语法：ps [options] 常用的参数解释： -A（all）: 列出所有的行程 -w 显示加宽可以显示较多的资讯 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 au(x) 输出格式 : USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND USER: 行程拥有者 PID: pid %CPU: 占用的 CPU 使用率 %MEM: 占用的记忆体使用率 VSZ: 占用的虚拟记忆体大小 RSS: 占用的记忆体大小 TTY: 终端的次要装置号码 (minor device number of tty) STAT: 该行程的状态: D: 不可中断的进程 （通常为IO） R: 正在执行中 S: 已经中断的进程，通常情况下，系统中大部分进程都是这个状态 s ：主进程 l： 多线程进程 T: 已经停止或者暂停的进程，如果我们正在运行一个命令，比如说 sleep 10 如果我们按一下ctrl -z让他暂停，那么我们用ps查看就会显示T这个状态 Z: 不存在但暂时无法消除。僵尸进程，杀不掉，打不死的垃圾进程，占系统一小点资源，不过没有关系。如果太多，就有问题了。一般不会出现。 W: 没有足够的记忆体分页可分配 &lt;: 高优先序的行程 N: 低优先序的行程 L: 有记忆体分页分配并锁在记忆体内 (实时系统或捱A I/O) + 代表在前台运行的进程 START: 行程开始时间 TIME: 执行的时间 COMMAND:所执行的指令 使用示例： 查看系统的进程信息： 可以使用ps -aux 或者 ps -elf 查看。 图：查看系统所有的进程 PID：进程的id，这个id很有用，在linux中内核管理进程就得靠pid来识别和管理某一个程，如果想终止某一个进程，则用 ‘kill 进程的pid 有时并不能杀掉，则需要加一个-9选项了 kill -9 进程pid。 显示指定用户的进程信息： ps -u root //只显示root用户的信息 123456789101112[root@localhost ~]# [root@localhost ~]# ps -u root PID TTY TIME CMD 1 ? 00:00:03 systemd 2 ? 00:00:00 kthreadd 3 ? 00:00:00 ksoftirqd/0 5 ? 00:00:00 kworker/0:0H 7 ? 00:00:00 migration/0 8 ? 00:00:00 rcu_bh 9 ? 00:00:01 rcu_sched 10 ? 00:00:00 lru-add-drain 11 ? 00:00:00 watchdog/0 连同管道符使用，可以查看某个进程的数量： 图：查看进程 在查看进程个数时要减1，因为使用grep命令时，grep命令本身也算一个。 netstat查看网络状况：netstat命令用来打印网络连接状况、系统所开放端口、路由表等信息。 语法：netstat 参数 常用参数： -a(all): 显示所有连线中的Socket。 -l(listening): 显示监控中的服务器的Socket。 -n(numeric):直接使用IP地址，而不通过域名服务器。 -p(programs): 显示正在使用Socket程序识别码和程序名称。 使用示例： 打印当前系统启动哪些端口:netstat -lnp（常用） 图：打印当前系统启动的端口号 打印网络连接状况：netstat -an（常用）: 图：显示网络连接状况 显示网络统计信息：netstat -s. 抓包工具tcpdump:常用的命令：tcpdump -nn -i eth0 -n：对地址以数字方式显示，否则显示为主机名。就是不做主机名解析。 -nn：除了-n的作用外，还把端口号显示为数值，否则显示端口服务名。 -i(interface):指定要监听的接口。 -c：指定要包的数量。 Linux网络相关：ifconfig查看网卡IP：ifconfig类似与windows的ipconfig，不加任何选项和参数只打印当前网卡的IP相关信息（子网掩码、网关等）。 在Linux设置IP需要去修改配置文件/etc/sysconfig/network-scripts/ifcfg-eth0了，如果是eth1那么配置文件是/etc/sysconfig/network-scripts/ifcfg-eth1. 如果Linux上有多个网卡，而只想重启某一个网卡的话，可以使用这个命令: 1[root@localhost ~]# ifdown eth0; ifup eth0 ifdown 即停掉网卡，ifup即启动网卡。有一点要提醒的是，如果我们远程登录服务器，当使用ifdown eth0这个命令的时候，很有可能后面的命令ifup eth0不会被运行，这样导致我们断网而无法连接服务器，所以请尽量使用 service network restart 这个命令来重启网卡。 给一个网卡设置多个IP：在linux系统中，网卡是可以设定多重IP的。 12[root@localhost ~]# cd /etc/sysconfig/network-scripts/[root@localhost network-scripts]# cp ifcfg-ens33 ifcfg-ens33\:1 然后编辑ifcfg-ens33:1 这个配置文件，内容如下，一定要注意 DEVICE 这里要写成 “ens33:1” 12345678910111213141516171819[root@localhost network-scripts]# cat ifcfg-ens33:1TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticIPADDR=192.168.171.129NETMASK=255.255.255.0GATEWAY=192.168.1.255DEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33:1UUID=60370590-730b-4981-b6e0-9aa43074b522DEVICE=ens33:1ONBOOT=yes 编辑好后，重启网卡： ifdown ens33:1 &amp;&amp; ifup ens33:1 然后查看网卡ip： 图：多个IP 查看网卡连接状态：12345[root@localhost network-scripts]# mii-tool ens33ens33: negotiated 1000baseT-FD flow-control, link ok[root@localhost network-scripts]# mii-tool ens33:1ens33:1: negotiated 1000baseT-FD flow-control, link ok[root@localhost network-scripts]# mii-tool lo 只要看到 “link ok” 就说明网卡为连接状态，如果显示 “no link” 说明网卡坏掉了或者没有连接网线。 更改主机名：当装完系统后，默认主机名为localhost，使用hostname就可以知道linux的主机名是什么:同样使用hostname可以更改主机名。 不过这样的更改只是保存在内存中，重启后，还会失效。所需要去配置文件：etc/sysconfig/network 123456[root@cao ~]# hostnamecao[root@cao ~]# cat /etc/sysconfig/network# Created by anacondaNETWORK=yesHOSTNAME=cao.localdomain 设置DNS：在配置文件etc/resolv.conf 中写入dns地址即可。 12345[root@localhost ~]# cat /etc/resolv.conf ; generated by /usr/sbin/dhclient-scriptsearch localdomainnameserver 192.168.171.2[root@localhost ~]# resolv.conf有它固有的格式，一定要写成 “nameserver IP” 的格式，上面那行以 ‘;’ 为开头的行是一行注释，没有实际意义，建议写两个或多个namserver，默认会用第一个namserver去解析域名，当第一个解析不到时会使用第二个。在linux下面有一个特殊的文件/etc/hosts也能解析域名，不过是需要我们手动在里面添加IP+域名这些内容，它的作用是临时解析某个域名，非常有用。 123[root@localhost ~]# cat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 /etc/hosts 的格式很简单，每一行作为一条记录，分成两部分，第一部分是IP，第二部分是域名。关于hosts文件，有几点需要注意： 1）一个IP后面可以跟多个域名，可以是几十个甚至上百个； 2）每行只能有一个IP，也就是说一个域名不能对应多个IP； 3）如果有多行中出现相同的域名（前面IP不一样），会按最前面出现的记录来解析。 Linux的防火墙：selinux：Selinux是Redhat/CentOS系统特有的安全机制。不过因为这个东西限制太多，配置也特别繁琐所以几乎没有人去真正应用它。所以装完系统，我们一般都要把selinux关闭，以免引起不必要的麻烦。关闭selinux的方法为，使“SELINUX=disabled”, 默认为 enforcing 12345678910111213[root@localhost ~]# cat /etc/selinux/config # This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=enforcing# SELINUXTYPE= can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection.SELINUXTYPE=targeted 将enforcing修改为disabled后，保存。重启机器方可生效。临时关闭selinux的命令为：setenforce 0, 可以使用fetenforce 来获取当前selinux的状态。 iptables：Iptables是linux上特有的防火墙机制，其功能非常强大。 语法： iptables(选项)(参数) 选项： 12345678910111213141516-t(table)&lt;表&gt;：指定要操纵的表；-A（append）：向规则链中添加条目；-D(delete)：从规则链中删除条目；-i(insert)：向规则链中插入条目；-R(replace)：替换规则链中的条目；-L(list)：显示规则链中已有的条目；-F(flush)：清除规则链中已有的条目；-Z（zero）：清空规则链中的数据包计算器和字节计数器；-N(new)：创建新的用户自定义规则链；-P(policy)：定义规则链中的默认目标；-h（help）：显示帮助信息；-p(protocol)：指定要匹配的数据包协议类型；-s(source)：指定要匹配的数据包源ip地址；-j(jump target)&lt;目标&gt;：指定要跳转的目标；-i&lt;网络接口&gt;：指定数据包进入本机的网络接口；-o&lt;网络接口&gt;：指定数据包要离开本机所使用的网络接口 iptables命令选项输入顺序： 1iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作 表名包括： raw：高级功能，如：网址过滤。 mangle：数据包修改（QOS），用于实现服务质量。 net：地址转换，用于网关路由器。 filter：包过滤，用于防火墙规则。 规则链名包括： INPUT链：处理输入数据包。 OUTPUT链：处理输出数据包。 PORWARD链：处理转发数据包。 PREROUTING链：用于目标地址转换（DNAT）。 POSTOUTING链：用于源地址转换（SNAT）。 动作包括： accept：接收数据包。 DROP：丢弃数据包。 REDIRECT：重定向、映射、透明代理。 SNAT：源地址转换。 DNAT：目标地址转换。 MASQUERADE：IP伪装（NAT），用于ADSL。 LOG：日志记录。 CentOS上默认是设有iptables规则的，这个规则虽然很安全，但是对于我们来说没有用，反而会造成某些影响，所以建议先清除规则，然后把清除后的规则保存一下。 使用示例： 清除已有的iptables规则： 123iptables -Fiptables -Xiptables -Z 开放指定的端口 123456789iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT #允许本地回环接口(即运行本机访问本机)iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT #允许已建立的或相关连的通行iptables -A OUTPUT -j ACCEPT #允许所有本机向外的访问iptables -A INPUT -p tcp --dport 22 -j ACCEPT #允许访问22端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT #允许访问80端口iptables -A INPUT -p tcp --dport 21 -j ACCEPT #允许ftp服务的21端口iptables -A INPUT -p tcp --dport 20 -j ACCEPT #允许FTP服务的20端口iptables -A INPUT -j reject #禁止其他未允许的规则访问iptables -A FORWARD -j REJECT #禁止其他未允许的规则访问 屏蔽IP 1234iptables -I INPUT -s 123.45.6.7 -j DROP #屏蔽单个IP的命令iptables -I INPUT -s 123.0.0.0/8 -j DROP #封整个段即从123.0.0.1到123.255.255.254的命令iptables -I INPUT -s 124.45.0.0/16 -j DROP #封IP段即从123.45.0.1到123.45.255.254的命令iptables -I INPUT -s 123.45.6.0/24 -j DROP #封IP段即从123.45.6.1到123.45.6.254的命令是 查看已添加的iptables规则 123456789101112131415iptables -L -n -vChain INPUT (policy DROP 48106 packets, 2690K bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 191K 90M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:221499K 133M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:804364K 6351M ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 6256 327K ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 3382K packets, 1819M bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- * lo 0.0.0.0/0 0.0.0.0/0 删除已添加的iptables规则 将所有iptables以序号标记显示，执行： 1iptables -L -n --line-numbers 比如要删除INPUT里序号为8的规则，执行： 1iptables -D INPUT 8 Linux系统的任务计划：定时任务（cron job）被用于安排那些需要被周期性执行的命令。关于cron任务计划功能的操作都是通过crontab这个命令来完成的。crontab 是用来安装、卸载或者列出定时任务列表的命令。其中常用的选项有： -u ：指定某个用户，不加-u选项则为当前用户； -e ：制定计划任务； -l ：列出计划任务； -r ：删除计划任务。 创建一个任务计划： 12[root@localhost ~]# crontab -eno crontab for root - using an empty one 使用 crontab -e 来进行编写任务计划，这实际上是使用vim工具打开了crontab的配置文件，我们写下如下内容: 101 10 05 06 3 echo "ok" &gt; /root/cron.log 每个字段的数字分表表示什么呢？从左到右，依次为：分，时，日，月，周，命令行。而上面的例子的含义是：在6月5日（这一天必须是星期3）的10点01分执行命令 echo &quot;ok&quot; &gt; /root/cron.log crontab -e 实际上是打开了 “/var/spool/cron/username” （如果是root则打开的是/var/spool/cron/root）这个文件。使用的是vim编辑器，所以要保存的话则在命令模式下输入:wq即可。但是，您千万不要直接去编辑那个文件，因为可能会出错，所以一定要使用 crontab -e 来编辑。查看已经设定的任务计划使用 crontab -l 命令: 12[root@localhost ~]# crontab -l01 10 05 06 3 echo "ok" &gt; /root/cron.log 删除计划任务要用 crontab -r 123[root@localhost ~]# crontab -r[root@localhost ~]# crontab -lno crontab for root 使用示例： 123456789101112131415161720 1 * * * echo "" &gt;/var/log/slow.log#每天凌晨1点20分清除/var/log/slow.log这个文件 0 3 * * 0 /bin/sh /usr/local/sbin/backup.sh#每周日3点执行 “/bin/sh /usr/local/sbin/backup.sh” 10 4 14 * * /bin/sh /usr/local/sbin/backup_month.sh#每月14号4点10分执行 “/bin/sh /usr/local/sbin/backup_month.sh” 0 */8 * * * ntpdate time.windows.com#每隔8小时执行 “ntpdate time.windows.com” 0 1,12,18 * * /bin/sh /usr/local/sbin/test.sh#每天的1点，12点，18点执行 “/bin/sh /usr/local/sbin/test.sh” 0 9-18 * * * /bin/sh /usr/local/sbin/test2.sh#每天的9点到18点执行 “/bin/sh /usr/local/sbin/test2.sh” 可通过serfvice crond status 查看crond服务是否启动。如果没启动通过service crond start 来启动。 Linux的系统服务管理：如果对windows非常熟悉的话，肯定配置过开机启动的服务，有些服务我们日常用不到则要把它停掉，一来可以节省资源，二来可以减少安全隐患。在linux上同样也有相关的工具来管理系统的服务。 ntsysv服务配置工具：什么是ntsysv呢？ntsysv -&gt; NeWT + SysV ，它是使用 newt 库的 SysV 风格的 runlevel 配置工具，Red Hat公司遵循GPL规则所开发的程序，它具有互动式操作界面，您可以轻易地利用方向键和空格键等，开启，关闭操作系统在每个执行等级中，设置系统的各种服务。 直接运行命令 ntsysv 回车后弹出一个配置界面： 图：管理界面 按键盘的上下方向键可以调节红色光标，按空格可以选择开启或者不开启，如果前面的中括号内显示有 * 则表示开启否则不开启。通过这个工具也可以看到目前系统中所有的服务。建议除 “crond, iptables, network, sshd, syslog, irqbalance, sendmail, microcode_ctl” 外其他服务全部停掉。选择好后，按 “tab” 键选择 “确定”, 然后回车，需要重启机器才能生效。 chkconfig服务管理工具：chkconfig是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。 chkconfig可以更新(启动或停止)和查询系统服务(service)运行级信息。更简单一点，chkconfig是一个用于维护/etc/rc[0-6].d目录的命令行工具。 Linux系统所有的预设服务可以查看/etc/init.d/目录得到: 12[root@localhost init.d]# lsfunctions iptables netconsole network README 其实这就是系统所有的预设服务了。为什么这样讲，因为系统预设服务都是可以通过这样的命令实现 service 服务名 start|stop|restart这里的服务名就是/etc/init.d/目录下的这些文件了。除了可以使用 service crond start 启动crond外，还可以使用 /etc/init.d/crond start 来启动。 可使用chkconfig --list 列出所有的服务及每个级别是否开启： 1234567891011[root@localhost init.d]# chkconfig --list注：该输出结果只显示 SysV 服务，并不包含原生 systemd 服务。SysV 配置数据可能被原生 systemd 配置覆盖。 要列出 systemd 服务，请执行 'systemctl list-unit-files'。 查看在具体 target 启用的服务请执行 'systemctl list-dependencies [target]'。netconsole 0:关 1:关 2:关 3:关 4:关 5:关 6:关network 0:关 1:关 2:开 3:开 4:开 5:开 6:关 这里的级别（0,1,2,3,4,5,6）就是 /etc/inittab 里面的那几个启动级别了，0、1、6运行级别被系统保留：其中0作为shutdown动作，1作为重启至单用户模式，6为重启；在一般的Linux系统实现中，都使用了2、3、4、5几个级别，在CentOS系统中，2表示无NFS支持的多用户模式，3表示完全多用户模式（也是最常用的级别），4保留给用户自定义，5表示图形登录方式。我们可以使用grep命令把我们想要看的服务过滤出来。 更改每个级别是否开启： 用 --level 指定级别，后面是服务名，然后是off或者on，–level` 后还可以跟多个级别:另外还可以省略级别，默认是针对2,3,4,5级别操作: 123[root@localhost init.d]# chkconfig --level 2 network off[root@localhost init.d]# chkconfig --list | grep networknetwork 0:关 1:关 2:关 3:开 4:开 5:开 6:关 chkconfig 还有一个功能就是可以把某个服务加入到系统服务，即可以使用 service 服务名 start 这样的形式，并且可以在 chkconfig --list 中查找到。当然也能删除掉: 1chkconfig --del 服务名 Linux系统日志：日志主要的功能有：审计和监测，还可以实时的监测系统状态，监测和追踪侵入者等等。 常查看的日志文件为/var/log/message, 它是核心系统日志文件，包含了系统启动时的引导消息，以及系统运行时的其他状态消息。IO错误、网络错误和其他系统错误都会记录到这个文件中。另外其他信息，比如某个人的身份切换为root以及用户自定义安装的软件（apache）的日志也会在这里列出。通常，/var/log/messages是在做故障诊断时首先要查看的文件。同时系统有一个日志轮询的机制，每星期切换一个日志，变成message.xxxxxxxx,message.xxxxxxxx, … messages.xxxxxxxx 连同messages一共有5个这样的日志文件。这里的xxxxxxxx就是按照日期的格式生成的文件，在CentOS5里，这个后缀并不是日期而是数字1,2,3,4. 这是通过logrotate工具的控制来实现的，它的配置文件是/etc/logrotate.conf如果没有特殊需求请不要修改这个配置文件。 /var/log/messages是由syslogd这个守护进程产生的，如果停掉这个服务则系统不会产生/var/log/messages，所以这个服务不要停。Syslogd服务的配置文件为/etc/syslog.conf这个文件定义了日志的级别。 除了关注/var/log/messages外，还应该多关注一下 dmesg 这个命令，它可以显示系统的启动信息，如果某个硬件有问题（比如说网卡）用这个命令也是可以看到的。 命令last:查看登录Linux历史信息 12345[root@localhost log]# last | head -n4hadoop pts/2 192.168.171.1 Thu Jul 5 20:43 still logged in hadoop pts/1 92.168.171.1 Thu Jul 5 17:37 still logged in hadoop pts/2 192.168.171.1 Thu Jul 5 17:28 - 17:28 (00:00) root pts/1 192.168.171.1 Thu Jul 5 16:05 - 17:37 (01:32) last命令用来查看登录Linux历史信息，从左至右依次为账户名称、登录终端、登录客户端ip、登录日期及时长。last命令输出的信息实际上是读取了二进制日志文件/var/log/wtmp, 只是这个文件不能直接使用cat, vim, head, tail等工具查看。 另外一个和登陆信息有关的日志文件为/var/log/secure, 该日志文件记录验证和授权等方面的信息，比如ssh登陆系统成功或者失败，都会把相关信息记录在这个日志里。 xargs与exec：xargs应用：123[root@localhost ~]# echo "121212121" &gt; 123.txt[root@localhost ~]# ls 123.txt | xargs cat121212121 xargs的作用就是把管道符前面的输出作为xargs后面的命令的输入。它的好处在于可以把本来两步或者多步才能完成的任务简单一步就能完成。xargs常常和find命令一起使用，比如，查找当前目录创建时间大于10天的文件，然后再删除。[root@localhost ~]# find . -mtime +10 |xargs rm 现在有一个这样的需求，查找当前目录下所有.txt的文件，然后把这些.txt的文件变成.txt_bak。正常情况下，我们不得不写脚本去实现，但是使用xargs就一步。 12345678[root@localhost ~]# ls123.txt Desktop Downloads Pictures Templates Videosabc.txt Documents Music Public test.txt[root@localhost ~]# ls *.txt | xargs -n1 -i&#123;&#125; mv &#123;&#125; &#123;&#125;_bak[root@localhost ~]# ls123.txt_bak Desktop Downloads Pictures Templates Videosabc.txt_bak Documents Music Public test.txt_bak[root@localhost ~]# xargs -n1 –i{} 类似for循环，-n1意思是一个一个对象的去处理，-i{}把前面的对象使用{}取代，mv {} {}_bak 相当于 mv 1.txt 1.txt_bak。 exec应用：使用find命令时，经常使用一个选项就是这个-exec了，可以达到和xargs同样的效果。比如，查找当前目录创建时间大于10天的文件并删除: 1[root@localhost ~]# find . -mtime +10 -exec rm -rf &#123;&#125; \; 这个命令中也是把{}作为前面find出来的文件的替代符，后面的 \ 为 ; 的脱意符，不然shell会把分号作为该行命令的结尾。这个-exec有时候也挺实用的，它同样可以实现刚刚上面批量更改文件名的需求: 12345[root@localhost test]# ls1.txt_bak 2.txt_bak 3.txt_bak 4.txt_bak 5.txt_bak[root@localhost test]# find ./*_bak -exec mv &#123;&#125; &#123;&#125;_bak \;[root@localhost test]# ls1.txt_bak_bak 2.txt_bak_bak 3.txt_bak_bak 4.txt_bak_bak 5.txt_bak_bak screen工具介绍：有时候，我们也许会有这样的需求，要执行一个命令或者脚本，但是需要几个小时甚至几天。这就要考虑一个问题，就是中途断网或出现其他意外情况，执行的任务中断了怎么办？可以把命令或者脚本丢到后台运行，不过也不保险。可以使用下面的两种方法来解决： 1. 使用nohup 123456[root@localhost ~]# cat /usr/local/sbin/sleep.sh#! /bin/bashsleep 1000[root@localhost ~]# nohup sh /usr/local/sbin/sleep.sh &amp;[1] 19997[root@localhost ~]# nohup: 忽略输入并把输出追加到"nohup.out" 直接加一个 ‘&amp;’ 虽然丢到后台了，但是当退出该终端时很有可能这个脚本也会退出的，而在前面加上 nohup 就没有问题了，nohup的作用就是不挂断地运行命令。 2. screen工具的使用 简单来说，screen是一个可以在多个进程之间多路复用一个物理终端的窗口管理器。screen中有会话的概念，用户可以在一个screen会话中创建多个screen窗口，在每一个screen窗口中就像操作一个真实的SSH连接窗口那样。 1）打开一个会话，直接输入screen命令然后回车，进入screen会话窗口。如果你没有screen命令，请用 yum install -y screen 安装。 12[root@localhost ~]# screen[root@localhost ~]# 2）screen -ls 查看已经打开的screen会话 1234[root@localhost ~]# screen -lsThere is a screen on: 20001.pts-0.localhost (Attached)1 Socket in /var/run/screen/S-root. 3）Ctrl +a 再按d退出该screen会话，只是退出，并没有结束。结束的话输入Ctrl +d 或者输入exit 4）退出后还想再次登录某个screen会话，使用screen -r [screen 编号]，这个编号就是上例中那个20001. 当只有一个screen会话时，后面的编号是可以省略的。当有某个需要长时间运行的命令或者脚本时就打开一个screen会话，然后运行该任务。按ctrl +a 再按d退出会话，不影响终端窗口上的任何操作。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记， Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的shell脚本]]></title>
    <url>%2F2018%2F07%2F02%2FLinux%E4%B8%8B%E7%9A%84shell%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[shell脚本的基本结构：shell脚本示例： 123456789[root@localhost ~]# cd /usr/local/sbin/[root@localhost sbin]# vim first.sh#! /bin/bash## This is my first shell script.## Writen by Cao 2018-7-2.dateecho "Hello world!" shell脚本用注意事项： Shell脚本通常都是以.sh 为后缀名的**，这个并不是说不带.sh这个脚本就不能执行，只是大家的一个习惯而已。所以，遇见.sh结尾的文件通常都是脚本。 shell脚本中第一行要以 “#! /bin/bash” 开头，它代表的意思是，该文件使用的是bash语法。如果不设置该行，虽然shell脚本也可以执行，但是这不符合规范。 # 表示注释。后面跟一些该脚本的相关注释内容以及作者和创建日期或者版本等等。为了方便管理，写注释是非常必要的。 shell脚本执行方法： sh shell.sh 另外使用sh命令去执行一个shell脚本的时候是可以加-x选项来查看这个脚本执行过程的，这样有利于我们调试这个脚本哪里出了问题: ./first.sh 该方法通常需要更改文件权限。chomod +x shell.sh 12345[root@localhost sbin]# sh -x first.sh + date2018年 07月 02日 星期一 15:05:17 CST+ echo 'Hello word!'Hello word! 命令date： 1234[root@localhost sbin]# date +"%Y-%m-%d %H:%M:%S"2018-07-02 15:08:01[root@localhost sbin]# date2018年 07月 02日 星期一 15:08:04 CST date在脚本中最常用的几个用法： data +%Y 以四位数字格式打印年份 date +%y 以两位数字格式打印年份 date +%m 月份 date +%d 日期 date +%H 小时 date +%M 分钟 date +%S 秒 date +%w 星期，如果结果显示0 则表示周日 有时在脚本中会用到一天前的日期: 12[root@localhost sbin]# date -d "-1 day" +%d23 或者一小时前: 12[root@localhost sbin]# date -d "-1 hour" +%H18 甚至1分钟前: 12[root@localhost sbin]# date -d "-1 min" +%M50 shell脚本中的变量：变量就是和其他编程语言中的变量一样，为了简化和使代码更容易维护。 使用变量的脚本示例： 123456789101112[root@localhost sbin]# cat variable.sh #! /bin/bash## In this script we will use variables.## Writen by Cao 2018-7-2.d=`date +%H:%M:%S`echo "The script begin at $d"echo "Now we'll sleep 2 seconds."sleep 2d1=`date +%H:%M:%S`echo "The script end at $d1." 1234[root@localhost sbin]# ./variable.sh The script begin at 15:21:23Now we'll sleep 2 seconds.The script end at 15:21:25. 脚本中使用了反引号 “ ` “ , 反引号的作用：在Linux中起着命令替换的作用。命令替换是指shell能够将一个命令的标准输出插在一个命令行中任何位置。 d’ 和 ‘d1’ 在脚本中作为变量出现，定义变量的格式为 变量名=变量的值当在脚本中引用变量时需要加上 ‘$’ 符号，引用变量的符号。 使用shell计算两个数的和： 1234567891011121314[root@localhost sbin]# cat sum.sh #！ /bin/bash## For get the sum fo tow numbers.## Cao 2018-7-2.a=1b=2sum=$[$a+$b]#数学计算要用[ ]括起来并且外头要带一个 ‘$’ echo "$a+$b=$sum"[root@localhost sbin]# ./sum.sh 1+2=3 Shell脚本还可以和用户交互: 123456789101112131415[root@localhost sbin]# cat read.sh #! /bin/bash## Using 'read' in shell script.## Writen by Cao 2018-7-2.read -p "Please input a number:" xread -p "please input another number:" ysum=$[$x+$y]echo "The sum of the tow number is:$sum"[root@localhost sbin]# sh read.sh Please input a number:20please input another number:30The sum of the tow number is:50 shell的预设变量： shell中的预设变量$0,代表脚本本身的名字。 shell脚本的逻辑判断：在shell中的判断的基本语法为： 1234567if 判断语句一 ; then commandelif 判断语句二; then commandelse commandfi 使用示例： 1234567891011121314151617181920[root@localhost sbin]# cat if.sh #! /bin/bashread -p "Please input your score:" aif ((a&lt;60)); then echo "You didn't pass the exam"elif ((a&gt;=60)) &amp;&amp; ((a&lt;85)); then echo "Good! You pass the exam."else echo "very good! Your socre is very high!"fi[root@localhost sbin]# sh if.sh Please input your score:90very good! Your socre is very high![root@localhost sbin]# sh if.sh Please input your score:78Good! You pass the exam.[root@localhost sbin]# sh if.sh Please input your score:49You didn't pass the exam 在判断数值大小除了可以用 (( )) 的形式外，还可以使用 [ ] 但是就不能使用&gt;, &lt; , = 这样的符号了，要使用 -lt （小于），-gt （大于），-le （小于等于），-ge （大于等于），-eq （等于），-ne （不等于）。 12345678[root@localhost sbin]# a=10; if [ $a -lt 5 ]; then echo ok; fi[root@localhost sbin]# a=10; if [ $a -gt 5 ]; then echo ok; fiok[root@localhost sbin]# a=10; if [ $a -ge 10 ]; then echo ok; fiok[root@localhost sbin]# a=10; if [ $a -eq 10 ]; then echo ok; fiok[root@localhost sbin]# a=10; if [ $a -ne 10 ]; then echo ok; fi shell 脚本中if还经常判断关于档案属性，比如判断是普通文件还是目录，判断文件是否有读写执行权限等。常用的也就几个选项： -e ：判断文件或目录是否存在 -d ：判断是不是目录，并是否存在 -f ：判断是否是普通文件，并存在 -r ：判断文档是否有读权限 -w ：判断是否有写权限 -x ：判断是否可执行 使用if判断时，具体格式为： if [ -e filename ] ; then 12345678root@localhost sbin]# if [ -f /root/test.txt ]; then echo ok; fiok[root@localhost sbin]# if [ -r /root/test.txt ]; then echo ok; fiok[root@localhost sbin]# if [ -w /root/test.txt ]; then echo ok; fiok[root@localhost sbin]# if [ -x /root/test.txt ]; then echo ok; fi[root@localhost sbin]# if [ -e /root/test1.txt ]; then echo ok; fi case的使用方法： 1234567891011121314case 变量 invalue1) command ;;value2) command ;;value3) command ;;*) command ;;esac 面的结构中，不限制value的个数， * 则代表除了上面的value外的其他值。 判断输入数值是奇数或者偶数的脚本: 12345678910111213141516171819202122232425[root@localhost sbin]# cat case.sh #！ /bin/bashread -p "Input a number:" na=$[$n%2]case $a in 1) echo "The number is odd." ;; 0) echo "The number is even." ;; *) echo "It's not a number!" ;;esac[root@localhost sbin]# sh case.sh Input a number:79The number is odd.[root@localhost sbin]# sh case.sh Input a number:90The number is even.[root@localhost sbin]# sh case.sh Input a number:sdThe number is even. case脚本常用于编写系统服务的启动脚本，例如/etc/init.d/iptables中就用到了。 shell脚本中的循环：for循环的基本结构: 123for 变量名 in 循环的条件； do commanddone for循环示例： 12345678910111213141516171819[root@localhost sbin]# cat for.sh #！ /bin/bash#脚本中的 seq 1 5 表示从1到5的一个序列。for i in `seq 1 5`; do echo $idone[root@localhost sbin]# sh for.sh 12345[root@localhost sbin]# for i in 1 2 3 a b; do echo $i; done123ab while循环： 1234while 条件; do commanddone while使用示例： 123456789101112131415[hadoop@localhost ~]$ cat while.sh #! /bin/basha=5while [ $a -ge 1 ]; do echo $a a=$[$a-1]done[hadoop@localhost ~]$ sh while.sh 54321[hadoop@localhost ~]$ 另外可以把循环条件拿一个冒号替代，这样可以做到死循环。 shell脚本中的函数：在shell脚本函数的格式为: 12345function 函数名() &#123;command&#125; 在shell脚本中，函数一定要写在最前面，不能出现在中间或者最后，因为函数是要被调用的，如果还没有出现就被调用，肯定是会出错的。 函数使用示例： 1234567891011121314[root@localhost sbin]# cat func.sh #! /bin/bashfunction sum()&#123; sum=$[$1+$2] echo $sum&#125;sum $1 $2[root@localhost sbin]# sh func.sh 1 23[root@localhost sbin]# sh func.sh 4 59 shell脚本实例：（1）计算1-100的和： 123456789101112[root@localhost sbin]# cat sum1-100.sh #! /bin/bash## Sum（1-100）sum=0for i in `seq 1 100`; do sum=$[$i+$sum]doneecho $sum[root@localhost sbin]# sh sum1-100.sh 5050 （2）要求输入一个数字，然后计算出从1到输入数字的和，要求，如果输入的数字小于1，则重新输入，直到输入正确的数字为止； 12345678910111213141516171819[root@localhost sbin]# cat sum.sh #! /bin/bashn=0while [ $n -lt "1" ]; do read -p "Please input a number, it must greater than "1":" ndonesum=0for i in `seq 1 $n`; do sum=$[$i+$sum]doneecho $sum[root@localhost sbin]# sh sum.sh Please input a number, it must greater than 1:501275[root@localhost sbin]# （3）把/root/目录下的所有目录（只需要一级）拷贝到/tmp/目录下； 1234567891011121314151617[root@localhost sbin]# cat copydir.sh #！/bin/bashcd /rootfor f in `ls`; do if [ -d $f ] ; then cp -r $f /tmp fidone[root@localhost sbin]# sh copydir.sh [root@localhost sbin]# ls /tmpDesktopDocumentsDownloadsMusicPicturesPublic （4）批量建立用户user_00, user_01, … user_100并且所有用户同属于users组； 123456789101112131415161718192021[root@localhost sbin]# cat useradd.sh #! /bin/bashgroupadd usersfor i in `seq 0 9`; do useradd -g users user_0$idonefor j in `seq 10 100`; do useradd -g users user_$jdone[root@localhost sbin]# sh useradd.sh [root@localhost sbin]# cat /etc/passwd | grep useruser_00:x:1005:100::/home/user_00:/bin/bashuser_01:x:1006:100::/home/user_01:/bin/bashuser_02:x:1007:100::/home/user_02:/bin/bashuser_03:x:1008:100::/home/user_03:/bin/bashuser_04:x:1009:100::/home/user_04:/bin/bashuser_05:x:1010:100::/home/user_05:/bin/bashuser_06:x:1011:100::/home/user_06:/bin/bash （5）截取文件test.log中包含关键词 ‘abc’ 的行中的第一列（假设分隔符为 ”:” ），然后把截取的数字排序（假设第一列为数字），然后打印出重复次数超过10次的列； 12345#! /bin/bashawk -F':' '$0~/abc/ &#123;print $1&#125;' test.log &gt;/tmp/n.txtsort -n n.txt |uniq -c |sort -n &gt;/tmp/n2.txtawk '$1&gt;10 &#123;print $2&#125;' /tmp/n2.txt (6)判断输入的IP是否正确（IP的规则是，n1.n2.n3.n4，其中1&lt;n1&lt;255, 0&lt;n2&lt;255, 0&lt;n3&lt;255, 0&lt;n4&lt;255）。 1234567891011121314151617181920212223242526272829303132 #! /bin/bashcheckip() &#123; if echo $1 |egrep -q '^[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;$' ; then a=`echo $1 | awk -F. '&#123;print $1&#125;'` b=`echo $1 | awk -F. '&#123;print $2&#125;'` c=`echo $1 | awk -F. '&#123;print $3&#125;'` d=`echo $1 | awk -F. '&#123;print $4&#125;'` for n in $a $b $c $d; do if [ $n -ge 255 ] || [ $n -le 0 ]; then echo "the number of the IP should less than 255 and greate than 0" return 2 fi done else echo "The IP you input is something wrong, the format is like 192.168.100.1" return 1 fi&#125;rs=1while [ $rs -gt 0 ]; do read -p "Please input the ip:" ip checkip $ip rs=`echo $?`doneecho "The IP is right!"]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
        <tag>Linux命令</tag>
        <tag>脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下正则表达式的应用]]></title>
    <url>%2F2018%2F06%2F29%2FLinux%E4%B8%8B%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正则表达式：在计算机科学中，正则表达式是这样解释的：它是指一个用来描述或者匹配一系列符合某个句法规则的字符串的单个字符串。在很多文本编辑器或其他工具里，正则表达式通常被用来检索和/或替换那些符合某个模式的文本内容。许多程序设计语言都支持利用正则表达式进行字符串操作。对于系统管理员来讲，正则表达式贯穿在日常运维工作中，无论是查找某个文档，抑或查询某个日志文件分析其内容，都会用到正则表达式。 在linux中，用到正则表达的常用工具有：grep，sed，awk等。 grep/egrep:grep （缩写来自Globally search a Regular Expression and Print）是一种强大的文本搜索工具，它能使用特定模式匹配（包括正则表达式）搜索文本，并默认输出匹配行。 语法： grep [-cinvABC] &#39;word&#39; filename -c（count） ：打印符合要求的行数 -i （ignore-case）：忽略大小写 -n （line-number）：在输出符合要求的行的同时连同行号一起输出 -v （invert-natch）：打印不符合要求的行 -A （after-context）：后跟一个数字（有无空格都可以），例如 –A2则表示打印符合要求的行以及下面两行 -B （before-context）：后跟一个数字，例如 –B2 则表示打印符合要求的行以及上面两行 -C （context）：后跟一个数字，例如 –C2 则表示打印符合要求的行以及上下各两行 grep应用示例： (1)过滤出带有某个关键词的行并输入行号。 123[root@localhost ~]# grep -n 'root' /etc/passwd1:root:x:0:0:usr:/root:/bin/bash10:operator:x:11:0:operator:/root:/sbin/nologin (2)过滤不带有某个关键词的行，并输出行号。 12345678910[root@localhost ~]# grep -nv 'nologin' /etc/passwd1:root:x:0:0:usr:/root:/bin/bash6:sync:x:5:0:sync:/sbin:/bin/sync7:shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown8:halt:x:7:0:halt:/sbin:/sbin/halt20:hadoop:x:1000:1000:Hadoop:/home/hadoop:/bin/bash44:cao:x:1001:1001::/home/cao:/bin/bash45:usr:x:1002:1002:用户,offic,1234567,123:/home/usr:/bin/bash46:test:x:1003:1003::/home/test:/bin/bash47:test1:x:1004:1003::/home/test1:/bin/bash （3）过滤出所有包含数字的行： 123[root@localhost ~]# grep '[0-9]' /etc/inittab# multi-user.target: analogous to runlevel 3# graphical.target: analogous to runlevel 5 （4）过滤出所有不包含数字的行： 12345678910111213141516[root@localhost ~]# grep -v '[0-9]' /etc/inittab# inittab is no longer used when using systemd.## ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target## systemd uses 'targets' instead of runlevels. By default, there are two main targets:### To view current default target, run:# systemctl get-default## To set a default target, run:# systemctl set-default TARGET.target# （5）把所有以‘#’开头的行去除： 12[root@localhost ~]# grep -v '#' /etc/inittab [root@localhost ~] （6）去除所有空行和以“#”开头的行： 1234[root@localhost ~]# grep -v '#' /etc/crontab | grep -v '^$'SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root 在正则表达式中， “^” 表示行的开始， “\$ ” 表示行的结尾，那么空行则可以用 “^$” 表示。 123456789101112131415161718192021[root@localhost ~]# cat test.txt 123abc456abc123#adff23###打印不以字母开头的行[root@localhost ~]# grep '^[^a-zA-Z]' test.txt 123456#adff23###打印以字母开头的行[root@localhost ~]# grep '^[a-zA-Z]' test.txt abcabc123 ‘[ ]’ 的应用，如果是数字的话就用[0-9]这样的形式，当然有时候也可以用这样的形式[15]即只含有1或者5，注意，它不会认为是15。如果要过滤出数字以及大小写字母则要这样写[0-9a-zA-Z]。另外[ ]还有一种形式，就是[^字符] 表示除[ ]内的字符之外的字符。 (7)过滤任意一个字符与重复的字符： 1234567[root@localhost ~]# grep 'r..o' /etc/passwdoperator:x:11:0:operator:/root:/sbin/nologinpolkitd:x:999:998:User for polkitd:/:/sbin/nologingeoclue:x:997:995:User for geoclue:/var/lib/geoclue:/sbin/nologinunbound:x:994:990:Unbound DNS resolver:/etc/unbound:/sbin/nologincolord:x:992:988:User for colord:/var/lib/colord:/sbin/nologinsssd:x:991:985:User for sssd:/:/sbin/nologin . 表示任意一个字符，上例中，就是把符合r与o之间有两个任意字符的行过滤出来， * 表示零个或多个前面的字符。 12345678[root@localhost ~]# grep 'ooo*' /etc/passwdroot:x:0:0:usr:/root:/bin/bashlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinhadoop:x:1000:1000:Hadoop:/home/hadoop:/bin/bashsetroubleshoot:x:990:984::/var/lib/setroubleshoot:/sbin/nologin ‘ooo*’ 表示oo, ooo, oooo … 或者更多的 ‘o’ ‘.*’ 表示零个或多个任意字符，空行也包含在内。 （8）指定要过滤字符出现的次数： 12345678[root@localhost ~]# grep 'o\&#123;2\&#125;' /etc/passwdroot:x:0:0:usr:/root:/bin/bashlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinhadoop:x:1000:1000:Hadoop:/home/hadoop:/bin/bashsetroubleshoot:x:990:984::/var/lib/setroubleshoot:/sbin/nologin 这里用到了{ }，其内部为数字，表示前面的字符要重复的次数。上例中表示包含有两个o 即 ‘oo’ 的行。注意，{ }左右都需要加上脱意字符 ‘\’,另外，使用{ }我们还可以表示一个范围的，具体格式是 ‘{n1,n2}’其中n1&lt;n2，表示重复n1到n2次前面的字符，n2还可以为空，则表示大于等于n1次。 egrep： 是grep的扩展版本，可以用egrep完成grep不能完成的工作，当然了grep能完成的egrep完全可以完成。 （1）筛选一个或一个以上前面的字符： 12345678910111213141516171819202122232425[root@localhost ~]# cat test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa·#筛选一个或多个前面是o的字符[root@localhost ~]# egrep 'o+' test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash#筛选一个或多个前面是oo的字符[root@localhost ~]# egrep 'oo+' test.txt operator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash#筛选一个或多个前面是ooo的字符[root@localhost ~]# egrep 'ooo+' test.txt operator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash[root@localhost ~]# egrep 'oooo+' test.txt roooot:x:0:0:/rooooot:/bin/bash[root@localhost ~]# （2）筛选零个或一个前面的字符： 12345678910111213141516171819[root@localhost ~]# egrep 'o?' test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa·[root@localhost ~]# egrep 'oo?' test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash[root@localhost ~]# egrep 'ooo?' test.txt operator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash[root@localhost ~]# egrep 'oooo?' test.txt operator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash （3）筛选字符串1或者字符串2： 12345[root@localhost ~]# egrep 'aaa|111|ooo' test.txt operator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa· （4）egrep中（）的应用： 用( )表示一个整体，例如(oo)+就表示1个 ‘oo’ 或者多个 ‘oo’ 123[root@localhost ~]# egrep '(111)|(aa)' test.txt 1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa· sed工具的使用：sed全称是：Stream EDitor。（流编辑器） SED是一项Linux指令，功能同awk类似，差别在于，sed简单，对列处理的功能要差一些，awk的功能复杂，对列处理的功能比较强大。 grep工具的功能其实还不够强大，grep实现的只是查找功能，而它却不能实现把查找的内容替换掉。以前用vim的时候，可以查找也可以替换，但是只局限于在文本内部来操作，而不能输出到屏幕上。sed工具以及下面要讲的awk工具就能实现把替换的文本输出到屏幕上的功能了，而且还有其他更丰富的功能。sed和awk都是流式编辑器，是针对文档的行来操作的。 语法：sed 参数 文件 -e command,–expression=command允许多台编辑。 -h,–help打印帮助，并显示bug列表的地址。 -n,–quiet,–silent取消默认输出。 -f,–filer=script-file引导sed脚本文件名。 -V,–version打印版本和版权信息。 动作说明： a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～ s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ sed应用示例： （1）打印某行： sed -n &#39;n&#39;p filename 单引号内的n是一个数字，表示第几行: 要想把所有行都打印出来可以使用 sed -n &#39;1,$&#39;p filename -n:取消默认输入，只输出指定的行。 p表示打印行。 123456789[root@localhost ~]# sed -n '2'p test.txt operator:x:11:0:operator:/root:/sbin/nologin[root@localhost ~]# sed -n '1,$'p test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa· 也可以指定一个区间: 1234[root@localhost ~]# sed -n '1,3'p test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologin （2）打印包含某个字符串的行： 12[root@localhost ~]# sed -n '/root/'p test.txt operator:x:11:0:operator:/root:/sbin/nologin （3）-e可以实现多个行为： 123[root@localhost ~]# sed -e '1'p -e '/111/'p -n test.txtt:x:0:0:/rot:/bin/bash1111111111111111111111111111111 （4）删除某行或者多行： d’ 这个字符就是删除的动作了，不仅可以删除指定的单行以及多行，而且还可以删除匹配某个字符的行，另外还可以删除从某一行一直到文档末行。 1234567891011[root@localhost ~]# sed '1'd test.txt operator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa·[root@localhost ~]# sed '1,3'd test.txt roooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa·[root@localhost ~]# （5）替换字符或字符串： ‘s’ 就是替换的命令， ‘g’ 为本行中全局替换，如果不加 ‘g’ 只换该行中出现的第一个。除了可以使用 ‘/’ 作为分隔符外，还可以使用其他特殊字符例如 ‘#’ 或者 ‘@’ 都没有问题。 12345678910111213141516171819202122[root@localhost ~]# cat test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa·[root@localhost ~]# sed '1,2s/ot/to/g' test.txtt:x:0:0:/rto:/bin/bashoperator:x:11:0:operator:/roto:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa·#将111全部都替换成222[root@localhost ~]# sed 's/111/222/g' test.txt t:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash2222222222222222222222222222221aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa· （6）调换两个字符串的位置： 1234567891011121314[root@localhost ~]# cat test.txtt:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa·[root@localhost ~]# sed 's/\(rot\)\(.*\)\(bash\)/\3\2\1/' test.txtt:x:0:0:/bash:/bin/rotoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash1111111111111111111111111111111aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa· 上例中用 () 把所想要替换的字符括起来成为一个整体，因为括号在sed中属于特殊符号，所以需要在前面加脱意字符 ‘’, 替换时则写成 ‘1’, ‘‘2’, ‘‘3’ 的形式。 1234567[root@localhost ~]# sed 's/^.*$/123&amp;/' test.txt123t:x:0:0:/rot:/bin/bash123operator:x:11:0:operator:/root:/sbin/nologin123operator:x:11:0:operator:/rooot:/sbin/nologin123roooot:x:0:0:/rooooot:/bin/bash1231111111111111111111111111111111123aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa· 在所有行前面加123. （7）直接修改文件的内容： 12345678[root@localhost ~]# sed -i 's/111/222/g' test.txt[root@localhost ~]# cat test.txtt:x:0:0:/rot:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinoperator:x:11:0:operator:/rooot:/sbin/nologinroooot:x:0:0:/rooooot:/bin/bash2222222222222222222222222222221aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa· awk工具的使用：AWK是一种处理文本文件的语言，是一个强大的文本分析工具。 之所以叫AWK是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。 语法： 123awk [选项参数] &apos;script&apos; var=value file(s)或awk [选项参数] -f scriptfile var=value file(s) awk常见应用： （1）截取文档中的某个段： 123[root@localhost ~]# head -n2 /etc/passwd | awk -F ':' '&#123;print $1&#125;'rootbin 解释一下，-F 选项的作用是指定分隔符，如果不加-F指定，则以空格或者tab为分隔符。 Print为打印的动作，用来打印出某个字段。\$1为第一个字段，\$2为第二个字段，依次类推，有一个特殊的那就是$0，它表示整行。 注意awk的格式，-F后紧跟单引号，然后里面为分隔符，print的动作要用 { } 括起来，否则会报错。print还可以打印自定义的内容，但是自定义的内容要用双引号括起来。 (2)匹配字符或字符串： 12345678910111213[root@localhost ~]# awk '/222/' test.txt2222222222222222222222222222221#以冒号分隔，让第一个字符段中匹配有00,[root@localhost ~]# awk -F ':' '$1 ~/oo/' test.txtroooot:x:0:0:/rooooot:/bin/bash#多次匹配[root@localhost ~]# awk -F ':' '/root/ &#123;print $1,$3&#125; /test/ &#123;print $1,$3&#125;' /etc/passwdroot 0operator 11test 1003test1 1004[root@localhost ~]# （3）条件操作符： awk中是可以用逻辑符号判断的，比如 ‘==’ 就是等于，也可以理解为 ‘精确匹配’ 另外也有 &gt;, ‘&gt;=, ‘&lt;, ‘&lt;=, ‘!= 等等，值得注意的是，即使\$3为数字，awk也不会把它当数字看待，它会认为是一个字符。所以不要妄图去拿$3当数字去和数字做比较。 != 为不匹配 另外还可以使用 &amp;&amp; 和 || 表示 “并且” 和 “或者” 的意思。 12[root@localhost ~]# awk -F ':' '$3=="0"' /etc/passwdroot:x:0:0:root:/root:/bin/bash (4)awk的内置变量： awk常用的变量有： NF ：用分隔符分隔后一共有多少段 NR ：行数 12345678910111213141516[root@localhost ~]# head -n3 /etc/passwd root:x:0:0:usr:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologin[root@localhost ~]# head -n3 /etc/passwd | awk -F ':' '&#123;print NF&#125;'777[root@localhost ~]# head -n3 /etc/passwd | awk -F ':' '&#123;print $NF&#125;'/bin/bash/sbin/nologin/sbin/nologin[root@localhost ~]# head -n3 /etc/passwd | awk -F ':' '&#123;print NR&#125;'123 可以使用行号作为判断条件： 12345678[root@localhost ~]# awk 'NR&gt;40' /etc/passwdgnome-initial-setup:x:989:983::/run/gnome-initial-setup/:/sbin/nologintcpdump:x:72:72::/:/sbin/nologinavahi:x:70:70:Avahi mDNS/DNS-SD Stack:/var/run/avahi-daemon:/sbin/nologincao:x:1001:1001::/home/cao:/bin/bashusr:x:1002:1002:用户,offic,1234567,123:/home/usr:/bin/bashtest:x:1003:1003::/home/test:/bin/bashtest1:x:1004:1003::/home/test1:/bin/bash （5）awk中的数学运算： 12345678[root@localhost ~]# head -n 3 /etc/passwd | awk -F ':' '$1="root"'root x 0 0 usr /root /bin/bashroot x 1 1 bin /bin /sbin/nologinroot x 2 2 daemon /sbin /sbin/nologin#可以进行数学运算[root@localhost ~]# head -n 3 /etc/passwd | awk -F ':' '$2=$3+$4'bin 2 1 1 bin /bin /sbin/nologindaemon 4 2 2 daemon /sbin /sbin/nologin]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
        <tag>Linux命令</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习shell脚本之前的基础知识]]></title>
    <url>%2F2018%2F06%2F23%2F%E5%AD%A6%E4%B9%A0shell%E8%84%9A%E6%9C%AC%E4%B9%8B%E5%89%8D%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[什么是shell：shell就是系统跟计算机硬件交互时使用的中间介质，它只是系统的一个工具。实际上，在shell和计算机硬件之间还有一层东西那就是系统内核了。用户直接面对的不是计算机硬件而是shell，用户把指令告诉shell，然后shell再传输给系统内核，接着内核再去支配计算机硬件去执行各种操作。 linux发布版本（Redhat/CentOS）系统默认安装的shell叫做bash，即Bourne Again Shell，它是sh（Bourne Shell）的增强版本。Bourn Shell 是最早行起来的一个shell，创始人叫Steven Bourne，为了纪念他所以叫做Bourn Shell，检称sh。bash的特点如下： （1）记录历史命令： Linux预设可以记录1000条历史命令。这些命令保存在用户的家目录中的.bash_history文件中。有一点需要您知道的是，只有当用户正常退出当前shell时，在当前shell中运行的命令才会保存至.bash_history文件中。 与命令历史有关的有一个有意思的字符那就是 ‘!’ 了。常用的有这么几个应用： !! 连续两个 ‘!’, 表示执行上一条指令； !n 这里的n是数字，表示执行命令历史中第n条指令，例如 !989 表示执行命令历史中第989个命令； history 命令如果未改动过环境变量，默认可以把最近1000条命令历史打印出来。 图：操作示例 (2)指令和文件名补全： tab键可以补全一个命令或者路径名， 文件名。连续按两次tab键，系统则会把所有的指令或者文件名都列出来。 （3）别名： alias（别名），这也是bash所特有的功能之一。可以通过alias把一个常用的并且很长的指令别名一个简洁易记的指令。如果不想用了，还可以用unalias解除别名功能。直接敲alias会看到目前系统预设的alias. 1234567891011[root@localhost ~]# alias alias cp='cp -i'alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'alias grep='grep --color=auto'alias l.='ls -d .* --color=auto'alias ll='ls -l --color=auto'alias ls='ls --color=auto'alias mv='mv -i'alias rm='rm -i'alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' 也可以自定义想要指令别名。alias的语法：alias 命令别名=‘具体的命令’使用 unalias 命令别名 就可以把设置的别名给解除了。 12345[root@localhost ~]# alias test='ls'[root@localhost ~]# testanaconda-ks.cfg Documents Music Public VideosDesktop Downloads Pictures Templates[root@localhost ~]# unalias test （4）通配符： 在bash下，可以使用 * 来匹配零个或多个字符，而用 ? 匹配一个字符。 （5）输入输出重定向： 输入重定向用于改变命令的输入，输出重定向用于改变命令的输出。输出重定向更为常用，它经常用于将命令的结果输入到文件中，而不是屏幕上。输入重定向的命令是&lt;，输出重定向的命令是&gt;，另外还有错误重定向2&gt;，以及追加重定向&gt;&gt;。 （6）管道： 管道符：‘|’，就是把前面命令的运行结果作为后面命令的输入。 （7）作业控制： 当运行一个进程时，可以使它暂停（按Ctrl+z），然后使用fg命令恢复它，利用bg命令使他到后台运行，也可以使它终止（按Ctrl+c）。 当在后台运行多个任务时，可以同时jobs 命令来查看在后台运行的进程。然后可以通过fg 进程编号 命令来继续恢复该进程。 当需要杀死某个进程时，可先通过ps 命令来查看正在运行的进程。然后用kill 进程号 来杀死进程。 变量:环境变量PATH，这个环境变量就是shell预设的一个变量，通常shell预设的变量都是大写的。变量，说简单点就是使用一个较简单的字符串来替代某些具有特殊意义的设定以及数据。就拿PATH来讲，这个PATH就代替了所有常用命令的绝对路径的设定。因为有了PATH这个变量，所以我们运行某个命令时不再去输入全局路径，直接敲命令名即可。可以使用echo命令显示变量的值。 123456789[root@localhost ~]# echo $PATH/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin[root@localhost ~]# echo $HOME/root[root@localhost ~]# echo PWDPWD[root@localhost ~]# echo $LOGNAMEroot[root@localhost ~]# 可以使用env 命令来列出系统预设的全部变量。不过登录的用户不一样这些环境变量的值也不一样。当前显示的就是root这个账户的环境变量了。 1234567891011121314151617181920[root@localhost ~]# envXDG_SESSION_ID=27HOSTNAME=localhost.localdomainTERM=vt100SHELL=/bin/bashHISTSIZE=1000USER=rootLS_COLORS=rs=0: #此处有省略PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binMAIL=/var/spool/mail/rootPWD=/rootLANG=zh_CN.UTF-8HISTCONTROL=ignoredupsHOME=/rootSHLVL=2LOGNAME=rootXDG_DATA_DIRS=/root/.local/share/flatpak/exports/share/:/var/lib/flatpak/exports/share/:/usr/local/share/:/usr/share/LESSOPEN=||/usr/bin/lesspipe.sh %s_=/bin/env[root@localhost ~]# 在常见的环境变量中： PATH：决定了shell将到哪些目录中寻找命令或程序。 HOME：当前用户主目录。 HISTSIZE：历史记录数。 LOGNAME：当前用户的登录名。 HOSTNAME：指主机的名称。 SHELL：当前用户shell类型。 LANG：语言相关的环境变量，多语言可以修改此环境变量。 MAIL：当前用户的邮件存放目录。 PWD：当前目录。 env命令显示的变量只是环境变量，系统预设的变量其实还有很多，可以使用set命令把系统预设的全部变量都显示出来。 set不仅可以显示系统预设的变量，也可以连同用户自定义的变量显示出来。 1234[root@localhost ~]# myname=Cao #自定义变量[root@localhost ~]# echo $mynameCao[root@localhost ~]# 自定义的变量只能在当前shell中生效。如果使用base命令再打开一个shell，自定义的shell就不存在了。如果想要自定义的shell一直生效。有两种情况： 如果想让系统内所有用户登录后都可以使用该变量： 需要在“/etc/profile” 文件最末行加入 export 自定义变量 然后运行 source /etc/profile 就可以生效了。 只想让当前用户使用该变量： 需要在用户主目录下的 .bashrc文件最后一行加入 export 自定义变量 然后运行 source .bashrc 就可以生效了。source命令的作用是，将目前设定的配置刷新，即不用注销再登录也能生效。 自定义变量的规则： 设定变量的格式为 “a=b”, 其中a为变量名，b为变量的内容，等号两边不能有空格； 变量名只能由英、数字以及下划线组成，而且不能以数字开头； 当变量内容带有特殊字符（如空格）时，需要加上单引号； 有一种情况，需要注意，就是变量内容中本身带有单引号，这就需要用到双引号了。 如果变量内容中需要用到其他命令运行结果则可以使用反引号; 变量内容可以累加其他变量的内容，需要加双引号; 如果不小心把双引号加错为单引号，将得不到想要的结果。 单引号和双引号的区别：用双引号时不会取消掉里面出现的特殊字符的本身作用（这里的$），而使用单引号则里面的特殊字符全部失去它本身的作用。 bash命令： 如果在当前shell中运行bash指令后，则会进入一个新的shell，这个shell就是原来shell的子shell了，可以pstree指令来查看。 pstree 这个指令会把linux系统中所有进程通过树形结构打印出来。在父shell中设定一个变量后，进入子shell后该变量是不会生效的，如果想让这个变量在子shell中生效则要用到export指令。 export其实就是声明一下这个变量的意思，让该shell的子shell也知道变量。如果export后面不加任何变量名，则它会声明所有的变量。 如果想取消某个变量：通过命令unset 变量名 去掉即可。 系统环境变量与个人环境变量的配置文件：/etc/profile ：这个文件预设了几个重要的变量，例如PATH, USER, LOGNAME, MAIL, INPUTRC, HOSTNAME, HISTSIZE, umask等等。 /etc/bashrc ：这个文件主要预设umask以及PS1。PS1就是用户平时的提示符。 12[root@localhost ~]# echo $PS1[\u@\h \W]\$ \u 就是用户， \h 主机名， \W 则是当前目录，\$ 就是那个 ‘#’ 了，如果是普通用户则显示为 ‘$’. 除了两个系统级别的配置文件外，每个用户的主目录下还有几个这样的隐藏文件： .bash_profile ：定义了用户的个人化路径与环境变量的文件名称。每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次。 .bashrc ：该文件包含专用于用户的shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取。例如可以将用户自定义的alias或者自定义变量写到这个文件中。 .bash_history ：记录命令历史用的。 .bash_logout ：当退出shell时，会执行该文件。可以把一些清理的工作放到这个文件中。 Linux shell中的特殊符号：常见符号的意思： * 代表零个或多个任意字符。 ? 只代表一个任意的字符 ，不管是数字还是字母，只要是一个都能匹配出来。 # 这个符号在linux中表示注释说明的意思，即 # 后面的内容linux忽略掉。 \ 脱意字符，将后面的特殊符号（例如” * ” ）还原为普通字符。 | 管道符，前面多次出现过，它的作用在于将符号前面命令的结果丢给符号后面的命令。 这里提到的后面的命令，并不是所有的命令都可以的，一般针对文档操作的命令比较常用，例如cat, less, head, tail, grep, cut, sort, wc, uniq, tee, tr, split, sed, awk等等。 $ 除了用于变量前面的标识符外，还有一个妙用，就是和 ‘!’ 结合起来使用。 !$ 表示上条命令中最后一个变量（总之就是上条命令中最后出现的那个东西）例如上边命令最后是tesb.txt那么在当前命令下输入!$则代表test.txt. 12345[root@localhost ~]# ls test.txt test.txt[root@localhost ~]# ls !$ls test.txttest.txt ; : 分号。平时我们都是在一行中敲一个命令，然后回车就运行了，那么想在一行中运行两个或两个以上的命令如何呢？则需要在命令之间加一个 ”;” 了。 12345[root@localhost ~]# head -n 3/etc/passwd; head test.txt root:x:0:0:usr:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologin4455 ~ : 用户的家目录，如果是root则是 /root ，普通用户则是 /home/username 。 &amp; : 如果想把一条命令放到后台执行的话，则需要加上这个符号。通常用于命令运行时间非常长的情况。 >, &gt;&gt;, 2&gt;, 2&gt;&gt; ：重定向符号&gt; 以及&gt;&gt; 分别表示取代和追加的意思，然后还有两个符号就是这里的2&gt; 和 2&gt;&gt; 分别表示错误重定向和错误追加重定向，当我们运行一个命令报错时，报错信息会输出到当前的屏幕，如果想重定向到一个文本里，则要用2&gt;或者2&gt;&gt; 。 [ ]:中括号，中间为字符组合，代表中间字符中的任意一个。 &amp;&amp; 与 ||: 分号，用于多条命令间的分隔符。还有两个可以用于多条命令中间的特殊符号，那就是 “&amp;&amp;” 和 “||” . command1 ; command2 command1 &amp;&amp; command2 command1 || command2 使用 ”;” 时，不管command1是否执行成功都会执行command2； 使用 “&amp;&amp;” 时，只有command1执行成功后，command2才会执行，否则command2不执行； 使用 “||” 时，command1执行成功后command2 不执行，否则去执行command2，总之command1和command2总有一条命令会执行。 常用的一些命令：命令cut ：用来截取某一个字段。 语法： cut -d &#39;分隔字符&#39; [-cf] n 这里的n是数字。 -d(delimiter):分界符，后面跟分隔字符，分隔字符要用单引号括起来。 -c（characters）：后面接第几个字符。 -f*（fields）：后面接的是第几个区块。 图：cut的具体用法 用法示例： 12345678910111213141516171819202122232425262728293031[root@localhost ~]# cat /etc/passwd | head -n 5root:x:0:0:usr:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin[root@localhost ~]# cat /etc/passwd | cut -d ':' -f 1 | head -n 5rootbindaemonadmlp[root@localhost ~]# cat /etc/passwd | cut -d ':' -f 2 | head -n 5xxxxx[root@localhost ~]# cat /etc/passwd | cut -c 1 | head -n 5rbdal[root@localhost ~]# cat /etc/passwd | cut -c 1-5 | head -n 5root:bin:xdaemoadm:xlp:x:[root@localhost ~]# 在上面的使用中，-d后面跟分割符，这里使用冒号作为分隔符。-f：后面跟截取第几段，1就是截取一段，2就是第二段。-f和1之间的空格可有可无。 -c 后面跟的是第几个字符，后面的数字是1-n，也可以是一个区间，如1-5，也可以是多个数：n1，n2等。 命令sort：用作排序。 语法： sort [-t 分隔符] [-kn1,n2] [-nru] 这里的n1 &lt; n2 常用的选项： t（field-separator）：分隔符：作用和cut的-d是一个意思。 -n（numeric-sort）：使用纯数字排序。 -r（reverse）：反向排序。 -u（unique）：去重复。 -kn1，n2：由n1区间排序到n2区间。可以只写-kn1，即对n1字段排序。 sort命令使用示例： 123456[root@localhost ~]# head -n5 /etc/passwd | sortadm:x:3:4:adm:/var/adm:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinroot:x:0:0:usr:/root:/bin/bash 如果sort不加任何选项，则从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。 123456[root@localhost ~]# head -n5 /etc/passwd | sort -t : -k3 -nroot:x:0:0:usr:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin -t 后面跟分隔符，-k后面跟数字，表示对第几个区域的字符串排序，-n 则表示使用纯数字排序。上面这条命令：以：为分割符，对第三个区域的数据进行排序。 123456[root@localhost ~]# head -n5 /etc/passwd | sort -t: -k3,5 -rlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinroot:x:0:0:usr:/root:/bin/bash -k3,5 表示从第3到第5区域间的字符串排序，-r表示反向排序。 命令wc：用于统计文档的行数、字符数、词数。 用法：wc 选项 文件 。 常用的选项有： -l （lines）：统计行数 -m （chars）：统计字符数 -w （words）：统计词数 wc 不跟任何选项，直接跟文档，则会把行数、词数、字符数依次输出。 12345678[root@localhost ~]# wc /etc/passwd 47 90 2420 /etc/passwd[root@localhost ~]# wc -l /etc/passwd47 /etc/passwd[root@localhost ~]# wc -m /etc/passwd2416 /etc/passwd[root@localhost ~]# wc -w /etc/passwd90 /etc/passwd 命令uniq：去重复的行。 语法：uniq 参数 文件名 常用的选项： -c：统计重复的行数，并把行数写在前面。 使用uniq 的前提是需要先给文件排序，否则不管用。 使用示例： 123456789101112131415161718192021[root@localhost ~]# cat test.txt 1122332211[root@localhost ~]# sort test.txt 1111222233[root@localhost ~]# sort test.txt | uniq 112233[root@localhost ~]# sort test.txt | uniq -c 2 11 2 22 1 33[root@localhost ~]# 命令tee：标准输入复制到每个指定文件，并显示到标准输出。 用法：tee [选项]... [文件]... -a(append) : 内容追加到给定的文件而非覆盖。 后跟文件名，类似与重定向 “&gt;”, 但是比重定向多了一个功能，在把文件写入后面所跟的文件中的同时，还显示在屏幕上。 tee 常用语管道符 “|” 后。 123456789[root@localhost ~]# echo "44" | tee test.txt 44[root@localhost ~]# cat test.txt 44[root@localhost ~]# echo "55" | tee -a test.txt 55[root@localhost ~]# cat test.txt 4455 命令tr：从标准输入中替换、缩减和/或删除字符，并将结果写到标准输出。 用法：tr [选项]... SET1 [SET2] 常用的选项有两个： -d(delete) ：删除某个字符，-d 后面跟要删除的字符 -s(squeeze-repeats) ：把重复的字符去掉. 最常用的就是把小写变大写: tr ‘[a-z]’ ‘[A-Z]’ SET 是一组字符串，一般都可按照字面含义理解。解析序列如下： \NNN 八进制值为NNN 的字符(1 至3 个数位) \ 反斜杠 \a 终端鸣响 \b 退格 \f 换页 \n 换行 \r 回车 \t 水平制表符 \v 垂直制表符 字符1-字符2 从字符1 到字符2 的升序递增过程中经历的所有字符 [字符] 在SET2 中适用，指定字符会被连续复制直到吻合设置1 的长度 [字符次数] 对字符执行指定次数的复制，若次数以 0 开头则被视为八进制数 [:alnum:] 所有的字母和数字 [:alpha:] 所有的字母 [:blank:] 所有呈水平排列的空白字符 [:cntrl:] 所有的控制字符 [:digit:] 所有的数字 [:graph:] 所有的可打印字符，不包括空格 [:lower:] 所有的小写字母 [:print:] 所有的可打印字符，包括空格 [:punct:] 所有的标点字符 [:space:] 所有呈水平或垂直排列的空白字符 [:upper:] 所有的大写字母 [:xdigit:] 所有的十六进制数 [=字符=] 所有和指定字符相等的字符 用法示例： 12345678910111213141516171819[root@localhost ~]# head -n5 /etc/passwd | tr '[a-z]' '[A-Z]'ROOT:X:0:0:USR:/ROOT:/BIN/BASHBIN:X:1:1:BIN:/BIN:/SBIN/NOLOGINDAEMON:X:2:2:DAEMON:/SBIN:/SBIN/NOLOGINADM:X:3:4:ADM:/VAR/ADM:/SBIN/NOLOGINLP:X:4:7:LP:/VAR/SPOOL/LPD:/SBIN/NOLOGIN[root@localhost ~]# head -n5 /etc/passwd root:x:0:0:usr:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin[root@localhost ~]# head -n5 /etc/passwd | tr 'r' 'R' # 替换一个字符Root:x:0:0:usR:/Root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/vaR/adm:/sbin/nologinlp:x:4:7:lp:/vaR/spool/lpd:/sbin/nologin[root@localhost ~]# 替换、删除以及去重复都是针对一个字符来讲的，有一定局限性。如果是针对一个字符串就不再管用了。 命令splist：切割文档。 用法：split [选项]... [输入 [前缀]] 常用选项： -b ：依据大小来分割文档，单位为byte。 -l（lines） ：依据行数来分割文档。 如果split不指定目标文件名，则会以xaa xab… 这样的文件名来存取切割后的文件。当然我们也可以指定目标文件名。 用法示例： 1234567891011121314[root@localhost ~]# split test.txt [root@localhost ~]# mkdir splist_dir[root@localhost ~]# cd !$cd splist_dir[root@localhost splist_dir]# cp /etc/passwd ./[root@localhost splist_dir]# lspasswd[root@localhost splist_dir]# split -b500 passwd [root@localhost splist_dir]# lspasswd xaa xab xac xad xae[root@localhost splist_dir]# split -b500 passwd 123[root@localhost splist_dir]# ls123aa 123ab 123ac 123ad 123ae passwd xaa xab xac xad xae[root@localhost splist_dir]#]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装RPM包或者安装源码包]]></title>
    <url>%2F2018%2F06%2F22%2F%E5%AE%89%E8%A3%85RPM%E5%8C%85%E6%88%96%E8%80%85%E5%AE%89%E8%A3%85%E6%BA%90%E7%A0%81%E5%8C%85%2F</url>
    <content type="text"><![CDATA[RPM工具使用方法：RPM是 “Redhat Package Manager” 的缩写，根据名字也能猜到这是Redhat公司开发出来的。RPM 是以一种数据库记录的方式来将所需要的套件安装到Linux 主机的一套管理程序。也就是说，linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM包是预先在linux机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。 如果光驱中还有系统安装盘的话，我们可以通过 mount /dev/cdrom /mnt命令把光驱挂载到/mnt目录下，那么在/mnt/Packages目录下看到很多.rpm的文件，这就是RPM包了。 每一个rpm包的名称都由 - 和 . 分成了若干部分。就拿 “abrt-cli-2.0.8-15.el6.centos.i686.rpm” 这个包来解释一下， “abrt-cli” 为包名， “2.0.8” 则为版本信息， “15.el6.centos” 为发布版本号， “i686” 为运行平台。其中运行平台常见的有i386, i586, i686, x86_64 ，需要注意的是cpu目前是分32位和64位的，i386,i586和i686都为32位平台，x86_64则代表为64位的平台。另外有些rpm包并没有写具体的平台而是noarch，这代表这个rpm包没有硬件平台限制。例如 “alacarte-0.10.0-1.fc6.noarch.rpm”. 下面介绍一下rpm常用的命令。 1.安装一个rpm包： 用法：rpm -ivh rpm_name 参数解释： -i（install）：安装软件包。 -v（verbose）：显示安装的过程信息。可视化。 -h（hash）：软件安装的时候列出哈希标记。即显示安装进度。 另外在安装一个rpm包时常用的附带参数有： --force : 强制安装，即使覆盖属于其他包的文件也要安装 --nodeps : 当要安装的rpm包依赖其他包时，即使其他包没有安装，也要安装这个包。 2.升级一个rpm包： 命令：rpm -Uvh filename -U（upgrade）：升级软件包。 -v，-h：同上，显示安装过程。 3.卸载一个rpm包： 命令：rpm -e filename -e（erase擦去，抹去，除掉）：清除，卸载软件包。 卸载时后边跟的filename和安装时的是有区别的，安装时是把一个存在的文件作为参数，而卸载时只需要包名即可。 4.查询一个包是否安装： 命令：rpm -q rpm包名 (这里的包名，是不带有平台信息以及后缀名的) -q（query查询）：查询选项。 -a（all）：查询/验证所有软件包。 可以使用 rpm -qa 查询当前系统所有安装过的rpm包。 123456789101112[hadoop@localhost ~]$ rpm -qa | head ipa-client-common-4.5.4-10.el7.centos.1.noarchkbd-legacy-1.15.5-13.el7.noarchgutenprint-5.2.9-18.el7.x86_64pycairo-1.8.10-8.el7.x86_64gnu-free-serif-fonts-20120503-8.el7.noarchtzdata-2018c-1.el7.noarchm17n-lib-1.6.4-14.el7.x86_64iprutils-2.4.15.1-1.el7.x86_64xdg-desktop-portal-0.5-2.el7.x86_64pango-1.40.4-1.el7.x86_64[hadoop@localhost ~]$ 5.得到一个已安装rpm包的相关信息： 命令：rpm -qi b包名 （同样不需要加平台信息与后缀名） -i(info):列出软件包的详细信息。rpm -q –info ibus 图：查询ibus示例 6.列出一个rpm包安装的文件： 命令 rpm -ql 包名 -l（list）：列出软件包中的文件。 -s（state）：显示列出文件的状态。 12345678910111213141516171819[hadoop@localhost ~]$ rpm -ql ibus | head/etc/X11/xinit/xinput.d/etc/X11/xinit/xinput.d/ibus.conf/etc/dconf/db/ibus.d/etc/dconf/db/ibus.d/00-upstream-settings/etc/dconf/profile/ibus/usr/bin/ibus/usr/bin/ibus-daemon/usr/lib64/python2.7/site-packages/gi/overrides/IBus.py/usr/lib64/python2.7/site-packages/gi/overrides/IBus.pyc/usr/lib64/python2.7/site-packages/gi/overrides/IBus.pyo[hadoop@localhost ~]$ [hadoop@localhost ~]$ rpm -qs ibus正常/etc/X11/xinit/xinput.d正常/etc/X11/xinit/xinput.d/ibus.conf正常/etc/dconf/db/ibus.d正常/etc/dconf/db/ibus.d/00-upstream-settings正常/etc/dconf/profile/ibus正常/usr/bin/ibus 7.列出某一个文件属于哪个rpm包： 命令 rpm -qf 文件的绝对路径 -f（file）： 查询/验证文件属于的软件包 12[hadoop@localhost ~]$ rpm -qf /usr/libfilesystem-3.2-25.el7.x86_64 8.其他用法总结： 用法：rpm[选项] 123456789101112131415161718192021222324252627282930313233343536373839404142434445[hadoop@localhost ~]$ rpm --help用法: rpm [选项...]#查询/验证软件包选项： -a, --all 查询/验证所有软件包 -f, --file 查询/验证文件属于的软件包 -g, --group 查询/验证组中的软件包 -p, --package 查询/验证一个软件包#查询选项（用 -q 或 --query）： -c, --configfiles 列出所有配置文件 -d, --docfiles 列出所有程序文档 -L, --licensefiles list all license files -l, --list 列出软件包中的文件 -s, --state 显示列出文件的状态#验证选项（用 -V 或 --verify）： --nofiledigest 不验证文件摘要 --nofiles 不验证软件包中文件 --nodeps 不验证包依赖 --noscript 不执行验证脚本#安装/升级/擦除选项： --allfiles 安装全部文件，包含配置文件，否则配置文件会被跳过。 -e, --erase=&lt;package&gt;+ 清除 (卸载) 软件包 --excludedocs 不安装程序文档 --excludepath=&lt;path&gt; 略过以 &lt;path&gt; 开头的文件 --force --replacepkgs --replacefiles 的缩写 -F, --freshen=&lt;packagefile&gt;+ 如果软件包已经安装，升级软件包 -h, --hash 软件包安装的时候列出哈希标记 --ignoresize 在安装前不检查磁盘空间 -i, --install 安装软件包 --justdb 更新数据库，但不修改文件系统 --nodeps 不验证软件包依赖 --nofiledigest 不验证文件摘要 --noorder 不对软件包安装重新排序以满足依赖关系 --noscripts 不执行软件包脚本 --notriggers 不执行本软件包触发的任何脚本 --oldpackage 更新到软件包的旧版本(带 --force 自动完成这一功能) --percent 安装软件包时打印百分比 --replacefiles 忽略软件包之间的冲突的文件 --replacepkgs 如果软件包已经有了，重新安装软件包 --test 不真正安装，只是判断下是否能安装 -U, --upgrade=&lt;packagefile&gt;+ 升级软件包 yum工具使用方法（常用）：yum最大的优势在于可以联网去下载所需要的rpm包，然后自动安装，在这个工程中如果要安装的rpm包有依赖关系，yum会帮您解决掉这些依赖关系依次安装所有rpm包。 1.列出所有可用的rpm包： 命令：yum list 12345678910111213141516[hadoop@localhost ~]$ yum list | head -n 15已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.sohu.com * extras: mirrors.sohu.com * updates: mirrors.sohu.com已安装的软件包GConf2.x86_64 3.2.6-8.el7 @base GeoIP.x86_64 1.5.0 11.el7 @anacondaModemManager.x86_64 1.6.10-1.el7 @base ModemManager-glib.x86_64 1.6.10-1.el7 @base NetworkManager.x86_64 1:1.10.2-14.el7_5 @updates NetworkManager-adsl.x86_64 1:1.10.2-14.el7_5 @updates NetworkManager-bluetooth.x86_64 1:1.10.2-14.el7_5 @updates NetworkManager-glib.x86_64 1:1.10.2-14.el7_5 @updates NetworkManager-libnm.x86_64 1:1.10.2-14.el7_5 @updates 从上例中可以看到有 “mirrors.btte.net” 信息出现，这是在告诉用户，它是从mirrors.btte.net这里下载到的rpm包资源。从上面的例子中还可以看到最左侧是rpm包名字，中间是版本信息，最右侧是安装信息，如果安装了就显示类似 “@anaconda-CentOS”, “@base” 或者 “@extras”, 他们前面都会有一个 “@” 符号，这很好区分。未安装则显示base或者extras, 如果是该rpm包已安装但需要升级则显示updates。”yum list” 会先列出已经安装的包(Installed Packages) 然后再列出可以安装的包(Available Packages)。 2.搜索一个rpm包： 命令 yum search [相关关键词] 除了这样搜索外，常用的是利用grep来过滤。 例如：yum list | grep vim 图：搜索软件包 3.安装一个rpm包： 命令： yum install [-y] [rpm包名] 如果不加 “-y” 选项，则会以与用户交互的方式安装，首先是列出需要安装的rpm包信息，然后会问用户是否需要安装，输入y则安装，输入n则不安装。 直接加上 “-y” 选项，这样就省略掉了问用户是否安装的那一步。 4.卸载一个rpm包： 命令：yum remove [-y] rpm包名 5.升级一个rpm包： 命令 ：yum update [-y] [rpm包] 6.yum其他用法： 12345678910111213141516171819202122check 检查 RPM 数据库问题check-update 检查是否有可用的软件包更新clean 删除缓存数据deplist 列出软件包的依赖关系distribution-synchronization 已同步软件包到最新可用版本downgrade 降级软件包erase 从系统中移除一个或多个软件包groups 显示或使用、组信息help 显示用法提示history 显示或使用事务历史info 显示关于软件包或组的详细信息install 向系统中安装一个或多个软件包list 列出一个或一组软件包load-transaction 从文件名中加载一个已存事务provides 查找提供指定内容的软件包reinstall 覆盖安装软件包repo-pkgs 将一个源当作一个软件包组，这样我们就可以一次性安装/移除全部软件包。repolist 显示已配置的源search 在软件包详细信息中搜索指定字符串update 更新系统中的一个或多个软件包upgrade 更新软件包同时考虑软件包取代关系version 显示机器和/或可用的源版本。 使用本地的光盘来制作一个yum源：有时候您的linux系统不能联网，当然就不能很便捷的使用联网的yum源了，这时候就需要会利用linux系统光盘制作一个yum源。具体步骤如下： a）挂载光盘 1[root@localhost ~]# mount /dev/cdrom /mnt b）删除/etc/yum.repos.d目录所有的repo文件 1[root@localhost ~]# rm -rf /etc/yum.repos.d/* c） 创建新文件dvd.repo 1[root@localhost ~]# vim /etc/yum.repos.d/dvd.repo 加入以下内容： 12345[dvd]name=install dvdbaseurl=file:///mntenabled=1gpgcheck=0 d） 刷新 repos 生成缓存 1[root@localhost ~]# yum makecache 然后就可以使用yum命令安装您所需要的软件包了。 利用yum工具下载一个rpm包：用yum工具下一个rpm包，但是不安装。步骤如下： 检测是否已经安装：rpm -qa |grep yum-utils CentOS7默认安装。如果没有安装则安装，安装命令: yum -y install yum-utils* 创建一个存放安装包的目录：/rpms 下载安装包及依赖存放至/rpms目录下：yumdownloader --resolve --destdir /rpms package-name –destdir 安装包存放位置。–resolve 下载依赖。 安装源码包：在linux下面安装一个源码包是最常用的。安装一个源码包，是需要我们自己把源代码编译成二进制的可执行文件。如果能读得懂这些源代码，那么就可以去修改这些源代码自定义功能，然后再去编译。使用源码包的好处除了可以自定义修改源代码外还可以定制相关的功能，因为源码包在编译的时候是可以附加额外的选项的。 源码包的编译用到了linux系统里的编译器，常见的源码包一般都是用C语言开发的，这也是因为C语言为linux上最标准的程序语言。Linux上的C语言编译器叫做gcc，利用它就可以把C语言变成可执行的二进制文件。所以如果机器上没有安装gcc就没有办法去编译源码。可以使用 yum install -y gcc 来完成安装。 安装一个源码包，通常需要三个步骤： 1）./configure 在这一步可以定制功能，加上相应的选项即可，具有有什么选项可以通过 ./configure --help 命令来查看。在这一步会自动检测您的linux系统与相关的套件是否有编译该源码包时需要的库，因为一旦缺少某个库就不能完成编译。只有检测通过后才会生成一个Makefile文件。 2） make 使用这个命令会根据Makefile文件中预设的参数进行编译，这一步其实就是gcc在工作了。 3） make install 安装步骤，生成相关的软件存放目录和配置文件的过程。 上面介绍的3步并不是所有的源码包软件都一样的，也就是说源码包的安装并非具有一定的标准安装步骤。这就需要拿到源码包解压后，然后进入到目录找相关的帮助文档，通常会以INSTALL或者README为文件名。所以，一定要去看一下。 安装httpd源码包过程示例： 下载一个源码包： 下载源码包一定要去官方站点去下载，不要在网上随便下载，那样很不安全。因为下载到的源码包很有可能是被人修改过的。 下载后的源码包一般都放在/usr/local/src 目录下。方便维护。 123[root@localhost src]# cd /usr/local/src/# cd /usr/local/src/[root@localhost src]# wget https://mirrors.tuna.tsinghua.edu.cn/apache//httpd/httpd-2.4.33.tar.bz2#wget为一个下载工具 解压源码包 1[root@localhost src]# tar -jxvf httpd-2.4.33.tar.bz2 进入解压后的文件，配置相关的选项，并生成Makefile。 可以通过./configure --hlep 命令查看可以使用的选项。一般常用的有 --prefix=PREFIX 这个选项的意思是定义软件包安装到哪里。通常源码包都是安装在/usr/local/目录下的。 图：帮助示例 验证这一步是否成功的命令是： 12[root@localhost httpd-2.2.24]# echo $?0 返回值如果是 “0” 则执行成功，否则就是没有成功。此时就成功生成 Makefile 了。 进行编译 : 运行命令：make 安装： 运行命令：make install 第四第五步也可以合成一步：命令为：make &amp;&amp; make install 安装的过程中会遇到很多问题。一般是缺少库文件所致。只要下载相应的库文件安装即可。 Ubuntu中apt-get工具使用方法：Apt-get的详细用法如下： 123456789101112131415161718192021222324hadoop@ubuntu:~$ apt-get --helpapt 1.2.26 (amd64)用法： apt-get [选项] 命令 apt-get [选项] install|remove 软件包1 [软件包2 ...] apt-get [选项] source 软件包1 [软件包2 ...]#apt-get 可以从认证软件源下载软件包及相关信息，以便安装和升级软件包，#或者用于移除软件包。在这些过程中，软件包依赖会被妥善处理。#常用命令： update - 取回更新的软件包列表信息 upgrade - 进行一次升级 install - 安装新的软件包(注：软件包名称是 libc6 而非 libc6.deb) remove - 卸载软件包 purge - 卸载并清除软件包的配置 autoremove - 卸载所有自动安装且不再使用的软件包 dselect-upgrade - 根据 dselect 的选择来进行升级 build-dep - 为源码包配置所需的编译依赖关系 clean - 删除所有已下载的包文件 autoclean - 删除已下载的旧包文件 check - 核对以确认系统的依赖关系的完整性 source - 下载源码包文件 download - 下载指定的二进制包到当前目录 changelog - 下载指定软件包，并显示其changelog]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文档的压缩与打包]]></title>
    <url>%2F2018%2F06%2F22%2F%E6%96%87%E6%A1%A3%E7%9A%84%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%89%93%E5%8C%85%2F</url>
    <content type="text"><![CDATA[Linux下的压缩文件： 在linux下最常见的压缩文件通常都是以.tar.gz 为结尾的，除此之外还有.tar, .gz, .bz2, .zip等等。linux系统中的后缀名其实要不要无所谓，但是对于压缩文件来讲必须要带上。这是为了判断压缩文件是由哪种压缩工具所压缩，而后才能去正确的解压缩这个文件。以下介绍常见的后缀名所对应的压缩工具。 .gz ：gzip 压缩工具压缩的文件 .bz2： bzip2 压缩工具压缩的文件 .tar： tar 打包程序打包的文件(tar并没有压缩功能，只是把一个目录合并成一个文件) .tar.gz ：可以理解为先用tar打包，然后再gzip压缩 .tar.bz2 ：同上，先用tar打包，然后再bzip2压缩 gzip压缩工具：语法： gzip [-d#] filename 其中#为1-9的数字 “-d” : 解压缩时使用 “-#” : 压缩等级，1压缩最差，9压缩最好，6为默认 gzip 后面直接跟文件名，就在当前目录下把该文件压缩了，而原文件也会消失。 “gzip -d” 后面跟压缩文件，会解压压缩文件。gzip 是不支持压缩目录的。 gzip其他具体用法如下： 图：gzip具体用法 -d(decompress): 解压文件。 -l（list）：列出压缩文件内容。 -q(quiet)：抑制所有警告。 -r（recursive）：递归的操作目录。 -t（test）：测试压缩文件的完整性。 -1：快速压缩。 -9：压缩等级最高。 123456789101112131415161718192021[root@localhost ~]# mkdir Dir[root@localhost ~]# lsanaconda-ks.cfg Dir Downloads Pictures TemplatesDesktop Documents Music Public Videos[root@localhost ~]# cd Dir[root@localhost Dir]# ls[root@localhost Dir]# touch file.txt[root@localhost Dir]# lsfile.txt[root@localhost Dir]# gzip file.txt [root@localhost Dir]# lsfile.txt.gz[root@localhost Dir]# cd ../[root@localhost ~]# gzip Dirgzip: Dir is a directory -- ignored[root@localhost ~]# cd Dir[root@localhost Dir]# lsfile.txt.gz[root@localhost Dir]# gzip -d file.txt.gz [root@localhost Dir]# lsfile.txt bzip2压缩工具：语法： bzip2 [-dz] filename bzip2 只有两个选项需要掌握。 “-d” : 解压缩 “-z” : 压缩。压缩时，可以加 “-z” 也可以不加，都可以压缩文件，”-d” 则为解压的选项： bzip2 同样也不可以压缩目录 bzip2其他具体用法如下： 图：bzip2具体用法 tar压缩工具：tar 本身为一个打包工具，可以把目录打包成一个文件，它的好处是它把所有文件整合成一个大文件整体，方便拷贝或者移动。 语法：tar [-zjxcvfpP] filename “-z” : 同时用gzip压缩 “-j” : 同时用bzip2压缩 “-x”(extract) (提取) ：解包或者解压缩 “-t”(list) : 查看tar包里面的文件,列出归档内容。 “-c” （create）: 建立一个tar包或者压缩文件包 “-v” （verbose）：详细地列出处理的文件。可视化。 “-f” : 后面跟文件名，压缩时跟 “-f 文件名”，意思是压缩后的文件名为filename, 解压时跟 “-f 文件名”，意思是解压filename. 请注意，如果是多个参数组合的情况下带有 “-f”，请把 “-f” 写到最后面。 “-p” : 使用原文件的属性，压缩前什么属性压缩后还什么属性。（不常用） “-P” : 可以使用绝对路径。（不常用） --exclude filename : 在打包或者压缩时，不要将filename文件包括在内。（不常用） 其他用法可使用tar –help来查看。 tar，打包还是解包，原来的文件是不会删除的，而且它会覆盖当前已经存在的文件或者目录。 打包的同时使用gzip压缩（常用）： tar命令非常好用的一个功能就是可以在打包的时候直接压缩，它支持gzip压缩和bzip2压缩。 “-cvzf”:可以在打包的同时使用gzip压缩。 “-tf” 可以查看包或者压缩包的文件列表. “-zxvf” 用来解压.tar.gz的压缩包. 具体操作示例如下： 图：打包的同时使用gzip压缩和解压缩 打包的同时使用bzip2压缩： 和gzip压缩不同的是，这里使用 “-cjvf” 选项来压缩。同样可以使用 “-tf” 来查看压缩包文件列表。 图：使用bzip2来压缩解压文件 –exclude的使用方法： 语法：tar -cvf Dir.tar --exclude file.txt Dir 请注意，Dir.tar是放到了 –exclude 选项的前面。该选项除了可以排除文件，也可以排除目录。 1234567891011121314151617[root@localhost ~]# lsanaconda-ks.cfg Dir Downloads Pictures TemplatesDesktop Documents Music Public Videos[root@localhost ~]# cd Dir[root@localhost Dir]# lsfile.txt NewDir[root@localhost Dir]# cd ../[root@localhost ~]# tar -cvf Dir.tar --exclude file.txt DirDir/Dir/NewDir/[root@localhost ~]# lsanaconda-ks.cfg Dir Documents Music Public VideosDesktop Dir.tar Downloads Pictures Templates[root@localhost ~]# tar -tf Dir.tarDir/Dir/NewDir/[root@localhost ~]#]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的文本编辑工具vim]]></title>
    <url>%2F2018%2F06%2F22%2FLinux%E7%9A%84%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%B7%A5%E5%85%B7vim%2F</url>
    <content type="text"><![CDATA[Linux vi/vim:所有的 Unix Linux系统都会内建 vi 文本编辑器，其他的文书编辑器则不一定会存在。 但是目前我们使用比较多的是 vim 编辑器。 vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 vi 和vim最大的区别就是编辑一个文本时，vi不会显示颜色，而vim会显示颜色。显示颜色更易于用户进行编辑。 vim的模式：vim的三种模式：一般模式、编辑模式、命令模式。 一般模式： 当您vim filename 编辑一个文件时，一进入该文件就是一般模式了。在这个模式下，您可以做的操作有，上下移动光标；删除某个字符；删除某行；复制、粘贴一行或者多行。 编辑模式：一般模式下，是不可以修改某一个字符的，只能到编辑模式了。从一般模式进入编辑模式，只需您按一个键即可（i, I, a, A, o, O, r, R）。当进入编辑模式时，会在屏幕的最下一行出现“INSERT或REPLACE”的字样。从编辑模式回到一般模式只需要按一下键盘左上方的ESC键即可。 命令模式：在一般模式下，输入 ”:” 或者 “/” 即可进入命令模式。在该模式下，您可以搜索某个字符或者字符串，也可以保存、替换、退出、显示行号等等。 vim三种模式之间的转换关系可以表示如下： 图：vim三种模式之间的关系 vim的常用命令：一般模式下移动光标： h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 如果将右手放在键盘上的话，会发现 hjkl 是排列在一起的，因此可以使用这四个按钮来移动光标。 如果想要进行多次移动的话，例如向下移动 30 行，可以使用 “30j” 或 “30↓” 的组合按键， 亦即加上想要进行的次数(数字)后，按下动作即可！ [Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) [Ctrl] + [d] 屏幕『向下』移动半页 [Ctrl] + [u] 屏幕『向上』移动半页 + 光标移动到非空格符的下一行 - 光标移动到非空格符的上一行 n&lt; space &gt; 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一行的 n 个字符。例如 20&lt; space &gt; 则光标会向后面移动 20 个字符距离。 0 或功能键[Home] 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处(常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个档案的最后一行(常用) nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) gg 移动到这个档案的第一行，相当于 1G 啊！ (常用) n&lt; Enter&gt; n 为数字。光标向下移动 n 行(常用) 搜索与替换： /word 向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 vbird 这个字符串，就输入 /vbird 即可！ (常用) ?word 向光标之上寻找一个字符串名称为 word 的字符串。 n 这个 n 是英文按键。代表重复前一个搜寻的动作。举例来说， 如果刚刚我们执行 /vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为 vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为 vbird 的字符串！ N 这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 /vbird 后，按下 N 则表示『向上』搜寻 vbird 。 使用 /word 配合 n 及 N 是非常有帮助的！可以让你重复的找到一些你搜寻的关键词！ :n1,n2s/word1/word2/g n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则：『:100,200s/vbird/VBIRD/g』。(常用) :1,$s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！(常用) :1,$s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用) 删除、复制与粘贴： x, X 在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用) nx n 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。 dd 删除游标所在的那一整行(常用) ndd n 为数字。删除光标所在的向下 n 行，例如 20dd 则是删除 20 行 (常用) d1G 删除光标所在到第一行的所有数据 dG 删除光标所在到最后一行的所有数据 d$ 删除游标所在处，到该行的最后一个字符 d0 那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符 yy 复制游标所在的那一行(常用) nyy n 为数字。复制光标所在的向下 n 行，例如 20yy 则是复制 20 行(常用) y1G 复制游标所在行到第一行的所有数据 yG 复制游标所在行到最后一行的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！ 举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？ 那么原本的第 20 行会被推到变成 30 行。 (常用) J 将光标所在行与下一行的数据结合成同一行 c 重复删除多个数据，例如向下删除 10 行，[ 10cj ] u 复原前一个动作。(常用) [Ctrl]+r 重做上一个动作。(常用) 这个 u 与 [Ctrl]+r 是很常用的指令！一个是复原，另一个则是重做一次～ 利用这两个功能按键，你的编辑，嘿嘿！很快乐的啦！ . 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用) 一般模式切换到编辑模式的可用按钮说明： i, I 进入输入模式(Insert mode)：i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』。 (常用) a, A 进入输入模式(Insert mode)：a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』。(常用) o, O 进入输入模式(Insert mode)：这是英文字母 o 的大小写。o 为『在目前光标所在的下一行处输入新的一行』； O 为在目前光标所在处的上一行输入新的一行！(常用) r, R 进入取代模式(Replace mode)：r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止；(常用) 上面这些按键中，在 vi 画面的左下角处会出现『–INSERT–』或『–REPLACE–』的字样。 由名称就知道该动作了吧！！特别注意的是，我们上面也提过了，你想要在档案里面输入字符时， 一定要在左下角处看到 INSERT 或 REPLACE 才能输入喔！ [Esc] 退出编辑模式，回到一般模式中(常用) 一般模式切换到指令模式的可用按钮说明：指令行的存储、离开等指令： w 将编辑的数据写入硬盘档案中(常用) :w! 若文件属性为『只读』时，强制写入该档案。不过，到底能不能写入， 还是跟你对该档案的档案权限有关啊！ :q 离开 vi (常用) :q! 若曾修改过档案，又不想储存，使用 ! 为强制离开不储存档案。 注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～ :wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用) ZZ 这是大写的 Z 喔！若档案没有更动，则不储存离开，若档案已经被更动过，则储存后离开！ :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中，读入另一个档案的数据。亦即将 『filename』 这个档案内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案。 :! command 暂时离开 vi 到指令行模式下执行 command 的显示结果！例如『:! ls /home』即可在 vi 当中察看 /home 底下以 ls 输出的档案信息！ vim环境的变更： :set nu 显示行号，设定之后，会在每一行的前缀显示该行的行号 :set nonu 与 set nu 相反，为取消行号！]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux磁盘管理]]></title>
    <url>%2F2018%2F06%2F20%2FLinux%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[查看磁盘或目录的容量：命令df:“df” 查看已挂载磁盘的总容量、使用容量、剩余容量等，可以不加任何参数，默认是按k为单位显示的。 图：df查看磁盘状态示例 df常用的选项有： -i ：显示inode 信息而非块使用量。 -h : 使用合适的单位显示，例如：M，K，G等。 -k：以K为单位显示。 -m：以M为单位显示。 图：df常用参数使用示例 命令du：du” 用来查看某个目录或文件所占空间大小. 语法 : du [-abckmsh] [文件或者目录名] 常用的参数有： -a（all）：全部文件与目录大小都列出来。 -b（bytes）：列出的值以bytes为单位输出。 -k，-m：分别以K为单位和以M为单位。du默认单位k。 -h(human-readable)：自动调节单位。 -c(total)：最后加总。 -s(summarize)：只列出总和。 图；du用法示例 磁盘的分区和格式化： 如果使用的是vmware虚拟机，可以通过配置新增加一块硬盘，以进行磁盘的操作。步骤如下： 先关闭正在运行的Linux系统 init 0. 到vmware的Linux虚拟机界面，点 “Edit virtual machine settings”, 点一下左侧靠下面的 “Add…” 按钮。 在左侧选中 “Hard Disk” 默认就是这一行，点右下角的 “Next”, 继续点 “Next”. “Virtual disk type” 选择 IDE, 点 “Next” 继续点 “Next”, “Disk size” 默认即可，最后点 “Finish”. 命令fdisk： fdisk 是Linux下硬盘的分区工具，是一个非常实用的命令，但是fdisk只能划分小于2T的分区。 语法 : fdisk [-l ] [设备名称] 图：fdisk用法 “-l” 后边不跟设备名会直接列出系统中所有的磁盘设备以及分区表，加上设备名会列出该设备的分区表。 图：fdisk -l /dev/sda 列出sda的磁盘分区信息 fdisk” 如果不加 “-l” 则进入另一个模式，在该模式下，可以对磁盘进行分区操作。 图：进行分区操作的界面 含义分别如下: 常用的为黑体 a：一个可引导的标志。 b：编辑bsd磁碟标签 c：切换dos兼容标志 d：删除一个分区 g：创建一个新的空GPT分区表 G：创建IRIX（SGI）分区表 l：列出已知的分区类型 m：打印这个菜单 n：增加一个新分区 o：创建一个新的空DOS分区表 p：打印分区表 q：在没有保存更改的情况下退出 s：创建一个新的空的Sun磁盘标签 t：改变分区的系统id u：变化显示/输入单元 v：验证分区表 w：写表到磁盘和出口 x：额外功能（仅限专家） 如下为新建一个主分区的步骤： 图：新建主分区 注意： 在创建分区时，最多只能创建四个主分区。如果想要创建更多分区，那么在创建第四个分区时，选择创建为扩展分区。在分配空间时，要把剩余空间都分配给扩展分区，然后就会被浪费掉。因为分完扩展分区后，再划分新的分区时是在已经划分的扩展分区里来分的。扩展分区时不可以格式化的，可以把它当成一个空壳子，在扩展分区下可以创建多个逻辑分区。而逻辑分区都是从sdb5开始的。如果想删掉某个分区，用命令d即可删除。 图：增加逻辑分区，删除分区操作 在删除分区时，如果删除了扩展分区，那么扩展分区下面的逻辑分区都会被删除掉。 分区完后，按w保存配置信息，然后按q退出即可。用fdisk -l 磁盘号，查看分区情况。 图：查看示例 在进行分区操作时，切记小心，一不小心，就可能把服务器的数据都删除掉。 格式化磁盘分区：命令 : mke2fs, mkfs.ext2, mkfs.ext3, mkfs.ext4当用man查询这四个命令的帮助文档时，您会发现我们看到了同一个帮助文档，这说明四个命令是一样的。mke2fs常用的选项有： ‘-b’ : 分区时设定每个数据区块占用空间大小，目前支持1024, 2048 以及4096 bytes每个块。 ‘-i’ ：设定inode的大小 ‘-N’： 设定inode数量，有时使用默认的inode数不够用，所以要自定设定inode数量。 ‘-c’： 在格式化前先检测一下磁盘是否有问题，加上这个选项后会非常慢 ‘-L’： 预设该分区的标签label ‘-j’ ：建立ext3格式的分区，如果使用mkfs.ext3 就不用加这个选项了 ‘-t’ ：用来指定什么类型的文件系统，可以是ext2, ext3 也可以是 ext4. 图：格式化示例 如上图，指定文件系统为ext4，标签fdisk。该命令直接等同于mkfs.ext4 /dev/sdb3， 目前CentOS7默认文件系统格式都为xfs。 在格式化中，有个块大小设置，默认为4096，即4k，需要指定块大小时，加-b 4096/2048等即可。 命令e2label:用来查看或修改分区的标签。比较少用。 图：查看和修改标签 挂载和卸载磁盘：在上面的内容中讲到了磁盘的分区和格式化，那么格式化完了后，如何去用它呢？这就涉及到了挂载这块磁盘。格式化后的磁盘其实是一个块设备文件，类型为b，也许您会想，既然这个块文件就是那个分区，那么直接在那个文件中写数据不就写到了那个分区中么？当然不行。 在挂载某个分区前需要先建立一个挂载点，这个挂载点是以目录的形式出现的。一旦把某一个分区挂载到了这个挂载点（目录）下，那么再往这个目录写数据使，则都会写到该分区中。这就需要注意一下，在挂载该分区前，挂载点（目录）下必须是个空目录。其实目录不为空并不影响所挂载分区的使用，但是一旦挂载上了，那么该目录下以前的东西就不能看到了。只有卸载掉该分区后才能看到。 命令mount：mount的用来挂载磁盘，具体用法如下： 图：mount的用法 如果不加任何选项，直接运行mount命令：这个命令可以查看当前系统已经挂载的所有分区，以及分区文件系统的类型，挂载点和一些选项等信息。如下图： 图：mount命令运行结果 在进行挂载分区前，先新建一个空目录，然后在目录里新建一个空白文档。然后把刚才格式化的/dev/sdb3挂载到该目录下。。具体操作如下： 我们也可以使用LABEL的方式挂载分区：mount LABEL=fdisk /mountPoint/ 图：挂载磁盘示例 mount 命令常用的选项有：’-a’, ‘-t’, ‘-o’. 在讲 ‘-a’ 选项前，我们有必要先了解一下这个文件 /etc/fstab. 123456789101112[hadoop@localhost ~]$ cat /etc/fstab## /etc/fstab# Created by anaconda on Wed Jun 6 04:23:31 2018## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/centos-root / xfs defaults 0 0UUID=0b59d613-ef63-4234-ae0b-5086cef89248 /boot xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0 这个文件是系统启动时，需要挂载的各个分区。第一列就是分区的标识，可以写分区的LABEL，也可以写分区的UUID，当然也可以写分区名(/dev/sda1)；第二列是挂载点；第三列是分区的格式；第四列则是mount的一些挂载参数，等下会详细介绍一下有哪些参数，一般情况下，直接写defaults即可；第五列的数字表示是否被dump备份，是的话这里就是1，否则就是0；第六列是开机时是否自检磁盘。1，2都表示检测，0表示不检测，在Redhat/CentOS中，这个1，2还有个说法，/ 分区必须设为1，而且整个fstab中只允许出现一个1，这里有一个优先级的说法。1比2优先级高，所以先检测1，然后再检测2，如果有多个分区需要开机检测那么都设置成2吧，1检测完了后会同时去检测2。下面为第四列中常用到的参数。 async/sync” : async表示和磁盘和内存不同步，系统每隔一段时间把内存数据写入磁盘中，而sync则会时时同步内存和磁盘中数据； “auto/noauto” : 开机自动挂载/不自动挂载； “default” : 按照大多数永久文件系统的缺省值设置挂载定义，它包含了rw, suid, dev, exec, auto, nouser, async “ro” : 按只读权限挂载 ； “rw” : 按可读可写权限挂载 ； “exec/noexec” : 允许/不允许可执行文件执行，但千万不要把根分区挂载为noexec，那就无法使用系统了，连mount命令都无法使用了，这时只有重新做系统了； “user/nouser” : 允许/不允许root外的其他用户挂载分区，为了安全考虑，请用nouser ； “suid/nosuid” : 允许/不允许分区有suid属性，一般设置nosuid ； “usrquota” : 启动使用者磁盘配额模式，磁盘配额相关内容在后续章节会做介绍； “grquota” : 启动群组磁盘配额模式； 学完这个/etc/fstab后，我们就可以自己修改这个文件，增加一行来挂载新增分区。 执行 vim /etc/fatab 按 i 进入插入模式：在最后一行，添加如下内容：/dev/sdb3/ /mountPoint/ ext4 defaults 0 0 ,然后按wq保存退出。 应为先前已经在/mountPoint/下挂载了该磁盘，首先执行umount /dev/sdb3 卸载该磁盘。然后执行df -h 查看挂载的磁盘，此时会发现磁盘卸载成功。 然后在执行 mount -a, 此时再输入df -h 查看挂载磁盘，会发现/dev/sdb3/ 又重新挂载到了/mountPoint/目录下。操作示例如下图： 图：mount -a的作用 ‘-a’ 选项会把/etc/fstab中出现的所有磁盘分区挂载上。 ‘-t’ 选项用来指定挂载的分区类型，默认不指定会自动识别。 ‘-o’ 选项用来指定挂载的分区有哪些特性，即上面 “/etc/fatab” 配置文件中第四列的那些。 图：mount -o配置示例 如上图，因为配置了ro，所有该分区成了只读。 通过mount命令，可以看到/dev/sdb3的信息如下： 1/dev/sdb3 on /mountPoint type ext4 (ro,relatime,sync,seclabel,data=ordered) 通过mount -o remount /dev/sdb3 /mountPoint/ 重新挂载来恢复读写。 命令blkid：假如在一台服务器上新装了两块磁盘，磁盘a（在服务器上显示为sdc）和磁盘b（在服务器上显示为sdd），有一次把这两块磁盘都拔掉了，然后再重新插上，重启机器，结果磁盘编号调换了，a变成了sdd，b变成了sdc（这是因为把磁盘插错了插槽），问题来了。通过上边的学习，您挂载磁盘是通过/dev/hdb1 这样的分区名字来挂载的，如果先前加入到了/etc/fstab 中，结果系统启动后则会挂载错分区。那么怎么样避免这样的情况发生？ 这就用到了UUID，可以通过 blkid 命令获取各分区的UUID: 12345678[root@localhost mountPoint]# blkid /dev/sda1: UUID="0b59d613-ef63-4234-ae0b-5086cef89248" TYPE="xfs" /dev/sda2: UUID="aouLF3-Rp2s-H1cO-rSyA-imRI-qqRU-qCtmAY" TYPE="LVM2_member" /dev/sdb1: LABEL="Label" UUID="beadb214-e697-494e-8caa-f92ee3f3b963" TYPE="ext4" /dev/sdb3: LABEL="fdisk" UUID="aef7352c-4ad6-44ba-91e9-1edc9236c291" TYPE="ext4" /dev/sr0: UUID="2018-05-03-20-55-23-00" LABEL="CentOS 7 x86_64" TYPE="iso9660" PTTYPE="dos" /dev/mapper/centos-root: UUID="f9453016-07b9-488a-8060-fabefdaeb086" TYPE="xfs" /dev/mapper/centos-swap: UUID="e11bdf96-040b-44f3-8f43-7906eea020d5" TYPE="swap" 这样可以获得全部磁盘分区的UUID，如果格式化的时候指定了 LABEL 则该命令也会显示LABEL值，甚至连文件系统类型也会显示。当然这个命令后面也可以指定哪个分区。 当获取到磁盘的UUID后，也可以通过UUID来挂载磁盘。 例： 1[root@localhost ~]# mount UUID="aef7352c-4ad6-44ba-91e9-1edc9236c291" /mountPoint 也可以将该UUID取代磁盘分区名，写入到/etc/fstab中。 所以在挂载挂载磁盘分区的时候，尽量使用UUID或者LABEL这两种方法。 如果想让某个分区开机后就自动挂载，有两个办法可以实现： 在 /etc/fstab 中添加一行，如上例中那行； 把挂载命令写到 /etc/rc.d/rc.local 文件中去。系统启动完后会执行这个文件中的命令，所以只要您想开机后运行什么命令统统写入到这个文件下面吧，直接放到最后面即可。 命令umount：这个命令用来卸载挂载点。后边可以跟挂载点，也可以跟分区名(/dev/hdb1), 但是不可以跟LABEL和UUID. umount 命令有一个非常有用的选项那就是 ‘-l’, 有时候您会遇到不能卸载的情况： 123456[root@localhost mountPoint]# umount /dev/sdb3umount: /mountPoint：目标忙。 (有些情况下通过 lsof(8) 或 fuser(1) 可以 找到有关使用该设备的进程的有用信息)[root@localhost mountPoint]# umount -l /dev/sdb3[root@localhost mountPoint]# 这是因为当前目录为要卸载的分区上，解决办法有两种，一是到其他目录，二是使用 ‘-l’ 选项。 建立一个swap文件增加虚拟内存：从装系统时就接触过这个swap了，它类似与windows的虚拟内存，分区的时候一般大小为内存的2倍，如果您的内存超过8G，那么分16G似乎是没有必要了。分16G足够日常交换了。然而，还会有虚拟内存不够用的情况发生。如果真遇到了，莫非还要重新给磁盘分区？当然不能，那我们就增加一个虚拟的磁盘出来。基本的思路就是：建立swapfile -&gt; 格式化为swap格式 -&gt; 启用该虚拟磁盘。 命令dd： dd作用是用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。 dd的使用方法，用 “if” 指定源，基本上除了 “/dev/zero” 外基本上不会写别的，而/dev/zero 是UNIX系统特有的一个文件，它可以提供源源不断的 “0”。 “of” 指定目标文件， “bs” 定义块的大小， “count” 定义块的数量，这两个参数的多少决定了目标文件的大小，目标文件大小 = bs x count。 例如：用dd建了一个大小为1G的文件，然后格式化成swap格式： 图：增加交换分区具体操作 增加swap交换文件 1、使用dd命令创建一个swap交换文件 1dd if=/dev/zero of=/home/swap bs=1024 count=1024000 这样就建立一个/home/swap的分区文件，大小为1G。 2、制作为swap格式文件： 1mkswap /home/swap 3、再用swapon命令把这个文件分区挂载swap分区 1/sbin/swapon /home/swap 4、为防止重启后swap分区变成0，要修改/etc/fstab文件 1vi /etc/fstab 在文件末尾（最后一行）加上 1/home/swap swap swap default 0 0 这样就算重启系统，swap分区还是有值。 删除swap交换文件 1、先停止swap分区 1swapoff /home/swap 2、删除swap分区文件 1rm -rf /home/swap 3、删除自动挂载配置命令 1vi /etc/fstab 这行删除 1/home/swap swap swap default 0 0 这样就能把手动增加的交换文件删除了。注意：1、增加删除swap的操作只能使用root用户来操作。2、装系统时分配的swap分区貌似删除不了。3、swap分区一般为内存的2倍，但最大不超过2G 磁盘配额：磁盘配额其实就是给每个用户分配一定的磁盘额度，只允许他使用这个额度范围内的磁盘空间。在linux系统中，是多用户多任务的环境，所以会有很多人共用一个磁盘的情况。针对每个用户去限定一定量的磁盘空间是有必要的，这样才显得公平。随着硬件成本的降低，服务器上的磁盘资源似乎不再刻意的去限制了，所以磁盘配额也就可有可无了。 在linux中，用来管理磁盘配额的东西就是quota了。如果您的linux上没有quota，则需要您安装这个软件包 quota-3.13-5.el5.RPM 。quota在实际应用中是针对整个分区进行限制的。比如，如果我们限制了/dev/sdb1这个分区，而/dev/sdb1 是挂载在/home 目录下的，那么/home 所有目录都会受到限制。 quota 这个模块主要分为quota， quotacheck ，quotaoff ，quotaon ，quotastats ，edquota ，setquota ，warnquota， repquota这几个命令，下面就分别介绍这些命令。 命令：quota “quota” 用来显示某个组或者某个使用者的限额。 语法：quota [-guvs] [user,group] “-g” 显示某个组的限额 “-u” 显示某个用户的限额 “-v” 显示的意思 “-s” 选择inod或硬盘空间来显示 命令 : quotacheck “quotacheck” 用来扫描某一个磁盘的quota空间。 语法：quotacheck [-auvg] /path “-a” 扫描所有已经mount的具有quota支持的磁盘 “-u” 扫描某个使用者的文件以及目录 “-g” 扫描某个组的文件以及目录 “-v” 显示扫描过程 “-m” 强制进行扫描 命令 : edquota “edquota” 用来编辑某个用户或者组的quota值。 语法：edquota [-u user] [-g group] [-t] “-u” 编辑某个用户的quota “-g” 编辑某个组的quota “-t” 编辑宽限时间 “-p” 拷贝某个用户或组的quota到另一个用户或组 当运行 edquota -u user 时，系统会打开一个文件，会看到这个文件中有7列，它们分别代表的含义是： “Filesystem” 磁盘分区，如/dev/sdb5 “blocks” 当前用户在当前的Filesystem中所占用的磁盘容量，单位是Kb。该值请不要修改。 “soft/hard” 当前用户在该Filesystem内的quota值，soft指的是最低限额，可以超过这个值，但必须要在宽限时间内将磁盘容量降低到这个值以下。hard指的是最高限额，即不能超过这个值。当用户的磁盘使用量高于soft值时，系统会警告用户，提示其要在宽限时间内把使用空间降低到soft值之下。 “inodes” 目前使用掉的inode的状态，不用修改。 命令 : quotaon “quotaon” 用来启动quota，在编辑好quota后，需要启动才能是quota生效 语法：quotaon [-a] [-uvg directory] “-a” 全部设定的quota启动 “-u” 启动某个用户的quota “-g” 启动某个组的quota “-s” 显示相关信息 命令 : quotaoff “quotaoff” 用来关闭quota, 该命令常用只有一种情况 quotaoff -a 关闭全部的quota. 下面来进行具体的操作过程： 在本次示例中，将/home目录单独挂载在一个分区下，然后进行操作。所以首先通过df -h检查/home目录是否挂载在一个分区下。如果不是，进行如下操作。编辑/etc/fstab ,将原先添加的那行改为： 1/dev/sdb3/ /home ext4 defaults 0 0 保存退出后，运行mount -a 命令挂载全部的分区。通过df -h可查看是否挂载成功。 123456789101112[root@localhost /]# mount -a[root@localhost /]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/mapper/centos-root 27G 3.9G 24G 15% /devtmpfs 895M 0 895M 0% /devtmpfs 911M 0 911M 0% /dev/shmtmpfs 911M 11M 901M 2% /runtmpfs 911M 0 911M 0% /sys/fs/cgroup/dev/sda1 1014M 152M 863M 15% /boottmpfs 183M 0 183M 0% /run/user/1000tmpfs 183M 12K 183M 1% /run/user/42/dev/sdb3 5.0G 21M 4.7G 1% /home 此时/home 为一个单独的分区。可以进行下面的操作。 （1）建立测试账户： 首先建立一个test用户，则同时建立了一个test组。其中uid和gid都为1003 ，然后又建立一个test1账号，使其加入test组，查看/etc/passwd文件发现test和test1用户的gid都为1003. 123456[root@localhost /]# useradd test[root@localhost /]# grep test /etc/passwdtest:x:1003:1003::/home/test:/bin/bash[root@localhost /]# useradd -g 1003 test1[root@localhost /]# grep test1 /etc/passwdtest1:x:1004:1003::/home/test1:/bin/bash （2）打开磁盘的quota功能 ： 默认linux并没有对任何分区做quota的支持，所以需要我们手动打开磁盘的quota功能。在前面内容中分析/etc/fstab文件的第四列时有过过这个quota选项（usrquota, grpquota），要想打开这个磁盘的quota支持就是需要修改这个第四列的。用vi编辑/etc/fstab 编辑刚才加的那一行，如下: 1/dev/sdb3/ /home ext4 defaults,usrquota,grpquota 0 0 保存后，重新挂载/home分区。 1234[root@localhost /]# umount /home/[root@localhost /]# mount -a[root@localhost /]# mount | grep /home/dev/sdb3 on /home type ext4 (rw,relatime,seclabel,quota,usrquota,grpquota,data=ordered) 此时可以看到/home 分区已经加上了 “usrquota,grpquota” 两个配额相关的参数。 （3）扫描磁盘的使用者使用状况，并产生重要的aquota.group与aquota.user ： 这一步就需要用到quotacheck了，aquota.group与aqouta.user分别是组以及用户磁盘配额需要的配置文件。如果没有这两个文件，则磁盘配额是不会生效的。执行如下命令quotacheck -augv . 通过查看有(aquota.group, aquota.user)两个文件。然后进入下一步。 （4）启动quota配额： 123[root@localhost /]# quotaon -av/dev/sdb3 [/home]: group quotas turned on/dev/sdb3 [/home]: user quotas turned on （5）编辑用户磁盘配额： 先来设定test账户的配额，然后直接把test的配额拷贝给test1即可。这里就需要用到edquota了。 1234[root@localhost ~]# edquota -u testDisk quotas for user test (uid 1003):Filesystem blocks soft hard inodes soft hard /dev/sdb3 28 0 0 7 0 0 将其中soft和hard的数值改为：20000 ，30000。其中单位为Kb，所有soft值大约为20Mb，hard值约为30Mb，保存文件后退出。 下面将test的配额复制给test1. 1[root@localhost ~]# edquota -p test test1 然后通过quota -uv test test1 查看用户的配额。 1234567[root@localhost /]# quota -uv test test1Disk quotas for user test (uid 1003): Filesystem blocks quota limit grace files quota limit grace /dev/sdb3 28 20000 30000 7 0 0 Disk quotas for user test1 (uid 1004): Filesystem blocks quota limit grace files quota limit grace /dev/sdb3 28 20000 30000 （6）编辑组磁盘配额： 1234[root@localhost ~]# edquota -g testDisk quotas for group test (gid 1003):Filesystem blocks soft hard inodes soft hard /dev/sdb3 56 0 0 14 0 0 设定组test的soft配额值为40M，hard值为50M。下面查看组test的配额。 1234[root@localhost /]# quota -gv testDisk quotas for group test (gid 1003): Filesystem blocks quota limit grace files quota limit grace /dev/sdb3 56 40000 50000 14 0 0 （7）设定开机启动： 前面已经讲到启动磁盘配额的命令是 quotaon -aug 所以要想开机启动，只需将这条命令加入到 /etc/rc.d/rc.local文件即可。 1[root@localhost ~]# echo "quotaon -aug" &gt;&gt; /etc/rc.d/rc.local]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux学习笔记</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive常用Shell操作和基础开发]]></title>
    <url>%2F2018%2F06%2F19%2FHive%E5%B8%B8%E7%94%A8Shell%E6%93%8D%E4%BD%9C%E5%92%8C%E5%9F%BA%E7%A1%80%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[Hive常用的HiveQL操作Hive的基本数据类型：Hive支持基本数据类型和复杂类型, 基本数据类型主要有数值类型(INT、FLOAT、DOUBLE ) 、布尔型和字符串, 复杂类型有三种:ARRAY、MAP 和 STRUCT。 a.基本数据类型 TINYINT: 1个字节 SMALLINT: 2个字节 INT: 4个字节 BIGINT: 8个字节 BOOLEAN: TRUE/FALSE FLOAT: 4个字节，单精度浮点型 DOUBLE: 8个字节，双精度浮点型STRING 字符串 b.复杂数据类型 ARRAY: 有序字段 MAP: 无序字段 STRUCT: 一组命名的字段 常用的HiveQL操作命令：创建、修改和删除数据库：12345678create database if not exists hive; #创建数据库show databases; #查看Hive中包含数据库show databases like &apos;h.*&apos;;#查看Hive中以h开头数据库describe databases; #查看hive数据库位置等信息alter database hive set dbproperties;#为hive设置键值对属性use hive; #切换到hive数据库下drop database if exists hive; #删除不含表的数据库drop database if exists hive cascade;#删除数据库和它中的表 注意，除 dbproperties属性外，数据库的元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置，没有办法删除或重置数据库属性。 创建、修改和删除表：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#创建内部表（管理表）create table if not exists hive.usr( name string comment &apos;username&apos;, pwd string comment &apos;password&apos;, address struct&lt;street:string,city:string,state:string,zip:int&gt;, comment &apos;home address&apos;, identify map&lt;int,tinyint&gt; comment &apos;number,sex&apos;) comment &apos;description of the table&apos; tblproperties(&apos;creator&apos;=&apos;me&apos;,&apos;time&apos;=&apos;2016.1.1&apos;); #创建外部表create external table if not exists usr2( name string, pwd string, address struct&lt;street:string,city:string,state:string,zip:int&gt;, identify map&lt;int,tinyint&gt;) row format delimited fields terminated by &apos;,&apos; location &apos;/usr/local/hive/warehouse/hive.db/usr&apos;; #创建分区表create table if not exists usr3( name string, pwd string, address struct&lt;street:string,city:string,state:string,zip:int&gt;, identify map&lt;int,tinyint&gt;) partitioned by(city string,state string); #复制usr表的表模式 create table if not exists hive.usr1 like hive.usr; show tables in hive; show tables &apos;u.*&apos;; #查看hive中以u开头的表describe hive.usr; #查看usr表相关信息alter table usr rename to custom; #重命名表 #为表增加一个分区alter table usr2 add if not exists partition(city=”beijing”,state=”China”) location &apos;/usr/local/hive/warehouse/usr2/China/beijing&apos;; #修改分区路径alter table usr2 partition(city=”beijing”,state=”China”) set location &apos;/usr/local/hive/warehouse/usr2/CH/beijing&apos;; #删除分区alter table usr2 drop if exists partition(city=”beijing”,state=”China”)#修改列信息alter table usr change column pwd password string after address; alter table usr add columns(hobby string); #增加列alter table usr replace columns(uname string);#删除替换列alter table usr set tblproperties(&apos;creator&apos;=&apos;liming&apos;);#修改表属性alter table usr2 partition(city=”beijing”,state=”China”)#修改存储属性set fileformat sequencefile; use hive; #切换到hive数据库下drop table if exists usr1; #删除表drop database if exists hive cascade;#删除数据库和它中的表 视图和索引的创建、修改和删除：主要语法如下： 12create view view_name as....; #创建视图alter view view_name set tblproperties(…);#修改视图 因为视图是只读的，所以 对于视图只允许改变元数据中的 tblproperties属性。 12345#删除视图drop view if exists view_name;#创建索引create index index_name on table table_name(partition_name/column_name) as&apos;org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler&apos; with deferred rebuild....; 里’org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler’是一个索引处理器，即一个实现了索引接口的Java类，另外Hive还有其他的索引实现。 1alter index index_name on table table_name partition(...) rebulid; #重建索引 如果使用 deferred rebuild，那么新索引成空白状态，任何时候可以进行第一次索引创建或重建。 1234#显示索引show formatted index on table_name; #删除索引drop index if exists index_name on table table_name; 用户自定义函数：在新建用户自定义函数（UDF）方法前，先了解一下Hive自带的那些函数。show functions; 命令会显示Hive中所有的函数名称： 12345678910111213141516171819202122hive&gt; show functions;OK!!=$sum0%&amp;*+&gt;&gt;=^absacosadd_monthsaes_decryptaes_encryptandarrayarray_containsascii........ 若要查看具体函数使用方法可使用describe function 函数名： 例如： 12345hive&gt; describe function abs;OKabs(x) - returns the absolute value of xTime taken: 0.491 seconds, Fetched: 1 row(s)hive&gt; 首先编写自己的UDF前需要继承UDF类并实现evaluate()函数，或是继承GenericUDF类实现initialize()函数、evaluate()函数和getDisplayString()函数，还有其他的实现方法。 另外，如果用户想在Hive中使用该UDF需要将我们编写的Java代码进行编译，然后将编译后的UDF二进制类文件(.class文件)打包成一个JAR文件，然后在Hive会话中将这个JAR文件加入到类路径下，在通过create function语句定义好使用这个Java类的函数。 12345 #创建函数add jar &lt;jar文件的绝对路径&gt;; create temporary function function_name;#删除函数drop temporary function if exists function_name; 数据操作：主要实现的是将数据装载到表中（或是从表中导出），并进行相应查询操作，对熟悉SQL语言的用户应该不会陌生。 向表中装载数据：这里我们以只有两个属性的简单表为例来介绍。首先创建表stu和course，stu有两个属性id与name，course有两个属性cid与sid。 1234create table if not exists hive.stu(id int,name string) row format delimited fields terminated by '\t';create table if not exists hive.course(cid int,sid int) row format delimited fields terminated by '\t'; 向表中装载数据有两种方法：从文件中导入和通过查询语句插入。 a.从文件中导入 假如这个表中的记录存储于文件stu.txt中，该文件的存储路径为/usr/local/hadoop/examples/stu.txt，内容如下。 stu.txt： 1231 xiapi 2 xiaoxue 3 qingqing 下面我们把这个文件中的数据装载到表stu中，操作如下： 1load data local inpath &apos;/usr/local/hadoop/examples/stu.txt&apos; overwrite into table stu; 如果stu.txt文件存储在HDFS 上，则不需要 local 关键字。 b.通过查询语句插入 使用如下命令，创建stu1表，它和stu表属性相同，我们要把从stu表中查询得到的数据插入到stu1中： 1create table stu1 as select id,name from stu; 上面是创建表，并直接向新表插入数据；若表已经存在，向表中插入数据需执行以下命令： 1insert overwrite table stu1 select id,name from stu where（条件）; 这里关键字overwrite的作用是替换掉表（或分区）中原有数据，换成into关键字，直接追加到原有内容后。 从表中导出数据：a.可以简单拷贝文件或文件夹 命令如下： 1hadoop fs -cp source_path target_path; b.写入临时文件 命令如下： 1insert overwrite local directory &apos;/usr/local/hadoop/tmp/stu&apos; select id,name from stu; 查询操作：和SQL的查询完全一样，这里不再赘述。主要使用select…from…where…等语句，再结合关键字group by、having、like、rlike等操作。这里我们简单介绍一下SQL中没有的case…when…then…句式、join操作和子查询操作。 case…when…then…句式和if条件语句类似，用于处理单个列的查询结果，语句如下： 12345select id,name, case when id=1 then &apos;first&apos; when id=2 then &apos;second&apos; else &apos;third&apos; 连接连接（join）是将两个表中在共同数据项上相互匹配的那些行合并起来, HiveQL 的连接分为内连接、左向外连接、右向外连接、全外连接和半连接 5 种。 a. 内连接(等值连接)内连接使用比较运算符根据每个表共有的列的值匹配两个表中的行。 首先，我们先把以下内容插入到course表中（自行完成）。 1231 32 13 1 下面, 查询stu和course表中学号相同的所有行，命令如下： 1select stu.*, course.* from stu join course on(stu .id=course .sid); 执行结果如下： b. 左连接左连接的结果集包括“LEFT OUTER”子句中指定的左表的所有行, 而不仅仅是连接列所匹配的行。如果左表的某行在右表中没有匹配行, 则在相关联的结果集中右表的所有选择列均为空值，命令如下： 1select stu.*, course.* from stu left outer join course on(stu .id=course .sid); 执行结果如下： c. 右连接右连接是左向外连接的反向连接,将返回右表的所有行。如果右表的某行在左表中没有匹配行,则将为左表返回空值。命令如下： 1select stu.*, course.* from stu right outer join course on(stu .id=course .sid); 执行结果如下： d. 全连接全连接返回左表和右表中的所有行。当某行在另一表中没有匹配行时,则另一个表的选择列表包含空值。如果表之间有匹配行,则整个结果集包含基表的数据值。命令如下： 1select stu.*, course.* from stu full outer join course on(stu .id=course .sid); 执行结果如下： e. 半连接半连接是 Hive 所特有的, Hive 不支持 in 操作,但是拥有替代的方案; left semi join, 称为半连接, 需要注意的是连接的表不能在查询的列中,只能出现在 on 子句中。命令如下： 1select stu.* from stu left semi join course on(stu .id=course .sid); 执行结果如下： 子查询标准 SQL 的子查询支持嵌套的 select 子句,HiveQL 对子查询的支持很有限,只能在from 引导的子句中出现子查询。 注意，在定义或是操作表时，不要忘记指定所需数据库。 Hive简单编程实践在MapReduce中要实现单词统计，需要一百多行代码；而在hive中只需要几行代码就可以，示例如下： 1234567create table docs(line string);load data inpath &apos;input&apos; overwrite into table docs;create table word_count as select word, count(1) as count from(select explode(split(line,&apos; &apos;))as word from docs) wgroup by wordorder by word; 这样就会把统计好的单词数放入到word_count表中。 由上可知，采用Hive实现最大的优势是，对于非程序员，不用学习编写Java MapReduce代码了，只需要用户学习使用HiveQL就可以了，而这对于有SQL基础的用户而言是非常容易的。 参考资料：http://dblab.xmu.edu.cn/blog/1080-2/]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Hive</tag>
        <tag>大数据开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统用户及用户组管理]]></title>
    <url>%2F2018%2F06%2F17%2FLinux%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E5%8F%8A%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[认识/etc/passwd和/etc/shadwo:这两个文件可以说是linux系统中最重要的文件之一。如果没有这两个文件或者这两个文件出问题，则是无法正常登录linux系统的。 /etc/passwd: 图：passwd前10行内容示例 ‘/etc/passwd’ 由 ‘:’ 分割成7个字段，每个字段的具体含义是: 用户名（如第一行中的root就是用户名），代表用户账号的字符串。用户名字符可以是大小写字母、数字、减号（不能出现在首位）、点以及下划线，其他字符不合法。虽然用户名中可以出现点，但不建议使用，尤其是首位为点时，另外减号也不建议使用，因为容易造成混淆。 存放的就是该账号的口令，为什么是 ‘x’ 呢？早期的unix系统口令确实是存放在这里，但基于安全因素，后来就将其存放到 ‘/etc/shadow’ 中了，在这里只用一个 ‘x’ 代替。 这个数字代表用户标识号，也叫做uid。系统识别用户身份就是通过这个数字来的，0就是root，也就是说可以修改test用户的uid为0，那么系统会认为root和test为同一个账户。通常uid的取值范围是0 ~ 65535(但实际上已经可以支持到4294967294)，0是超级用户（root）的标识号，1~499由系统保留，作为管理账号，普通用户的标识号从500开始，如果我们自定义建立一个普通用户，您会看到该账户的标识号是大于或等于500的。 表示组标识号，也叫做gid。这个字段对应着/etc/group 中的一条记录，其实/etc/group和/etc/passwd基本上类似。 注释说明，该字段没有实际意义，通常记录该用户的一些属性，例如姓名、电话、地址等等。使用finger的功能时就会显示这些信息的。 用户的家目录，当用户登录时就处在这个目录下。root的家目录是/root，普通用户的家目录则为/home/username，这个字段是可以自定义的，比如您建立一个普通用户test1，要想让test1的家目录在/data目录下，只要修改/etc/passwd文件中test1那行中的该字段为/data即可。 shell，用户登录后要启动一个进程，用来将用户下达的指令传给内核，这就是shell。Linux的shell有很多种sh, csh, ksh, tcsh, bash等，而Redhat/CentOS的shell就是bash。查看/etc/passwd文件，该字段中除了/bin/bash外还有/sbin/nologin比较多，它表示不允许该账号登录。如果您想建立一个账号不让他登录，那么就可以把该字段改成/sbin/nologin，默认是/bin/bash. 例如：此时登录的hadoop用户，uid=1000,gid=1000,注释：hadoop，家目录：/home/hadoop/,shell：/bin/bash /etc/shadow: 图：shadow文件示例 这个文件总共被’:’分割成9个字段，具体意思如下： 用户名，和/etc/passwd对应。 用户密码：这是账号真正的密码，不过是被加密后的。该文件属性为000，但是root账户可以访问和更改。 /etc/passwd不安全。有些黑客可破解。 上次更改密码的日期。这个数字是这样计算得来的，距离1970年1月1日到上次更改密码的日期。例如上次更改密码的日期为2012年1月1日，则这个值就是 ‘365 x (2012-1970) + (2012-1970)/4 + 1 = 15341’. 因为如果是闰年，则有366天。 要过多少天才可以更改密码，默认是0，即不限制。 密码多少天后到期。即在多少天内必须更改密码，例如这里设置成30，则30天内必须更改一次密码，否则将不能登录系统，默认是99999，可以理解为永远不需要改。 密码到期前的警告期限，若这个值设置成7，则表示当7天后密码过期时，系统就发出警告告诉用户，提醒用户他的密码将在7天后到期。 账号失效期限。如果设置这个值为3，则表示：密码已经到期，然而用户并没有在到期前修改密码，那么再过3天，则这个账号就失效了，即锁定了。 账号的生命周期，跟第三段一样，是按距离1970年1月1日多少天算的。它表示的含义是，账号在这个日期前可以使用，到期后账号作废。 作为保留用的，没有什么意义。 新增和删除用户和用户组： 新增一个组：groupadd 语法 : groupadd [-g GID] groupname “-g” 选项可以自定义gid。不加 “-g” 选项则按照系统默认的gid创建组，跟用户一样，gid也是从500开始的。 新增一个用户：useradd 语法 : useradd [-u UID] [-g GID] \[ -d HOME \][-s] ‘-u’ 自定义UID ‘-g’ 使其属于已经存在的某个组，后面可以跟组id, 也可以跟组名 ‘-d’ 自定义用户的家目录 ‘-M’ 不建立家目录 ‘-s’ 自定义shell useradd’ 不加任何选项直接跟用户名，则会创建一个跟用户名同样名字的组。 ‘-g’ 选项后面跟一个不存在的gid会报错，提示该组不存在。 ‘-M’ 选项加上后则不建立用户家目录，但是在/etc/passwd文件中仍然有这个字段。但是使用 ls /home/user 查看一下会提示该目录不存在。所以 ‘-M’ 选项的作用只是不创建那个目录。 删除一个用户：userdel 语法 : userdel [-r] username ‘-r’ 选项的作用只有一个，就是删除账户的时候连带账户的家目录一起删除。 删除一个组：groupdel语法 : gropudel groupname 有一种情况下不能删除组，当组下有用户是必须先删除用户才能删除组。 用户和用户组操作示例 chfn更改用户finger（不常用）：chfn，即change finger information，是用来改变 finger 指令显示的信息。chfn 指令可用来更改执行 finger 指令时所显示的信息，这些信息都存放在/etc 目录里的 passwd 文件里。若不指定任何参数，则 chfn 指令会进入问答式界面。 用法： chfn 选项 [用户名] 选项： -f, –full-name &lt;全名&gt; 真实姓名 -o, –office &lt;办公&gt; 办公号码 -p, –office-phone &lt;电话&gt; 办公电话 -h, –home-phone &lt;电话&gt; 住宅电话 -u, –help 显示此帮助并退出 -v, –version 输出版本信息并退出 chfn命令示例 顺便看下finger的用法: finger命令用来查找并显示用户信息，系统管理员通过使用该命令可以知道某个时候到底有多少用户在使用这台Linux主机。 语法： finger [-lmps] [login ...] 命令中各选项的含义如下： -l ：列出该用户的帐号名称，真实姓名，用户专属目录，登入所用的 Shell，登入时间，转信地址，电子邮件状态，还有计划文件和方案文件内容。-m ：排除查找用户的真实姓名。-s ：列出该用户的帐号名称，真实姓名，登入终端机，闲置时间，登入时间以及地址和电话。-p： 列出该用户的帐号名称，真实姓名，用户专属目录，登入所用的 Shell，登入时间，转信地址，电子邮件状态，但不显示该用户的计划文件和方案文件内容。 图：finger命令示例 创建和修改一个用户的密码：设置密码:passwd 等创建完账户后，默认是没有设置密码的，虽然没有密码，但该账户同样登录不了系统。只有设置好密码后方可登录系统。 passwd的用法如下： 图：passwd的用法 “passwd” 后面不加username则是修改当前账户的密码。如果登陆的是root账户，后面可以跟普通账户的名字，意思是修改指定账户的密码。 只有root才可以修该其他账户的密码，普通账户只能修改自己的密码，其他账户的密码是不可以修改的。 图：更改密码示例 mkpasswd：用来生成密码的一个工具 默认linux是没有这个密码的，需要安装一个包“expect”。在CentOS上可以通过命令yum install -y expect 安装。 mkpasswd使用示例如下： 123456[root@localhost hadoop]# mkpasswdlc2Sv2Ww_[root@localhost hadoop]# mkpasswd&gt;3WciqcW6[root@localhost hadoop]# mkpasswdVwnY&#125;hy62 用户身份切换： 命令su：切换用户 su的用法如下： 图：su的用法 语法：su - username 后面可以跟 ‘-‘ 也可以不跟，普通用户su不加username时就是切换到root用户，当然root用户同样可以su到普通用户。 ‘-‘这个字符的作用是，加上后会初始化当前用户的各种环境变量。 如果不加 ‘-‘ 切换到root账户下时，当前目录没有变化，而加上 ‘-‘ 切换到root账户后，当前目录为root账户的家目录，这跟直接登陆root账户是一样的。当用root切换普通用户时，是不需要输入密码的。这也体现了root用户至高无上的权利。 命令sudo:(很重要命令) 用su是可以切换用户身份，如果每个普通用户都能切换到root身份，如果某个用户不小心泄漏了root的密码，那岂不是系统非常的不安全？没有错，为了改进这个问题，产生了sudo这个命令。使用sudo执行一个root才能执行的命令是可以办到的，但是需要输入密码，这个密码并不是root的密码而是用户自己的密码。默认只有root用户能使用sudo命令，普通用户想要使用sudo，是需要root预先设定的，即，使用 visudo 命令去编辑相关的配置文件/etc/sudoers. 如果没有visudo这个命令，请使用 yum install -y sudo 安装。 默认root能够sudo是因为这个文件中有一行 “root ALL=(ALL) ALL” 在该行下面加入 “hadoop ALL=(ALL) ALL” 就可以让hadoop用户拥有了sudo的权利。使用 “visudo” 命令编辑/etc/sudoers配置文件，其实它的操作方法和前面阿铭介绍的 “vi” 命令使用方法是一样的，按 ‘i’ 进入编辑模式，编辑完成后，按 “Esc” ，再输入 ”:wq” 完成保存。 在visudo 里面有“# %wheel ALL=(ALL) ALL”，把#去掉，让这一行生效。它的意思是，wheel这个组的所有用户都拥有了sudo的权利。接下来就需要您把想让有sudo权利的所有用户加入到wheel这个组中即可。CentOS7默认生效。 有一个很实用的案例： 需求是把Linux服务器设置成：只允许使用普通账户登陆，而普通账户登录后，可以不输入密码就能sudo切换到root账户。 可以这样设置： 进入visduo，在文件后面加入三行： 1234&gt; User_Alias USER_SU = test&gt; Cmnd_Alias SU = /bin/su&gt; USER_SU ALL=(ALL) NOPASSWD: SU&gt; 保存配置文件后，使用test,账户登陆Linux后，执行命令 sudo su - 切换到root账户，获取root账户的所有权利。 而不让root直接登陆，这个简单，设置一个非常复杂连自己都记不住的密码。不过这样也有一个问题，就是普通用户可以su到root，然后他再自己修改简单的密码就能直接root登陆。 推荐一个很好的管理账号密码的工具：keeppass它是免费的、开源的、重量轻且易于使用的密码管理器。 这是它的官网：https://keepass.info/ KeepPass的介绍： KeePass是一个免费的开源密码管理器，它可以帮助您以安全的方式管理密码。您可以将所有密码放在一个数据库中，数据库用一个主密钥或一个密钥文件锁定。因此，您只需记住一个主密码或选择密钥文件来解锁整个数据库。数据库是使用目前已知的最好和最安全的加密算法(AES和Twofish)加密的。 官网下载的软件是英语的，可以在官网翻译一栏，下载中文插件。按要求放在安装文件的language目录下即可。然后更改语言。 图：软件截图 建议下载：免安装版的（zip），可以放在任何移动存储介质上。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件与目录管理]]></title>
    <url>%2F2018%2F06%2F16%2FLinux%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[绝对路径和相对路径：绝对路径：路径的写法一定由根目录 ‘/’写起，例如 /usr/local/mysql 这就是绝对路径。 相对路径：路径的写法不是由根目录 ‘/’写起，例如，首先用户进入到/, 然后再进入到home ，命令为 cd /home 然后 cd test 此时用户所在的路径为 /home/test 第一个cd命令后跟 ‘/home’ 第二个cd命令后跟 ‘test’, 并没有斜杠，这个 ‘test’ 是相对于 ‘/home’ 目录来讲的，所以叫做相对路径。 环境变量PATH： 通俗的讲，环境变量就是告诉电脑 (实际是操作系统)几个目录。这几个目录下存储几个执行文件，如前面显示的/usr/bin目录，大部分的系统命令都在这个目录下。 当我们输入命令mkdir时，系统就会在环境变量所代表的几个目录从前到后去查找，哪个里面有mkdir文件，然后去执行mkdir命令。 系统中环境变量的名字是PATH，其内容可通过下面的命令显示 (根据操作系统不同和配置不同，略有差别，但格式是统一的，: 分割的一堆路径) echo $PATH：显示当前PATH环境变量。 加到环境变量的路径必须是全路径，全路径指以/开头或以~开头的路径。 注意第一个PATH不含 $ , 第二个PATH有 \$ 符号\$ export PATH=$PATH:/home/ct所以在以后安装了新的软件，或者写了新的脚本后，都把软件的可执行程序和可执行的脚本所在的目录，加到环境变量里面就可以了。 但是，在命令行中执行export，对环境变量所做的修改，只对当前终端有效，退出后就无效了。为了使得这一操作长期有效，我们需要把这句话写入一个文件中，一个登陆服务器就会被自动读取的文件中。 /etc/profile ： 此文件为系统的环境变量，它为每个用户设置环境信息，当用户第一次登录时，该文件被执行。并从/etc/profile.d 目录的配置文件中搜集shell 的设置。 ​ 这个文件，是任何用户登陆操作系统以后都会读取的文件（如果用户的shell 是csh 、tcsh 、zsh ，则不会读取此文件），用于获取系统的环境变量，只在登陆的时候读取一次。 更改完后，执行source /etc/profile 生效。 ~/.bashrc : 该文件包含专用于单个人的bash shell 的bash 信息，当登录时以及每次打开一个新的shell 时, 该该文件被读取。 ​ 单个用户此文件的修改会影响到他以后的每一次登陆系统和每一次新开一个bash 。因此，可以在这里设置单个用户的特殊的环境变量或者特殊的操作，那么每次它新登陆系统或者新开一个bash ，都会去获取相应的特殊的环境变量和特殊操作。 更改完后，执行 source ~/.bashrc 生效。 文件管理命令： cd:这个命令是用来变更用户所在目录的，后面如果什么都不跟，就会直接到当前用户的根目录下。 ./ 表示当前目录，../ 表示当前目录的上一级目录 pwd：打印出当前所在目录。 mkdir：创建目录。‘mkdir’ 其实就是make directory的缩写。 -m ：指定创建目录的权限。 -p : 可以创建多级目录。如果要创建目录已经存在，会覆盖。 rmdir：删除空目录。用法与mkdir相同，用的少，一般用rm代替。 rm:删除文件或目录。最常用。 -m : 删除目录是用的选项，等同于rmdir。但是可以删除非空目录。同时会提示是否确认删除。 -f : 强制删除。不会提示确认删除。就算文件要删除的文件不存在也不会报错。要删除一个目录时，即使加上 ‘-f’ 选项也会报错，所以删除目录一定要加 ‘-r’ 选项。 cp :copy的简写，即拷贝。格式为 cp [选项] [ 来源文件 ] [目的文件] 。 -r ：如果要拷贝目录是必须加 -r。 -i : 安全选项。和rm类似，如果遇到一个存在的文件，会问是否覆盖。在Redhat 和 centos系统中，cp默认覆盖。 mv：‘mv’ 是move的简写。格式为 mv [ 选项 ] [源文件] [目标文件] 。 -i ：安全选项。会有提示。 该命令有几种情况： 1） 目标文件是目录，而且目标文件不存在； 2） 目标文件是目录，而且目标文件存在； 3） 目标文件不是目录不存在； 4） 目标文件不是目录存在； 目标文件是目录，存在和不存在，移动的结果是不一样的，如果存在，则会把源文件移动到目标文件目录中。不存在的话移动完后，目标文件是一个文件。相当于重命名，常用。 cat: 查看文件。 -n : 查看文件时，把行号也显示到屏幕上。 -A : 显示所有东西出来，包括特殊字符. tac ：用来把文件的内容显示在屏幕上，只不过是先显示最后一行，然后是倒数第二行，最后显示的是第一行。 more:查看文件内容，当屏幕占满后按空格才能看下一屏幕。按q可提前退出。 less:查看文件内容，可以上下翻阅。按 ‘j’ 键可以向下移动，按 ‘k’ 键向上移动。 在用more和less查看内容是可以通过：按一下 ‘/’ 键，然后输入一个word回车，这样就可以查找这个word了。如果是多个该word可以按 ‘n’ 键显示下一个。另外也可以不按 ‘/’ 而是按 ‘?’ 后边同样跟word来搜索这个word，唯一不同的是， ‘/’ 是在当前行向下搜索，而 ‘?’ 是在当前行向上搜索。 head：显示文件的前十行。如果加 -n 选项则显示文件前n行。 tail：显示文件最后十行。如果加-n 选项则显示文件最后n行。 文件的所属主以及所属组：一个linux目录或者文件，都会有一个所属主和所属组。所属主，即文件的拥有者，而所属组，即该文件所属主所在的一个组。 可通过ls -l查看文件属性。 1234[root@localhost hadoop]# ls -l总用量 4-rw-r--r--. 1 root root 13 6月 16 23:08 file.txt[root@localhost hadoop]# Linux文件属性：1234567[root@localhost etc]# ls -l yum总用量 4drwxr-xr-x. 2 root root 6 4月 13 20:58 fssnap.ddrwxr-xr-x. 2 root root 83 6月 5 21:45 pluginconf.ddrwxr-xr-x. 2 root root 26 4月 13 20:58 protected.ddrwxr-xr-x. 2 root root 37 4月 13 20:58 vars-rw-r--r--. 1 root root 444 4月 13 20:58 version-groups.conf 在查看文件属性时，有9列内容：具体含义如下： 第一列：代表这个文件是“目录、文件或链接文件等”。 若是【d】则代表该条记录是目录； 若是【-】则代表是文件； 若是【|】则表示为连接文件(linkfile)； 若是【b】则表示设备文件里面的可供存储的接口设备； 若是【c】则表示设备文件里面的串口端口设备，例如键盘、鼠标。 接下来以3个为一组：“rwx” 其中【r】代表可读(read)； 其中【w】代表可写(write)； 其中【x】代表可执行(execute)； 这3个权限的位置不会改变，如果没有相应的权限，就会出现减号【-】 前三位为所属主（user）的权限，中间三位为所属组（group）的权限，最后三位为其他非本群组（others）的权限。 第二列表示有多少文件名连接到此节点(i-node) 第三列表表示这个文件(或目录)的“所有者账号” 第四列表表示这个文件的所属用户组 第五列为这个文件的大小，默认单位为B 第六列为这个文件的创建文件日期或者是最近的修改日期 第七列为文件名. 图:示例 更改文件权限： 更改所属组：chgrp 语法：chgrp [组名] [文件名] ‘chgrp’命令也可以更改目录的所属组，但是只能更改目录本身，而目录下面的目录或者文件没有更改，要想级联更改子目录以及子文件，需要加个参数：-R。 该命令使用不多，可用可用chown代替。 更改文件的所属主：chown 语法： chown [ -R ] 账户名 文件名 chown [-R] 账户名：组名 文件名 这里的-R选项只作用于目录，作用是级联更改，即不仅更改当前目录，连目录里的目录或者文件全部更改。 改变用户读文件的读写执行权限：chmod chmod 语法： chmod [-R] xyz 文件名 （这里的xyz，表示数字，‘-R’ 选项作用同chown，级联更改） 在linux中为了方便更改这些权限，linux使用数字去代替rwx, 具体规则为 ‘r’ 等于4, ‘w’ 等于2, ‘x’ 等于1, ‘-‘ 等于0。 举个例子: ‘-rwxrwx—’ 用数字表示就是 ‘770’, 具体是这样来的: ‘rwx’ = 4+2+1=7; ‘rwx’ = 4+2+1=7; ‘- --‘ = 0+0+0=0. 在linux系统中，默认一个目录的权限为 755，而一个文件的默认权限为644. ’chmod’ 还支持使用rwx的方式来设置权限。九个属性分别是(1)user (2)group (3)others,可以使用u, g, o 来代表它们三个的属性，此外， a 则代表 all 亦即全部。例：chmod u-x test/test2 另外还可以针对u, g, o, a增加或者减少某个权限（读，写，执行），例:chmod u-x test/test2 umask: umask语法： umask xxx （这里的xxx代表三个数字） umask预设是0022，其代表什么含义？先看一下下面的规则： 1）若用户建立为普通文件，则预设 ‘没有可执行权限’, 只有’rw’两个权限。最大为666 (‘-rw-rw-rw-‘). 2）若用户建立为目录，则预设所有权限均开放，即777 (‘drwxrwxrwx’). umask数值代表的含义为，上边两条规则中的默认值（文件为666，目录为777）需要减掉的权限。所以目录的权限为 &#39;rwxrwxrwx&#39; - &#39;----w--w-&#39; = &#39;rwxr-xr-x&#39;，普通文件的权限为 &#39;rw-rw-rw-&#39; - &#39;----w--w-&#39; = &#39;rw-r--r--&#39;. umask的值是可以自定义的，比如设定umask 为 002，您再创建目录或者文件时，默认权限分别为 &#39;rwxrwxrwx&#39; - &#39;-------w-&#39; = &#39;rwxrwxr-x&#39; 和 &#39;rw-rw-rw-&#39; - &#39;-------w-&#39; = &#39;rw-rw-r--&#39;. umask 可以在 /etc/bashrc 里面更改，预设情况下，root的umask为022，而一般使用者则为002，因为可写的权限非常重要，因此预设会去掉写权限。 修改文件特殊属性：chattr 语法： chattr [+-=][ASaci [文件或者目录名] ‘+-=’ : 分别为增加、减少、设定 ‘A’ : 增加该属性后，文件或目录的atime将不可被修改； ‘S’ : 增加该属性后，会将数据同步写入磁盘中； ‘a’ : 增加该属性后，只能追加不能删除，非root用户不能设定该属性； ‘c’ : 自动压缩该文件，读取时会自动解压； ‘i’ : 增加后，使文件不能被删除、重命名、设定链接接、写入、新增数据； 读取文件或目录的特殊权限：lsattr 语法为 lsattr [-aR] [文件/目录名] ‘-a’ : 类似与ls 的-a 选项，即连同隐藏文件一同列出； ‘-R’ : 连同子目录的数据一同列出。 在Linux下搜索一个文件：（1）通过which可以查找文件的绝对路径。 需要注意的一点是，which只能用来查找PATH环境变量中出现的路径下的可执行文件。 （2）whereis： 通过预先生成的一个文件列表库去查找跟给出的文件名相关的文件。 语法： whereis [-bmsu] [文件名称] ‘-b’ : 只找binary 文件 ‘-m’ : 只找在说明文件manual路径下的文件 ‘-s’ : 只找source来源文件 ‘-u’ : 没有说明档的文件 这个命令一般很少使用。 （3）‘locate’ 类似于’whereis’, 也是通过查找预先生成的文件列表库来告诉用户要查找的文件在哪里。 用的也不是太多。 （4）find:使用最多的搜索命令。 语法 : find [路径] [参数] 常用参数： ‘-atime +n/-n’ : 访问或执行时间大于/小于n天的文件. ‘-ctime +n/-n’ : 写入、更改inode属性（例如更改所有者、权限或者链接）时间大于/小于n天的文件。 ‘-mtime +n/-n’ : 写入时间大于/小于n天的文件。 注：文件的三个time属性。 文件的 Access time也就是 ‘atime’ 是在读取文件或者执行文件时更改的。文件的 Modified time也就是 ‘mtime’ 是在写入文件时随文件内容的更改而更改的。文件的 Create time也就是 ‘ctime’ 是在写入文件、更改所有者、权限或链接设置时随inode的内容更改而更改的。 因此，更改文件的内容即会更改mtime和ctime，但是文件的ctime可能会在 mtime 未发生任何变化时更改，例如，更改了文件的权限，但是文件内容没有变化。 ‘stat’ 命令可用来列出文件的 atime、ctime 和 mtime。 atime不一定在访问文件之后被修改，因为：使用ext3文件系统的时候，如果在mount的时候使用了noatime参数那么就不会更新atime的信息。总之, 这三个 time stamp 都放在 inode 中。若 mtime, atime 修改 inode 就一定会改, 既然 inode 改了, 那 ctime 也就跟着要改了。 ‘-name filename’ 直接查找该文件名的文件，这个选项使用很多。 ‘-type filetype’ 通过文件类型查找。filetype 包含了 f, b, c, d, l, s 等。 -：普通文件 d ：目录 c：字符设备 b：块设备 s：套接口文件 l：符号连接 Linux文件类型：1）普通文件(regular file)：就是一般类型的文件，当用 ls -l 查看某个目录时，第一个属性为 ‘-‘ 的文件就是正规文件，或者叫普通文件。正规文件又可分成纯文字文件(ascii)和二进制文件(binary)。纯文本文件是可以通过cat, more, less等工具直接查看内容的，而二进制文件并不能。例如我们用的命令/bin/ls 这就是一个二进制文件。 2）目录(directory)：这个很容易理解，就是目录，跟windows下的文件夹一个意思，只不过在linux中我们不叫文件夹，而是叫做目录。ls -l 查看第一个属性为 ‘d’. 3）链接文件(link)：ls -l 查看第一个属性为 ‘l’, 类似windows下的快捷方式。 4）设备(device)：与系统周边相关的一些档案，通常都集中在 /dev 这个目录之下! 通常又分为两种：块(block)设备 ：就是一些储存数据，以提供系统存取的接口设备，简单的说就是硬盘。例如您的一号硬盘的代码是 /dev/sda1, 第一个属性为 ‘b’；另一种是字符(character)设备 ：是一些串行端口的接口设备，例如键盘、鼠标等等，第一个属性为 ‘c’. Linux文件后缀名 在linux系统中，文件的后缀名并没有具体意义，也就是说，加或者不加，都无所谓。但是为了容易区分，我们习惯给文件加一个后缀名，这样当用户看到这个文件名时就会很快想到它到底是一个什么文件。例如1.sh, 2.tar.gz, my.cnf, test.zip等等。 早期Unix系统文件名最多允许14个字符，而新的Unix或者linux系统中，文件名最长可以到达 256 个字符。 Linux的链接文件:链接文件分为两种，硬链接(hard link)和软链接(symbolic link)。两种链接的本质区别关键点在于inode。 Hard Links : 当系统要读取一个文件时，就会先去读inode table，然后再去根据inode中的信息到块区域去将数据取出来。而hard link 是直接再建立一个inode链接到文件放置的块区域。也就是说，进行hard link的时候实际上该文件内容没有任何变化，只是增加了一个指到这个文件的inode, hard link 有两个限制：(1)不能跨文件系统，因为不同的文件系统有不同的inode table; (2) 不能链接目录。 硬链接只是复制了一份inode信息。空间大小不变 Symbolic Links : 跟hard link不同，这个是建立一个独立的文件，而这个文件的作用是当读取这个链接文件时，它会把读取的行为转发到该文件所link的文件上。软连接就是windows中的快捷方式。 建立软连接即快捷方式的命令：ln 语法 : ln [-s] [来源文件] [目的文件] ln 常用的选项就一个 ‘-s’, 如果不加就是建立硬链接，加上就建立软链接。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce编程实践]]></title>
    <url>%2F2018%2F06%2F13%2FMapReduce%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[编程环境准备： 要在 Eclipse 上编译和运行 MapReduce 程序，需要安装 hadoop-eclipse-plugin，可下载 Github 上的 hadoop2x-eclipse-plugin。 下载后，将 release 中的 hadoop-eclipse-kepler-plugin-2.6.0.jar 复制到 Eclipse 安装目录的 plugins 文件夹中，运行 eclipse -clean 重启 Eclipse 即可（添加插件后只需要运行一次该命令，以后按照正常方式启动就行了）。 打开eclipse，进行hadoop插件配置。 选择Window菜单下的Preference。 然后选择Hadoop Map/Reduce，选择hadoop的安装目录，并确认配置。 在输出窗口下又一个蓝色大象，点击可进行hadoop环境配置。 按如下进行设置： 其中，Localtion name可以随意填写，端口号则为9000。还有很多配置参数，为了方便，直接先创建WordCount的MapReduce工程，然后将/usr/local/hadoop/etc/hadoop中的配置文件core-site.xml ，hdfs-site.xml以及 log4j.properties 复制到 WordCount 项目下的 src 文件夹（~/workspace/WordCount/src）中：复制完成后，需要对工程文件进行刷新。 这样在运行MapReduce作业时，就会使用配置文件中的配置参数。 然后就可以进行开发了。 注：HDFS 中的内容变动后，Eclipse 不会同步刷新，需要右键点击 Project Explorer中的 MapReduce Location，选择 Refresh，才能看到变动后的文件。 (1)编程实例–WordCount：功能:对指定输入的文件进行单词个数统计，然后输出到指定文件夹中。 程序代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119import java.io.IOException;import java.util.Iterator;import java.util.StringTokenizer;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;public class WordCount&#123; public WordCount()&#123; &#125; public static void main(String[] args) throws Exception&#123; Configuration conf = new Configuration(); //指定输入文件路径input和输出文件路径output String[] otherArgs = new String[]&#123;"/input","/output"&#125;; if(otherArgs.length &lt; 2)&#123; System.err.println("没有输入输出路径！"); System.exit(2); &#125; /** * Job:它允许用户配置作业、提交作业、控制其执行和查询状态。 * SET方法仅在提交作业之前工作， * 之后它们将引发非法LealEtExeExchange。 */ //创建没有特定集群和给定作业名的新作业。 //只有当需要时，才会从CONF参数创建一个集群。 //作业生成配置的副本，以便任何必要的内部修改不反映传入参数。 Job job = Job.getInstance(conf, "word count"); //通过找到给定类的来源来设置jar job.setJarByClass(WordCount.class); job.setMapperClass(WordCount.TokenizerMapper.class); job.setCombinerClass(WordCount.IntSumReducer.class); job.setReducerClass(WordCount.IntSumReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); for(int i = 0; i &lt; otherArgs.length - 1; ++i) &#123; //FileInputFormat:基于文件的输入格式的基类 //添加输入文件路径 FileInputFormat.addInputPath(job, new Path(otherArgs[i])); &#125; //FileOutputFormat:基于文件的输出格式的基类 //添加输出文件路径 FileOutputFormat.setOutputPath(job, new Path(otherArgs[otherArgs.length - 1])); System.exit(job.waitForCompletion(true)?0:1); &#125; /** * Reduce:减少一组中间值，这些值共享一组较小的值。 */ public static class IntSumReducer extends Reducer &lt;Text, IntWritable, Text, IntWritable&gt;&#123; private IntWritable result = new IntWritable(); public IntSumReducer()&#123; &#125; public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context) throws IOException, InterruptedException&#123; int sum = 0; IntWritable val = null; for(Iterator it = values.iterator(); it.hasNext(); sum += val.get())&#123; val = (IntWritable) it.next(); &#125; this.result.set(sum); context.write(key, this.result); &#125; &#125; /** * Mapper:将输入的键/值对映射到一组中间键/值对 * 映射是将输入记录转换为中间记录的单个任务。转换后的 * 中间记录不需要与输入记录相同。给定的输入对可以映射到零或多个输出对。 */ public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;&#123; //IntWritable:一个可写的用于int型的。 //设置一个变量one为１． private static final IntWritable one = new IntWritable(1); //Text:该类使用标准UTF8编码存储文本。 private Text word = new Text(); public TokenizerMapper()&#123; &#125; //map():为输入分割中的每个键/值对调用一次。 //大多数应用程序应该重写这个，但是默认是标识函数。 public void map(Object key, Text value, Mapper&lt;Object, Text, Text, IntWritable&gt;.Context context) throws IOException, InterruptedException&#123; // StringTokenizer这个类主要是把一个字符串按某个标记分段, //默认的情况下的分割符是空格 StringTokenizer itr = new StringTokenizer(value.toString()); while(itr.hasMoreTokens())&#123; this.word.set(itr.nextToken()); context.write(this.word, one); &#125; &#125; &#125; &#125; (2)编程实例－求平均值：功能：计算学生的平均成绩，每个文件包括所有的学生成绩，格式为 姓名 成绩，有多少个科目，就有多少个输入文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111import java.io.IOException;import java.util.Iterator;import java.util.StringTokenizer;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.FloatWritable;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;//import org.apache.hadoop.util.GenericOptionsParser;/** * 计算学生的平均成绩 * 学生成绩以每科一个文件输入 * 文件内容：姓名 成绩 * 例如： 小明 80 */public class AverageScore &#123; public AverageScore()&#123; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; Configuration conf = new Configuration(); //设置文件输入输出路径 String[] otherArgs = new String[]&#123;"/input1","/output1"&#125;; //可以用来读取输入输出文件参数，这里采用上一行代码，手动设置路径 //String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs(); if(otherArgs.length &lt; 2)&#123; System.err.println("请输入至少两个文件！"); System.exit(2); &#125; //设置工作参数 Job job = Job.getInstance(conf,"Average Score"); job.setJarByClass(AverageScore.class); job.setMapperClass(AverageScore.AverageMapper.class); job.setCombinerClass(AverageScore.AverageReduce.class); job.setReducerClass(AverageScore.AverageReduce.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(FloatWritable.class); //输入文件路径 FileInputFormat.addInputPath(job, new Path(otherArgs[0])); //输出文件路径 FileOutputFormat.setOutputPath(job, new Path(otherArgs[1])); System.exit(job.waitForCompletion(true)?0:1); &#125; /* * map():将每个输入文件，将姓名和成绩分割开。 */ public static class AverageMapper extends Mapper&lt;Object, Text, Text, FloatWritable&gt;&#123; public AverageMapper()&#123; &#125; @Override protected void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123; String line = value.toString(); //按行进行划分 StringTokenizer tokens = new StringTokenizer(line,"\n"); while(tokens.hasMoreTokens())&#123; String tmp = tokens.nextToken(); //按空格进行划分 StringTokenizer sz = new StringTokenizer(tmp); String name = sz.nextToken(); float score = Float.valueOf(sz.nextToken()); Text outName = new Text(name); FloatWritable outScore = new FloatWritable(score); context.write(outName, outScore); &#125; &#125; &#125; /** * reduce():将同一个学的各科成绩加起来，求平均数 */ public static class AverageReduce extends Reducer&lt;Text, FloatWritable, Text, FloatWritable&gt;&#123; public AverageReduce()&#123; &#125; protected void reduce(Text key, Iterable&lt;FloatWritable&gt; value, Context context) throws IOException, InterruptedException &#123; float sum = 0;//刚开始总分为０ int count = 0;//记录有几科成绩 Iterator&lt;FloatWritable&gt; it = value.iterator();//遍历成绩 //获取各科成绩进行累加 while(it.hasNext())&#123; sum += it.next().get(); count++; &#125; //求出平均值 FloatWritable averageScore = new FloatWritable(sum/count); //写人文件 context.write(key,averageScore); &#125; &#125; &#125; (3)编程实例－数据去重：功能：数据重复，map中每一行做为一个key，value值任意，经过shuffle之后输入到reduce中利用key的唯一性直接输出key。 数据： file1.txt 2016-6-1 b2016-6-2 a2016-6-3 b2016-6-4 d2016-6-5 a2016-6-6 c2016-6-7 d2016-6-3 c file2.txt 2016-6-1 a2016-6-2 b2016-6-3 c2016-6-4 d2016-6-5 a2016-6-6 b2016-6-7 c2016-6-3 c 源代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.io.IOException; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.Path; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Job; import org.apache.hadoop.mapreduce.Mapper; import org.apache.hadoop.mapreduce.Reducer; import org.apache.hadoop.mapreduce.lib.input.FileInputFormat; import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat; //import org.apache.hadoop.util.GenericOptionsParser; /** * 数据去重 */ public class Dedup &#123; public static class MyMapper extends Mapper&lt;Object, Text, Text, Text&gt;&#123; @Override protected void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123; //value:为每行数据 context.write(value, new Text("")); &#125; &#125; public static class MyReducer extends Reducer&lt;Text, Text, Text, Text&gt;&#123; @Override protected void reduce(Text key, Iterable&lt;Text&gt; value, Context context) throws IOException, InterruptedException &#123; context.write(key, new Text("")); &#125; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException&#123; Configuration conf = new Configuration(); //String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs(); String[] otherArgs = new String[]&#123;"/input2","/output2"&#125;; if(otherArgs.length&lt;2)&#123; System.out.println("parameter errors!"); System.exit(2); &#125; Job job = Job.getInstance(conf, "Dedup"); job.setJarByClass(Dedup.class); job.setMapperClass(MyMapper.class); job.setCombinerClass(MyReducer.class); job.setReducerClass(MyReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(Text.class); FileInputFormat.addInputPath(job, new Path(otherArgs[0])); FileOutputFormat.setOutputPath(job, new Path(otherArgs[1])); System.exit(job.waitForCompletion(true)?0:1); &#125; &#125; 程序运行后输入文件为： 2016-6-1 a2016-6-1 b2016-6-2 a2016-6-2 b2016-6-3 b2016-6-3 c2016-6-4 d2016-6-5 a2016-6-6 b2016-6-6 c2016-6-7 c2016-6-7 d]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>MapReduce</tag>
        <tag>大数据开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase常用Shell命令和基础开发]]></title>
    <url>%2F2018%2F06%2F11%2FHBase%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4%E5%92%8C%E5%9F%BA%E7%A1%80%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[HBase常用Shell命令HBase中用create命令创建表：1create 'Student','Num','Name','Sex','Age' 运行结果如下： 1234hbase(main):008:0&gt; create 'Student','Num','Name','Sex','Age'0 row(s) in 2.4910 seconds=&gt; Hbase::Table - Studenthbase(main):009:0&gt; 此时，即创建了一个’Student’表，属性有：Num,Name,Sex,Age。因为HBase的表中会有一个系统默认的属性作为行键，无需自行创建，默认为put命令操作中表名后第一个数据。创建完“student”表后，可通过describe命令查看“student”表的基本信息。 HBase数据库基本操作：添加数据-put：HBase中用put命令添加数据，注意：一次只能为一个表的一行数据的一个列，也就是一个单元格添加一个数据，所以直接用shell命令插入数据效率很低，在实际应用中，一般都是利用编程操作数据。 在添加数据时，HBase会自动为添加的数据添加一个时间戳，故在需要修改数据时，只需直接添加数据，HBase即会生成一个新的版本，从而完成“改”操作，旧的版本依旧保留，系统会定时回收垃圾数据，只留下最新的几个版本，保存的版本数可以在创建表的时候指定。 当运行命令：put ‘Student’,’1001’,’ZhangSan’,male’,’23’时，即为Student表添加了学号为1001，姓名为ZhangSan，性别男，年龄23的一条数据。行键为1001. 1put 'Student','1001','ZhangSan',male','23' 删除数据：在HBase中用delete以及deleteall命令进行删除数据操作，它们的区别是：1. delete用于删除一个数据，是put的反向操作；2. deleteall操作用于删除一行数据。 12345delete 'Student','1001','Age'#删除学号为1001的年龄。delete 'Student','1001'#删除学号为1001的所示数据。 查看数据：HBase中有两个用于查看数据的命令：1. get命令，用于查看表的某一行数据；2. scan命令用于查看某个表的全部数据 12345get 'Student','1001'#查看学生学号为1001的信息scan 'student'#查看整个Student表的信息。 删除表：删除表有两步，第一步先让该表不可用，第二步删除表。 12345disable 'Student'#先禁用表drop 'Student'#删除表 查询表历史数据：查询表的历史版本，需要两步。1、在创建表的时候，指定保存的版本数（假设指定为5） 1create 'Student',&#123;NAME=&gt;'username',VERSIONS=&gt;5&#125; 2、插入数据然后更新数据，使其产生历史版本数据，注意：这里插入数据和更新数据都是用put命令 1234put 'Student','1001','username','Mary'put 'Student','1001','username','Mary1'put 'Student','1001','username','Mary2'put 'Student','1001','username','Mary3' 3、查询时，指定查询的历史版本数。默认会查询出最新的数据。（有效取值为1到5） 1get 'Student','1001',&#123;COLUMN=&gt;'username',VERSIONS=&gt;5&#125; 退出HBase数据库表操作：最后退出数据库操作，输入exit命令即可退出，注意：这里退出HBase数据库是退出对数据库表的操作，而不是停止启动HBase数据库后台运行。 HBase API详解 写HBase程序，需导入hbase安装目录中的lib文件中的所有jar包就行。 HBase常用API介绍：Admin:HBase的管理API。从connecgetadmin（）获取一个实例，然后调用close（）。 Admin可用于创建、删除、列出、启用和禁用表、添加和删除表列家庭和其他行政操作。 Admin的常用方法： 123456789101112131415161718192021//判断表是否存在boolean tableExists(TableName tableName) throws IOException//这个对象使用的连接。Connection getConnection()//列出与给定模式匹配的所有用户空间表。HTableDescriptor[] listTables(Pattern pattern) //列出所有用户表的空间 TableName[] listTableNames(String regex) //获得表描述符的方法HTableDescriptor getTableDescriptor(TableName tableName) //创建一个新表。同步操作void createTable(HTableDescriptor desc)//删除一个表。同步操作。void deleteTable(TableName tableName) Connection:一个集群连接，将较低层次的个人连接封装到实际的服务器上，并连接到zookeeper。连接通过ConnectionFactory类实例化。连接的生命周期由调用者管理，后者必须close()连接以释放资源。 连接对象包含找到master的逻辑，定位集群上的区域，保留一个位置的缓存，然后知道如何在移动后重新校准。与服务器、元缓存、zookeeper连接等的个人连接都是由Table和Admin从该连接获得的管理实例共享的. 连接创建是一个重量级的操作。连接实现是线程安全的，因此客户端可以创建一次连接，并与不同的线程共享它。另一方面，Admin和Table实例是轻量级的，并且不是线程安全的。通常，每个客户端应用程序的单个连接被实例化，并且每个线程都将获得它自己的表实例。不建议对Table和Admin进行缓存或合用。 Connection的常用方法： 1234567891011void close()//关闭连接Admin getAdmin() //检索管理实现来管理HBase集群。//这个连接实例正在使用的配置实例org.apache.hadoop.conf.Configuration getConfiguration() //检索表实现来访问表。返回的表不是线程安全的，应该为每个使用线程创建一个新的实例。这是一个轻量级的操作，既不需要也不需要对返回的表进行池或缓存。Table getTable(TableName tableName)//检索管理实现来管理HBase集群。返回的管理员不能保证是线程安全的。每一个使用线程都应该创建一个新的实例。这是一个轻量级操作。不建议对返回的管理员进行池或缓存。Admin getAdmin() Table:用于与单个HBase表进行通信。从连接中获取一个实例，然后调用close（）. 表格可用于从表中获取、放置、删除或扫描数据。 HTableDescriptor：HTableDescriptor包含关于HBase表的详细信息，例如所有列家族的描述符，是表a目录表，-根-或HBase:meta，如果表只读取，memstore的最大大小，当区域拆分时，与之关联的协处理器等等。 ##HBase编程示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.*;import org.apache.hadoop.hbase.client.*;import java.io.IOException; public class ExampleForHbase&#123; public static Configuration configuration; public static Connection connection; public static Admin admin; //主函数中的语句请逐句执行，只需删除其前的//即可，如：执行insertRow时请将其他语句注释 public static void main(String[] args)throws IOException&#123; //创建一个表，表名为Score，列族为sname,course createTable("Score",new String[]&#123;"sname","course"&#125;); //在Score表中插入一条数据，其行键为95001,sname为Mary（因为sname列族下没有子列所以第四个参数为空） //等价命令：put 'Score','95001','sname','Mary' //insertRow("Score", "95001", "sname", "", "Mary"); //在Score表中插入一条数据，其行键为95001,course:Math为88（course为列族，Math为course下的子列） //等价命令：put 'Score','95001','score:Math','88' //insertRow("Score", "95001", "course", "Math", "88"); //在Score表中插入一条数据，其行键为95001,course:English为85（course为列族，English为course下的子列） //等价命令：put 'Score','95001','score:English','85' //insertRow("Score", "95001", "course", "English", "85"); //1、删除Score表中指定列数据，其行键为95001,列族为course，列为Math //执行这句代码前请deleteRow方法的定义中，将删除指定列数据的代码取消注释注释，将删除制定列族的代码注释 //等价命令：delete 'Score','95001','score:Math' //deleteRow("Score", "95001", "course", "Math"); //2、删除Score表中指定列族数据，其行键为95001,列族为course（95001的Math和English的值都会被删除） //执行这句代码前请deleteRow方法的定义中，将删除指定列数据的代码注释，将删除制定列族的代码取消注释 //等价命令：delete 'Score','95001','score' //deleteRow("Score", "95001", "course", ""); //3、删除Score表中指定行数据，其行键为95001 //执行这句代码前请deleteRow方法的定义中，将删除指定列数据的代码注释，以及将删除制定列族的代码注释 //等价命令：deleteall 'Score','95001' //deleteRow("Score", "95001", "", ""); //查询Score表中，行键为95001，列族为course，列为Math的值 //getData("Score", "95001", "course", "Math"); //查询Score表中，行键为95001，列族为sname的值（因为sname列族下没有子列所以第四个参数为空） //getData("Score", "95001", "sname", ""); //删除Score表 //deleteTable("Score"); &#125; //建立连接 public static void init()&#123; configuration = HBaseConfiguration.create(); configuration.set("hbase.rootdir","hdfs://localhost:9000/hbase"); try&#123; connection = ConnectionFactory.createConnection(configuration); admin = connection.getAdmin(); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125; //关闭连接 public static void close()&#123; try&#123; if(admin != null)&#123; admin.close(); &#125; if(null != connection)&#123; connection.close(); &#125; &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125; /** * 建表。HBase的表中会有一个系统默认的属性作为主键，主键无需自行创建，默认为put命令操作中表名后第一个数据，因此此处无需创建id列 * @param myTableName 表名 * @param colFamily 列族名 * @throws IOException */ public static void createTable(String myTableName,String[] colFamily) throws IOException &#123; init(); TableName tableName = TableName.valueOf(myTableName); if(admin.tableExists(tableName))&#123; System.out.println("talbe is exists!"); &#125;else &#123; HTableDescriptor hTableDescriptor = new HTableDescriptor(tableName); for(String str:colFamily)&#123; HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(str); hTableDescriptor.addFamily(hColumnDescriptor); &#125; admin.createTable(hTableDescriptor); System.out.println("create table success"); &#125; close(); &#125; /** * 删除指定表 * @param tableName 表名 * @throws IOException */ public static void deleteTable(String tableName) throws IOException &#123; init(); TableName tn = TableName.valueOf(tableName); if (admin.tableExists(tn)) &#123; admin.disableTable(tn); admin.deleteTable(tn); &#125; close(); &#125; /** * 查看已有表 * @throws IOException */ public static void listTables() throws IOException &#123; init(); HTableDescriptor hTableDescriptors[] = admin.listTables(); for(HTableDescriptor hTableDescriptor :hTableDescriptors)&#123; System.out.println(hTableDescriptor.getNameAsString()); &#125; close(); &#125; /** * 向某一行的某一列插入数据 * @param tableName 表名 * @param rowKey 行键 * @param colFamily 列族名 * @param col 列名（如果其列族下没有子列，此参数可为空） * @param val 值 * @throws IOException */ public static void insertRow(String tableName,String rowKey,String colFamily,String col,String val) throws IOException &#123; init(); Table table = connection.getTable(TableName.valueOf(tableName)); Put put = new Put(rowKey.getBytes()); put.addColumn(colFamily.getBytes(), col.getBytes(), val.getBytes()); table.put(put); table.close(); close(); &#125; /** * 删除数据 * @param tableName 表名 * @param rowKey 行键 * @param colFamily 列族名 * @param col 列名 * @throws IOException */ public static void deleteRow(String tableName,String rowKey,String colFamily,String col) throws IOException &#123; init(); Table table = connection.getTable(TableName.valueOf(tableName)); Delete delete = new Delete(rowKey.getBytes()); //删除指定列族的所有数据 //delete.addFamily(colFamily.getBytes()); //删除指定列的数据 //delete.addColumn(colFamily.getBytes(), col.getBytes()); table.delete(delete); table.close(); close(); &#125; /** * 根据行键rowkey查找数据 * @param tableName 表名 * @param rowKey 行键 * @param colFamily 列族名 * @param col 列名 * @throws IOException */ public static void getData(String tableName,String rowKey,String colFamily,String col)throws IOException&#123; init(); Table table = connection.getTable(TableName.valueOf(tableName)); Get get = new Get(rowKey.getBytes()); get.addColumn(colFamily.getBytes(),col.getBytes()); Result result = table.get(get); showCell(result); table.close(); close(); &#125; /** * 格式化输出 * @param result */ public static void showCell(Result result)&#123; Cell[] cells = result.rawCells(); for(Cell cell:cells)&#123; System.out.println("RowName:"+new String(CellUtil.cloneRow(cell))+" "); System.out.println("Timetamp:"+cell.getTimestamp()+" "); System.out.println("column Family:"+new String(CellUtil.cloneFamily(cell))+" "); System.out.println("row Name:"+new String(CellUtil.cloneQualifier(cell))+" "); System.out.println("value:"+new String(CellUtil.cloneValue(cell))+" "); &#125; &#125;&#125;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HBase</tag>
        <tag>大数据开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初步认识Linux]]></title>
    <url>%2F2018%2F06%2F09%2F%E5%88%9D%E6%AD%A5%E8%AE%A4%E8%AF%86Linux%2F</url>
    <content type="text"><![CDATA[Linux系统启动的过程Linux系统的启动过程大体上可分为五部分：内核的引导、运行init、系统初始化、建立终端、用户登录系统。 1.内核引导：当计算机打开电源后，首先是BIOS开机自检，按照BIOS中设置的启动设备（通常是硬盘）来启动。紧接着由启动设备上的grub程序开始引导Linux，当引导程序成功完成引导任务后，Linux从它们手中接管了CPU的控制权，然后CPU就开始执行Linux的核心映象代码，开始了Linux启动过程。也就是所谓的内核引导开始了，在内核引导过程中其实是很复杂的，我们就当它是一个黑匣子，反正是Linux内核做了一些列工作，最后内核调用加载了init程序，至此内核引导的工作就完成了。交给了下一个主角init. 运行init：init 进程是系统所有进程的起点，您可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。init最主要的功能就是准备软件执行的环境，包括系统的主机名、网络设定、语言、文件系统格式及其他服务的启动等。 而所有的动作都会通过 init的配置文件/etc/inittab来规划，而inittab 内还有一个很重要的设定内容，那就是默认的 run level (开机运行级别)。先来看看运行级别Run level,Linux就是通过设定run level来规定系统使用不同的服务来启动，让Linux的使用环境不同。 123456789101112131415161718[hadoop@localhost ~]$ cat /etc/inittab# inittab is no longer used when using systemd.## ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target## systemd uses 'targets' instead of runlevels. By default, there are two main targets:## multi-user.target: analogous to runlevel 3# graphical.target: analogous to runlevel 5## To view current default target, run:# systemctl get-default## To set a default target, run:# systemctl set-default TARGET.target# Linux系统有7个运行级别(runlevel)： 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 在这个文件中，都是注释行，在CentOS7中这个文件已经给别的文件代替。可以看到很多行都提及到某个配置文件，而所有配置文件都是在/etc/init/目录下。 init程序的类型： SysV: init, CentOS 5之前, 配置文件： /etc/inittab。 Upstart: init,CentOS 6, 配置文件： /etc/inittab, /etc/init/*.conf。 Systemd： systemd, CentOS 7,配置文件： /usr/lib/systemd/system、 /etc/systemd/system。 3.系统初始化：系统初始化流程（内核级别）：post(加电自检)–&gt;BootSequence（启动顺序选择BIOS中实现）–&gt;bootloder（引导加载器，MBR中实现）–&gt;Kernel（加载内核，会生成ramdisk）–&gt;rootfs（以readonly方式加载根文件系统）–&gt;/sbin/init(运行第一个应用程序（相当于小管家）) 4.建立终端：建立终端是由配置文件/etc/init/tty.conf,/etc/init/serial.conf和/etc/sysconfig/init等配置文件来完成的。在2、3、4、5的运行级别中都将以respawn方式运行mingetty程序，mingetty程序能打开终端、设置模式。同时它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名，而用户输入的用户将作为参数传给login程序来验证用户身份。 5.用户登录系统：对于运行级别为5的图形方式用户来说，他们的登录是通过一个图形化的登录界面。登录成功后可以直接进入KDE、Gnome等窗口管理器。而本文主要讲的还是文本方式登录的情况：当我们看到mingetty的登录界面时，我们就可以输入用户名和密码来登录系统了。 Linux的账号验证程序是login，login会接收mingetty传来的用户名作为用户名参数。然后login会对用户名进行分析：如果用户名不是root，且存在 “/etc/nologin” 文件，login将输出nologin文件的内容，然后退出。这通常用来系统维护时防止非root用户登录。只有 “/etc/securetty” 中登记了的终端才允许root用户登录，如果不存在这个文件，则root可以在任何终端上登录。”/etc/usertty” 文件用于对用户作出附加访问限制，如果不存在这个文件，则没有其他限制。 在分析完用户名后，login将搜索 “/etc/passwd” 以及 “/etc/shadow” 来验证密码以及设置账户的其它信息，比如：主目录是什么、使用何种shell。如果没有指定主目录，将默认为根目录；如果没有指定shell，将默认为 “/bin/bash”。 login程序成功后，会向对应的终端在输出最近一次登录的信息(在 “/var/log/lastlog” 中有记录)，并检查用户是否有新邮件(在 “/usr/spool/mail/” 的对应用户名目录下)。然后开始设置各种环境变量：对于bash来说，系统首先寻找 “/etc/profile” 脚本文件，并执行它；然后如果用户的主目录中存在 .bash_profile 文件，就执行它，在这些文件中又可能调用了其它配置文件，所有的配置文件执行后后，各种环境变量也设好了，这时会出现大家熟悉的命令行提示符，到此整个启动过程就结束了。 图形界面与命令行界面切换Linux预设提供了六个命令窗口终端机让我们来登录。默认我们登录的就是第一个窗口，也就是tty1，这个六个窗口分别为tty1,tty2 … tty6，可以按下Ctrl + Alt + F1 ~ F6 来切换它们。如果您安装了图形界面，默认情况下是进入图形界面的，此时您就可以按Ctrl + Alt F1 ~ F6来进入其中一个命令窗口界面。当您进入命令窗口界面后再返回图形界面只要按下Ctrl + Alt + F7 就回来了。如果您用的vmware 虚拟机，命令窗口切换的快捷键为 Alt + Space + F1~F6. 如果您在图形界面下请按Alt + Shift + Ctrl + F1~F6 切换至命令窗口。 常用快捷键 Ctrl + C：这个是用来终止当前命令的快捷键。 Tab：命令补全键。 Ctrl + D： 退出当前终端，同样您也可以输入exit。 Ctrl + Z： 暂停当前进程，比如您正运行一个命令，突然觉得有点问题想暂停一下，就可以使用这个快捷键。暂停后，可以使用fg 恢复它。 Ctrl + L： 清屏，使光标移动到第一行。 查询帮助文档–manman 通常是用来看一个命令的帮助文档的。格式为 ” man 命令 ” 例如输入命令：man ls 1234567891011121314151617181920212223242526272829[root@localhost hadoop]# man lsLS(1) User Commands LS(1)NAME ls - list directory contentsSYNOPSIS ls [OPTION]... [FILE]...DESCRIPTION List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters...... 进入后按 ‘q’ 键退出。 Linux系统目录 /bin bin是Binary的缩写。这个目录存放着最经常使用的命令。 /boot这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev dev是Device(设备)的缩写。该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。 /etc这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media Linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux会把识别的设备挂载到这个目录下。 /mnt系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /opt 这是给主机额外安装软件所摆放的目录。比如您安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过/proc/sys/net/ipv4/icmp_echo_ignore_all命令来屏蔽主机的ping命令，使别人无法ping您的机器： /root该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /selinux 这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv 该目录存放一些服务启动之后需要提取的数据。 /sys 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs ，sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统种被创建。 /tmp这个目录是用来存放一些临时文件的。 /usr 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似与windows下的program files目录。 /usr/bin 系统用户使用的应用程序。 /usr/sbin 超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src 内核源代码默认的放置目录。 /var这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 在Linux系统中，有几个目录是比较重要的，平时需要注意不要误删除或者随意更改内部文件。/etc： 上边也提到了，这个是系统中的配置文件，如果您更改了该目录下的某个文件可能会导致系统不能启动。/bin, /sbin, /usr/bin, /usr/sbin: 这是系统预设的执行文件的放置目录，比如 ls 就是在/bin/ 目录下的。值得提出的是，/bin, /usr/bin 是给系统用户使用的指令（除root外的通用账户），而/sbin, /usr/sbin 则是给root使用的指令。 /var：这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在/var/log 目录下，另外mail的预设放置也是在这里。 关机命令、重启命令如果要关机，必须要保证当前系统中没有其他用户在线。可以下达 who 这个指令，而如果要看网络的联机状态，可以下达 netstat -a 这个指令，而要看背景执行的程序可以执行 ps -aux 这个指令。使用这些指令可以让您稍微了解主机目前的使用状态！ 正确的关机流程为：sync –&gt; shutdown –&gt; reboot –&gt; halt sync 将数据由内存同步到硬盘中。 shutdown 关机指令，您可以man shutdown 来看一下帮助文档。例如您可以运行如下命令关机： shutdown -h 10 计算机将在10分钟后关机，并且会显示在登陆用户的当前屏幕中。 shutdown -h now 立马关机 shutdown -h 20:25 系统会在今天20:25关机 shutdown -h +10 十分钟后关机 shutdown -r now 系统立马重启 shutdown -r +10 系统十分钟后重启 reboot 就是重启，等同于 shutdown -r now halt 关闭系统，等同于shutdown -h now 和 poweroff 最后总结一下，不管是重启系统还是关闭系统，首先要运行sync命令，把内存中的数据写到磁盘中。关机的命令有 shutdown -h now, halt, poweroff 和 init 0 , 重启系统的命令有 shutdown -r now, reboot, init 6. 忘记root该怎么办当忘记root密码后，可以进入单用户模式更改root密码。CentOS7 在进入单用户的时候和6.x做了很多改变，centos7进入单用户模式的步骤如下： 重启系统，在选择内核界面使用上下箭头移动。 选择第一个短的那个内核，并按 e。 进入后，找到linux16开头的一行，找到ro，然后修改ro为 rw init=/sysroot/bin/sh，该完后，按Ctrl+X重启。 - 现在，可以使用下面的命令访问系统 chroot /sysroot 重置密码，passwd root 更新系统信息 touch /.autorelabel 退出chroot ，exit 重启你的系统， reboot CentOS在图形界面和命令行界面切换，并设置默认启动界面： 从命令行界面切化图形界面：startx或Ctral+Alt+F2； 从图形界面切命令行界面：Ctral+Alt+F2或int3； 设置默认启动界面： 12345678#设置默认启动界面为图形桌面。systemctl set-default graphical.target #设置默认启动界面为命令行界面。systemctl set-default multi-user.target#获取当前默认启动信息systemctl get-default]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS常用Shell命令和基础开发]]></title>
    <url>%2F2018%2F06%2F08%2FHDFS%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4%E5%92%8C%E5%9F%BA%E7%A1%80%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[HDFS常用Shell命令Hadoop支持很多Shell命令，其中fs是HDFS最常用的命令，利用fs可以查看HDFS文件系统的目录结构、上传和下载数据、创建文件等。 HDFS有三种shell命令方式： hadoop fs :适用于任何不同的文件系统，比如本地文件系统和HDFS文件系统。 Hadoop dfs:只能适用与HDFS文件系统。 hdfs dfs：跟hadoop dfs命令作用一样，也只能适用与HDfS文件系统。 我这里的的命令用的都是第三种，hdfs dfs。 对文件和文件夹的操作：1234567891011121314151617181920212223242526272829303132333435hdfs dfs -mkdir input#在HDFS文件系统中创建一个'input'目录hdfs dfs -ls input#列出 input 目录下的内容hdfs dfs -put /home/hadoop/myFlie.txt input#将本地的文件myFile.txt上传到HDFS文件系统的input中。hdfs dfs -get input/myFlie.txt /home/hadoop/下载#从HDFS文件系统中下载文件到本地文件系统hdfs dfs -cat input/myFlie.txt#查看文件的全部内容hdfs dfs -cp input/myFile.txt input#在HDFS上复制文件hdfs dfs -mv input/myFile.txt output#在HDFS上移动文件hdfs dfs -rm input/myFile.txt #从HDFS删除文件hdfs dfs -du input/myFile.txt#查看HDFS上某目录下所有文件大小，指定文件后显示具体文件大小hdfs dfs -touchz input/file.txt#创建一个0字节的空文件。hdfs dfs -chmod #改名文件权限hdfs dfs -chown #改变文件所有者 图；操作示例 HDFS dfsadmin管理命令： hdfs dfsadmin -report 查看文件系统的基本信息和统计信息。 hdfs dfsadmin -safemode get/enter enter | leave | get | wait：安全模式命令。安全模式是NameNode的一种状态，在这种状态下，NameNode不接受对名字空间的更改（只读）；不复制或删除块。NameNode在启动时自动进入安全模式，当配置块的最小百分数满足最小副本数的条件时，会自动离开安全模式。enter是进入，leave是离开。 hdfs dfsadmin -refreshNodes 重新读取hosts和exclude文件，使新的节点或需要退出集群的节点能够被NameNode重新识别。这个命令在新增节点或注销节点时用到。 hdfs dfsadmin -finalizeUpgrade 终结HDFS的升级操作。DataNode删除前一个版本的工作目录，之后NameNode也这样做。 hdfs dfsadmin -fupgradeProgress status| details | force：请求当前系统的升级状态 | 升级状态的细节| 强制升级操作 hdfs dfsadmin -metasave filename 保存NameNode的主要数据结构到hadoop.log.dir属性指定的目录下的文件中。 图：操作示例 HDFS API详解Hadoop中关于文件操作类基本上全部是在”org.apache.hadoop.fs”包中，这些API能够支持的操作包含：打开文件，读写文件，删除文件等。 Hadoop类库中最终面向用户提供的接口类是FileSystem，该类是个抽象类，只能通过来类的get方法得到具体类。get方法存在几个重载版本，常用的是这个： 1static FileSystem get(Configuration conf); 该类封装了几乎所有的文件操作，例如mkdir，delete等。综上基本上可以得出操作文件的程序库框架： 12345678operator()&#123; 得到Configuration对象 得到FileSystem对象 进行文件操作&#125; 为了编写一个能够与HDFS交互的Java应用程序，一般需要向Java工程中添加以下JAR包：（1）”/usr/local/hadoop/share/hadoop/common”目录下的hadoop-common-2.7.1.jar和haoop-nfs-2.7.1.jar；（2）/usr/local/hadoop/share/hadoop/common/lib”目录下的所有JAR包；（3）“/usr/local/hadoop/share/hadoop/hdfs”目录下的haoop-hdfs-2.7.1.jar和haoop-hdfs-nfs-2.7.1.jar；（4）“/usr/local/hadoop/share/hadoop/hdfs/lib”目录下的所有JAR包。 上传本地文件：通过”FileSystem.copyFromLocalFile（Path src，Patch dst） “可将本地文件上传到HDFS的制定位置上，其中src和dst均为文件的完整路径。具体代码如下： 123456789101112131415161718192021222324252627282930313233import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class CopyFile &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); FileSystem hdfs = FileSystem.get(conf); //本地文件路径 Path srcPath = new Path("/home/hadoop/myFile.txt"); //HDFS路径 Path dstPath = new Path("/input/"); //进行文件上传 hdfs.copyFromLocalFile(srcPath, dstPath); //打印hdfs的文件默认路径 System.out.println("复制文件到： " + conf.get("fs.default.name")); FileStatus[] files= hdfs.listStatus(dstPath); //打印文件被复制到的路径 for(FileStatus file:files) System.out.println(file.getPath()); &#125;&#125; 程序运行结果： 12复制文件到： file:///file:/input 如果遇到因为文件权限不够，程序运行失败，解决方法如下： 可能出现问题的原因有三种： hdfs 中的文件或文件夹 没有读取权限； hdfs 的配置中未允许拷出文件； linux 文件夹没有写入权限； 针对上述三个原因，解决方法如下： 增加hdfs文件夹权限 hdfs dfs -chmod 777 / 修改hdfs配置文件： 123456789&gt; # 在 $HADOOP_HOME/etc/hadoop/目录中，找到hdfs-site.xml，添加或更改以下属性：&gt;&gt; &lt;property&gt;&gt; &lt;name&gt;dfs.permissions&lt;/name&gt;&gt; &lt;value&gt;false&lt;/value&gt;&gt; &lt;/property&gt;&gt;&gt; # 将true该为false。&gt; 增加Linux文件夹权限： sudo chmod 777 / 创建HDFS文件：通过”FileSystem.create（Path f）”可在HDFS上创建文件，其中f为文件的完整路径。具体代码如下： 1234567891011121314151617181920import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FSDataOutputStream;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class CreatFile &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); //要输入文件的字符串 byte[] s = "hello hdfs\n".getBytes(); Path dfsPath = new Path("/text.txt"); FSDataOutputStream outputStream = hdfs.create(dfsPath); //写入文件 outputStream.write(s, 0, s.length); &#125;&#125; 写入文件和读取文件：123456789101112131415161718192021222324252627282930313233343536373839404142import java.io.BufferedReader;import java.io.InputStreamReader;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FSDataInputStream;import org.apache.hadoop.fs.FSDataOutputStream;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class ReadFile &#123; public static void main(String[] args) throws Exception&#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); //要写入文件的内容 byte[] wString = "hello word! \nHello Hadoop!\nHello HDFS!\n".getBytes(); //要写入的文件名 String filename = "file"; FSDataOutputStream os = hdfs.create(new Path(filename)); //写入文件 os.write(wString, 0, wString.length); os.close(); FSDataInputStream is = hdfs.open(new Path(filename)); BufferedReader br = new BufferedReader(new InputStreamReader(is)); //读取文件 String line; while((line = br.readLine()) != null) System.out.println(line); is.close(); br.close();// hdfs.close(); &#125;&#125; 程序运行结果： 123hello word! Hello Hadoop!Hello HDFS! 创建HDFS目录：通过”FileSystem.mkdirs（Path f）”可在HDFS上创建文件夹，其中f为文件夹的完整路径。具体实现如下： 12345678910111213141516171819202122import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class CreatDir &#123; /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); Path dfs = new Path("/TextDir"); hdfs.mkdirs(dfs); System.out.println(hdfs.exists(dfs)); &#125;&#125; 重命名HDFS文件：通过”FileSystem.rename（Path src，Path dst）”可为指定的HDFS文件重命名，其中src和dst均为文件的完整路径。具体实现如下： 12345678910111213141516171819import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class Rename &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); Path oldname = new Path("/text.txt"); Path newname = new Path("/newtext.txt"); hdfs.rename(oldname, newname); System.out.println(hdfs.exists(newname)); &#125;&#125; 删除HDFS上的文件：通过”FileSystem.delete（Path f，Boolean recursive）”可删除指定的HDFS文件，其中f为需要删除文件的完整路径，recuresive用来确定是否进行递归删除。具体实现如下： 12345678910111213141516import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class DeleteFile &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); Path deletePath = new Path("/text4.txt"); hdfs.delete(deletePath, true); &#125;&#125; 删除目录和删除文件代码一样，换成路径就行，如果目录下有文件，递归删除。 查看某个HDFS文件是否存在：通过”FileSystem.exists（Path f）”可查看指定HDFS文件是否存在，其中f为文件的完整路径。具体实现如下： 123456789101112131415161718import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class CheckFile &#123; public static void main(String[] args) throws Exception&#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); Path findpPath = new Path("/input/myFile.txt"); System.out.println("文件是否存在：" + hdfs.exists(findpPath)); &#125;&#125; 图：HDFS文件系统结构图 程序运行结果： 1文件是否存在：true 查看HDFS文件的信息状态：通过”FileSystem.getModificationTime()”可查看指定HDFS文件的修改时间。具体实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.Date;import javax.ws.rs.core.NewCookie;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class GetTime &#123; public static void main(String[] args) throws Exception&#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); Path findpPath = new Path("/input/myFile.txt"); FileStatus fileStatus = hdfs.getFileStatus(findpPath); long accessTime = fileStatus.getAccessTime(); long modeTime = fileStatus.getModificationTime(); long size = fileStatus.getBlockSize(); long len = fileStatus.getLen(); String owner = fileStatus.getOwner(); Path path = fileStatus.getPath(); String group = fileStatus.getGroup(); //将时间戳转换为格式化日期 SimpleDateFormat sdf = new SimpleDateFormat(); String time1 = sdf.format(new Date(accessTime)); String time2 = sdf.format(new Date(modeTime)); //获取文件的权限信息 System.out.println("文件的权限：" + fileStatus.getPermission()); System.out.println("文件创建时间：" + time1); System.out.println("文件修改时间：" + time2); System.out.println("HDFS文件块大小：" + size); System.out.println("文件大小：" + len); System.out.println("文件所有者：" + owner); System.out.println("文件所在路径：" + path); System.out.println("文件所属组：" + group); &#125;&#125; 程序运行结果： 12345678文件的权限：rw-r--r--文件创建时间：18-6-9 下午1:59文件修改时间：18-6-9 下午1:59HDFS文件块大小：134217728文件大小：37文件所有者：hadoop文件所在路径：hdfs://localhost:9000/input/myFile.txt文件所属组：supergroup 读取HDFS某个目录下的所有文件：通过”FileStatus.getPath（）”可查看指定HDFS中某个目录下所有文件。具体实现如下： 12345678910111213141516171819202122import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class ReadDirFile &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); Path dirPath = new Path("/input"); FileStatus[] stats = hdfs.listStatus(dirPath); for(int i = 0; i &lt; stats.length; i++) System.out.println(stats[i].getPath().toString()); hdfs.close(); &#125;&#125; 图：input目录下有两文件 程序运行结果如下： 12hdfs://localhost:9000/input/myFile.txthdfs://localhost:9000/input/text2.txt 查找某个文件在HDFS集群的位置：通过”FileSystem.getFileBlockLocation（FileStatus file，long start，long len）”可查找指定文件在HDFS集群上的位置，其中file为文件的完整路径，start和len来标识查找文件的路径。具体实现如下： 12345678910111213141516171819202122232425262728import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.BlockLocation;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.hdfs.protocol.BlockLocalPathInfo;public class FileLoc &#123; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); Path fPath = new Path("/input/myFile.txt"); FileStatus status = hdfs.getFileStatus(fPath); BlockLocation[] blInfo = hdfs.getFileBlockLocations(status, 0, status.getLen()); for(int i = 0; i &lt; blInfo.length; i++)&#123; String [] hosts = blInfo[i].getHosts(); System.out.println("block: " + i + " Location: " + hosts[0]); &#125; &#125;&#125; 程序运行结果： 1block: 0 Location: ubuntu 获取HDFS集群上所有节点名称信息：通过”DatanodeInfo.getHostName（）”可获取HDFS集群上的所有节点名称。具体实现如下： 123456789101112131415161718192021import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.hdfs.DistributedFileSystem;import org.apache.hadoop.hdfs.protocol.DatanodeInfo;public class GetInfo &#123; public static void main(String[] args) throws Exception&#123; Configuration conf = new Configuration(); conf.set("fs.defaultFS", "hdfs://localhost:9000"); FileSystem hdfs = FileSystem.get(conf); DistributedFileSystem dFileSystem = (DistributedFileSystem) hdfs; DatanodeInfo[] dInfos = dFileSystem.getDataNodeStats(); for(int i = 0; i &lt; dInfos.length; i++) System.out.println("DataNode_" + i + "_Name:" + dInfos[i].getHostName()); &#125;&#125; 程序运行结果： 1DataNode_0_Name:ubuntu]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据开发</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper技术原理]]></title>
    <url>%2F2018%2F06%2F03%2FZooKeeper%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[ZooKeeper简介ZooKeeper概述：ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 ZooKeeper分布式服务框架主要是用来解决分布式应用中经常遇到的一些数据管理问题，提供分布式、高可用性的协调服务能力。 安全模式下ZooKeeper依赖于Kerberos和L搭配Server进行安全认证，非安全模式则不依赖与Kerberos与Ldap。ZooKeeper作为底层组件广泛被上层组件使用并依赖，如Kafka，HDFS，HBase，Storm等。 ZooKeeper提供什么？ 文件系统 通知机制：客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。 ZooKeeper文件系统 每个子目录项如 NameService 都被称作为znode，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。 有四种类型的znode： PERSISTENT-持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在 。 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 。 EPHEMERAL-临时目录节点 客户端与zookeeper断开连接后，该节点被删除 。 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 。 ZooKeeper做什么？ 命名服务 配置管理 集群管理 分布式锁 队列管理 Zookeeper命名服务 在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们使用tborg无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现。 Zookeeper的配置管理 程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好 Zookeeper集群管理 所谓集群管理无在乎两点：是否有机器退出和加入、选举master。 对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。 新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。 Zookeeper分布式锁 有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。 对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。 Zookeeper队列管理 两种类型的队列： 1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 2、队列按照 FIFO 方式进行入队和出队操作。 第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。 ZooKeeper在FusionInsight中的位置： 图：ZooKeeper在FusionInsight中的位置 ZooKeeper基于开源Apache ZooKeeper作为底层组件为上层组件提供服务，主要用于解决分布式应用中经常遇到的一些数据管理问题。 ZooKeeper系统架构ZooKeeper角色描述： ZooKeeper服务架构 - 模型： 图：ZooKeeper服务架构 ZooKeeper集群分布式地分布在一组机器中，由一组Server节点组成，这一组Server节点中只存在一个Leader节点，其他节点都为Follower。 所有节点存储整份数据（在内存也在硬盘）。 启动时选举出Leader。 ZooKeeper使用自定义的原子消息协议，保证了整个系统中节点数据的一致性。 Leader节点在接收到数据变更请求后，先写磁盘再写内存。 图：节点分布命名 分层命名空间。 每个命名空间的节点都叫做 znode。 每个znode被路径区分（如：/app1）。 znode节点类型 - 永久节点和临时节点。 临时节点不能有子节点。 每个znode节点有数据，也可以选择有子节点。 znode不能被重命名 可以给znode增加或删除watchers。 ZooKeeper分布式与数据复制：Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处： 容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 提高性能：让客户端本地访问就近的节点，提高用户访问速度。 从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 写主(WriteMaster) ：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； 写任意(Write Any)：对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。 对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。 ZooKeeper的工作原理：Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。 为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。 容灾能力：一般情况下，ZooKeeper能够完成选举即能够正常对外提供服务。ZooKeeper选举时，当某个实例获得半数以上的票数时，则变为Leader。 对于n个示例，n可能为技术或偶数： n为奇数时，假定n=2x+1，则成为leader的节点需要获得x+1票。容灾能力为x。 n为偶数时，假定n=2x+2，则成为leader的节点需要获得x+2票（大于一半），容灾能力为x。 由此可见，2x+1个节点与2x+2个节点的容灾能力相同（3个与4个相同，5个与6个相同…）,而考虑到选举以及完成写操作的速度与节点数的相关性，建议ZooKeeper部署奇数个节点。 ZooKeeper关键特性介绍关键特性： 最终一致性：无论哪个server，对外展示的均是同一个视图。 实时性：保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。 可靠性：一条消息被一个server接受，它将被所有server接受。 等待无关性：慢的或者失效的client不会干预快速的client的请求，使得每个client都能有效的等待。 原子性：更新只能成功或者失败，没有中间状态。 顺序一致性：客户端所发送的更新会安装它们被发送的顺序进行应用。 读特性： 图：读特性 由ZooKeeper的一致性可知，客户端无论连接哪个server，获取的均是同一个视图。所以，读操作可在客户端与任意节点间完成。 写特性： 图：写特性 客户端可以向任意一个Server提出写的请求，然后这个server会将这个请求发送给ZooKeeper 的 leader，Leader在获取写请求以后，会向所有节点发送这条写的请求，询问其他节点是否可以执行这个写的操作。Follower节点会根据自身的情况给出反馈信息，Leader根据收到的反馈信息，如果同意写的信息超过半数，那么就执行写操作。如果同意写的票数少于半数，那么就不执行写操作。如果要执行写操作,Leader最后会将投票结果反馈给各个Follower，然后完成写的操作，每个Follower节点会同步Leader节点的数据。最后整个写的操作就完成了。 ACL(访问控制列表)：ACL可以控制访问ZooKeeper的节点，只能应用于特定的znode上，而不能应用于该znode的所有子节点上。设置ACL的命令为：setAcl /znode scheme : id : perm。 Scheme为认证方式，ZooKeeper内置了4种方式： world:一个单独的ID，表示任何人都可以访问。 auth：不使用ID，只有认证的用户可以访问。 digest：使用username：passwrod生成MD5哈希值作为认证ID。 IP：使用客户端主机IP地址来进行认证。 id：用来认证的字段，用来判断认证信息是否合法，不同的scheme的认证方式不同。 Perm：即Permission，通过Acl认证的用户对节点可拥有的操作权限。 日志增强：Ephemeral node（临时节点）在session过期之后就会被系统删除。在审计日志中添加Ephemeral node被删除的审计日志，以便了解当时Ephemeral node的状态信息。 ZooKeeper客户端常用命令使用： 调用ZooKeeper客户端，执行命令： zkCli.sh -server 172.16.0.1:24002 创建节点：create /node 列出节点子节点：ls / node 创建节点数据: set /node data 获取节点数据：get /node 删除节点：delete /node 删除节点及所有子节点：deleteall /node ZooKeeper与其他组件的关系ZooKeeper和Storm Nimbus HA的配合关系： 图：ZooKeeper和Storm Nimbus HA的配合关系 Storm Nimbus利用ZooKeeper来选举主备。 ZooKeeper提供了以下两种能力： 分布式锁服务： 多个Nimbus进程都会尝试去Zookeeper创建对应的节点，该节点只能被一个Nimbus进程创建成功，创建成功的Nimbus进程成为主Nimbus。 时间侦听机制–watcher： 备Nimbus侦听对应的ZooKeeper节点。主Nimbus进程宕掉之后，该节点会被删除，那么备Nimbus就可以接受到相应的消息。 ZooKeeper和HDFS的配合关系： 图：ZooKeeper和HDFS的关系 ZKFC(ZooKeeper Failover Controller)作为一个ZooKeeper集群的客户端，用来监控NameNode的状态信息。ZKFC进程仅在部署了NameNode的节点中存在。HDFS NameNode的Active和Standby节点均部署有ZKFC进程： HDFS NameNode的ZKFC连接到Zookeeper，把主机名等信息保存到ZooKeeper中，即“/hadoop-ha”下的znode目录里。先创建znode目录的NmaeNode节点为主节点，另一个为备节点。HDFS NameNode Standby通过ZooKeeper定时读取NmaeNode信息。 当主节点进程异常结束时，HDFS NameNode Standby通过ZooKeeper感知“/hadoop-ha”目录下发生了变化，NmaeNode会进行主备切换。 ZooKeeper和YARN的配合关系： 图：ZooKeeper和YARN的配置关系 在系统启动时，ResourceManager会尝试把选举信息写入Zookeeper，第一个成功写入Zookeeper的ResourceManager被选举为Active ResourceManager，另一个为Standby ResourceManager。Standby ResourceManager定时去ZooKeeper监控Active ResourceManager选举信息。 Active ResourceManager还会在ZooKeeper中创建Statestore目录，存储Application相关信息。当Active ResourceManager产生故障时，Standby ResourceManager会从Statestore目录获取Application相关信息，恢复数据并升为Active。 ZooKeeper和HBase的配合关系： 图：ZooKeeper和HBase的关系 HRegionServer把自己以Ephemeral方式注册到Zookeeper中。其中ZooKeeper存储HBase的如下信息：HBase元数据、HMaster地址。 HMaster通过ZooKeeper随时感知各个HRegionServer的健康状况，以便进行控制管理。 HBase也可以部署多对HMaster，类似HDFS NameNode，当HMaster主节点出现故障时，HMaster备用节点会通过ZooKeeper获取主HMaster存储的整个HBase集群状态信息。即通过ZooKeeper实现避免HBase单点故障问题。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka技术原理]]></title>
    <url>%2F2018%2F06%2F02%2FKafka%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Kafka简介Kafka概述：Kafka由 linked-in 开源 。 kafka-高产出的分布式消息系统(A high-throughput distributed messaging system)。 Kafka是一个高吞吐、分布式、基于发布订阅的消息系统，利用Kafka技术可以在廉价的PC Server上搭建起大规模消息系统。 Kafka的特性： 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作； 可扩展性：kafka集群支持热扩展； 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失； 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）； 高并发：支持数千个客户端同时读写； 支持实时在线处理和离线处理：可以使用Storm这种实时流处理系统对消息进行实时进行处理，同时还可以使用Hadoop这种批处理系统进行离线处理； Kafka应用场景： 图：Kafka应用场景 Kafka和其他组件比较，具有消息持久化、高吞吐、分布式、多客户端支持、实时等特性，适用于离线和在线的消息消费，如常规的消息收集、网站活性跟踪、聚合统计系统运营数据（监控数据）、日志收集等大量数据的互联网服务的数据收集场景。 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如Hadoop、Hbase、Solr等； 消息系统：解耦和生产者和消费者、缓存消息等； 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到Hadoop、数据仓库中做离线分析和挖掘； 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告； 流式处理：比如spark streaming和storm； 事件源； kafka在FusionInsight中的位置： 图：Kafka在FusionInsight中的位置 Kafka作为一个分布式消息系统，支持在线和离线消息处理，并提供了Java API以便其他组件对接使用。 Kafka架构与功能Kafka架构： 图：Kafka架构图 基本概念： Broker：Kafka集群包含一个或多个服务实例，这些服务实例被称为Broker。是Kafka当中具体处理数据的单元。Kafka支持Broker的水平扩展。一般Broker数据越多，集群的吞吐力就越强。 Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。 Partition：Kafka将Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件下存储这个Partition的所有消息。 Producer：负责发布消息到Kafka Broker。 Consumer：消息消费者，从Kafka Broker读取消息的客户端。 Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name）。 ZooKeeper：kafka与Zookeeper级联，通过Zookeeper管理级联配置，选举Leader。 Kafka Topics： 图；Kafka Topics 每条发布到Kafka的消息都有个类别，这个类别被称为Topic，也可以理解为一个存储消息的队列。例如：天气作为一个Topic，每天的温度消息就可以存储在“天气”这个队列里。数据总数先进先出。后来的数据追加到后面。 Kafka Partition： 图：Kafka Partition 每个Topic都有一个或者多个Partitions构成。每个Partition都是有序且不可变的消息队列。引入Partition机制，保证了Kafka的高吞吐能力。 在每个Partition当中，都会存储一个Log文件，Log文件中记录了所有的消息文件。一个Topic的多个Partition，它分布在不同的Kafka节点上，这样多个客户端包括Producer和Consumer就可以并发的访问不同节点，对同一个Topic进行消息的读取。 图：Partition Topic的Partition数量可以在创建时配置。 Partition数据决定了每个Consumer group中并发消费者的最大数据。 Consumer group A有两个消费者来读取4个Partition中数据；Consumer group B有四个消费者来读取4个partition中数据。 Kafka Partition offset: 图：Kafka Partition offset 任何发布到此Partition的消息都会被直接追加到log文件的尾部。 每条消息在文件中的位置称为offset（偏移量），offset是一个long型数字，它唯一标记一条消息。消费者通过（offset、partition、topic）跟踪记录。 Kafka不支持消息的随机读取。 Kafak Partition Replicas（副本）: 图：副本机制 副本以分区为单位。每个分区都有各自的主副本。 可以通过配置文件，配置副本的个数。 一个Kafka集群中，各个节点可能互为Leader和Follower。 主副本叫做Leader，从副本叫做Follower，处于同步状态的副本叫做In-Sync Replicas（ISR）。 如果Leader失效，那么将会有其他的Follower来接管成为新的Leader。如果由于Follower自身的原因，比如网络原因导致同步落后太多，那么当Leader失效后，就不会将这个Follower选为leader。 由于Leader的Server承载了全部的请求压力，因此从集群的整体考虑，Kafka会将Leader均衡的分散在每个实例上，来保持整体稳定。 Follower通过拉取的方式从Leader中同步数据。消费者和生产这都是从Leader中读取数据，不与Follower交互。 主副本和从副本的数据同步： 图：主副本和从副本的数据同步 从Partition的Leader复制数据到Follower，需要一个线程，实际上，复制数据的操作，是Follower主动从Leader上批量拉取数据，这就极大的提高了Kafka的吞吐量。Follower复制数据的线程叫做ReplicaFetcher Thread，而Kafka的Producer和Consumer只与Leader进行交互，不会与Follower进行交互。 Kafka中每个Broker启动的时候，都会创建一个副本管理服务ReplicaManager，该服务负责维护ReplicaFether Thread与其他Broker链路连接关系。该服务中存在的Follower Partition对应的Leader Partition会分布在不同的Broker上，这些Broker创建相同数量的ReplicaFether Thread，同步对应Partition数据。Kafka中Partition间复制数据，是由Follower主动从Leader拉消息的。Follower每次读取消息都会更新HW状态，用于记录当前最新消息的标识。每当Follower的Partition发生变化而影响Leader所在的Broker时，ReplicaManager就会新建或者销毁相对应的ReplicaFether Thread。 Kafka Logs：为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索性文件。Kafka把Topic中一个Partition大文件分成多个小文件段通过多个小文件段，就容易定期清除或删除已经消费完的文件，减少磁盘占用。 Kafka的存储布局非常简单，Topic的每个分区对应一个逻辑日志，物理上一个日志为相同大小的一个分段文件。每次Producer发布一个消息到一个分区的时候，代理就将这些数据追加到最后一个段文件当中。当发布的消息数量达到消息设定的阈值，或者经过一定的时间后，段文件就会真正的写到磁盘当中。在写入完成以后，消息就会公开给Consumer。 同一个Topic下有不同的分区，每个分区会划分为多个文件，只有一个当前文件在写，其他文件是只读的。当写满一个文件（即达到某个设定的值）Kafka会新建一个空文件继续来写。而老文件切换为只读。 文件的命名以起始的偏移量来进行命名。Segment Files由两大部分组成，分别为Index file和data file，此两个文件一一对应成对出现。后缀 .index 和 .log 就分别表示为Segment的索引文件和数据文件。Segment文件的命名规则是：Partition全局的第一个Segment从0开始，后续每个segment文件为上一个全局Partition的最大offset，这个数据时64位的long型数据。如果没有数据就用0进行填充。通常把日志文件默认为1G，当达到1G就会创建新的Log文件和index文件。如果设置的参数过小，会产生大量的log文件和index文件，系统在启动的时候就需要加载大量的index到内存，占用大量的句柄。如果设置的太大，分段文件又比较少，不利于快速的查找。Kafka就是通过索引实现快速的定位message。 图：索引文件 通过索引信息可以快速定位message。 通过将index元数据全部映射到memory，可以避免segment file的index数据IO磁盘操作。 通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。 稀疏存储：将原来完整的数据，只间隔的选择多条数据进行存储。 Kafka Log Cleanup: 日志的清理方式有两种：delete和compact。 删除的阈值有两种：过期的时间和分区内总日志大小。 图：日志清理方式–compact compact操作是保存每个消息的最新value值。消息时顺序存储的，offset大的为最新的数据。 Kafka数据可靠性：Kafka所有消息都会被持久化到磁盘中，同时Kafka通过对Topic Partition设置Replication来保障数据可靠。 消息传输过程中保障通常有以下三种： 最多一次（At Most Once）：消息可能丢失；消息不会重复发送和处理。 最少一次（At Lease Once）：消息不会丢失；消息可能会重复发送和处理。 仅有一次（Exactly Once）：消息不会丢失；消息仅被处理一次。 Kafka消息传输保障机制，通过配置不同的消息发送模式来保障消息传输，进而满足不同的可靠性要求应用场景。 Kafka关键流程写流程： 图：Kafka写流程–Producer写数据 总体流程： Producer连接任意存活的Broker，请求制定Topic、Partition的Leader元数据信息，然后直接与对应的Broker直接链接，发布数据。 开发分区接口： 用户可以指定分区函数，使得消息可以根据Key，发送到特定的Partition。 Kafka读流程： 图：Kafka读流程–Consumer读数据 总体流程： Consumer连接指定Topic Partition所在的Leader Broker，用主动获取方式从Kafka中获取消息。 Kafka在Zookeeper上的目录结构Zookeeper在Kafka的作用： 无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性集群保存一些meta信息。 Kafka使用zookeeper作为其分布式协调框架，很好的将消息生产、消息存储、消息消费的过程结合在一起。 同时借助zookeeper，kafka能够生产者、消费者和broker在内的所以组件在无状态的情况下，建立起生产者和消费者的订阅关系，并实现生产者与消费者的负载均衡。 Zookeeper Shell：通过zkCli来连接正在运行的Zookeeper Shell客户端，可以通过ls和get命令来获取Kafka相关信息。 图：用法示例 Kafka in ZooKeeper： 图：Kafka在ZooKeeper中的目录结构 Kafka Cluster Mirroring 图：Kafka CLuster Mirroring Kafka Cluster Mirroring是Kafka跨集群数据同步方案，通过Kafka内置的MirrorMaker工具来实现。通过Mirror Maker工具中的consumer从源集群消费数据，然后再通过内置的Producer，将数据重新发布到目标集群。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flume技术原理]]></title>
    <url>%2F2018%2F06%2F02%2FFlume%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Flume简介Flume概述：Flume是开源日志系统。是一个分布式、可靠性和高可用的海量日志聚合系统，支持在系统中定制各类数据发送方，用于收集数据；同时，FLume提供对数据进行简单处理，并写到各种数据接收方（可定制）的能力。 Flume是什么？Flume是流式日志采集工具，FLume提供对数据进行简单处理并且写到各种数据接收方（可定制）的能力，Flume提供从本地文件（spooling directory source）、实时日志（taildir、exec）、REST消息、Thift、Avro、Syslog、Kafka等数据源上收集数据的能力。 Flume能干什么？ 提供从固定目录下采集日志信息到目的地（HDFS，HBase，Kafka）能力。 提供实时采集日志信息（taidir）到目的地的能力。 FLume支持级联（多个Flume对接起来），合并数据的能力。 Flume支持按照用户定制采集数据的能力。 Flume在FusionInsight中的位置： 图：Flume在FusionInsight中的位置 Flume是收集、聚合事件流数据的分布式框架。 Flume系统架构Flume基础架构： 图：Flume基础架构图 Flume基础架构：Flume可以单节点直接采集数据，主要应用于集群内数据。 Flume多agent架构： 图：Flume多agent架构 Flume多agent架构：Flume可以将多个节点连接起来，将最初的数据源经过收集，存储到最终的存储系统中。主要应用于集群外的数据导入到集群内。 Flume架构： 图：Flume架构图 各组件具体介绍如下： events：Flume当中对数据的一种封装。是一个数据单元。flume传输数据最基本的单元。 Interceptor：拦截器，主要作用是将采集到的数据根据用户的配置进行过滤和修饰。 Channel Selector：通道选择器，主要作用是根据用户配置将数据放到不同的Channel当中。 Channel：主要作用是临时的缓存数据。 Sink Runner：sink的运行器，主要是通过它来驱动Sink Processor，Sink Processor驱动Sink来从Channel当中获取数据。 Sink Processor：主要策略有，负载均衡，故障转移以及直通。 Sink：主要作用是从Channel当中取出数据，并将数据放到不同的目的地。 基本概念- Source：Source负责接收events或通过特殊机制产生events，并将events批量放到一个或多个Channels。有驱动和轮询2中类型的Source。 驱动型Source：是外部主动发送数据给Flume，驱动Flume接收数据。 轮询source：是FLume周期性主动去获取数据。 Source必须至少和一个channel关联。 Source的类型如下： 基本概念 - Channel：Channel位于Source和Sink之间，Channel的作用类似队列，用于临时缓存进来的events，当Sink成功地将events发送到下一跳的channel或最终目的，events从Channel移除。 不同的Channel提供的持久化水平也是不一样的： Memory Channel：不会持久化。消息存放在内存中，提供高吞吐，但提供可靠性；可能丢失数据。 File Channel：对数据持久化；基于WAL（预写式日志Write-Ahaad Log）实现。但是配置较为麻烦，需要配置数据目录和checkpoint目录；不同的file channel均需要配置一个checkpoint目录。 JDBC Channel：基于嵌入式Database实现。内置derby数据库，对event进行了持久化，提供高可靠性；可以取代同样持久特性的file channel。 Channels支持事物，提供较弱的顺序保证，可以连接任何数量的Source和Sink。 基本概念 - Sink：Sink负责将events传输到下一跳或最终目的，成功完成后将events从channel移除。 必须作用于一个确切的channel。 Sink类型： Flume关键特性介绍Flume支持采集日志文件： 图：Flume采集日志文件 Flume支持将集群外的日志文件采集并归档到HDFS、HBase、Kafka上，供上层应用对数据分析、清洗数据使用。 Flume支持多级级联和多路复制： 图：Flume级联 Flume支持将多个Flume级联起来，同时级联节点内部支持数据复制。 这个场景主要应用于：收集FusionInsight集群外上的节点上的日志，并通过多个Flume节点，最终汇聚到集群当中。 Flume级联消息压缩、加密： 图：Flume级联消息压缩、加密 Flume级联节点之间的数据传输支持压缩和加密，提升数据传输效率和安全性。 在同一个Flume内部进行传输时，不需要加密，为进程内部的数据交换。 Flume数据监控： 图：Flume数据监控 Source接收的数据量，Channel缓存的数据量，Sink写入的数据量，这些都可以通过Manager图形化界面呈现出来。 Flume传输可靠性： 图：Flume传输可靠性原理 Flume在传输数据过程中，采用事物管理方式，保证数据传输过程中数据不会丢失，增强了数据传输的可靠性，同时缓存在channel中的数据如果采用了file channel，进程或者节点重启数据不会丢失。 图：Flume传输过程中出错情况 Flume在传输数据过程中，如果下一跳的Flume节点故障或者数据接收异常时，可以自动切换到另外一路上继续传输。 Flume传输过程中数据过滤： 图：过滤原理 Flume在传输数据过程中，可以见到的对数据简单过滤、清洗，可以去掉不关心的数据，同时如果需要对复杂的数据过滤，需要用户根据自己的数据特殊性，开发过滤插件，Flume支持第三方过滤插件调用。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Flume</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Loader技术原理]]></title>
    <url>%2F2018%2F06%2F01%2FLoader%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Loader简介什么是Loader：Loader是实现FusionInsight HD与关系型数据库、文件系统之间交互数据和文件的数据加载工具。基于开源Sqoop研发，做了大量优化和扩展。提供可视化向导式的作业配置管理界面；提供定时调度任务，周期性执行Loader作业；在界面中可指定多种不同的数据源、配置数据的清洗和转换步骤、配置集群存储系统等。 Loader的特点： 图形化：提供图形化配置、监控界面，操作简便。 高性能：利用MapReduce并行处理数据。 高可靠：Loader Server采用主备双机；作业通过MapReduce执行，支持失败重试；作业失败后，不会残留数据。 安全：Kerberos认证；作业权限管理。 Loader的应用场景： 图：Loader的应用场景 通过Loader，我们可以从关系型数据库或文件系统中把数据导入HBase或者Hive，HDFS中。反过来，Loader也可以从HDFS和HBase中导出数据。但是Loader不支持从Hive当中导出数据，只能把数据导入Hive。 Loader在FusionInsight产品中的位置： 图：Loader在FusionInsight中的位置 FusionInsight HD提供大数据处理环境，基于社区开源软件增强，安装场景选择业界最佳实践；Porter是FusionInsight HD的数据集成服务，提供与Hadoop集群多种交换数据方式（包括Loader，Flume，SFTP）及Hadoop图形界面（Hue）。 Loader是实现FusionInsight HD与关系型数据库、文件系统之间交换数据和文件的数据加载工具。 Loader系统架构Loader模块架构： 图：Loader模块架构图 模块说明： 名称 描述 Loader Client Loader的客户端，包括WebUI和CLI两种交互界面。 Loader Server Loader的服务端，主要功能包括：处理客户端请求，管理连接器和元数据，提交MapReduce作业和监控MapReduce作业状态等。 REST API 实现RESTful（HTTP+JSON）接口，处理来自客户端的请求。 Job Scheduler 简单的作业调度模块，支持周期ing的执行Loader作业。 Transform Engine 数据转换处理引擎，支持字段合并、字符串剪切、字符串反序等。 Execution Engine Loader作业执行引擎，包含MapReduce作业的详细处理逻辑。 Submission Engine Loader作业提交引擎，支持将作业提交给MapReduce执行。 Job Manager 管理Loader作业，包括创建作业、查询作业、更新作业、删除作业、激活作业、去激活作业、启动作业、停止作业。 Metadata Repository 元数据仓库，存储和管理Loader的连接器、转换步骤、作业等数据。 HA Manager 管理Loader Server进程的主备状态，Loader Server包含2个节点，以主备方式部署。 Loader作业管理作业：​ 作业用来描述将数据从数据源经过抽取、转换和加载至目的端的过程。包括数据源位置及数据源属性、从源数据到目标数据的转换规则、目标端属性。 ​ Loader提供了诸多功能，用于管理与作业相关的操作。包括创建作业、导入作业、导出作业、迁移作业分组、批量删除作业、启动作业、停止作业、查看作业历史记录、复制作业和删除指定作业等功能。 脏数据：是指不符和Loader转换规则的数据。 作业转换规则：​ Loader提供了丰富的作用转换规则，能将数据按照不同的业务场景进行转换和清洗，转换成目标数据结构，实际应用中，如果不需要转换，可以不指定转换规则。 Loader提供了14中转换算子，描述如下： 长整型时间转换：实现长整型数值与日期类型的互换。 空值转换：将空值替换成指定值。 增加常量字段：生成常量字段。 随机值转换：生成羧基数据字段。 拼接转换：拼接已有字段，生成新字段。 分割转换：将已有字段，按指定分隔符，分割出新字段。 取模转换：对已有字段取模，生成新字段。 剪切字符串：通过指定起止位置，截取已有字符串类型的字段，生成新字段。 EL操作转换：指定算法，对字段值进行运算，目前支持的算法有：MD5sum、sha1sum、sha256sum和sha512sum等。 字符串大小写转换：对已有的字符串类型字典，切换大小写，生成新字段。 字符串逆序转换：对已有的字符串类型字段，做逆序变换，生成新字段。 字符串空格清除转换：对已有的字符串类型字段，清除左右空格，生成新字段。 过滤行转换：配置逻辑条件过滤掉含触发条件的行。 更新域：当满足某些条件时，更新字段的值。 客户端脚本介绍：Loader除了提供图形化操作界面外，还体用了一套完整的shell脚本，通过这些脚本，可实现数据源的增删查改，作业的增删查改、启动作业、停止作业，查看作业状态，判断作业是否正在运行等功能。 脚本介绍如下： lt-ctl：简称作业控制工具，用于查询作业状态、启动作业，停止作业以及判断作业是否在运行中。 lt-ucj：简称作业管理工具，用于查询、创建、修改和删除作业。 lt-ucc：简称数据源管理工具，用于查询、创建、修改和删除数据源连接信息。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Loader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink技术原理]]></title>
    <url>%2F2018%2F05%2F31%2FFlink%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Flink简介Flink概述： Flink是一个批处理和流处理结合的统一计算框架，其核心是一个提供了数据分发以及并发化计算的流数据处理引擎。它的最大亮点是流处理，是业界最顶级的开源流处理引擎。 Flink与Storm类似，属于事件驱动型实时流系统。 Flink特点： Streaming-first、流处理引擎。 Fault-tolerant，容错，可靠性，checkpoint。 Scalable，可扩展性，1000节点以上。 Performance，性能，高吞吐量， 低延迟。 Flink关键特性： 低延时：提供ms级时延的处理能力。 Exactly Once：提供异步快照机制，保证所有数据真正处理一次。 HA：JobManager支持主备模式，保证无单点故障。 水平扩展能力：TaskManager支持手动水平扩展。 Hadoop兼容性： Flink能够支持Yarn，能够从HDFS和HBase中获取数据。 能够使用所有的Hadoop的格式化输入和输出。 能够使用Hadoop原有的Mappers和Reducers，并且能与FLink的操作混合使用。 能够更快的运行Hadoop作业。 Flink应用场景：Flink最适合的应用场景是低延时的数据处理场景：高并发处理数据，实验毫秒级，且兼具可靠性。 典型应用场景有： 互联网金融业务。 点击流日志处理。 舆情监控。 流式计算框架的性能对比： 图：Storm和Flink流式计算框架的性能对比 通过对比，可以看出Flink流计算框架比Storm的性能高的多。 Flink在FusionInsight产品中的位置： 图：Flink在FusionInsight中的位置 FusionInsight HD提供大数处理环境，基于社交开源软件增强，按照场景选择业界最佳实践。 FLink是批处理和流处理结合的统计计算框架，用于高并发pipeline处理数据，实验毫秒级的场景响应，且兼具可靠性。 在FusionInsight HD集群中，Flink主要组以下组件进行交互： HDFS：Flink在HDFS文件系统中读写数据（必选）。 YARN：Flink任务的运行以来Yarn来进行资源的调度管理（必选）。 Zookeeper：FLink的checkpoint的实现依赖Zookeeper。（必选） Kafka：Flink可以接收Kafka发送的数据流（可选）。 Flink原理与技术架构Flink架构： 图：Flink架构图 ##Flink技术栈： 图：Flink技术栈 API:DataStream API是用于流处理的接口。 DataSet API是用于批处理的接口。它们都会使用单独编译的处理方式。 Core：Flink的Core叫做Runtime，是Flink流处理和批处理时共用的一个引擎。Runtime以 Deploy（部署方式）：在最底层，Flink提供了三种部署模式。分别为Local，Cluster，Cloud。 Flink核心概念–DataStream：DataStream：FLink用类DataStream来表示程序中的流式数据、用户可以认为它们是含有重复数据的不可修改的集合（Collection），DataStaram中元素的数据时无限的。 图：DataStream类 图：处理流程 Data Source：流数据源的接入，支持HDFS文件，Kafka，文本数据等。 Transformations：流数据转换。 Data sink：数据输出，支持HDFS，Kafka，文本等。 Flink数据源： 批处理： Files：HDFS，Local file system，MapReduce file system，Text，csv等。 JDBC HBase Collections 流处理： Files Socket streams Kafka Flume Collections RabbitMQ DataStream Transformation： 常用的Transformation有：map(), flatMap(), filter(), keyBy(), partition(), rebalance(), shuffle(), broadcast(), project()等。 Flink运行流程： 图：Flink架构，运行流程 关键角色概念： Client：需求提出方，负责提交需求（应用），构造流图。 JobManager：负责应用的资源管理，根据应用的需求，想资源管理部门（ResourceManager）申请资源。 Yarn的ResourceManager：资源管理部门，负责整个集群的资源统一调度和分配。 TaskManager：负责实际计算工资，一个应用会拆给多个TaskManager来进行计算。 TaskSlot：任务槽，类似于Yarn当中的Container，用于资源的封装。但是在FLink中，taskSlot只负责封装内存的资源，不包含CPU的资源。每一个TaskManager中会包含3个TaskSlot，所以每一个TaskManager中最多能并发执行的任务是可控的，最多3个。TaskSlot有独占的内存资源，在一个TaskManager中可以运行不同的任务。 Task：TsakSlot当中的Task就是任务执行的具体单元。 Flink on YARN： 图：Flink on YARN运行流程图 首先Flink Yarn Client会检验系统是否有足够的资源来启动YARN集群，如果资源足够，它就会将Jar包和配置文件上传到HDFS。 Flink YARN CLient首先与Yarn ResourceManager进行通信，申请启动applicationMaster，在FLink Yarn的集群中，ApplicationMaster与Flink JobManager被封装在同一个container中。 ApplicationMaster在启动的过程中，会和Yarn的ResourceManager进行交互，向ResourceManager申请所需要的TaskManager Container。当ApplicationMaster申请到TaskManager Container以后，它会在所对应的NodeManager节点上启动TaskManager进程。 由于ApplicationMaster和Flink JobManager是封装在同一个Container中的，所以ApplicationMaster会将JobManager的IPC地址，通过HDFS共享的方式通知到各个TaskManager上。TaskManager启动成功以后，就会向JobManager进行注册。 当所有的TaskManager都向JobManager注册成功以后，Flink基于Yarn的集群就启动成功了。Flink Yarn Client就可以提交FLink job到Flink JobManager上，然后进程后面的映射、调度、计算等处理。 Flink原理：用户实现的Flink程序是由Stream数据和Transformation算子组成。 Stream是一个中间结果数据，而Transformation是算子，它对一个或多个输入Stream进行计算处理，输出一个或多个结果Stream。 图：Flink原理图 Flink程序在执行的时候，会被映射成一个Streaming Dataflow，一个Streaming Dataflow是由一组Stream和Transformation Operator组成的。在启动时从一个或多个Source Operator开始，结束与一个或多个Sink Operator。 Source操作符载入数据，通过map(), keyBy(), apply()等Transformation操作符处理stream。数据处理完成后，调用sink写入相关存储系统，如HDFS、HBase、Kafka等。 ###Flink并行数据流： 图：Flink并行数据流 一个Stream可以被分成多个Stream的分区，也就是Stream Partition。一个Operator也可以被分为多个Operator Subtask。如上图中，Source被分成Source1和Source2，它们分别为Source的Operator Subtask。每一个Operator Subtask都是在不同的线程当中独立执行的。一个Operator的并行度，就等于Operator Subtask的个数。上图Source的并行度为2。而一个Stream的并行度就等于它生成的Operator的并行度。 数据在两个operator之间传递的时候有两种模式： One to One模式：两个operator用此模式传递的时候，会保持数据的分区数和数据的排序；如上图中的Source1到Map1，它就保留的Source的分区特性，以及分区元素处理的有序性。 Redistributing 模式：这种模式会改变数据的分区数；每个一个operator subtask会根据选择transformation把数据发送到不同的目标subtasks,比如keyBy()会通过hashcode重新分区,broadcast()和rebalance()方法会随机重新分区； ###Flink操作符链： 图：FLink操作符链 Flink内部有一个优化的功能，它会根据上下游算子的紧密程度来进行优化，紧密程度高的算子可以把它优化成一个大的Operator。如图中的Source和Map紧密程度很高，就可以优化成一个Operator Chain。实际上就是一个执行链，每个执行链都会在TaskManager中一个独立的线程汇总执行。Operator Chain实际上就是一个Operator，keyBy也是一个Operator，sink也是一个Operator，图的上半部分都是通过Stream连接，每个Operator都在一个独立的Task中运行。下半部分是上半部分的一个并行版本，对每一个Task都并行为多个Subtask。 Flink窗口：Flink支持基于时间窗口操作，也支持基于数据的窗口操作： 按分割标准划分：timeWindow、countWindow。 按窗口行为划分：Tumbling Window， Sliding Window、自定义窗口。 Flink常用窗口类型—时间和计数窗口：TimeWindow：时间窗口，按固定的时间划分的窗口。 CountWindow：事件窗口，窗口是以数据驱动的，比如每经过100个元素，就把这100个元素归结到一个事件窗口当中。 图：时间和事件窗口示意图 Flink常用窗口类型—滚动窗口：Tumbing Windows：滚动窗口，窗口之间时间点不重叠。它是按照固定的时间，或固定的事件个数划分的，分别可以叫做滚动时间窗口和滚动事件窗口。 图：时间滚动窗口示意图 Flink常用窗口类型—滑动窗口：Sliding Windows：滑动窗口，窗口之间时间点存在重叠。对于某些应用，它们需要的时间是不间断的，需要平滑的进行窗口聚合。例如，可以每30s记算一次最近1分钟用户所购买的商品数量的总数，这个就是时间滑动窗口；或者每10个客户点击购买，然后就计算一下最近100个客户购买的商品的总和，这个就是事件滑动窗口。 图 ：滑动窗口示意图 Flink常用窗口类型—会话窗口：Session Windows：会话窗口，经过一段设置时间无数据认为窗口完成。 图：会话窗口示意图 Flink高级特性Flink容错功能： ckeckpoint机制是FLink运行过程中容错的重要手段。 checkpoint机制不断绘制流应用的快照，流应用的状态快照被保存在配置的位置（如：JobManager的内存里，或者HDFS上）。 Flink分布式快照机制的核心是barriers，这些barriers周期性插入到数据流中，并作为数据流的一部分随之流动。 图：checkpoint机制 Checkpoint机制是Flink可靠运行的基石，可以保证Flink集群在某个算子因为某些原因（如异常退出）出现故障时，能够将整个应用流图的状态恢复到故障之前的某一状态，保证应用流图状态的一致性。 该机制可以保证应用在运行过程中出现失败时，应用的所以有状态能够从某一个检测点恢复，保证数据仅被处理一次（Exactly Once）。另外，也可以选择至少处理一次（at least once）。 Checkpoint机制具体执行过程： 图：Checkpoint机制执行具体过程 每个需要checkpoint的应用，它在启动的时候，Flink的JobManager就会为它创建一个checkpointCoordinator。checkpointCoordinator它全权负责本应用的快照的制作，用户可以通过checkpointCoordinator中的setCheckpointInterval接口设置checkpoint的周期。 Checkpoint机制的第一步，就是CheckpointCoordinator周期性的向该流应用，所有的source算子发送barrier。 第二步，Source算子接收到一个barrier后，便暂停处理数据，将当前的状态制作成快照，并保存到指定的持久化存储中，最后它再向CheckpointCoordinator报告自己的快照制作情况。同时向自身下游所有算子广播该barrier。然后恢复该算子的数据处理工作。 下游的算子接收到barrier后，也会暂停自的数据处理过程，同2过程。 最后CheckpointCoordinator会确认它接收到的报告，如果收到本周期的所有算子的快照就认为快照制作成功，否则失败。 多Source源的Checkpoint机制： 图：多Source源的Checkpoint机制 当一个算子上游有多个来源时，它会将首先接收到barrier端阻塞掉，等待其他输入端的barrier，只有当接收到所有输入端的barrier时，该算子才会开始合并barrier执行制作快照过程，并将合并后的barrier广播到下游算子。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pregel（图计算）技术原理]]></title>
    <url>%2F2018%2F05%2F30%2FPregel%EF%BC%88%E5%9B%BE%E8%AE%A1%E7%AE%97%EF%BC%89%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[图计算简介图结构数据： 许多大数据都是以大规模图或网络的形式呈现。 许多非图结构的大数据，也常常会被转换为图模型后进行分析。 图数据结构很好地表达了数据之间的关联性。 关联性计算是大数据计算的核心——通过获得数据的关联性，可以从噪音很多的海量数据中抽取有用的信息。 传统图计算解决方案的不足之处：很多传统的图计算算法都存在以下几个典型问题： 常常表现出比较差的内存访问局部性 针对单个顶点的处理工作过少 计算过程中伴随着并行度的改变 针对大型图（比如社交网络和网络图）的计算问题，可能的解决方案及其不足之处具体如下： 为特定的图应用定制相应的分布式实现 基于现有的分布式计算平台进行图计算 使用单机的图算法库：比如BGL、LEAD、NetworkX、JDSL、Standford GraphBase和FGL等 使用已有的并行图计算系统：比如，Parallel BGL和CGM Graph，实现了很多并行图算法 图计算通用软件：针对大型图的计算，目前通用的图计算软件主要包括两种： 第一种主要是基于遍历算法的、实时的图数据库，如Neo4j、OrientDB、DEX和 Infinite Graph。 第二种则是以图顶点为中心的、基于消息传递批处理的并行引擎，如GoldenOrb、Giraph、Pregel和Hama，这些图处理软件主要是基于BSP模型实现的并行图处理系统。 一次BSP(Bulk Synchronous Parallel Computing Model，块同步并行计算模型,又称“大同步”模型)计算过程包括一系列全局超步（所谓的超步就是计算中的一次迭代），每个超步主要包括三个组件： 局部计算：每个参与的处理器都有自身的计算任务。 通讯：处理器群相互交换数据。 栅栏同步(Barrier Synchronization)：当一个处理器遇到“路障”（或栅栏），会等到其他所有处理器完成它们的计算步骤。 图：一个超步的垂直结构图 Pregel图计算模型Pregel简介:谷歌公司在2003年到2004年公布了GFS、MapReduce和BigTable 谷歌在后Hadoop时代的新“三驾马车” Caffeine Dremel Pregel Pregel是一种基于BSP模型实现的并行图处理系统。 为了解决大型图的分布式计算问题，Pregel搭建了一套可扩展的、有容错机制的平台，该平台提供了一套非常灵活的API，可以描述各种各样的图计算。 Pregel作为分布式图计算的计算框架，主要用于图遍历、最短路径、PageRank计算等等。 有向图和顶点： 图：有向图和顶点 Pregel计算模型以有向图作为输入 有向图的每个顶点都有一个String类型的顶点ID 每个顶点都有一个可修改的用户自定义值与之关联 每条有向边都和其源顶点关联，并记录了其目标顶点ID 边上有一个可修改的用户自定义值与之关联 图：超步示意图 在每个超步S中，图中的所有顶点都会并行执行相同的用户自定义函数。 每个顶点可以接收前一个超步(S-1)中发送给它的消息，修改其自身及其出射边的状态，并发送消息给其他顶点，甚至是修改整个图的拓扑结构。 在这种计算模式中，“边。”并不是核心对象，在边上面不会运行相应的计算，只有顶点才会执行用户自定义函数进行相应计算。 顶点之间的消息传递: 图：纯消息传递模型图 采用消息传递模型主要基于以下两个原因： 消息传递具有足够的表达能力，没有必要使用远程读取或共享内存的方式. 有助于提升系统整体性能. Pregel的计算过程：Pregel的计算过程是由一系列被称为“超步”的迭代组成的。 在每个超步中，每个顶点上面都会并行执行用户自定义的函数，该函数描述了一个顶点V在一个超步S中需要执行的操作。 该函数可以读取前一个超步(S-1)中其他顶点发送给顶点V的消息，执行相应计算后，修改顶点V及其出射边的状态，然后沿着顶点V的出射边发送消息给其他顶点，而且，一个消息可能经过多条边的传递后被发送到任意已知ID的目标顶点上去。 这些消息将会在下一个超步(S+1)中被目标顶点接收，然后像上述过程一样开始下一个超步(S+1)的迭代过程。 在Pregel计算过程中，一个算法什么时候可以结束，是由所有顶点的状态决定的。 在第0个超步，所有顶点处于活跃状态。 当一个顶点不需要继续执行进一步的计算时，就会把自己的状态设置为“停机”，进入非活跃状态。 当一个处于非活跃状态的顶点收到来自其他顶点的消息时，Pregel计算框架必须根据条件判断来决定是否将其显式唤醒进入活跃状态。 当图中所有的顶点都已经标识其自身达到“非活跃（inactive）”状态，并且没有消息在传送的时候，算法就可以停止运行。 图：一个简单的状态机图 一个简单示例： 图：一个求最大值的Pregel计算过程图 Pregel的工作原理Pregel的C++ API：Pregel已经预先定义好一个基类——Vertex类： 12345678910111213141516171819template &lt;typename VertexValue, typename EdgeValue, typename MessageValue&gt;class Vertex &#123; public: //定义的虚函数，Computer（）；用户的处理逻辑在这实现 virtual void Compute(MessageIterator* msgs) = 0; //参数顶点ID const string&amp; vertex_id() const; //记录执行的超步数 int64 superstep() const; //获取顶点关联的值 const VertexValue&amp; GetValue(); VertexValue* MutableValue(); //出射边迭代器，获取所有的出射边 OutEdgeIterator GetOutEdgeIterator(); //发送消息 void SendMessageTo(const string&amp; dest_vertex, const MessageValue&amp; message); //设为停机 void VoteToHalt();&#125;; 在Vetex类中，定义了三个值类型参数，分别表示顶点、边和消息。每一个顶点都有一个给定类型的值与之对应。 编写Pregel程序时，需要继承Vertex类，并且覆写Vertex类的虚函数Compute()。 消息传递机制：顶点之间的通讯是借助于消息传递机制来实现的，每条消息都包含了消息值和需要到达的目标顶点ID。用户可以通过Vertex类的模板参数来设定消息值的数据类型。 在一个超步S中，一个顶点可以发送任意数量的消息，这些消息将在下一个超步（S+1）中被其他顶点接收。 一个顶点V通过与之关联的出射边向外发送消息，并且，消息要到达的目标顶点并不一定是与顶点V相邻的顶点，一个消息可以连续经过多条连通的边到达某个与顶点V不相邻的顶点U，U可以从接收的消息中获取到与其不相邻的顶点V的ID。 Combiner：Pregel计算框架在消息发出去之前，Combiner可以将发往同一个顶点的多个整型值进行求和得到一个值，只需向外发送这个“求和结果”，从而实现了由多个消息合并成一个消息，大大减少了传输和缓存的开销。 在默认情况下，Pregel计算框架并不会开启Combiner功能。 当用户打算开启Combiner功能时，可以继承Combiner类并覆写虚函数Combine()。 此外，通常只对那些满足交换律和结合律的操作才可以去开启Combiner功能。 图：Combiner应用的例子 Aggregator:Aggregator提供了一种全局通信、监控和数据查看的机制。 在一个超步S中，每一个顶点都可以向一个Aggregator提供一个数据，Pregel计算框架会对这些值进行聚合操作产生一个值，在下一个超步（S+1）中，图中的所有顶点都可以看见这个值。 Aggregator的聚合功能，允许在整型和字符串类型上执行最大值、最小值、求和操作，比如，可以定义一个“Sum”Aggregator来统计每个顶点的出射边数量，最后相加可以得到整个图的边的数量。 Aggregator还可以实现全局协同的功能，比如，可以设计“and” Aggregator来决定在某个超步中Compute()函数是否执行某些逻辑分支，只有当“and” Aggregator显示所有顶点都满足了某条件时，才去执行这些逻辑分支。 拓扑改变：Pregel计算框架允许用户在自定义函数Compute()中定义操作，修改图的拓扑结构，比如在图中增加（或删除）边或顶点。 对于全局拓扑改变，Pregel采用了惰性协调机制。 对于本地的局部拓扑改变，是不会引发冲突的，顶点或边的本地增减能够立即生效，很大程度上简化了分布式编程。 输入和输出：在Pregel计算框架中，图的保存格式多种多样，包括文本文件、关系数据库或键值数据库等。 在Pregel中，“从输入文件生成得到图结构”和“执行图计算”这两个过程是分离的，从而不会限制输入文件的格式。 对于输出，Pregel也采用了灵活的方式，可以以多种方式进行输出。 Pregel的体系结构Pregel的执行过程： 图：图的划分图 在Pregel计算框架中，一个大型图会被划分成许多个分区，每个分区都包含了一部分顶点以及以其为起点的边。 一个顶点应该被分配到哪个分区上，是由一个函数决定的，系统默认函数为hash(ID) mod N，其中，N为所有分区总数，ID是这个顶点的标识符；当然，用户也可以自己定义这个函数。 这样，无论在哪台机器上，都可以简单根据顶点ID判断出该顶点属于哪个分区，即使该顶点可能已经不存在了。 图：Pregel的执行过程 在理想的情况下（不发生任何错误），一个Pregel用户程序的执行过程如下： 选择集群中的多台机器执行图计算任务，有一台机器会被选为Master，其他机器作为Worker。 Master把一个图分成多个分区，并把分区分配到多个Worker。一个Worker会领到一个或多个分区，每个Worker知道所有其他Worker所分配到的分区情况。 Master会把用户输入划分成多个部分。然后，Master会为每个Worker分配用户输入的一部分。如果一个Worker从输入内容中加载到的顶点，刚好是自己所分配到的分区中的顶点，就会立即更新相应的数据结构。否则，该Worker会根据加载到的顶点的ID，把它发送到其所属的分区所在的Worker上。当所有的输入都被加载后，图中的所有顶点都会被标记为“活跃”状态。 Master向每个Worker发送指令，Worker收到指令后，开始运行一个超步。当一个超步中的所有工作都完成以后，Worker会通知Master，并把自己在下一个超步还处于“活跃”状态的顶点的数量报告给Master。上述步骤会被不断重复，直到所有顶点都不再活跃并且系统中不会有任何消息在传输，这时，执行过程才会结束。 计算过程结束后，Master会给所有的Worker发送指令，通知每个Worker对自己的计算结果进行持久化存储。 容错性：Pregel采用检查点机制来实现容错。在每个超步的开始，Master会通知所有的Worker把自己管辖的分区的状态写入到持久化存储设备。 Master会周期性地向每个Worker发送ping消息，Worker收到ping消息后会给Master发送反馈消息。 每个Worker上都保存了一个或多个分区的状态信息，当一个Worker发生故障时，它所负责维护的分区的当前状态信息就会丢失。Master监测到一个Worker发生故障“失效”后，会把失效Worker所分配到的分区，重新分配到其他处于正常工作状态的Worker集合上，然后，所有这些分区会从最近的某超步S开始时写出的检查点中，重新加载状态信息。 Worker:在一个Worker中，它所管辖的分区的状态信息是保存在内存中的。分区中的顶点的状态信息包括： 顶点的当前值。 以该顶点为起点的出射边列表，每条出射边包含了目标顶点ID和边的值。 消息队列，包含了所有接收到的、发送给该顶点的消息。 标志位，用来标记顶点是否处于活跃状态。 在每个超步中，Worker会对自己所管辖的分区中的每个顶点进行遍历，并调用顶点上的Compute()函数，在调用时，会把以下三个参数传递进去： 该顶点的当前值 一个接收到的消息的迭代器 一个出射边的迭代器 在Pregel中，为了获得更好的性能，“标志位”和输入消息队列是分开保存的。 对于每个顶点而言，Pregel只保存一份顶点值和边值，但是，会保存两份“标志位”和输入消息队列，分别用于当前超步和下一个超步。 如果一个顶点V在超步S接收到消息，那么，它表示V将会在下一个超步S+1中（而不是当前超步S中）处于“活跃”状态。 当一个Worker上的一个顶点V需要发送消息到其他顶点U时，该Worker会首先判断目标顶点U是否位于自己机器上。 如果目标顶点U在自己的机器上，就直接把消息放入到与目标顶点U对应的输入消息队列中。 如果发现目标顶点U在远程机器上，这个消息就会被暂时缓存到本地，当缓存中的消息数目达到一个事先设定的阈值时，这些缓存消息会被批量异步发送出去，传输到目标顶点所在的Worker上。 Master：Master的主要作用： Master主要负责协调各个Worker执行任务，每个Worker会借助于名称服务系统定位到Master的位置，并向Master发送自己的注册信息，Master会为每个Worker分配一个唯一的ID。 Master维护着关于当前处于“有效”状态的所有Worker的各种信息，包括每个Worker的ID和地址信息，以及每个Worker被分配到的分区信息。 Master中保存这些信息的数据结构的大小，只与分区的数量有关，而与顶点和边的数量无关。 Master与Worker的交互： 一个大规模图计算任务会被Master分解到多个Worker去执行，在每个超步开始时，Master都会向所有处于“有效”状态的Worker发送相同的指令，然后等待这些Worker的回应。 如果在指定时间内收不到某个Worker的反馈，Master就认为这个Worker失效。 如果参与任务执行的多个Worker中的任意一个发生了故障失效，Master就会进入恢复模式。 在每个超步中，图计算的各种工作，比如输入、输出、计算、保存和从检查点中恢复，都会在“路障（barrier）”之前结束。 Master在内部运行了一个HTTP服务器来显示图计算过程的各种信息。用户可以通过网页随时监控图计算执行过程各个细节： 图的大小 关于出度分布的柱状图 处于活跃状态的顶点数量 在当前超步的时间信息和消息流量 所有用户自定义Aggregator的值 Aggregator：每个用户自定义的Aggregator都会采用聚合函数对一个值集合进行聚合计算得到一个全局值。 每个Worker都保存了一个Aggregator的实例集，其中的每个实例都是由类型名称和实例名称来标识的。 在执行图计算过程的某个超步S中，每个Worker会利用一个Aggregator对当前本地分区中包含的所有顶点的值进行归约，得到一个本地的局部归约值。 在超步S结束时，所有Worker会将所有包含局部归约值的Aggregator的值进行最后的汇总，得到全局值，然后提交给Master。 在下一个超步S+1开始时，Master就会将Aggregator的全局值发送给每个Worker。 Pregel的应用实例—单源最短路径 图：Dijkstra算法是解决单源最短路径问题的贪婪算法 Pregel非常适合用来解决单源最短路径问题，实现代码如下： 12345678910111213141516class ShortestPathVertex : public Vertex&lt;int, int, int&gt; &#123; void Compute(MessageIterator* msgs) &#123; int mindist = IsSource(vertex_id()) ? 0 : INF; for (; !msgs-&gt;Done(); msgs-&gt;Next()) mindist = min(mindist, msgs-&gt;Value()); if (mindist &lt; GetValue()) &#123; *MutableValue() = mindist; OutEdgeIterator iter = GetOutEdgeIterator(); for (; !iter.Done(); iter.Next()) SendMessageTo(iter.Target(), mindist + iter.GetValue()); &#125; VoteToHalt(); &#125;&#125;; Hama简介Hama概述： Hama是Google Pregel的开源实现。 与Hadoop适合于分布式大数据处理不同，Hama主要用于分布式的矩阵、graph、网络算法的计算。 Hama是在HDFS上实现的BSP(Bulk Synchronous Parallel)计算框架，弥补Hadoop在计算能力上的不足。 Hama是基于BSP(BulkSynchronous Parallel)计算技术的并行计算框架，用于大量的科学计算（比如矩阵、图论、网络等）。BSP计算技术最大的优势是加快迭代，在解决最小路径等问题中可以快速得到可行解。同时，Hama提供简单的编程，比如flexible模型、传统的消息传递模型，而且兼容很多分布式文件系统，比如HDFS、Hbase等。用户可以使用现有的Hadoop集群进行Hama BSP. 现在Hama最新的版本为2012年6月31号发行的0.5.0.这是 Hama 做为 Apache 顶级项目后首次发布的版本，该版本包含两个显著的新特性，分别是消息压缩器和完整的 Google Pregel 克隆，另外在计算系统性能和可持续性上都得以提升。 Hama结构：Hama主要有三部分构成：BSPMaster、GroomServers 和Zookeeper。与Hadoop结构很相似，但没有通信和同步机制的部分。 Hama的集群由一个BSPMaster和多个互不关联的GroomServer作计算结点组成，HDFS和Zookeeper都可以是独立的集群。启动从BSPMaster开始，如果是master会启动BSPMaster、GroomServer两个进程，如果只是计算结点则只会启动GroomServer，启动/关闭脚本都是Master机器远程在GroomServer机器上执行。 图：Hama体系结构 BSPMaster:BSPMaster 即集群的主，负责了集群各GroomServer结点的管理与作业的调度，就我所知它还存在单点的问题。相当于Hadoop的JobTracker或HDFS的NameNode。其基本作用如下： 维持Groom服务器状态。 维护supersteps和集群中的计数器。 维护Job的进度信息。 调度作业和任务分配给Groom服务器 分配执行的类和配置，整个Groom服务器。 为用户提供集群控制接口（Web和基于控制台）。 GroomServer： GroomServer是一个process，通过BSPMaster启动BSP任务。每一个Groom都有BSPMaster通信，可以通过BSPMaster获取任务，报告状态。GroomServer在HDFS或者其他文件系统上运行，通常，GroomServer与与数据结点在一个物理结点上运行，以保证获得最佳性能。 Zookeeper：Zookeeper用来管理BSPPeer的同步，用于实现BarrierSynchronisation机制。在ZK上，进入BSPPeer主要有进入Barrier和离开Barrier操作，所有进入Barrier的Peer会在zk上创建一个EPHEMERAL的node（/bsp/JobID/Superstep NO./TaskID），最后一个进入Barrier的Peer同时还会创建一个readynode(/bsp/JobID/Superstep NO./ready)，Peer进入阻塞状态等待zk上所有task的node都删除后退出Barrier。 BSP Programming Model：BSP(BulkSynchronous Parallel，整体同步并行计算模型)是英国计算机科学家Viliant在上世纪80年代提出的一种并行计算模型。Google发布的一往篇论文(《Pregel: A System for Large-Scale Graph Processing》)使得这一概念被更多人所认识，据说在Google 80%的程序运行在MapReduce上，20%的程序运行在Pregel上。和MapReduce一样，Google并没有开源Pregel，Apache按Pregel的思想提供了类似框架Hama。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Pregel</tag>
        <tag>Hama</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark技术原理]]></title>
    <url>%2F2018%2F05%2F25%2FSpark%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spark概述Spark简介：Spark最初由美国加州伯克利大学（UCBerkeley）的AMP实验室于2009年开发，是基于内存计算的大数据并行计算框架，可用于构建大型的、低延迟的数据分析应用程序。 2013年Spark加入Apache孵化器项目后发展迅猛，如今已成为Apache软件基金会最重要的三大分布式计算系统开源项目之一（Hadoop、Spark、Storm）。 Spark在2014年打破了Hadoop保持的基准排序纪录 Spark/206个节点/23分钟/100TB数据 Hadoop/2000个节点/72分钟/100TB数据 Spark用十分之一的计算资源，获得了比Hadoop快3倍的速度。 Spark具有如下几个主要特点： 运行速度快：使用DAG执行引擎以支持循环数据流与内存计算。 容易使用：支持使用Scala、Java、Python和R语言进行编程，可以通过Spark Shell进行交互式编程。 通用性：Spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件。 运行模式多样：可运行于独立的集群模式中，可运行于Hadoop中，也可运行于Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源。 图：Spark的特点 Spark如今已吸引了国内外各大公司的注意，如腾讯、淘宝、百度、亚马逊等公司均不同程度地使用了Spark来构建大数据分析应用，并应用到实际的生产环境中。 图：谷歌应用趋势:Spark与Hadoop对比 Spark是什么？ Spark是一个基于内存的分布式批处理引擎。 由AMP LAB贡献到Apache社区的开源项目，是AMP大数据栈的基础组件。 Spark是一站式解决方案，集批处理、实时流计算、交互式查询、图计算与机器学习与一体。 Spark做什么？ 数据处理（Data Processing）：可以用来快速处理数据，兼具容错性和可扩展性。 迭代计算（Iterrative Computation）：支持迭代计算，有效应对多步数据处理逻辑。 数据挖掘（Data Mining）：在还海量数据的基础上进程复杂的挖掘分析，可支持各种数据挖掘和机器学习算法。 Spark适用场景： 数据处理,ETL（抽取、转换、加载） 机器学习。如：可用于自动判断淘宝买家的评论是好评还是差评。 交互式分析：可用于查询Hive数据仓库。 特别使用与迭代计算，数据重复利用场景。 流计算：流处理可用于页面点击浏览分析，推荐系统，舆情分析等实时业务。 需要反复操作的次数越多，所需读取的数据量越大，收益越大。 Scala简介：Scala是一门现代的多范式编程语言，运行于Java平台（JVM，Java 虚拟机），并兼容现有的Java程序。 Scala的特性： Scala具备强大的并发性，支持函数式编程，可以更好地支持分布式系统。 Scala语法简洁，能提供优雅的API Scala兼容Java，运行速度快，且能融合到Hadoop生态圈中。Scala是Spark的主要编程语言，但Spark还支持Java、Python、R作为编程语言 Scala的优势是提供了REPL（Read-Eval-Print Loop，交互式解释器），提高程序开发效率。 Spark与Hadoop的对比：对比Hadoop： 性能上提升高于100倍。 Spark的中间数据存放在内存中，对于迭代运算的效率更高，进行批处理时更高效。 更低的延时。 Spark提供更多的数据操作类型，编程模型比Hadoop更灵活，开发效率更高。 更高的容错能力（血统机制）。 Hadoop存在如下一些缺点： 表达能力有限 磁盘IO开销大 延迟高 任务之间的衔接涉及IO开销 在前一个任务执行完成之前，其他任务就无法开始，难以胜任复杂、多阶段的计算任务 Spark在借鉴Hadoop MapReduce优点的同时，很好地解决了MapReduce所面临的问题。 相比于Hadoop MapReduce，Spark主要具有如下优点： Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比Hadoop MapReduce更灵活。 Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高 Spark基于DAG的任务调度执行机制，要优于Hadoop MapReduce的迭代执行机制。 图：Hadoop与Spark的执行流程对比 使用Hadoop进行迭代计算非常耗资源。Spark将数据载入内存后，之后的迭代计算都可以直接使用内存中的中间结果作运算，避免了从磁盘中频繁读取数据。 图：Hadoop与Spark执行逻辑回归的时间对比 Spark生态系统##Spark生态系统的原因： 在实际应用中，大数据处理主要包括以下三个类型： 复杂的批量数据处理：通常时间跨度在数十分钟到数小时之间。 基于历史数据的交互式查询：通常时间跨度在数十秒到数分钟之间。 基于实时数据流的数据处理：通常时间跨度在数百毫秒到数秒之间。 当同时存在以上三种场景时，就需要同时部署三种不同的软件 比如: MapReduce / Impala / Storm 这样做难免会带来一些问题： 不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换。 不同的软件需要不同的开发和维护团队，带来了较高的使用成本。 比较难以对同一个集群中的各个系统进行统一的资源协调和分配。 Spark设计的理念：Spark的设计遵循“一个软件栈满足不同应用场景”的理念，逐渐形成了一套完整的生态系统。 既能够提供内存计算框架，也可以支持SQL即席查询、实时流式计算、机器学习和图计算等。 Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案。 因此，Spark所提供的生态系统足以应对上述三种场景，即同时支持批处理、交互式查询和流数据处理。 Spark生态系统： 图：BDAS架构 Spark生态系统已经成为伯克利数据分析软件栈BDAS（Berkeley Data Analytics Stack）的重要组成部分。 Spark的生态系统主要包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX 等组件。 Spark生态系统组件的应用场景： Spark运行架构 图：Spark体系架构 基本概念： RDD：是Resillient Distributed Dataset（弹性分布式数据集）的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型。 DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系。 Executor：是运行在工作节点（WorkerNode）的一个进程，负责运行Task。 Application：用户编写的Spark应用程序。 Task：运行在Executor上的工作单元。 Job：一个Job包含多个RDD及作用于相应RDD上的各种操作。 Stage：是Job的基本调度单位，一个Job会分为多组Task，每组Task被称为Stage，或者也被称为TaskSet，代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集。 Spark架构设计： Spark运行架构包括集群资源管理器（Cluster Manager）、运行作业任务的工作节点（Worker Node）、每个应用的任务控制节点（Driver）和每个工作节点上负责具体任务的执行进程（Executor）。 资源管理器可以自带或Mesos或YARN。（在华为FusionInsight中只能用YARN。） 与Hadoop MapReduce计算框架相比，Spark所采用的Executor有两个优点： 一是利用多线程来执行具体的任务，减少任务的启动开销。 二是Executor中有一个BlockManager存储模块，会将内存和磁盘共同作为存储设备，有效减少IO开销。 图：Spark中各种概念之间的相互联系 一个Application由一个Driver和若干个Job构成，一个Job由多个Stage构成，一个Stage由多个没有Shuffle关系的Task组成. 当执行一个Application时，Driver会向集群管理器申请资源，启动Executor，并向Executor发送应用程序代码和文件，然后在Executor上执行Task，运行结束后，执行结果会返回给Driver，或者写到HDFS或者其他数据库中。 Spark运行基本流程： 图：Spark运行基本流程图 Spark运行基本流程如下： 首先为应用构建起基本的运行环境，即由Driver创建一个SparkContext，进行资源的申请、任务的分配和监控。 资源管理器为Executor分配资源，并启动Executor进程。 SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAGScheduler解析成Stage，然后把一个个TaskSet提交给底层调度器TaskScheduler处理；Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行，并提供应用程序代码。 Task在Executor上运行，把执行结果反馈给TaskScheduler，然后反馈给DAGScheduler，运行完毕后写入数据并释放所有资源。 总体而言，Spark运行架构具有以下特点： 每个Application都有自己专属的Executor进程，并且该进程在Application运行期间一直驻留。Executor进程以多线程的方式运行Task。 Spark运行过程与资源管理器无关，只要能够获取Executor进程并保持通信即可。 Task采用了数据本地性和推测执行等优化机制。 Spark on Yarn的运行流程： 图：Spark on Yarn-client的运行流程 图：Spark on Yarn-cluster的运行流程 Yarn-client和Yarn-cluster的区别： Yarn-client和Yarn-cluster主要区别是Application Master进程的区别。 Yarn-client适合测试，Yarn-cluster适合生成。 Yarn-client任务提交节点宕机，整个任务失败。Yarn-cluster不会。 RDD运行原理设计背景：许多迭代式算法（比如机器学习、图算法等）和交互式数据挖掘工具，共同之处是，不同计算阶段之间会重用中间结果。 目前的MapReduce框架都是把中间结果写入到HDFS中，带来了大量的数据复制、磁盘IO和序列化开销。 RDD就是为了满足这种需求而出现的，它提供了一个抽象的数据架构，我们不必担心底层数据的分布式特性，只需将具体的应用逻辑表达为一系列转换处理，不同RDD之间的转换操作形成依赖关系，可以实现管道化，避免中间数据存储。 RDD概念：一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算。 RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和group by）而创建得到新的RDD。 RDD提供了一组丰富的操作以支持常见的数据运算，分为“动作”（Action）和“转换”（Transformation）两种类型。 RDD提供的转换接口都非常简单，都是类似map、filter、groupBy、join等粗粒度的数据转换操作，而不是针对某个数据项的细粒度修改（不适合网页爬虫）。 表面上RDD的功能很受限、不够强大，实际上RDD已经被实践证明可以高效地表达许多框架的编程模型（比如MapReduce、SQL、Pregel）。 Spark用Scala语言实现了RDD的API，程序员可以通过调用API实现对RDD的各种操作。 RDD典型的执行过程如下： RDD读入外部数据源进行创建。 RDD经过系列的转换（Transformation）操作，每一次都会产生不同的RDD，供给下一个转换操作使用。 最后一个RDD经过“动作”操作进行转换，并输出到外部数据源。 这一系列处理称为一个Lineage（血缘关系），即DAG拓扑排序的结果。 优点：惰性调用、管道化、避免同步等待、不需要保存中间结果、每次操作变得简单。 图：RDD执行过程的一个示例 RDD特性：Spark采用RDD以后能够实现高效计算的原因主要在于： （1）高效的容错性 现有容错机制：数据复制或者记录日志。 RDD：血缘关系、重新计算丢失分区、无需回滚系统、重算过程在不同节点之间并行、只记录粗粒度的操作。 （2）中间结果持久化到内存，数据在内存中的多个RDD操作之间进行传递，避免了不必要的读写磁盘开销 。 （3）存放的数据可以是Java对象，避免了不必要的对象序列化和反序列化。 RDD之间的依赖关系： 图：窄依赖于宽依赖的区别 窄依赖表现为一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区. 宽依赖则表现为存在一个父RDD的一个分区对应一个子RDD的多个分区。 Stage的划分：Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage，具体划分方法是： 在DAG中进行反向解析，遇到宽依赖就断开 遇到窄依赖就把当前的RDD加入到Stage中 将窄依赖尽量划分在同一个Stage中，可以实现流水线计算 图：根据RDD分区的依赖关系划分Stage 如上图，被分成三个Stage，在Stage2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作。 流水线操作实例： 分区7通过map操作生成的分区9，可以不用等待分区8到分区10这个map操作的计算结束，而是继续进行union操作，得到分区13，这样流水线执行大大提高了计算的效率。 Stage的类型包括两种：ShuffleMapStage和ResultStage，具体如下：（1）ShuffleMapStage：不是最终的Stage，在它之后还有其他Stage，所以，它的输出一定需要经过Shuffle过程，并作为后续Stage的输入；这种Stage是以Shuffle为输出边界，其输入边界可以是从外部获取数据，也可以是另一个ShuffleMapStage的输出，其输出可以是另一个Stage的开始；在一个Job里可能有该类型的Stage，也可能没有该类型Stage； （2）ResultStage：最终的Stage，没有输出，而是直接产生结果或存储。这种Stage是直接输出结果，其输入边界可以是从外部获取数据，也可以是另一个ShuffleMapStage的输出。在一个Job里必定有该类型Stage。因此，一个Job含有一个或多个Stage，其中至少含有一个ResultStage。 RDD运行的过程: 图；RDD在Spark中的运行过程 通过上述对RDD概念、依赖关系和Stage划分的介绍，结合之前介绍的Spark运行基本流程，再总结一下RDD在Spark架构中的运行过程：（1）创建RDD对象；（2）SparkContext负责计算RDD之间的依赖关系，构建DAG；（3）DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执行。 RDD的算子：Transformation： Transformation是通过转换从一个或多个RDD生成新的RDD，该操作时Lazy的，当调用action算子，才发起job。 典型算子：map、flatMap、filter、reduceByKey。 Action： 当代码调用该类型算子时，立即启动job。 典型算子：take、count、savaAsTextFile等。 Spark SQL从Shark说起：Shark即Hive on Spark，为了实现与Hive兼容，Shark在HiveQL方面重用了Hive中HiveQL的解析、逻辑执行计划翻译、执行计划优化等逻辑，可以近似认为仅将物理执行计划从MapReduce作业替换成了Spark作业，通过Hive的HiveQL解析，把HiveQL翻译成Spark上的RDD操作。 Shark的设计导致了两个问题： 一是执行计划优化完全依赖于Hive，不方便添加新的优化策略； 二是因为Spark是线程级并行，而MapReduce是进程级并行，因此，Spark在兼容Hive的实现上存在线程安全问题，导致Shark不得不使用另外一套独立维护的打了补丁的Hive源码分支。 图：Hive中SQL查询的MapReduce作业转换过程 Spark SQL设计:Spark SQL是Spark中用于结构化数据处理的模块。在Spark应用中，可以无缝的使用SQL语句亦或是DataFrame APi对结构化数据进程查询。 图：Spark SQL架构 Spark SQL在Hive兼容层面仅依赖HiveQL解析、Hive元数据，也就是说，从HQL被解析成抽象语法树（AST）起，就全部由Spark SQL接管了。Spark SQL执行计划生成和优化都由Catalyst（函数式关系查询优化框架）负责。 图：Spark SQL支持的数据格式和编程语言 Spark SQL增加了SchemaRDD（即带有Schema信息的RDD），使用户可以在Spark SQL中执行SQL语句，数据既可以来自RDD，也可以是Hive、HDFS、Cassandra等外部数据源，还可以是JSON格式的数据。 Spark SQL目前支持Scala、Java、Python三种语言，支持SQL-92规范。 Dataset简介：DataSet是一个由特定域的对象组成的强类型集合，可通过功能或关系操作并行转换其中的对象。 DataSet以Catalyst逻辑执行计划表示，并且数据以编码的二进制形式存储，不需要反序列化就可以执行sort、filter、shuffle等操作。 DataSet是“懒惰的”，只在执行cation操作时触发计算。当执行action操作时，Spark用查询优化程序来优化逻辑计划，并生成一个高效的并行分布式的物理计划。 DataFrame介绍：DateFrame：指定列名称的DataSet。DataFream是Dataset[Row]的特例。 RDD、DataFrame与Dataset：RDD： 优点：类型安全，面向对象。 缺点：序列化和反序列化的性能开销大；GC的性能开销，频繁的创建和销毁对象，势必会增加GC。 DataFrame： 优点：自带scheme信息，降低序列化反序列化开销。 缺点：不是面向对象的。编译器不安全。 Dataset的特点： 快：大多数场景下，性能优于RDD；Encoders（编译器）优于Kryo或者Java序列号；避免了不必要的格式转换。 类型安全：类似于RDD，函数尽可能编译时安全。 和DataFrame，RDD互相转换。 Dataset具有RDD和DataFrame的有点，又避免它们的缺点。 Spark SQL vs Hive：区别： Spark SQL的执行引擎为Spark core，HIve默认执行引擎为MapReduce。 Spark SQL的执行速度是Hive的10-100倍。 Spark SQL不支持buckets，Hive支持。 联系： Spark SQL依赖于Hive的元数据。 Spark SQL兼容绝大部分Hive的语法和函数。 Spark SQL可以使用HIve的自定义函数。 Spark Structured StreamingStructured Streaming概述：Structured Streaming是构建在Spark SQL引擎上的流式数据处理引擎。可以像使用静态RDD数据那样编写流式计算过程。当流数据连续不断的产生时，SPark SQL将会增量的、持续不断的处理这些数据，并将结果更新到结果集中。如下图: 图：Structured Streaming Structured Streaming计算模型： 图：计算模型图 图：计算模型示例 每一次计算后将结果更新到数据集中。 Spark Streaming概述：Spark Streaming是Spark核心API的一个扩展，一个实时计算框架。具有可扩展性、高吞吐量、可容错性等特定。 图：Spark Streaming过程示意图 Spark Streaming微批处理:Spark Streaming计算基于DStream，将流式计算分解成一系列短小的批处理作业。Spark引擎将数据生成最终结果数据。 图：批处理示意图 使用DStream从Kafka和HDFS等源获取连续的数据流，DStreams由一系列连续的RDD组成，每个RDD包含确定时间间隔的数据，任何对DStreams的操作都转换成对RDD的操作。 Spark Streaming容错机制：Spark Streaming本质仍是基于RDD计算，当RDD的某些partiton丢失，可以通过RDD的血统机制重新恢复丢失的RDD。 Spark的部署和应用方式Spark三种部署方式：Spark支持三种不同类型的部署方式，包括： Standalone（类似于MapReduce1.0，slot为资源分配单位） Spark on Mesos（和Spark有血缘关系，更好支持Mesos） Spark on YARN 从Hadoop+Storm架构转向Spark架构： 图：采用Hadoop+Storm部署方式的一个案例 用Spark架构具有如下优点：实现一键式安装和配置、线程级别的任务监控和告警. 降低硬件集群、软件维护、任务监控和应用开发的难度。 便于做成统一的硬件、计算平台资源池. ​ 需要说明的是，Spark Streaming无法实现毫秒级的流计算，因此，对于需要毫秒级实时响应的企业应用而言，仍然需要采用流计算框架（如Storm）. 图：用Spark架构满足批处理和流处理需求 Hadoop和Spark的统一部署：由于Hadoop生态系统中的一些组件所实现的功能，目前还是无法由Spark取代的，比如，Storm。 现有的Hadoop组件开发的应用，完全转移到Spark上需要一定的成本，不同的计算框架统一运行在YARN中，可以带来如下好处： 计算资源按需伸缩 不用负载应用混搭，集群利用率高 共享底层存储，避免数据跨集群迁移 图：Hadoop和Spark的统一部署]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Storm（流计算）技术原理]]></title>
    <url>%2F2018%2F05%2F24%2FStorm%EF%BC%88%E6%B5%81%E8%AE%A1%E7%AE%97%EF%BC%89%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[流计算概述什么是流数据：数据有静态数据和流数据。 静态数据： 很多企业为了支持决策分析而构建的数据仓库系统，其中存放的大量历史数据就是静态数据。技术人员可以利用数据挖掘和OLAP（On-Line Analytical Processing）分析工具从静态数据中找到对企业有价值的信息。 图：静态数据的一般处理流程 流数据： 近年来，在Web应用、网络监控、传感监测等领域，兴起了一种新的数据密集型应用——流数据，即数据以大量、快速、时变的流形式持续到达。 实例：PM2.5检测、电子商务网站用户点击流 流数据具有如下特征： 数据快速持续到达，潜在大小也许是无穷无尽的。 数据来源众多，格式复杂。 数据量大，但是不十分关注存储，一旦经过处理，要么被丢弃，要么被归档存储。 注重数据的整体价值，不过分关注个别数据。 数据顺序颠倒，或者不完整，系统无法控制将要处理的新到达的数据元素的顺序。 批量计算和实时计算：对静态数据和流数据的处理，对应着两种截然不同的计算模式：批量计算和实时计算。 批量计算：充裕时间处理静态数据，如Hadoop。 流计算：流数据不适合采用批量计算，因为流数据不适合用传统的关系模型建模。流数据必须采用实时计算，响应时间为秒级。在大数据时代，数据格式复杂、来源众多、数据量巨大，对实时计算提出了很大的挑战。因此，针对流数据的实时计算——流计算，应运而生。 图：数据的两种处理模型 流计算的概念：流计算：实时获取来自不同数据源的海量数据，经过实时分析处理，获得有价值的信息。 图：流计算示意图 流计算秉承一个基本理念，即数据的价值随着时间的流逝而降低，如用户点击流。因此，当事件出现时就应该立即进行处理，而不是缓存起来进行批量处理。为了及时处理流数据，就需要一个低延迟、可扩展、高可靠的处理引擎. 对于一个流计算系统来说，它应达到如下需求： 高性能 海量式 实时性 分布式 易用性 可靠性 Streaming定义：Streaming是基于开源Storm，是一个分布式、实时计算框架。 特点： 实时响应，低延时。 数据不存储，先计算 连续查询 事件驱动 传统数据库计算：数据先存储，在查询处理。 流计算与Hadoop:Hadoop设计的初衷是面向大规模数据的批量处理。 MapReduce是专门面向静态数据的批量处理的，内部各种实现机制都为批处理做了高度优化，不适合用于处理持续到达的动态数据。 可能会想到一种“变通”的方案来降低批处理的时间延迟——将基于MapReduce的批量处理转为小批量处理，将输入数据切成小的片段，每隔一个周期就启动一次MapReduce作业。但这种方式也无法有效处理流数据。 切分成小片段，可以降低延迟，但是也增加了附加开销，还要处理片段之间依赖关系。 需要改造MapReduce以支持流式处理。 结论：鱼和熊掌不可兼得，Hadoop擅长批处理，不适合流计算。 Streaming在FusionInsight中的位置： 图：Streaming在FusionInsight中的位置 Streaming是一个实时分布式的实时计算框架，在实时业务汇总有广泛的应用。 流计算框架：当前业界诞生了许多专门的流数据实时计算系统来满足各自需求。 商业级：IBM InfoSphere Streams和IBM StreamBase。 开源流计算框架 Twitter Storm：免费、开源的分布式实时计算系统，可简单、高效、可靠地处理大量的流数据。 Yahoo! S4（Simple Scalable Streaming System）：开源流计算平台，是通用的、分布式的、可扩展的、分区容错的、可插拔的流式系统。 公司为支持自身业务开发的流计算框架： Facebook Puma Dstream（百度） 银河流数据处理平台（淘宝） 流计算的应用：流计算是针对流数据的实时计算，可以应用在多种场景中。如百度、淘宝等大型网站中，每天都会产生大量流数据，包括用户的搜索内容、用户的浏览记录等数据。采用流计算进行实时数据分析，可以了解每个时刻的流量变化情况，甚至可以分析用户的实时浏览轨迹，从而进行实时个性化内容推荐。但是，并不是每个应用场景都需要用到流计算的。流计算适合于需要处理持续到达的流数据、对数据处理有较高实时性要求的场景。 主要应用于以下几种场景： 实时分析：如实时日志处理、交通流量分析等。 实时统计：如网站的实时访问统计、排序等。 实时推荐：如实时的广告定位、时间营销等。 流计算处理流程概述：传统的数据处理流程，需要先采集数据并存储在关系数据库等数据管理系统中，之后由用户通过查询操作和数据管理系统进行交互。 传统的数据处理流程隐含了两个前提： 存储的数据是旧的。存储的静态数据是过去某一时刻的快照，这些数据在查询时可能已不具备时效性了。 需要用户主动发出查询来获取结果。 流计算的处理流程一般包含三个阶段：数据实时采集、数据实时计算、实时查询服务。 图：流计算处理流程示意图 数据实时采集：数据实时采集阶段通常采集多个数据源的海量数据，需要保证实时性、低延迟与稳定可靠。 以日志数据为例，由于分布式集群的广泛应用，数据分散存储在不同的机器上，因此需要实时汇总来自不同机器上的日志数据。 目前有许多互联网公司发布的开源分布式日志采集系统均可满足每秒数百MB的数据采集和传输需求，如： Facebook的Scribe LinkedIn的Kafka 淘宝的Time Tunnel 基于Hadoop的Chukwa和Flume 数据采集系统的基本架构一般有以下三个部分： 图：数据采集系统基本框架 Agent：主动采集数据，并把数据推送到Collector部分。 Collector：接收多个Agent的数据，并实现有序、可靠、高性能的转发。 Store：存储Collector转发过来的数据（对于流计算不存储数据）。 数据实时计算：数据实时计算阶段对采集的数据进行实时的分析和计算，并反馈实时结果。 经流处理系统处理后的数据，可视情况进行存储，以便之后再进行分析计算。在时效性要求较高的场景中，处理之后的数据也可以直接丢弃。 图：数据实时计算流程 实时查询服务：实时查询服务：经由流计算框架得出的结果可供用户进行实时查询、展示或储存。 传统的数据处理流程，用户需要主动发出查询才能获得想要的结果。而在流处理流程中，实时查询服务可以不断更新结果，并将用户所需的结果实时推送给用户。 虽然通过对传统的数据处理系统进行定时查询，也可以实现不断地更新结果和结果推送，但通过这样的方式获取的结果，仍然是根据过去某一时刻的数据得到的结果，与实时结果有着本质的区别。 可见，流处理系统与传统的数据处理系统有如下不同： 流处理系统处理的是实时的数据，而传统的数据处理系统处理的是预先存储好的静态数据。 用户通过流处理系统获取的是实时结果，而通过传统的数据处理系统，获取的是过去某一时刻的结果。 流处理系统无需用户主动发出查询，实时查询服务可以主动将实时结果推送给用户。 开源流计算框架StormStorm简介：Twitter Storm是一个免费、开源的分布式实时计算系统，Storm对于实时计算的意义类似于Hadoop对于批处理的意义，Storm可以简单、高效、可靠地处理流数据，并支持多种编程语言。 Storm框架可以方便地与数据库系统进行整合，从而开发出强大的实时计算系统。 Twitter是全球访问量最大的社交网站之一，Twitter开发Storm流处理框架也是为了应对其不断增长的流数据实时处理需求。 Storm的特点：Storm可用于许多领域中，如实时分析、在线机器学习、持续计算、远程RPC、数据提取加载转换等。 Storm具有以下主要特点： 整合性 简易的API 可扩展性 可靠的消息处理 支持各种编程语言 快速部署 免费、开源 系统架构： 图：流计算系统架构图 基本概念：Storm主要术语包括Streams、Spouts、Bolts、Topology和Stream Groupings. Topology：Streaming中运行的一个实时应用程序。 Nimbus：负责资源分配和任务调度。 Supervisor：负责接收Nimbus分配的任务，启动和停止属于自己管理的worker进程。 Worker：Topology运行时的物理进程。每个Worker是一个JVM进程。 Spout：Storm认为每个Stream都有一个源头，并把这个源头抽象为Spout。 在一个Topology中产生源数据流的组件。 通常Spout会从外部数据源（队列、数据库等）读取数据，然后封装成Tuple形式，发送到Stream中。Spout是一个主动的角色，在接口内部有个nextTuple函数，Storm框架会不停的调用该函数。 Bolt：在一个Topology中接收数据后然后执行处理的组件。 Task：Worker中每一个Spout/Bolt的线程称为一个Task。 Tuple：Streaming的核心数据结构，是消息传递的基本单元，不可变Key-Value对，这些Tuple会以一种分布式的方式进程创建和处理。 Stream：Storm将流数据Stream描述成一个无限的Tuple序列，这些Tuple序列会以分布式的方式并行地创建和处理。即无界的Tuple序列。 Zookeeper：为Streaming服务中各自进程提供分布式的协作服务、主备Nimbus、Supervisor、Worker将自己的信息注册到Zookeeper中，Nimbus据此感知各个角色的监控状态。 Topology介绍： 图：Topology示意图 Storm将Spouts和Bolts组成的网络抽象成Topology，它可以被提交到Storm集群执行。Topology可视为流转换图，图中节点是一个Spout或Bolt，边则表示Bolt订阅了哪个Stream。当Spout或者Bolt发送元组时，它会把元组发送到每个订阅了该Stream的Bolt上进行处理。 Topology里面的每个处理组件（Spout或Bolt）都包含处理逻辑， 而组件之间的连接则表示数据流动的方向。 Topology里面的每一个组件都是并行运行的： 在Topology里面可以指定每个组件的并行度，Storm会在集群里面分配那么多的线程来同时计算。 在Topology的具体实现上，Storm中的Topology定义仅仅是一些Thrift结构体（二进制高性能的通信中间件），支持各种编程语言进行定义。 一个Topology是由一组Spout组件(数据源)和Bolt组件（逻辑处理）通过Stream Groupings进行连接的有向无环图（DAG）。 业务处理逻辑被封装进Streaming中的Topology中。 Worker介绍： 图：Worker Process示意图 Worker：一个Worker是一个JVM进程，所有的Topology都是在一个或者多个Worker中运行的。Worker启动后是长期运行的，除非人工停止。Worker进程的个数取决于Topology的设置，且无设置上限，具体可获得并调度启动的Worker个数则取决于Supervisor配置的slot个数。 Executor：在一个单独的Worker进程中会运行一个或多个Executor线程。每个Executor只能运Spout或者Bolt中的一个或多个Task实例。 Task：是最终完成数据处理的实体单元。 Task介绍： 图：Task示意图 Topology里面的每一个Component(组件)（Spout/Blot）节点都是并行运行的。在Topology里面，可以指定每个节点的并发度，Streaming则会在集群里分配响应的Task来同时计算，以增强系统的处理能力。 消息分发策略（Stream Groupings）：Groupings：Storm中的Stream Groupings用于告知Topology如何在两个组件间（如Spout和Bolt之间，或者不同的Bolt之间）进行Tuple的传送。每一个Spout和Bolt都可以有多个分布式任务，一个任务在什么时候、以什么方式发送Tuple就是由Stream Groupings来决定的。 目前，Storm中的Stream Groupings有如下几种方式： ShuffleGrouping：随机分组，随机分发Stream中的Tuple，保证每个Bolt的Task接收Tuple数量大致一致。 FieldsGrouping：按照字段分组，保证相同字段的Tuple分配到同一个Task中。 AllGrouping：广播发送，每一个Task都会收到所有的Tuple。 GlobalGrouping：全局分组，所有的Tuple都发送到同一个Task中。 NonGrouping：不分组，和ShuffleGrouping类似，当前Task的执行会和它的被订阅者在同一个线程中执行。 DirectGrouping：直接分组，直接指定由某个Task来执行Tuple的处理。 Storm框架设计：Storm集群采用“Master—Worker”的节点方式： Master节点运行名为“Nimbus”的后台程序（类似Hadoop中的“JobTracker”），负责在集群范围内分发代码、为Worker分配任务和监测故障。 Worker节点运行名为“Supervisor”的后台程序，负责监听分配给它所在机器的工作，即根据Nimbus分配的任务来决定启动或停止Worker进程，一个Worker节点上同时运行若干个Worker进程。 Storm使用Zookeeper来作为分布式协调组件，负责Nimbus和多个Supervisor之间的所有协调工作。借助于Zookeeper，若Nimbus进程或Supervisor进程意外终止，重启时也能读取、恢复之前的状态并继续工作，使得Storm极其稳定。 图：Storm集群架构示意图 Nimbus并不直接和Supervisor交换，而是通过Zookeeper进行消息的传递。 Storm和Hadoop架构组件功能对应关系：Storm运行任务的方式与Hadoop类似：Hadoop运行的是MapReduce作业，而Storm运行的是“Topology”。 但两者的任务大不相同，主要的不同是：MapReduce作业最终会完成计算并结束运行，而Topology将持续处理消息（直到人为终止）。 图：Storm和Hadoop架构组件功能对应关系 Storm工作流程： 图：Storm工作流程示意图 Storm工作流程为： 提交Topology 将任务存储在Zookeeper中 获取分配的任务，并启动Worker Worker进程执行具体的任务 所有Topology任务的提交必须在Storm客户端节点上进行，提交后，由Nimbus节点分配给其他Supervisor节点进行处理。 Nimbus节点首先将提交的Topology进行分片，分成一个个Task，分配给相应的Supervisor，并将Task和Supervisor相关的信息提交到Zookeeper集群上。 Supervisor会去Zookeeper集群上认领自己的Task，通知自己的Worker进程进行Task的处理。 Streaming提供的接口：REST接口：（Representational State Transfer）表述性状态转移接口。 Thrift接口：由Nimbus提供。Thrift是一个基于静态代码生成的跨语言的RPC协议栈实现，它可以生成包括C++,Java,Python, Ruby ， PHP等主流语言的代码实现，这些代码实现了RPC的协议层和传输层功能，从而让用户可以集中精力与服务的调用和实现。 Streaming的关键特性介绍Nimbus HA： 图：Nimbus HA架构 使用Zookeeper分布式锁： Nimbus HA的实现是使用Zookeeper分布式锁，通过主备间争抢模式完成的Leader选举和主备切换。 主备间元数据同步： 主备Nimbus之间会周期性的同步元数据，保证在发生主备切换后拓扑数据不丢失，业务不受损。 容灾能力： 图：容灾示意图 容灾能力：节点失效，自动迁移到正常节点，业务不中断。 整个过程无需人工干预！ 消息可靠性： 在Streaming里面一个Tuple被完全处理的意思是：这个Tuple所派生的所有tuple都被成功处理。如果这个消息在Timeout所指定的时间内没有成功处理，这个tuple就被认为处理失败了。 可靠性级别设置： ​ 如果并不要求每个消息必须被处理（允许在处理过程中丢失一些信息），那么可以关闭消息的可靠性处理机制，从而可以获得较好的性能。关闭消息的可靠性机制一位着系统中的消息数会减半。 有三种方法可以关闭消息的可靠性处理机制： 将参数Config.TOPOLGY_ACKERS设置为0. Spout发送一个消息时，使用不指定消息message ID的接口进行发送。 Blot发送消息时使用Unanchor方式发送，使Tuple树不往下延伸，从而关闭派生消息的可靠性。 ACK机制： 图：Ack机制 一个Spout发送一个Tuple时，会通知Acker一个新的根消息产生了，Acker会创建一个新的Tuple tree，并初始化校验和为0. Bolt发送消息时间向Acker发送anchor tuple，刷新tuple tree，并在发送成功后向Acker反馈结果。如果成功则重新刷新校验和，如果失败则Acker会立即通知Spout处理失败。 当Tuple tree被完成吹了（校验和为0），Acker会通知Spout处理成功。 Spout提供ack（）和Fail（）接口方法用户处理Acker的反馈结果，需要用户实现。一般在fail（）方法中实现消息重发逻辑。 Streaming与其他组件： 整合HDFS/HBase等外部组件，将实时结构提供给其他组件，进程离线分析。 Spark StreamingSpark Streaming设计：Spark Streaming可整合多种输入数据源，如Kafka、Flume、HDFS，甚至是普通的TCP套接字。经处理后的数据可存储至文件系统、数据库，或显示在仪表盘里。 图：SPark Streaming支持的输入、输出数据源 Spark Streaming的基本原理是将实时输入数据流以时间片（秒级）为单位进行拆分，然后经Spark引擎以类似批处理的方式处理每个时间片数据。 图：Spark Streaming执行流程 Spark Streaming最主要的抽象是DStream（Discretized Stream，离散化数据流），表示连续不断的数据流。在内部实现上，Spark Streaming的输入数据按照时间片（如1秒）分成一段一段的DStream，每一段数据转换为Spark中的RDD，并且对DStream的操作都最终转变为对相应的RDD的操作。 图：DStream操作示意图 Spark Streaming 与 Storm的对比： Spark Streaming和Storm最大的区别在于，Spark Streaming无法实现毫秒级的流计算，而Storm可以实现毫秒级响应。 Spark Streaming构建在Spark上，一方面是因为Spark的低延迟执行引擎（100ms+）可以用于实时计算，另一方面，相比于Storm，RDD数据集更容易做高效的容错处理。 Spark Streaming采用的小批量处理的方式使得它可以同时兼容批量和实时数据处理的逻辑和算法，因此，方便了一些需要历史数据和实时数据联合分析的特定应用场合。 Samza技术原理基本概念：（1）作业：一个作业（Job）是对一组输入流进行处理转化成输出流的程序。 （2）分区： Samza的流数据单位既不是Storm中的元组，也不是Spark Streaming中的DStream，而是一条条消息。 Samza中的每个流都被分割成一个或多个分区，对于流里的每一个分区而言，都是一个有序的消息序列，后续到达的消息会根据一定规则被追加到其中一个分区里。 （3）任务： 一个作业会被进一步分割成多个任务（Task）来执行，其中，每个任务负责处理作业中的一个分区。 分区之间没有定义顺序，从而允许每一个任务独立执行。 YARN调度器负责把任务分发给各个机器，最终，一个工作中的多个任务会被分发到多个机器进行分布式并行处理。 （4）数据流图： 一个数据流图是由多个作业构成的，其中，图中的每个节点表示包含数据的流，每条边表示数据传输。 多个作业串联起来就完成了流式的数据处理流程。 由于采用了异步的消息订阅分发机制，不同任务之间可以独立运行。 图：数据流图 Samza的系统架构：Samza系统架构主要包括： 流数据层（Kafka） 执行层（YARN） 处理层（Samza API） 流处理层和执行层都被设计成可插拔的，开发人员可以使用其他框架来替代YARN和Kafka。 图：MapReduce批处理架构和Samza流处理架构对比 处理分析过程： 图：处理分析过程图 处理分析过程如下： Samza客户端需要执行一个Samza作业时，它会向YARN的ResouceManager提交作业请求。 ResouceManager通过与NodeManager沟通为该作业分配容器（包含了CPU、内存等资源）来运行Samza ApplicationMaster。 Samza ApplicationMaster进一步向ResourceManager申请运行任务的容器。 获得容器后，Samza ApplicationMaster与容器所在的NodeManager沟通，启动该容器，并在其中运行Samza Task Runner。 Samza Task Runner负责执行具体的Samza任务，完成流数据处理分析。 Storm、Spark Streaming和Samza的应用场景从编程的灵活性来讲，Storm是比较理想的选择，它使用Apache Thrift，可以用任何编程语言来编写拓扑结构（Topology）。 当需要在一个集群中把流计算和图计算、机器学习、SQL查询分析等进行结合时，可以选择Spark Streaming，因为，在Spark上可以统一部署Spark SQL，Spark Streaming、MLlib，GraphX等组件，提供便捷的一体化编程模型。 当有大量的状态需要处理时，比如每个分区都有数十亿个元组，则可以选择Samza。当应用场景需要毫秒级响应时，可以选择Storm和Samza，因为Spark Streaming无法实现毫秒级的流计算。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Storm</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Impala技术原理]]></title>
    <url>%2F2018%2F05%2F22%2FImpala%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Impala简介Impala是由Cloudera公司开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase上的PB级大数据，在性能上比Hive高出3~30倍。 Impala的运行需要依赖于Hive的元数据。Impala是参照 Dremel系统进行设计的。 Impala采用了与商用并行关系数据库类似的分布式查询引擎，可以直接与HDFS和HBase进行交互查询。 Impala和Hive采用相同的SQL语法、ODBC驱动程序和用户接口。 图：Impala与其他组件的关系 Impala系统架构 图：Impala系统架构图 Impala和Hive、HDFS、HBase等工具是统一部署在一个Hadoop平台上的。Impala主要由Impalad，State Store和CLI三部分组成。 （1）Impalad 负责协调客户端提交的查询的执行 包含Query Planner、Query Coordinator和Query Exec Engine三个模块。 与HDFS的数据节点（HDFS DN）运行在同一节点上。 给其他Impalad分配任务以及收集其他Impalad的执行结果进行汇总。 Impalad也会执行其他Impalad给其分配的任务，主要就是对本地HDFS和HBase里的部分数据进行操作。 （2）State Store 会创建一个statestored进程。 负责收集分布在集群中各个Impalad进程的资源信息，用于查询调度。 （3）CLI 给用户提供查询使用的命令行工具。 还提供了Hue、JDBC及ODBC的使用接口。 说明：Impala中的元数据直接存储在Hive中。Impala采用与Hive相同的元数据、SQL语法、ODBC驱动程序和用户接口，从而使得在一个Hadoop平台上，可以统一部署Hive和Impala等分析工具，同时支持批处理和实时查询。 Impala查询执行过程 图：Impala查询执行过程图 Impala执行查询的具体过程： 第0步，当用户提交查询前，Impala先创建一个负责协调客户端提交的查询的Impalad进程，该进程会向Impala State Store提交注册订阅信息，State Store会创建一个statestored进程，statestored进程通过创建多个线程来处理Impalad的注册订阅信息。 第1步，用户通过CLI客户端提交一个查询到impalad进程，Impalad的Query Planner对SQL语句进行解析，生成解析树；然后，Planner把这个查询的解析树变成若干PlanFragment，发送到Query Coordinator. 第2步，Coordinator通过从MySQL元数据库中获取元数据，从HDFS的名称节点中获取数据地址，以得到存储这个查询相关数据的所有数据节点。 第3步，Coordinator初始化相应impalad上的任务执行，即把查询任务分配给所有存储这个查询相关数据的数据节点。 第4步，Query Executor通过流式交换中间输出，并由Query Coordinator汇聚来自各个impalad的结果。 第5步，Coordinator把汇总后的结果返回给CLI客户端。 Impala与Hive的比较 图：Impala与Hive的对比 Hive与Impala的不同点总结如下： Hive适合于长时间的批处理查询分析，而Impala适合于实时交互式SQL查询。 Hive依赖于MapReduce计算框架，Impala把执行计划表现为一棵完整的执行计划树，直接分发执行计划到各个Impalad执行查询。 Hive在执行过程中，如果内存放不下所有数据，则会使用外存，以保证查询能顺序执行完成，而Impala在遇到内存放不下数据时，不会利用外存，所以Impala目前处理查询时会受到一定的限制。 Hive与Impala的相同点总结如下： Hive与Impala使用相同的存储数据池，都支持把数据存储于HDFS和HBase中。 Hive与Impala使用相同的元数据。 Hive与Impala中对SQL的解释处理比较相似，都是通过词法分析生成执行计划。 总结： Impala的目的不在于替换现有的MapReduce工具。 把Hive与Impala配合使用效果最佳。 可以先使用Hive进行数据转换处理，之后再使用Impala在Hive处理后的结果数据集上进行快速的数据分析。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Impala</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive技术原理]]></title>
    <url>%2F2018%2F05%2F22%2FHive%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Hive概述数据仓库的概念：数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。 传统数据仓库面临的挑战： 无法满足快速增长的海量数据存储需求。 无法有效处理不同类型的数据。 计算和处理能力不足。 Hive简介： Hive是一个构建于Hadoop顶层的数据仓库工具，可以查询和管理PB级别的分布式数据。 支持大规模数据存储、分析，具有良好的可扩展性 某种程度上可以看作是用户编程接口，本身不存储和处理数据。 依赖分布式文件系统HDFS存储数据。 依赖分布式并行计算模型MapReduce处理数据。 定义了简单的类似SQL 的查询语言——HiveQL。 用户可以通过编写的HiveQL语句运行MapReduce任务。 可以很容易把原来构建在关系数据库上的数据仓库应用程序移植到Hadoop平台上。 是一个可以提供有效、合理、直观组织和使用数据的分析工具。 Hive具有的特点非常适用于数据仓库。 （1）采用批处理方式处理海量数据 Hive需要把HiveQL语句转换成MapReduce任务进行运行。 数据仓库存储的是静态数据，对静态数据的分析适合采用批处理方式，不需要快速响应给出结果，而且数据本身也不会频繁变化。 （2）提供适合数据仓库操作的工具 Hive本身提供了一系列对数据进行提取、转换、加载（ETL）的工具，可以存储、查询和分析存储在Hadoop中的大规模数据。 这些工具能够很好地满足数据仓库各种应用场景。 （3）支持MapReduce，Tez，Spark等多种计算引擎。 （4）可以直接访问HDFS文件以及HBase。 （5）易用易编程。 Hive与Hadoop生态系统中其他组件的关系： 图：Hadoop生态系统 Hive依赖于HDFS 存储数据 Hive依赖于MapReduce 处理数据 在某些场景下Pig可以作为Hive的替代工具 HBase 提供数据的实时访问 Hive的优缺点：Hive的优点： 高可靠、高容错：HiveServer采用集群模式。双MetaStor。超时重试机制。 类SQL：类似SQL语法，内置大量函数。 可扩展：自定义存储格式，自定义函数。 多接口：Beeline，JDBC，ODBC，Python，Thrift。 Hive的缺点： 延迟较高：默认MR为执行引擎，MR延迟较高。 不支持雾化视图：Hive支持普通视图，不支持雾化视图。Hive不能再视图上更新、插入、删除数据。 不适用OLTP：暂不支持列级别的数据添加、更新、删除操作。 暂不支持存储过程：当前版本不支持存储过程，只能通过UDF来实现一些逻辑处理。 Hive与传统数据库的对比分析：Hive在很多方面和传统的关系数据库类似，但是它的底层依赖的是HDFS和MapReduce，所以在很多方面又有别于传统数据库。 Hive在企业中的部署和作用：Hive在企业大数据分析平台中的应用： 图：企业中一种常见的大数据分析平台部署框架 Hive在Facebook公司中的应用： 基于Oracle的数据仓库系统已经无法满足激增的业务需求 Facebook公司开发了数据仓库工具Hive，并在企业内部进行了大量部署 Hive在FusionInsight中的位置： 图：Hive在FusionInsight中的位置 Hive是一种数据仓库处理工具，使用类SQL的HiveQL语言实现数据查询功能，所有的Hive数据都存储在HDFS中。 Hive应用场景： 数据挖掘：用户行为分析；兴趣分区；区域展示； 非实时分析：日志分析；文本分析。 数据汇总：每天/每周用户点击数，流量统计。 数据仓库：数据抽取，加载，转换（ETL）。 Hive功能与架构Hive系统架构： 图：Hive系统架构 用户接口模块包括CLI、HWI、JDBC、ODBC、Thrift Server。 驱动模块（Driver）包括编译器、优化器、执行器等，负责把HiveSQL语句转换成一系列MapReduce作业。 元数据存储模块（Metastore）是一个独立的关系型数据库（自带derby数据库，或MySQL数据库）。 FusionInsight HD中Hive的架构： 图：FusionInsight中Hive的架构 Hive分为三个角色：HiveServer、MetaStore、WebHcat。 HiveServer：将用户提交的HQL语句进行编译，解析成对应的Yarn任务，Spark任务或者HDFS操作，从而完成数据的提取，转换，分析。 MetaStroe：提供元数据服务。 WebHcat：对外提供基于Htpps洗衣的元数据访问、DDL查询等服务。 HCatalog架构： 图：HCatalog架构 HCatalog包括Hcatalog Client和Hcatalog Server： HCatalog CLient包括命令行工具CLI和Clent jar包（用于给Pig， MR提供元数据读写支持）。 HCatalog通过Hive提供的HiveMetaStoreClent对象来间接访问MetaStore。 HCatalog对外提供Hcatloader，HCatinputFormat来读取数据；提供HCatStore,HCatOutputFormat来写入数据。 WebHCat架构： 图：WebHCat架构 WebHCat提供Rest接口，是用户能够通过安全的HTTPS协议执行以下操作： 执行Hive DDL操作。 运行Hive HQL任务。 运行MapReduce任务。 Hive数据存储模型： 图：Hive数据存储模型 分区：数据表可以按照某个字段的值划分分区。 每个分区是一个目录。 分区数量不固定。 分区下可再有分区或者桶。 桶：数据可以根据桶的方式将不同数据放入不同的桶中。 每个桶是一个文件。 建表时指定桶个数，桶内可排序。 数据按照某个字段的值Hash后放入某个桶中。 Hive可以创建托管表和外部表： 默认创建托管表，Hiva会将数据移动到数据仓库的目录。 创建外部表，这时Hiva会到仓库目录以外的位置访问数据。 如果所有处理都由Hive完成，建议使用托管表。 如果要用Hive和其他工具来处理同一个数据集，建议使用外部表。 Hive支持的函数： Hive内置函数： 数据函数：如round(),fllor(), abs(), rand()等。 日期函数：如to_date(), month(), day(). 字符串函数,如trim(), length(), substr()等。 UDF（User-Defined Funcation）用户自定义函数。 Hive工作原理：（1）SQL语句转换成MapReduce作业的基本原理： 图：join的实现原理 图：group by实现原理 存在一个分组（Group By）操作，其功能是把表Score的不同片段按照rank和level的组合值进行合并，计算不同rank和level的组和值分别有几条记录。 （2）Hive中SQL查询转换成MapReduce作用的过程：当用户向Hive输入一段命令或查询时，Hive需要与Hadoop交互工作来完成该操作： 驱动模块接收该命令或查询编译器 对该命令或查询进行解析编译 由优化器对该命令或查询进行优化计算 该命令或查询通过执行器进行执行 详细如果如下： 图：SQL查询转换成MapReduce作业的过程 第1步：由Hive驱动模块中的编译器对用户输入的SQL语言进行词法和语法解析，将SQL语句转化为抽象语法树的形式。 第2步：抽象语法树的结构仍很复杂，不方便直接翻译为MapReduce算法程序，因此，把抽象语法书转化为查询块。 第3步：把查询块转换成逻辑查询计划，里面包含了许多逻辑操作符。 第4步：重写逻辑查询计划，进行优化，合并多余操作，减少MapReduce任务数量。 第5步：将逻辑操作符转换成需要执行的具体MapReduce任务。 第6步：对生成的MapReduce任务进行优化，生成最终的MapReduce任务执行计划。 第7步：由Hive驱动模块中的执行器，对最终的MapReduce任务进行执行输出。 几点说明： 当启动MapReduce程序时，Hive本身是不会生成MapReduce算法程序的。 需要通过一个表示“Job执行计划”的XML文件驱动执行内置的、原生的Mapper和Reducer模块。 Hive通过和JobTracker通信来初始化MapReduce任务，不必直接部署在JobTracker所在的管理节点上执行。 通常在大型集群上，会有专门的网关机来部署Hive工具。网关机的作用主要是远程操作和管理节点上的JobTracker通信来执行任务。 数据文件通常存储在HDFS上，HDFS由名称节点管理。 #Hive增强特性 Hive增强特性-Colocation：Colocation（同分布）：将存在关联关系的数据或可能进行管理操作的数据存储在相同的存储节点上。 文件级同分布实现文件的快速访问，避免了因数据搬迁带来的大量网络开销。 Hive增强特性–Hbase记录批量删除：在Hive on HBase功能汇总，FusionInsight HD Hive提供了对HBase表的单条数据的删除功能，通过特定的语法，Hive可以将HBase表中符合条件的一条或多条数据批量清除。 Hive增强特性–流控特性：通过流控特性，可以实现： 当前已经建立连接数据阈值控制。 每个用户已经建立的连接数阈值控制。 单位时间内所有建立的连接数阈值控制。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云数据库]]></title>
    <url>%2F2018%2F05%2F20%2F%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[云数据库概述云计算是云数据库兴起的基础：云计算的概念：通过整合、管理、调配分布在网络各处的计算资源，通过互联网以统一界面，同时向大量的用户提供服务。 云计算特点：按需服务，随时服务，通用型，高可靠性，极其廉价，超大规模，虚拟化，高扩展性。 云数据库的概念：云数据库是部署和虚拟化在云计算环境中的数据库。云数据库是在云计算的大背景下发展起来的一种新兴的共享基础架构的方法，它极大地增强了数据库的存储能力，消除了人员、硬件、软件的重复配置，让软、硬件升级变得更加容易。云数据库具有高可扩展性、高可用性、采用多租形式和支持资源有效分发等特点。 云数据库的特性：云数据库具有以下特性： 动态可扩展 高可用性 较低的使用代价 易用性 高性能 免维护 安全 图：腾讯云数据库和自建数据库的比较 云数据库是个性化数据库存储需求的理想选择：企业类型不同，对于存储的需求也千差万别，而云数据库可以很好地满足不同企业的个性化存储需求： 首先，云数据库可以满足大企业的海量数据存储需求。 其次，云数据库可以满足中小企业的低成本数据存储需求。 另外，云数据库可以满足企业动态变化的数据存储需求。 到底选择自建数据库还是选择云数据库，取决于企业自身的具体需求 对于一些大型企业，目前通常采用自建数据库 对于一些财力有限的中小企业而言，IT预算比较有限，云数据库这种前期零投入、后期免维护的数据库服务，可以很好满足它们的需求。 云数据库与其他数据库的关系：从数据模型的角度来说，云数据库并非一种全新的数据库技术，而只是以服务的方式提供数据库功能。 云数据库并没有专属于自己的数据模型，云数据库所采用的数据模型可以是关系数据库所使用的关系模型（微软的SQL Azure云数据库、阿里云RDS都采用了关系模型），也可以是NoSQL数据库所使用的非关系模型（Amazon Dynamo云数据库采用的是“键/值”存储）。 同一个公司也可能提供采用不同数据模型的多种云数据库服务。 许多公司在开发云数据库时，后端数据库都是直接使用现有的各种关系数据库或NoSQL数据库产品。 云数据库产品云数据库厂商的概述： 图：云数据库产品 Amazon的云数据库产品：Amazon是云数据库市场的先行者。Amazon除了提供著名的S3存储服务和EC2计算服务以外，还提供基于云的数据库服务： Amazon RDS：云中的关系数据库 Amazon SimpleDB：云中的键值数据库 Amazon DynamoDB：云中的NoSQL数据库 Amazon Redshift：云中的数据仓库 Amazon ElastiCache：云中的分布式内存缓存 Google的云数据库产品：Google Cloud SQL是谷歌公司推出的基于MySQL的云数据库。 使用Cloud SQL，所有的事务都在云中，并由谷歌管理，用户不需要配置或者排查错误。 谷歌还提供导入或导出服务，方便用户将数据库带进或带出云。 谷歌使用用户非常熟悉的MySQL，带有JDBC支持（适用于基于Java的App Engine应用）和DB-API支持（适用于基于Python的App Engine应用）的传统MySQL数据库环境，因此，多数应用程序不需过多调试即可运行，数据格式对于大多数开发者和管理员来说也是非常熟悉的。 Google Cloud SQL还有一个好处就是与Google App Engine集成。 Microsoft的云数据库产品：SQL Azure具有以下特性： 属于关系型数据库：支持使用TSQL（Transact Structured Query Language）来管理、创建和操作云数据库。 支持存储过程：它的数据类型、存储过程和传统的SQL Server具有很大的相似性，因此，应用可以在本地进行开发，然后部署到云平台上。 支持大量数据类型：包含了几乎所有典型的SQL Server 2008的数据类型。 支持云中的事务：支持局部事务，但是不支持分布式事务。 云数据库系统架构UMP系统概述：UMP（Unified MySQL Platform）系统是低成本和高性能的MySQL云数据库方案。总的来说，UMP系统架构设计遵循了以下原则： 保持单一的系统对外入口，并且为系统内部维护单一的资源池。 消除单点故障，保证服务的高可用性。 保证系统具有良好的可伸缩，能够动态地增加、删减计算与存储节点。 保证分配给用户的资源也是弹性可伸缩的，资源之间相互隔离，确保应用和数据安全。 UMP系统架构： 图：UMP系统架构 UMP系统中的角色包括： (1)Controller服务器 Controller服务器向UMP集群提供各种管理服务，实现集群成员管理、元数据存储、MySQL实例管理、故障恢复、备份、迁移、扩容等功能. Controller服务器上运行了一组Mnesia分布式数据库服务，其中存储了各种系统元数据，主要包括集群成员、用户的配置和状态信息，以及用户名到后端MySQL实例地址的映射关系（或称为“路由表”）等。 当其它服务器组件需要获取用户数据时，可以向Controller服务器发送请求获取数据。 为了避免单点故障，保证系统的高可用性，UMP系统中部署了多台Controller服务器，然后，由Zookeeper的分布式锁功能来帮助选出一个“总管”，负责各种系统任务的调度和监控。 (2)Proxy服务器 ​ Proxy服务器向用户提供访问MySQL数据库的服务，它完全实现了MySQL协议，用户可以使用已有的MySQL客户端连接到Proxy服务器，Proxy服务器通过用户名获取到用户的认证信息、资源配额的限制(例如QPS、IOPS（I/O Per Second）、最大连接数等)，以及后台MySQL实例的地址，然后，用户的SQL查询请求会被转发到相应的MySQL实例上。除了数据路由的基本功能外，Proxy服务器中还实现了很多重要的功能，主要包括屏蔽MySQL实例故障、读写分离、分库分表、资源隔离、记录用户访问日志等。 (3)Agent服务器 ​ Agent服务器部署在运行MySQL进程的机器上，用来管理每台物理机上的MySQL实例，执行主从切换、创建、删除、备份、迁移等操作，同时，还负责收集和分析MySQL进程的统计信息、慢查询日志（Slow Query Log）和bin-log。 (4)Web控制台 ​ Web控制台向用户提供系统管理界面。 (5)日志分析服务器 ​ 日志分析服务器存储和分析Proxy服务器传入的用户访问日志，并支持实时查询一段时间内的慢日志和统计报表。 (6)信息统计服务器 ​ 信息统计服务器定期将采集到的用户的连接数、QPS数值以及MySQL实例的进程状态用RRDtool进行统计，可以在 Web界面上可视化展示统计结果，也可以把统计结果作为今后实现弹性的资源分配和自动化的MySQL实例迁移的依据。 (7)愚公系统 ​ 愚公系统是一个全量复制结合bin-log分析进行增量复制的工具，可以实现在不停机的情况下动态扩容、缩容和迁移。 依赖的开源组件包括： (1)Mnesia Mnesia是一个分布式数据库管理系统. Mnesia支持事务，支持透明的数据分片，利用两阶段锁实现分布式事务，可以线性扩展到至少50个节点。 Mnesia的数据库模式(schema)可在运行时动态重配置，表能被迁移或复制到多个节点来改进容错性。 Mnesia的这些特性，使其在开发云数据库时被用来提供分布式数据库服务。 （2）LVS LVS(Linux Virtual Server)即Linux虚拟服务器，是一个虚拟的服务器集群系统。 UMP系统借助于LVS来实现集群内部的负载均衡。 LVS集群采用IP负载均衡技术和基于内容请求分发技术。 调度器是LVS集群系统的唯一入口点，调度器具有很好的吞吐率，将请求均衡地转移到不同的服务器上执行，且调度器自动屏蔽掉服务器的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器。 整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序。 （3）RabbitMQ RabbitMQ是一个工业级的消息队列产品（功能类似于IBM公司的消息队列产品IBM Websphere MQ），作为消息传输中间件来使用，可以实现可靠的消息传送。 UMP集群中各个节点之间的通信，不需要建立专门的连接，都是通过读写队列消息来实现的。 （4）ZooKeeper Zookeeper是高效和可靠的协同工作系统，提供分布式锁之类的基本服务（比如统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等），用于构建分布式应用，减轻分布式应用程序所承担的协调任务. 在UMP系统中，Zookeeper主要发挥三个作用： 作为全局的配置服务器 提供分布式锁（选出一个集群的“总管”） 监控所有MySQL实例 UMP系统功能：UMP系统是构建在一个大的集群之上的，通过多个组件的协同作业，整个系统实现了对用户透明的各种功能： 容灾、读写分离、分库分表、资源管理、资源调度、资源隔离、数据安全。 容灾：为了实现容灾，UMP系统会为每个用户创建两个MySQL实例，一个是主库，一个是从库主库和从库的状态是由Zookeeper负责维护的。 主从切换过程如下： Zookeeper探测到主库故障，通知Controller服务器。 Controller服务器启动主从切换时，会修改“路由表”，即用户名到后端MySQL实例地址的映射关系。 把主库标记为不可用。 借助于消息中间件RabbitMQ通知所有Proxy服务器修改用户名到后端MySQL实例地址的映射关系。 全部过程对用户透明。 宕机后的主库在进行恢复处理后需要再次上线，过程如下： 在主库恢复时，会把从库的更新复制给自己。 当主库的数据库状态快要达到和从库一致的状态时，Controller服务器就会命令从库停止更新，进入不可写状态，禁止用户写入数据。 等到主库更新到和从库完全一致的状态时，Controller服务器就会发起主从切换操作，并在路由表中把主库标记为可用状态。 通知Proxy服务器把写操作切回主库上，用户写操作可以继续执行，之后再把从库修改为可写状态。 读写分离：充分利用主从库实现用户读写操作的分离，实现负载均衡。 UMP系统实现了对于用户透明的读写分离功能，当整个功能被开启时，负责向用户提供访问MySQL数据库服务的Proxy服务器，就会对用户发起的SQL语句进行解析，如果属于写操作，就直接发送到主库，如果是读操作，就会被均衡地发送到主库和从库上执行。 分库分表：UMP支持对用户透明的分库分表（shard / horizontal partition） 当采用分库分表时，系统处理用户查询的过程如下： 首先，Proxy服务器解析用户SQL语句，提取出重写和分发SQL语句所需要的信息。 其次，对SQL语句进行重写，得到多个针对相应MySQL实例的子语句，然后把子语句分发到对应的MySQL实例上执行。 最后，接收来自各个MySQL实例的SQL语句执行结果，合并得到最终结果。 资源管理：UMP系统采用资源池机制来管理数据库服务器上的CPU、内存、磁盘等计算资源，所有的计算资源都放在资源池内进行统一分配，资源池是为MySQL实例分配资源的基本单位。 整个集群中的所有服务器会根据其机型、所在机房等因素被划分多个资源池，每台服务器会被加入到相应的资源池中。 对于每个具体MySQL实例，管理员会根据应用部署在哪些机房、需要哪些计算资源等因素，为该MySQL实例具体指定主库和从库所在的资源池，然后，系统的实例管理服务会本着负载均衡的原则，从资源池中选择负载较轻的服务器来创建MySQL实例。 资源调度：UMP系统中有三种规格的用户，分别是数据量和流量比较小的用户、中等规模用户以及需要分库分表的用户。 多个小规模用户可以共享同一个MySQL实例 对于中等规模的用户，每个用户独占一个MySQL实例 对于分库分表的用户，会占有多个独立的MySQL实例 资源隔离：UMP采用的两种资源隔离方式： 数据安全：UMP系统设计了多种机制来保证数据安全： SSL数据库连接：SSL(Secure Sockets Layer)是为网络通信提供安全及数据完整性的一种安全协议，它在传输层对网络连接进行加密。Proxy服务器实现了完整的MySQL客户端/服务器协议，可以与客户端之间建立SSL数据库连接。 数据访问IP白名单：可以把允许访问云数据库的IP地址放入“白名单”，只有白名单内的IP地址才能访问，其他IP地址的访问都会被拒绝，从而进一步保证账户安全。 记录用户操作日志：用户的所有操作记录都会被记录到日志分析服务器，通过检查用户操作记录，可以发现隐藏的安全漏洞。 SQL拦截：Proxy服务器可以根据要求拦截多种类型的SQL语句，比如全表扫描语句“select *”。 Amazon AWS（Amazon Web Services）和云数据库Amazon和云计算的渊源： 2016年3月14日，亚马逊网络服务（AWS）十岁了。 Amazon Web Services业务相当于紧随其后的4大竞争对手的总和。 亚马逊在全球拥有12个区域性数据中心。 Amazon Web Services提供的多个亚马逊数据库都在与甲骨文（Oracle）激烈竞争，其中Amazon RDS有10万多个活跃用户。 亚马逊数据库Aurora，是Amazon Web Services历史上增长最快的服务。 亚马逊的云服务提供了多达几十种服务，涵盖了IaaS、PaaS、SaaS这三层。 Amazon AWS： 图：Amazon AWS架构图 (1)AWS Global Infrastructure(AWS全局基础设施) 在全局基础设施中有3个很重要的概念。 第一个是Region（区域），每个Region是相互独立的，自成一套云服务体系，分布在全球各地。目前全球有10个Region（比如 北京）。 第二个是Availability Zone(可用区)，每个Region又由数个可用区组成，每个可用区可以看做一个数据中心，相互之间通过光纤连接。 第三个是Edge Locations（边缘节点）。全球目前有50多个边缘节点，是一个内容分发网络（CDN，Content Distrubtion Network），可以降低内容分发的延迟，保证终端用户获取资源的速度。 (2)Network(网络)： AWS提供的网络服务主要有： Direct Connect：支持企业自身的数据中心直接与AWS的数据中心直连，充分利用企业现有的资源。 VPN Connection：通过VPN连接AWS，保证数据的安全性。 Virtual Private Cloud： 私有云，从AWS云资源中分一块给你使用，进一步提高安全性。 Route 53：亚马逊提供的高可用的可伸缩的云域名解析系统。Amazon Route 53 高效地将用户请求连接到 AWS 中运行的基础设施，例如 Amazon EC2 实例、Elastic Load Balancing 负载均衡器或 Amazon S3 存储桶。 （3）Computer（计算）: 亚马逊的计算核心，包括了众多的服务: EC2： Elastic Compute Cloud，亚马逊的虚拟机，支持Windows和Linux的多个版本，支持API创建和销毁，有多种型号可供选择，按需使用。并且有自动扩展功能(5分钟即可新建一个虚拟机)，有效解决应用程序性能问题。 ELB： Elastic Load Balancing， 亚马逊提供的负载均衡器，可以和EC2无缝配合使用，横跨多个可用区，可以自动检查实例的健康状况，自动剔除有问题的实例，保证应用程序的可靠性。 Glacier：主要用于较少使用的存储存档文件和备份文件，价格便宜量又足，安全性高。 （4）DateBase（数据库）： 亚马逊提供关系型数据库和NoSQL数据库，以及一些cache等数据库服务： SimpleDB：基于云的键 / 值数据存储服务。 DynamoDB： DynamoDB是亚马逊自主研发的No SQL数据库，性能高，容错性强，支持分布式。 RDS：Relational Database Service，关系型数据库服务。支持MySQL，SQL Server和Oracle等数据库。 Amazon ElastiCache： 数据库缓存服务。 （5）Application Server（应用程序服务）： Cloud Search: 一个弹性的搜索引擎，可用于企业级搜索 Amazon SQS： 队列服务，存储和分发消息 Simple Workflow：一个工作流框架 CloudFront：世界范围的内容分发网络（CDN） EMR： Elastic MapReduce，一个Hadoop框架架的实例，可用于大数据处理。 （6）Deployment &amp; Admin（部署和管理）： Elastic BeanStalk: 一键式创建各种开发环境和运行时。 CloudFormation：采用JSON格式的模板文件来创建和管理一系列亚马逊云资源。 OpsWorks： OpsWorks允许用户将应用程序的部署模块化，可以实现对数据库、运行时、服务器软件等自动化设置和安装。 IAM： Identity &amp; Access Management，认证和访问管理服务。用户使用云服务最担心的事情之一就是安全问题。亚马逊通过IAM提供了立体化的安全策略，保证用户在云上的资源绝对的安全 总体而言，Amazon AWS的产品分为几个部分： 计算类 弹性计算云EC2：EC2提供了云中的虚拟机。 弹性MapReduce：将Hadoop MapReduce搬到云环境中，大量EC2实例动态地成为执行大规模MapReduce计算任务的工作机。 存储类 弹性块存储EBS 简单消息存储SQS Blob对象存储S3 NoSQL型数据库：SimpleDB和DynamoDB 关系数据库RDS 工具支持 AWS支持多种开发语言，提供Java、Rupy、Python、PHP、Windows &amp;.NET 以及Android和iOS的工具集。 工具集中包含各种语言的SDK，程序自动部署以及各种管理工具。 AWS通过CloudWatch系统提供丰富的监控功能。 微软云数据库SQL AzureSQL Azure简介：SQL Azure是微软的云关系型数据库，后端存储又称为“云SQL Server”。 构建在SQL Server之上，通过分布式技术提升传统关系数据库的可扩展性和容错能力。 云SQL Server数据模型: 图：云SQL Server数据模型 1.逻辑模型: 一个逻辑数据库称为一个表格组 表格组中所有划分主键相同的行集合称为行组（row group） 只支持同一个行组内的事务，同一个行组的数据逻辑上会分布到一台服务器，以此规避分布式事务 通过主备复制将数据复制到多个副本，保证高可用性 2.物理模型： 在物理层面，每个有主键的表格组根据划分主键列有序地分成多个数据分区。每个行组属于唯一分区。 分区是SQL Azure复制、迁移、负载均衡的基本单位。每个分区包含多个副本（默认为3），每个副本存储在一台物理的SQL Server上。 SQL Azure保证每个分区的多个副本分布到不同的故障域。每个分区有一个副本为主副本（Primary）,其他副本为从副本（Secondary）。主副本处理所有的查询、更新事务，并以操作日志的形式，将事务同步到从副本，从副本接收主副本发送的事务日志并应用到本地数据库。 体系架构： 图：云SQL Server的分层架构 SQL Azure分为四个主要部分： SQL Server实例、全局分区管理器、协议网关、分布式基础部件。 每个SQL Server实例是一个运行着SQLServer的物理进程。每个物理数据库包含多个子数据库，它们之间相互隔离。子数据库是一个分区，包含用户的数据以及schema信息. 全局分区管理器维护分区映射表信息. 协议网关负责将用户的数据库连接请求转发到相应的主分区上. 分布式基础部件（Fabric）用于维护机器上下线状态，检测服务器故障并为集群中的各种角色执行选取主节点操作. 图：SQL Azure的体系架构 SQL Azure的体系架构中包含了一个虚拟机簇，可以根据工作负载的变化，动态增加或减少虚拟机的数量。 每台虚拟机SQL Server VM(virtualmachine)安装了SQL Server 数据库管理系统，以关系模型存储数据。 通常，一个数据库会被散存储到3~5台SQL Server VM中。 阿里云RDS阿里云RDS简介：RDS是阿里云提供的关系型数据库服务，它将直接运行于物理服务器上的数据库实例租给用户，是专业管理的、高可靠的云端数据库服务。 RDS由专业数据库管理团队维护，还可以为用户提供数据备份、数据恢复、扩展升级等管理功能，相对于用户自建数据库而言，RDS具有专业、高可靠、高性能、灵活易用等优点，能够帮助用户解决费时费力的数据库管理任务，让用户将更多的时间聚焦在核心业务上。 RDS具有安全稳定、数据可靠、自动备份、管理透明、性能卓越，灵活扩容等优点，可以提供专业的数据库管理平台、专业的数据库优化建议以及完善的监控体系。 RDS中的概念：RDS实例，是用户购买RDS服务的基本单位。在实例中： 可以创建多个数据库 可以使用常见的数据库客户端连接、管理及使用数据 可以通过RDS管理控制台或OPEN API来创建、修改和删除数据库 RDS数据库，是用户在一个实例下创建的逻辑单元 一个实例可以创建多个数据库，在实例内数据库命名唯一，所有数据库都会共享该实例下的资源，如CPU、内存、磁盘容量等 RDS不支持使用标准的SQL语句或客户端工具创建数据库，必须使用OPEN API或RDS管理控制台进行操作 地域指的是用户所购买的RDS实例的服务器所处的地理位置。RDS目前支持杭州、青岛、北京、深圳和香港五个地域，服务品质完全相同。用户可以在购买RDS实例时指定地域，购买实例后暂不支持更改。 RDS可用区是指在同一地域下，电力、网络隔离的物理区域，可用区之间内网互通，可用区内网络延时更小，不同可用区之间故障隔离。 RDS可用区又分为单可用区和多可用区 单可用区是指RDS实例的主备节点位于相同的可用区，它可以有效控制云产品间的网络延迟 多可用区是指RDS实例的主备节点位于不同的可用区，当主节点所在可用区出现故障（如机房断电等），RDS进行主备切换后，会切换到备节点所在的可用区继续提供服务。多可用区的RDS轻松实现了同城容灾 磁盘容量是用户购买RDS实例时，所选择购买的磁盘大小实例所占用的磁盘容量，除了存储表格数据外，还有实例正常运行所需要的空间，如系统数据库、数据库回滚日志、重做日志、索引等。 RDS连接数，是应用程序可以同时连接到RDS实例的连接数量 任意连接到RDS实例的连接均计算在内，与应用程序或者网站能够支持的最大用户数无关 用户在购买RDS]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>云数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL数据库]]></title>
    <url>%2F2018%2F05%2F19%2FNoSQL%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[NoSQL简介NoSQL概念: 图；NoSQL概念的演变 NoSQL最初表示的“反SQL”运动，用新型的非关系型数据库取代关系型数据库。 现在NoSQL（Not only SQL）表示关系和非关系型数据库各有优缺点，彼此都无法互相取代。 NoSQL的特点：通常，NoSQL数据库具有以下几个特点： 灵活的可扩展性。 灵活的数据模型 与云计算紧密融合。 现在有很多公司都使用了NoSQL数据库：如Google，Facebook，百度，阿里等。 NoSQL兴起的原因原因一：关系型数据库已经无法满足Web2.0的需求关系型数据库无法满足Web2.0的需求，主要表现在以下几个方面： 无法满足海量数据的管理需求。 无法满足数据高并发的需求。 无法满足高可扩展性和高可用性的需求。 在现在1分钟的时间内： 新浪可以发送2万条微博。 苹果可以下载4.7万次应用。 淘宝可以卖出6万件商品。 人人网可以发送30万次访问。 百度可以产生90万次搜索查询。 MySQL集群是否可以完全解决问题？ 复杂性：部署、管理、配置很复杂。 数据库复制：MySQL主备之间采用复制方式，只能是异步复制，当主库压力较大时可能产生较大延迟，主备切换可能会丢失最后一部分更新事务，这时往往需要人工介入，备份和恢复不方便。 扩容问题：如果系统压力过大需要增加新的机器，这个过程涉及数据重新划分，整个过程比较复杂，且容易出错。 动态数据迁移问题：如果某个数据库组压力过大，需要将其中部分数据迁移出去，迁移过程需要总控节点整体协调，以及数据库节点的配合。这个过程很难做到自动化。 原因二：“One size fits all”模式很难适用于截然不同的业务场景： 关系模型作为统一的数据模型既被用于数据分析，也被用于在线业务。但这两者一个强调高吞吐，一个强调低延时，已经演化出完全不同的架构。用同一套模型来抽象显然是不合适的。 Hadoop就是针对数据分析。 MongoDB、Redis等是针对在线业务，两者都抛弃了关系模型。 原因三：关系型数据库的关键特性：关系数据库的关键特性包括完善的事务机制和高效的查询机制。但是，关系数据库引以为傲的两个关键特性，到了Web2.0时代却成了鸡肋，主要表现在以下几个方面： Web2.0网站系统通常不要求严格的数据库事务。 Web2.0并不要求严格的读写实时性。 Web2.0通常不包含大量复杂的SQL查询（去结构化，存储空间换取更好的查询性能）。 NoSQL与关系型数据库的比较NoSQL和关系数据库的简单比较： RDBMS即关系数据库管理系统(Relational Database Management System)。 对比总结：关系数据库： 优势：以完善的关系代数理论作为基础，有严格的标准，支持事务ACID四性，借助索引机制可以实现高效的查询，技术成熟，有专业公司的技术支持 。 劣势：可扩展性较差，无法较好支持海量数据存储，数据模型过于死板、无法较好支持Web2.0应用，事务机制影响了系统的整体性能等。 NoSQL数据库： 优势：可以支持超大规模数据存储，灵活的数据模型可以很好地支持Web2.0应用，具有强大的横向扩展能力等 。 劣势：缺乏数学理论基础，复杂查询性能不高，大都不能实现事务强一致性，很难实现数据完整性，技术尚不成熟，缺乏专业团队的技术支持，维护较困难等。 关系数据库和NoSQL数据库各有优缺点，彼此无法取代。 关系数据库应用场景：电信、银行等领域的关键业务系统，需要保证强事务一致性。 NoSQL数据库应用场景：互联网企业、传统企业的非关键业务（比如数据分析）。 采用混合架构： 案例：亚马逊公司就使用不同类型的数据库来支撑它的电子商务应用。 对于“购物篮”这种临时性数据，采用键值存储会更加高效。 当前的产品和订单信息则适合存放在关系数据库中。 大量的历史订单信息则适合保存在类似MongoDB的文档数据库中。 NoSQL的四大类型四大类：NoSQL数据库虽然数量众多，但是，归结起来，典型的NoSQL数据库通常包括键值数据库、列族数据库、文档数据库和图形数据库。 图:键值数据库示例 图：列族数据库 图：文档数据库 图：图形数据库 四大数据库的主要产品： 图：四大数据库的主要产品 键值数据库：相关产品： Redis、Riak、SimpleDB、Chordless、Scalaris、Memcached。 数据模型： 键/值对 键是一个字符串对象 值可以是任意类型的数据，比如整型、字符型、数组、列表、集合等。 典型应用： 涉及频繁读写、拥有简单数据模型的应用 内容缓存，比如会话、配置文件、参数、购物车等 存储配置和用户数据信息的移动应用 优点： 扩展性好 灵活性好 大量写操作时性能高 缺点： 无法存储结构化信息，条件查询效率较低 不适用情形： 不是通过键而是通过值来查：键值数据库根本没有通过值查询的途径。 需要存储数据之间的关系：在键值数据库中，不能通过两个或两个以上的键来关联数据。 需要事务的支持：在一些键值数据库中，产生故障时，不可以回滚。 使用者： 百度云数据库（Redis）、GitHub（Riak）、BestBuy（Riak）、Twitter（Redis和Memcached）、StackOverFlow（Redis）、Instagram （Redis）、Youtube（Memcached）、Wikipedia（Memcached） 图：键值数据库成为理想的缓冲层解决方案 Redis有时候会被人们称为“强化版的Memcached” 支持持久化、数据恢复、更多数据类型. 列族数据库：相关产品： BigTable、HBase、Cassandra、HadoopDB、GreenPlum、PNUTS 数据模型：列族 典型应用： 分布式数据存储与管理 数据在地理上分布于多个数据中心的应用程序 可以容忍副本中存在短期不一致情况的应用程序 拥有动态字段的应用程序 拥有潜在大量数据的应用程序，大到几百TB的数据 优点： 查找速度快 可扩展性强 容易进行分布式扩展 复杂性低 缺点： 功能较少，大都不支持强事务一致性。 不适用情形： 需要ACID事务支持的情形，Cassandra等产品就不适用 使用者： Ebay（Cassandra）、Instagram（Cassandra）、NASA（Cassandra）、Twitter（Cassandra and HBase）、Facebook（HBase）、Yahoo!（HBase） 文档数据库：“文档”其实是一个数据记录，这个记录能够对包含的数据类型和内容进行“自我描述”。XML文档、HTML文档和JSON 文档就属于这一类。SequoiaDB就是使用JSON格式的文档数据库，它的存储的数据是这样的： 图：文档数据库示例 文档数据库的特点： 数据是不规则的，每一条记录包含了所有的有关“SequoiaDB”的信息而没有任何外部的引用，这条记录就是“自包含”的。 这使得记录很容易完全移动到其他服务器，因为这条记录的所有信息都包含在里面了，不需要考虑还有信息在别的表没有一起迁移走。 同时，因为在移动过程中，只有被移动的那一条记录（文档）需要操作，而不像关系型中每个有关联的表都需要锁住来保证一致性，这样一来ACID的保证就会变得更快速，读写的速度也会有很大的提升。 文档数据库的相关产品： MongoDB、CouchDB、Terrastore、ThruDB、RavenDB、SisoDB、RaptorDB、CloudKit、Perservere、Jackrabbit 数据模型： 键/值 值（value）是版本化的文档 典型应用： 存储、索引并管理面向文档的数据或者类似的半结构化数据。 比如，用于后台具有大量读写操作的网站、使用JSON数据结构的应用、使用嵌套结构等非规范化数据的应用程序。 优点： 性能好（高并发），灵活性高，复杂性低，数据结构灵活。 提供嵌入式文档功能，将经常查询的数据存储在同一个文档中。 既可以根据键来构建索引，也可以根据内容构建索引 缺点：缺乏统一的查询语法。 不适用情形： 在不同的文档上添加事务。文档数据库并不支持文档间的事务，如果对这方面有需求，则不应该选用这个解决方案。 使用者： 百度云数据库（MongoDB）、SAP （MongoDB）、Codecademy （MongoDB）、Foursquare （MongoDB）、NBC News （RavenDB） 图形数据库：相关产品： Neo4J、OrientDB、InfoGrid、Infinite Graph、GraphDB 数据模型：图结构 典型应用： 专门用于处理具有高度相互关联关系的数据，比较适合于社交网络、模式识别、依赖分析、推荐系统以及路径寻找等问题 优点： 灵活性高，支持复杂的图形算法，可用于构建复杂的关系图谱。 缺点：复杂性高，只能支持一定的数据规模。 使用者： Adobe（Neo4J）、Cisco（Neo4J）、T-Mobile（Neo4J） 不同类型数据库比较分析； MySQL产生年代较早，而且随着（Web应用软件组合）LAMP（Linux+Apache+Mysql/MariaDB+Perl/PHP/Python）大潮得以成熟。尽管其没有什么大的改进，但是新兴的互联网使用的最多的数据库。 MongoDB是个新生事物，提供更灵活的数据模型、异步提交、地理位置索引等五花十色的功能。 HBase是个“仗势欺人”的大象兵。依仗着Hadoop的生态环境，可以有很好的扩展性。但是就像象兵一样，使用者需要养一头大象(Hadoop),才能驱使他。 Redis是键值存储的代表，功能最简单。提供随机数据存储。就像一根棒子一样，没有多余的构造。但是也正是因此，它的伸缩性特别好。就像悟空手里的金箍棒，大可捅破天，小能成缩成针。 NoSQL的三大基石 三大基石：CAP，BASE，最终一致性。 CAP：所谓的CAP指的是： C（Consistency）：一致性，是指任何一个读操作总是能够读到之前完成的写操作的结果，也就是在分布式环境中，多点的数据是一致的，或者说，所有节点在同一时间具有相同的数据。 A:（Availability）：可用性，是指快速获取数据，可以在确定的时间内返回操作结果，保证每个请求不管成功或者失败都有响应； P（Tolerance of Network Partition）：分区容忍性，是指当出现网络分区的情况时（即系统中的一部分节点无法和其他节点进行通信），分离的系统也能够正常运行，也就是说，系统中任意信息的丢失或失败不会影响系统的继续运作。 图：CAP Theorem(理论) CAP理论告诉我们，一个分布式系统不可能同时满足一致性、可用性和分区容忍性这三个需求，最多只能同时满足其中两个，正所谓“鱼和熊掌不可兼得”。 当处理CAP的问题时，可以有几个明显的选择： CA：也就是强调一致性（C）和可用性（A），放弃分区容忍性（P），最简单的做法是把所有与事务相关的内容都放到同一台机器上。很显然，这种做法会严重影响系统的可扩展性。传统的关系数据库（MySQL、SQL Server和PostgreSQL），都采用了这种设计原则，因此，扩展性都比较差 CP：也就是强调一致性（C）和分区容忍性（P），放弃可用性（A），当出现网络分区的情况时，受影响的服务需要等待数据一致，因此在等待期间就无法对外提供服务 AP：也就是强调可用性（A）和分区容忍性（P），放弃一致性（C），允许系统返回不一致的数据 图：不同产品在CAP理论下的不同设计原则 BASE:说起BASE（Basically Availble, Soft-state, Eventual consistency），不得不谈到ACID。 一个数据库事务具有ACID四性： A（Atomicity）：原子性，是指事务必须是原子工作单元，对于其数据修改，要么全都执行，要么全都不执行。 C（Consistency）：一致性，是指事务在完成时，必须使所有的数据都保持一致状态。 I（Isolation）：隔离性，是指由并发事务所做的修改必须与任何其它并发事务所做的修改隔离。 D（Durability）：持久性，是指事务完成之后，它对于系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持。 BASE的基本含义是基本可用（Basically Availble）、软状态（Soft-state）和最终一致性（Eventual consistency）： 基本可用： 基本可用，是指一个分布式系统的一部分发生问题变得不可用时，其他部分仍然可以正常使用，也就是允许分区失败的情形出现。 软状态： “软状态（soft-state）”是与“硬状态（hard-state）”相对应的一种提法。数据库保存的数据是“硬状态”时，可以保证数据一致性，即保证数据一直是正确的。“软状态”是指状态可以有一段时间不同步，具有一定的滞后性。 最终一致性： ​ 一致性的类型包括强一致性和弱一致性，二者的主要区别在于高并发的数据访问操作下，后续操作是否能够获取最新的数据。对于强一致性而言，当执行完一次更新操作后，后续的其他读操作就可以保证读到更新后的最新数据；反之，如果不能保证后续访问读到的都是更新后的最新数据，那么就是弱一致性。而最终一致性只不过是弱一致性的一种特例，允许后续的访问操作可以暂时读不到更新后的数据，但是经过一段时间之后，必须最终读到更新后的数据。 ​ 最常见的实现最终一致性的系统是DNS（域名系统）。一个域名更新操作根据配置的形式被分发出去，并结合有过期机制的缓存；最终所有的客户端可以看到最新的值。 最终一致性根据更新数据后各进程访问到数据的时间和方式的不同，又可以区分为： 因果一致性：如果进程A通知进程B它已更新了一个数据项，那么进程B的后续访问将获得A写入的最新值。而与进程A无因果关系的进程C的访问，仍然遵守一般的最终一致性规则。 “读己之所写”一致性：可以视为因果一致性的一个特例。当进程A自己执行一个更新操作之后，它自己总是可以访问到更新过的值，绝不会看到旧值。 单调读一致性：如果进程已经看到过数据对象的某个值，那么任何后续访问都不会返回在那个值之前的值。 会话一致性：它把访问存储系统的进程放到会话（session）的上下文中，只要会话还存在，系统就保证“读己之所写”一致性。如果由于某些失败情形令会话终止，就要建立新的会话，而且系统保证不会延续到新的会话。 单调写一致性：系统保证来自同一个进程的写操作顺序执行。系统必须保证这种程度的一致性，否则就非常难以编程了。 如何实现各种类型的一致性？ 对于分布式数据系统： N — 数据复制的份数 W — 更新数据是需要保证写完成的节点数 R — 读取数据的时候需要读取的节点数 如果W+R&gt;N，写的节点和读的节点重叠，则是强一致性。例如对于典型的一主一备同步复制的关系型数据库，N=2,W=2,R=1，则不管读的是主库还是备库的数据，都是一致的。一般设定是R＋W = N+1，这是保证强一致性的最小设定。 如果W+R&lt;=N，则是弱一致性。例如对于一主一备异步复制的关系型数据库，N=2,W=1,R=1，则如果读的是备库，就可能无法读取主库已经更新过的数据，所以是弱一致性。 对于分布式系统，为了保证高可用性，一般设置N&gt;=3。不同的N,W,R组合，是在可用性和一致性之间取一个平衡，以适应不同的应用场景。 如果N=W,R=1，任何一个写节点失效，都会导致写失败，因此可用性会降低，但是由于数据分布的N个节点是同步写入的，因此可以保证强一致性。 实例：HBase是借助其底层的HDFS来实现其数据冗余备份的。HDFS采用的就是强一致性保证。在数据没有完全同步到N个节点前，写操作是不会返回成功的。也就是说它的W＝N，而读操作只需要读到一个值即可，也就是说它R＝1。 像Voldemort，Cassandra和Riak这些类Dynamo的系统，通常都允许用户按需要设置N，R，W三个值，即使是设置成W＋R&lt;= N也是可以的。也就是说他允许用户在强一致性和最终一致性之间自由选择。而在用户选择了最终一致性，或者是W&lt;N的强一致性时，则总会出现一段“各个节点数据不同步导致系统处理不一致的时间”。为了提供最终一致性的支持，这些系统会提供一些工具来使数据更新被最终同步到所有相关节点。 从NoSQL到NewSQL数据库 图：大数据引发数据处理架构变革 图：关系数据库、NoSQL和NewSQL数据库产品分类图 文档数据库MongoDBMongoDB简介：MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。 在高负载的情况下，添加更多的节点，可以保证服务器性能。 MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。 MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 图：mangoDB示例 MongoDB主要特点： 提供了一个面向文档存储，操作起来比较简单和容易 可以设置任何属性的索引来实现更快的排序 具有较好的水平可扩展性 支持丰富的查询表达式，可轻易查询文档中内嵌的对象及数组 可以实现替换完成的文档（数据）或者一些指定的数据字段 MongoDB中的Map/Reduce主要是用来对数据进行批量处理和聚合操作 支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等语言 MongoDB安装简单 MongoDB概念解析：在mongodb中基本的概念是文档、集合、数据库。 通过下图实例，我们也可以更直观的的了解MongoDB中的一些概念： 图：关系数据库和MongoDB的示例 举例2：在一个关系型数据库中，一篇博客（包含文章内容、评论、评论的投票）会被打散在多张数据表中。在文档数据库MongoDB中，能用一个文档来表示一篇博客， 评论与投票作为文档数组，放在正文主文档中。这样数据更易于管理，消除了传统关系型数据库中影响性能和水平扩展性的“JOIN”操作。 数据库 一个mongodb中可以建立多个数据库。 MongoDB的默认数据库为”db”，该数据库存储在data目录中。 MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 文档文档是一个键值(key-value)对(即BSON)。MongoDB 的文档不需要设置相同的字段，并且相同的字段不需要相同的数据类型，这与关系型数据库有很大的区别，也是 MongoDB 非常突出的特点。一个简单的文档例子如下： 1&#123;"site":"dblab.xmu.edu.cn", "name":"厦门大学数据库实验室"&#125; RDBMS与MongoDB对应术语： 集合 集合就是 MongoDB 文档组，类似于 RDBMS （关系数据库管理系统：Relational Database Management System)中的表格。 集合存在于数据库中，集合没有固定的结构，这意味着你在对集合可以插入不同格式和类型的数据，但通常情况下我们插入集合的数据都会有一定的关联性。 比如，我们可以将以下不同数据结构的文档插入到集合中： 1&#123;"site":"www.baidu.com"&#125; &#123;"site":"dblab.xmu.edu.cn", "name":"厦门大学数据库实验室"&#125; &#123;"site":"www.runoob.com","name":"菜鸟教程","num":5&#125; MongoDB数据类型：]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>NoSQL</tag>
        <tag>数据库</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase技术原理]]></title>
    <url>%2F2018%2F05%2F17%2FHBase%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[HBase基本介绍BigTable简介：BigTable是一个分布式存储系统，BigTable起初用于解决典型的互联网搜索问题。 BigTable是一个分布式存储系统。 利用谷歌提出的MapReduce分布式并行计算模型来处理海量数据。 使用谷歌分布式文件系统GFS作为底层数据存储。 采用Chubby提供协同服务管理。 可以扩展到PB级别的数据和上千台机器，具备广泛应用性、可扩展性、高性能和高可用性等特点。 谷歌的许多项目都存储在BigTable中，包括搜索、地图、财经。 HBase简介：HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，是谷歌BigTable的开源实现，主要用来存储非结构化和半结构化的松散数据。HBase的目标是处理非常庞大的表，可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据和数百万列元素组成的数据表。 图：Hadoop生态系统中HBase与其他部分的关系 适合用于大表数据（表的规模可以达到数十亿行以及数百万列），并且对大表数据的读写访问可以达到实时级别。 利用Hadoop HDFS作为其文件存储系统，提供实时读写的分布式数据库系统。 利用ZooKeeper作为协同服务。 HBase和BigTable的底层技术对应关系： BIgTable hbase GFS HDFS MapReduce Hadoop MapReduce Chubby Zookeeper HBase出现的原因：关系数据库已经流行很多年，并且Hadoop已经有了HDFS和MapReduce，为什么需要HBase? Hadoop可以很好地解决大规模数据的离线批量处理问题，但是，受限于Hadoop MapReduce编程框架的高延迟数据处理机制，使得Hadoop无法满足大规模数据实时处理应用的需求。 HDFS面向批量访问模式，不是随机访问模式。 传统的通用关系型数据库无法应对在数据规模剧增时导致的系统扩展性和性能问题（分库分表也不能很好解决）。 传统关系数据库在数据结构变化时一般需要停机维护；空列浪费存储空间。 因此，业界出现了一类面向半结构化数据存储和处理的高可扩展、低写入/查询延迟的系统，例如，键值数据库、文档数据库和列族数据库（如BigTable和HBase等）。 HBase已经成功应用于互联网服务领域和传统行业的众多在线式数据分析处理系统中。 HBase与传统关系数据库对比分析：HBase与传统的关系数据库的区别主要体现在以下几个方面： 数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式，HBase则采用了更加简单的数据模型，它把数据存储为未经解释的字符串。 数据操作：关系数据库中包含了丰富的操作，其中会涉及复杂的多表连接。HBase操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、清空等，因为HBase在设计上就避免了复杂的表和表之间的关系。 存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的，每个列族都由几个文件保存，不同列族的文件是分离的。 数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数据访问性能。HBase只有一个索引——行键，通过巧妙的设计，HBase中的所有访问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来。 数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来的旧值，旧值被覆盖后就不会存在。而在HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留。 可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相反，HBase和BigTable这些分布式数据库就是为了实现灵活的水平扩展而开发的，能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩 HBase应用场景：HBase适合具有如下需求的应用： 海量数据（TB，PB）。 不需要完全拥有传统关系型数据库所具备的ACID特性。 高吞吐量。 需要在海量数据中实现高效的随机读取。 需要很好的性能伸缩性。 能够同时处理结构化和非结构化数据。 HBase访问接口： HBase在FusionInsight中的位置：HBase作为一个高可靠性、高性能、面向列、可伸缩的分布式数据库，提供海量数据存储功能，用来解决关系型数据库在海量数据时的局限性。 图： HBase在FusionInsight中的位置 HBase数据模型数据模型概述： HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限定符和时间戳。 每个值是一个未经解释的字符串，没有数据类型。 用户在表中存储数据，每一行都有一个可排序的行键和任意多的列。 表在水平方向由一个或者多个列族组成，一个列族中可以包含任意多个列，同一个列族里面的数据存储在一起。 列族支持动态扩展，可以很轻松地添加一个列族或列，无需预先定义列的数量以及类型，所有列均以字符串形式存储，用户需要自行进行数据类型转换。 HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留（这是和HDFS只允许追加不允许修改的特性相关的）。 数据模型相关概念： 表：HBase采用表来组织数据，表由行和列组成，列划分为若干个列族。 行：每个HBase表都由若干行组成，每个行由行键（row key）来标识。 列族：一个HBase表被分组成许多“列族”（Column Family）的集合，它是基本的访问控制单元。 列限定符：列族里的数据通过列限定符（或列）来定位。 单元格：在HBase表中，通过行、列族和列限定符确定一个“单元格”（cell），单元格中存储的数据没有数据类型，总被视为字节数组byte[]。 时间戳：每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引。 图：表示例 如上图：该单元格有2个时间戳ts1和ts2，每个时间戳对应一个数据版本。 数据坐标：HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]。 图：数据表示法示例 概念视图： 图：HBase数据的概念视图 物理视图: 图：HBase数据的物理视图 面向列的存储： 图：夯实数据库和列式数据库示意图 行存储：数据按行存储在底层文件系统中。通常，每一行会被分配固定的空间。 优点：有利于增加、修改整行记录等操作；有理由数据的读取操作。 缺点：单列查询时，会读取一些不必要的数据。 列存储：数据以列为单位，存储在底层文件系统中。 优点：有利于面向单列数据的读取、统计等操作。 缺点：整行读取时，可能需要多次I/O操作。 KeyValue存储模型： 图：KeyValue存储模型 KeyValue具有特性的结构。Key部分被用来快速检索一条数据记录，Value部分用来存储实际的用户数据信息。 KeyValue作为承载用户数据的基本单元，需要保存一些对自身的描述信息。例如，时间戳，类型等等。那么势必会有一定的结构化空间开销。 支持动态增加列，容易适应数据类型和结构的变化。以块为单元操作数据，列间、表间并无关联关系。 KeyValue型数据库数据分区方式–按Key值连续范围分区。如下图： 数据按照RowKey的范围（按RowKey的字典顺序），划分为一个个的子区间。每一个子区间都是一个分布式存储的基本单元。 HBase的底层数据以KeyValue的形式存在，KeyValue具有特定的格式。 KeyValue中拥有时间戳、类型等关键信息。 同一个Key值可以关联多个Value，每一个KeyValue都拥有一个Qualifier标识。 即使是Key值相同，Qualifier也相同的多个KeyValue，也可能有多个，此时使用时间戳来区分，这就是同一条数据记录的多版本。 HBase实现原理HBase功能组件：HBase的实现包括三个主要的功能组件： 库函数：链接到每个客户端 一个Master主服务器 许多个Region服务器 主服务器Master负责管理和维护HBase表的分区信息，维护Region服务器列表，分配Region，负载均衡。 Region服务器负责存储和维护分配给自己的Region，处理来自客户端的读写请求。 客户端并不是直接从Master主服务器上读取数据，而是在获得Region的存储位置信息后，直接从Region服务器上读取数据。 客户端并不依赖Master，而是通过Zookeeper来获得Region位置信息，大多数客户端甚至从来不和Master通信，这种设计方式使得Master负载很小。 Region基本概念： 图：Region的来源 将一个数据表按Key值范围横向划分为一个个的子表，实现分布式存储。 这个子表，在HBase中被称作“Region”。 每一个Region都关联一个Key值范围，即一个使用StartKey和EndKey描述的区间，事实上，每一个Region仅仅记录StartKey就可以，因为它的EndKey就是下一个Region的StartKey。 Region是HBase分布式存储的最基本单元。 图：Region分类 Region分为元数据Region以及用户Region两类。 Meta Region记录了每一个User Region的路由信息。 读写Region数据的路由，包括如下几步： 寻找Meta Region地址。 再由Meta Region寻找User Region地址。 Column Family(列族)： 图：列族 ColumnFamily是Region的一个物理存储单元。同一个Region下面的多个ColumnFamily，位于不同的路径下面。 ColumnFamily信息是表级别的配置。也就是说，同一个表的多个Region，都拥有相同的ColumnFamily信息。（例如，都有两个ColumnFamily，且不同Region的同一个ColumnFamily配置信息相同）。 表和Region：开始只有一个Region，后来不断分裂Region拆分操作非常快，接近瞬间，因为拆分之后的Region读取的仍然是原存储文件，直到“合并”过程把存储文件异步地写到独立的文件之后，才会读取新文件。 每个Region默认大小是100MB到200MB（2006年以前的硬件配置） 每个Region的最佳大小取决于单台服务器的有效处理能力。 目前每个Region最佳大小建议1GB-2GB（2013年以后的硬件配置）。 同一个Region不会被分拆到多个Region服务器. 每个Region服务器存储10-1000个Region. Region的定位: 元数据表 又名.META.表，存储了Region和Region服务器的映射关系.用来帮助Client定位到具体的Region。 当HBase表很大时，元数据也会被切分为多个Regina，Region的元数据信息保存在Zookeeper中。 根数据表，又名-ROOT-表，记录所有元数据的具体位置。 -ROOT-表只有唯一一个Region，名字是在程序中被写死的。 Zookeeper文件记录了-ROOT-表的位置。 图：HBase的三层结构 HBase的三层结构中各层次的名称和作用： 第一层：Zookeeper文件，记录以-ROOt-表的位置信息。 第二层：-ROOT-表，记录了.META.表的Region位置信息。-ROOT-表只能一个Region。通过-ROOT-表，就可以访问.META。表中的数据。 第三层：.META.表，记录了用户数据表的Region位置息，.META.表可以有多个Region，保存了HBase中所有用户数据表的Region位置信息。 为了加快访问速度，.META.表的全部Region都会被保存在内存中。 假设.META.表的每行（一个映射条目）在内存中大约占用1KB，并且每个Region限制为128MB，那么，上面的三层结构可以保存的用户数据表的Region数目的计算方法是： -ROOT-表能够寻址的.META.表的Region个数）×（每个.META.表的 Region可以寻址的用户数据表的Region个数） 一个-ROOT-表最多只能有一个Region，也就是最多只能有128MB，按照每行（一个映射条目）占用1KB内存计算，128MB空间可以容纳128MB/1KB=2的17次方 行。 行，也就是说，一个-ROOT-表可以寻址2的17次方个.META.表的Region。 同理，每个.META.表的 Region可以寻址的用户数据表的Region个数是128MB/1KB=2的17次方。 最终，三层结构可以保存的Region数目是(128MB/1KB) × (128MB/1KB) = 2的34次方个Region。 客户端访问数据时的“三级寻址”: 为了加速寻址，客户端会缓存位置信息，同时，需要解决缓存失效问题. 寻址过程客户端只需要询问Zookeeper服务器，不需要连接Master服务器. Zookeeper为HBase提供： 分布式锁的服务： 多个HMaster进程都会尝试着去Zookeeper中写入一个对应的节点，该结点只能被一个HMaster进程创建成功，创建成功的HMaster进程就是Active。 事件监听机制： 主HMaster进程宕掉之后，备HMaster在监听对应的Zookeeper节点。主HMaster进程宕掉之后，该节点会被删除，其他的备HMaste就可以收到响应的消息。 微型数据库角色： Zookeeper中存放了Region Server的地址，此时，可以将它理解成一个微型数据库。 HBase系统架构HBase系统架构： 图：HBase系统架构图 各组件功能： 客户端客户端包含访问HBase的接口，同时在缓存中维护着已经访问过的Region位置信息，用来加快后续数据访问过程。 Zookeeper服务器 Zookeeper可以帮助选举出一个Master作为集群的总管，并保证在任何时刻总有唯一一个Master在运行，这就避免了Master的“单点失效”问题 。 Zookeeper是一个很好的集群管理工具，被大量用于分布式计算，提供配置维护、域名服务、分布式同步、组服务等。 Master（HMaster）主服务器Master主要负责表和Region的管理工作：– 管理用户对表的增加、删除、修改、查询等操作。– 实现不同Region服务器之间的负载均衡。– 在Region分裂或合并后，负责重新调整Region的分布。– 对发生故障失效的Region服务器上的Region进行迁移。 -HMaster进程负责所有Region的转移操作： 新表创建时的Region分配。 运行期间的负载均衡保证。 RegionServer Failover后的Region接管。 HMaster进程有主备角色。集群可以配置两个HMaster角色，集群启动时，这些HMaster角色通过竞争获得主HMaster角色。主HMaster只能有一个，备HMaster进程在集群运行期间处于休眠状态，不干涉任何集群事务。 RegionServer： Region服务器是HBase中最核心的模块，是HBase的数据服务进程负责处理用户的数据的读写请求。 Region由RegionServer管理。所有用户数据的读写请求，都是和RegionServer上的Region进行交互。 Region可以在RegionServer之间迁移。 RegionServer工作原理：###RegionServer的架构： 图：HBase的RegionServer架构 Store:一个Region由一个或多个Store组成。每个Store对应图中的一个Column Family。 MemStore：一个Store包含一个MemStore，MemStore缓存客户端向Region插入的数据。 StoreFile：MemStore的数据Flush到HDFS后成为StoreFile。 Hfile：Hfile定义了StoreFile在文件系统中的存储格式，它是当前HBase系统汇总StoreFile的具体实现。 Hlog：HLog日志保证了当RegionServer故障的情况下用户写入的数据不丢失。 RegionServer的多个Region共享一个相同的Hlog。 Region服务器Region服务器向HDFS文件系统中读写数据： 图：Region服务器向HDFS文件系统中读写数据 (1)用户读写数据过程： 用户写入数据时，被分配到相应Region服务器去执行。 用户数据首先被写入到MemStore和Hlog中。 只有当操作写入Hlog之后，commit()调用才会将其返回给客户端。 当用户读取数据时，Region服务器会首先访问MemStore缓存，如果找不到，再去磁盘上面的StoreFile中寻找。 （2）缓存的刷新： 系统会周期性地把MemStore缓存里的内容刷写到磁盘的StoreFile文件中，清空缓存，并在Hlog里面写入一个标记。 每次刷写都生成一个新的StoreFile文件，因此，每个Store包含多个StoreFile文件。 每个Region服务器都有一个自己的HLog 文件，每次启动都检查该文件，确认最近一次执行缓存刷新操作之后是否发生新的写入操作；如果发现更新，则先写入MemStore，再刷写到StoreFile，最后删除旧的Hlog文件，开始为用户提供服务。· （3）StoreFile的合并（Compaction）： Hfile文件数目越来越多，读取时延也越来越大。 每次刷写都生成一个新的StoreFile，数量太多，影响查找速度。 调用Store.compact()把多个合并成一个。 合并操作比较耗费资源，只有数量达到一个阈值才启动合并。 Store工作原理： Store是Region服务器的核心。 多个StoreFile合并成一个。 单个StoreFile过大时，又触发分裂操作，1个父Region被分裂成两个子Region。 图：StoreFile的合并和分裂过程 ##HLog工作原理： 分布式环境必须要考虑系统出错。HBase采用HLog保证系统恢复。 HBase系统为每个Region服务器配置了一个HLog文件，它是一种预写式日志（Write Ahead Log）。 用户更新数据必须首先写入日志后，才能写入MemStore缓存，并且，直到MemStore缓存内容对应的日志已经写入磁盘，该缓存内容才能被刷写到磁盘。 Zookeeper会实时监测每个Region服务器的状态，当某个Region服务器发生故障时，Zookeeper会通知Master。 Master首先会处理该故障Region服务器上面遗留的HLog文件，这个遗留的HLog文件中包含了来自多个Region对象的日志记录。 系统会根据每条日志记录所属的Region对象对HLog数据进行拆分，分别放到相应Region对象的目录下，然后，再将失效的Region重新分配到可用的Region服务器中，并把与该Region对象相关的HLog日志记录也发送给相应的Region服务器。 Region服务器领取到分配给自己的Region对象以及与之相关的HLog日志记录以后，会重新做一遍日志记录中的各种操作，把日志记录中的数据写入到MemStore缓存中，然后，刷新到磁盘的StoreFile文件中，完成数据恢复。 共用日志优点：提高对表的写操作性能； ​ 缺点：恢复时需要分拆日志。 写流程：（1）客户端发起写数据请求。 （2）定位Regoin。定位到需要写到的RegionServer，Region，Rowkey。 （3）数据分组：整个数据分组，涉及到两步。 “分篮子”操作： 根据mete表找到标的Region信息，此时也得到了对应的RegionServer信息。 根据rowkey，将数据写到指定的region中。 每个RegionServer上的数据会一起发送。发送数据中，都是已经按照Region分好组了。 （4）往RegionServer发送请求。 利用HBase自身封装的RPC框架，来完成数据发送操作。 往多个RegionServer发送请求是并行的。 客户端发送完写数据请求后，会自动等待请求处理结果。 如果客户端没有捕获到任何的异常，则认为所有数据都已经被写入成功。如果全部写入失败，或者部分写入失败，客户端能过获知详细的失败key值列表。 （5）Region写数据流程。 获取Region操作锁。（读写锁） 一次获取各行行锁。 写入到MemStore中。（一个内存排序集合） 释放以获取的行锁。 写数据到WAL中。（Write-Ahead-Log） 释放Region锁。 既然是Write-Ahead-Log，为何先写内存再写WAL？ 先写内存的原因：HBase提供了一个MVCC机制，来保障些数据阶段的数据可见性。写写MemStore再写WAL，是为了一些特殊场景下，内存中的数据能够更及时的可将。如果先写WAL失败的话，MemStore助攻的数据会被回滚。 将需要写入或删除的数据暂时保存在每个Region的内存中，即MemStore中。 写内存，避免多Region情形下带来的过多的分散IO操作。 数据在写入到MemStore之后，也会顺序写到HLog中，以保障数据的安全。 （6）Flush。 以下多个场景，会触发Memstore的Flush操作： Region中的MemStore的总大小，达到了预设的Flush Size阈值。 MemStore占用内存的总量和RegionServer总内存的比值超出来了预设的阈值大小。 当WALs中文件数量达到阈值时。 HBase定期刷新MemStore，默认周期为1小时。 用户可以通过shell命令分别对一个表或者一个Region进行Flush。 （7）Compaction。 Compaction的目的，是为了减少同一个Region中的同一个ColumnFamily下面的小文件（HFile）数目，从而提升读取的性能。 Compaction分为Minor、Major两类： Minor：小范围的Compaction。有最少和最大文件数目的限制。通常会选择一些连续时间范围的小文件进行合并。 Major：涉及该Region该ColumnFamily下面的所有HFile文件。 Minor Compaction选取文件时，遵循一定的算法。 图：Compaction操作示例 （8）Region Split。 Region Split是指集群期间，某一个Region的大小超出了预设的阈值，则需要将该Region自动分裂成为两个REgion。 分裂过程中，被分裂的Region会暂停读写服务。由于分裂过程中，父Region的数据文件并不会真正的分裂，而是仅仅通过在新的Region中创建引用文件的方式，来实现快速分裂。因此，Region暂停服务的时间比较短暂。 客户端册所缓存的父Region的路由信息需要被更新。 读流程：（1）客户端发起读数据请求： Get操作在精准的Key值的情形下，读取单行用户数据。 Sacn操作时为了批量扫描限定KEy值范围的用户数据。 （2）定位Region。定位到该数据所在的RegionServer，Region，Rowkey。 （3）OpenScanner：OpenScanner过程中，会创建两种不同的Scanner来读取Hfile、MemStore的数据。 HFile 对应的Scanner为StoreFileScanner。 MemStore对应的Scanner为对应的MemStoreScanner。 （4）Next： 每一个Scanner中，都有一个指针，指向接下来要读取的用户数据KeyValue是哪一个。 同一级的Scanner，被放在同一个优先级队列中。通过不断的对比每一个Scanner的指针所指向的KeyValue，将这些Scanner进行排序。 每一次next请求，都是从该优先级队列中，Poll出一个Scanner，然后，读取该Scanner的当前指针所指向的KeyValue即可。 每读一个Scanner，指针都会我那个下移一个KeyValue。而后，该Scanner被返还到队列中。如果已经读完，则直接关闭。 （5）Filter允许在Scan过程或只能怪，设定一定的过滤条件。符合条件的用户数据才返回。当前包含的一些典型的Filter有： RowFilter SingleColumnValueFilter KeyOnlyFilter FilterList 使用Filter时，可能会扫描大量的用户数据，才可以找到所期望的满足条件的数据。因此，一些场景下性能是不可预估的。 （6）BloomFilter： BloomFilter用来优化一些随机读取的场景，即Get场景。它可以被用来快速的判断一条用户数据在一个大的数据集合（该数据集合的大部分数据都没法加载到内存中）中是否存在。 BloomFilter在判断一个数据是否存在时，拥有一定的误判率。但对于“用户数据XXX不存在”的判断结果是可信的。 HBase的BLoomFilter的相关数据，被保存在HFile中。 HBase应用方案HBase实际应用中的性能优化方法： 行键（Row Key）行键是按照字典序存储，因此，设计行键时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。 举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳作为行键的一部分，由于是字典序排序，所以可以使用Long.MAX_VALUE - timestamp作为行键，这样能保证新写入的数据在读取时可以被快速命中。 InMemory 创建表的时候，可以通过HColumnDescriptor.setInMemory(true)将表放到Region服务器的缓存中，保证在读取的时候被cache命中。 Max Version 创建表的时候，可以通过HColumnDescriptor.setMaxVersions(int maxVersions)设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置setMaxVersions(1)。 Time TO Live： 创建表的时候，可以通过HColumnDescriptor.setTimeToLive(int timeToLive)设置表中数据的存储生命期，过期数据将自动被删除，例如如果只需要存储最近两天的数据，那么可以设置setTimeToLive(2 24 60 * 60)。 HBase性能监视：Master-status(自带)：HBase Master默认基于Web的UI服务端口为60010，HBase region服务器默认基于Web的UI服务端口为60030.如果master运行在名为master.foo.com的主机中，mater的主页地址就是http://master.foo.com:60010，用户可以通过Web浏览器输入这个地址查看该页面可以查看HBase集群的当前状态。 Ganglia：Ganglia是UC Berkeley发起的一个开源集群监视项目，用于监控系统性能。 OpenTSDB：OpenTSDB可以从大规模的集群（包括集群中的网络设备、操作系统、应用程序）中获取相应的metrics并进行存储、索引以及服务，从而使得这些数据更容易让人理解，如web化，图形化等。 Ambari：Ambari 的作用就是创建、管理、监视 Hadoop 的集群。 在HBase之上构建SQL引擎：NoSQL区别于关系型数据库的一点就是NoSQL不使用SQL作为查询语言，至于为何在NoSQL数据存储HBase上提供SQL接口，有如下原因： 易使用。使用诸如SQL这样易于理解的语言，使人们能够更加轻松地使用HBase。 减少编码。使用诸如SQL这样更高层次的语言来编写，减少了编写的代码量。 方案： 1.Hive整合HBase 2.Phoenix 1.Hive整合HBase Hive与HBase的整合功能从Hive0.6.0版本已经开始出现，利用两者对外的API接口互相通信，通信主要依靠hive_hbase-handler.jar工具包(Hive Storage Handlers)。由于HBase有一次比较大的版本变动，所以并不是每个版本的Hive都能和现有的HBase版本进行整合，所以在使用过程中特别注意的就是两者版本的一致性。 2.Phoenix Phoenix由Salesforce.com开源，是构建在Apache HBase之上的一个SQL中间层，可以让开发者在HBase上执行SQL查询。 构建HBase二级索引：HBase只有一个针对行健的索引 访问HBase表中的行，只有三种方式： 通过单个行健访问 通过一个行健的区间来访问 全表扫描 使用其他产品为HBase行健提供索引功能： Hindex二级索引 HBase+Redis HBase+solr 原理：采用HBase0.92版本之后引入的Coprocessor特性。 Coprocessor构建二级索引：Coprocessor（协处理器）提供了两个实现：endpoint和observer，endpoint相当于关系型数据库的存储过程，而observer则相当于触发器。 observer允许我们在记录put前后做一些处理，因此，而我们可以在插入数据时同步写入索引表。 优点： 非侵入性：引擎构建在HBase之上，既没有对HBase进行任何改动，也不需要上层应用做任何妥协。 缺点：每插入一条数据需要向索引表插入数据，即耗时是双倍的，对HBase的集群的压力也是双倍的。 图：二级索引示意图 ###Hindex: Hindex 是华为公司开发的纯 Java 编写的HBase二级索引，兼容 Apache HBase 0.94.8。当前的特性如下： 多个表索引 多个列索引 基于部分列值的索引 HBase+Redis: Redis+HBase方案 Coprocessor构建二级索引 Redis做客户端缓存 将索引实时更新到Redis等KV系统中，定时从KV更新索引到HBase的索引表中. 图：HBase+Redis二级索引 HBase+solr:Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。 图：HBase+Solr HBase华为增强特性支持二级索引：二级索引为HBase提供了按照某些列的值进行索引的能力。 HFS（HBase FileStream）：HBase文件存储模块（HBase FileStream，简称HFS）是HBase的独立模块，它作为对HBase与HDFS接口的封装，应用在FusionInsight的上层应用，为上层应用提供文件的存储、读取、删除等功能。 HFS的出现解决了需要在HDFS中存储海量小文件，同时也要存储一些大文件的混合的场景。简单来说，就是在HBase表中，需要存放大量的小文件（10MB以下），同时又需要存放一些比较大的文件（10MB以上。） HBase MOB：MOB数据（即100KB到10MB大小的数据）直接以HFile的格式存储在文件系统上（例如HDFS文件系统），然后把这个文件的地址信息及大小信息作为value存储在普通HBase的store上，通过攻击集中管理这些文件。这样就可以大大降低HBase的compation和split频率，提升性能。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓝桥杯第九届省赛Java-B组]]></title>
    <url>%2F2018%2F05%2F14%2F%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%AC%AC%E4%B9%9D%E5%B1%8A%E7%9C%81%E8%B5%9BJava-B%E7%BB%84%2F</url>
    <content type="text"><![CDATA[第一题：第几天 2000年的1月1日，是那一年的第1天。 那么，2000年的5月4日，是那一年的第几天？ 注意：需要提交的是一个整数，不要填写任何多余内容。 日期类题目解题方法如下： 解法1：2000年是闰年二月有29天，一月和三月有31天，四月有30天，所以：31+29+31+30+4=125 解法2：在考场可以拿电脑自带日期计算器： 解法3：利用vbs脚本： 新建记事本，写入如下代码，把文件后缀txt改为vbs就行。 求两日期间隔类题目： 1msgbox( DateDiff( "d", "2000-1-1", "2000-5-4") + 1 ) 图：程序运行结果 求一个日期加上指定天数后的日期： 如下：求2015/5/14日加上6天后的日期. 1msgbox( DateAdd("d", 6, "2018-5-14")) 图：程序运行结果解法4：java编程：更多日期类计算可参考：Java日期与时间的处理 程序源代码： 123456789101112131415161718import java.util.Calendar;import java.util.Date;public class 第几天 &#123; public static void main(String[] args) &#123; Calendar c1 = Calendar.getInstance(); c1.set(2000, 1, 1); Calendar c2 = Calendar.getInstance(); c2.set(2000, 5, 4); Date d2 = c2.getTime(); Date d1 = c1.getTime(); long diff = d2.getTime() - d1.getTime(); long days = diff / (1000 * 60 * 60 * 24); System.out.println(days + 1); &#125;&#125; 程序运行结果： 1125 第二题：方格计数 如图下图所示，在二维平面上有无数个1x1的小方格。 我们以某个小方格的一个顶点为圆心画一个半径为1000的圆。 你能计算出这个圆里有多少个完整的小方格吗？ 注意：需要提交的是一个整数，不要填写任何多余内容。 解题思路：只看第一象限，圆心为（0，0），然后遍历第一象限圆内的所有点( i, j )，当且仅当这个点的左上角到圆心的距离小于半径，ans++。最后ans *= 4。 程序源代码： 12345678910111213141516171819202122public class Main &#123; /** * 只看第一象限，圆心为（0，0），然后遍历第一象限圆内的所有点( i, j )，当且仅当这 * 个点的左上角到圆心的距离小于半径，ans++。最后ans *= 4。 * @param args */ public static void main(String[] args) &#123; System.out.println(work(1000)); &#125; private static int work(int n) &#123; int count = 0; for(int i = 1; i &lt;= n; ++i) for(int j = 1; j &lt;= n; ++j) &#123; int d = i*i + j*j; if( d &lt;= n*n) ++count; &#125; return count*4; &#125;&#125; 程序运行结果： 13137548 第三题：复数幂 设i为虚数单位。对于任意正整数n，(2+3i)^n 的实部和虚部都是整数。 求 (2+3i)^123456 等于多少？ 即(2+3i)的123456次幂，这个数字很大，要求精确表示。 答案写成 “实部±虚部i”的形式，实部和虚部都是整数（不能用科学计数法表示），中间任何地方都不加空格，实部为正时前面不加正号。(2+3i)^2 写成: -5+12i，(2+3i)^5 的写成: 122-597i 注意：需要提交的是一个很庞大的复数，不要填写任何多余内容。 解题思路：把实部和虚部存储，连乘123456次。 程序源代码： 12345678910111213public class 复数幂 &#123; public static void main(String[] args) &#123; //(2 + 3i)(a + bi) = 2a + 2bi + 3ai - 3b int a = 2, b = 3; for(int i = 1; i &lt; 123456; i++) &#123; int temp = 2*a - 3*b; b = 3*a + 2*b; a = temp; &#125; System.out.println(a + "+"+b+"i"); &#125;&#125; 程序运行结果： 113483137+1100011648i 第四题：测试次数 x星球的居民脾气不太好，但好在他们生气的时候唯一的异常举动是：摔手机。 各大厂商也就纷纷推出各种耐摔型手机。x星球的质监局规定了手机必须经过耐摔测试，并且评定出一个耐摔指数来，之后才允许上市流通。 x星球有很多高耸入云的高塔，刚好可以用来做耐摔测试。塔的每一层高度都是一样的，与地球上稍有不同的是，他们的第一层不是地面，而是相当于我们的2楼。 如果手机从第7层扔下去没摔坏，但第8层摔坏了，则手机耐摔指数=7。 特别地，如果手机从第1层扔下去就坏了，则耐摔指数=0。如果到了塔的最高层第n层扔没摔坏，则耐摔指数=n 为了减少测试次数，从每个厂家抽样3部手机参加测试。 某次测试的塔高为1000层，如果我们总是采用最佳策略，在最坏的运气下最多需要测试多少次才能确定手机的耐摔指数呢？ 请填写这个最多测试次数。 注意：需要填写的是一个整数，不要填写任何多余内容。 程序源代码： 12 1234567891011121314151617181920212223242526272829303132333435363738package 蓝桥杯2018省赛;public class 测试次数 &#123; public static void main(String[] args) &#123; System.out.println(Test(1000, 3)); &#125; private static int Test(int m, int n) &#123; if(m &lt; 1 || n &lt; 1) return 0; //上一层备忘录，存储手机数量-1的m层楼层条件下的最优化尝试次数 int [] preCache = new int[m + 1]; //当前备忘录，存储当前鸡蛋数量的m层楼层条件下的最优化尝试次数 int [] currentCache = new int[m + 1]; //把备忘录每个元素初始化成最大的尝试次数 for(int i = 0; i &lt;= m; i++) &#123; currentCache[i] = i; &#125; for(int i = 2; i &lt;= n; i++) &#123; //当前备忘录拷贝给上一次备忘录，并重新初始化当前备忘录 preCache = currentCache.clone(); for(int j = 0; j &lt;= m; j++) &#123; currentCache[j] = j; &#125; for(int floor = 1; floor &lt;= m; floor++) &#123; for(int k = 1; k &lt; floor; k++) &#123; //扔手机的楼层从1到m枚举一遍，如果当前算出的尝试次数小于 //上一次算出的尝试次数，则取代上一次的尝试次数。 //这里可以打印k的值，从而知道第一个手机是从第几次扔的。 currentCache[floor] = Math.min(currentCache[floor], 1 + Math.max(preCache[k-1], currentCache[floor-k])); &#125; &#125; &#125; return currentCache[m]; &#125;&#125; 程序运行结果： 119 第五题：快速排序 以下代码可以从数组a[]中找出第k小的元素。它使用了类似快速排序中的分治算法，期望时间复杂度是O(N)的。 请仔细阅读分析源码，填写划线部分缺失的内容。 注意：只提交划线部分缺少的代码，不要抄写任何已经存在的代码或符号。 12345678910111213141516171819202122232425262728293031&gt; public class Main&#123; &gt; public static int quickSelect(int a[], int l, int r, int k) &#123; &gt; Random rand = new Random(); &gt; int p = rand.nextInt(r - l + 1) + l; &gt; int x = a[p]; &gt; int tmp = a[p]; a[p] = a[r]; a[r] = tmp; &gt; int i = l, j = r; &gt; while(i &lt; j) &#123; &gt; while(i &lt; j &amp;&amp; a[i] &lt; x) i++; &gt; if(i &lt; j) &#123; &gt; a[j] = a[i]; &gt; j--; &gt; &#125; &gt; while(i &lt; j &amp;&amp; a[j] &gt; x) j--; &gt; if(i &lt; j) &#123; &gt; a[i] = a[j]; &gt; i++; &gt; &#125; &gt; &#125; &gt; a[i] = x; &gt; p = i; &gt; if(i - l + 1 == k) return a[i]; &gt; if(i - l + 1 &lt; k) return quickSelect( _______________________ ); //填空 &gt; else return quickSelect(a, l, i - 1, k); &gt; &#125; &gt; public static void main(String args[]) &#123; &gt; int [] a = &#123;1, 4, 2, 8, 5, 7&#125;; &gt; System.out.println(quickSelect(a, 0, 5, 4)); &gt; &#125; &gt; &#125;&gt; 答案：a, i+1, r, k-(i-l+1) 第六题：递增三元组 给定三个整数数组 A = [A1, A2, … AN], B = [B1, B2, … BN], C = [C1, C2,… CN]， 请你统计有多少个三元组(i, j, k) 满足： 1 &lt;= i, j, k &lt;= N Ai &lt; Bj &lt; Ck 【输入格式】 第一行包含一个整数N。 第二行包含N个整数A1, A2, … AN。 第三行包含N个整数B1, B2, … BN。第四行包含N个整数C1, C2, … CN。 对于30%的数据，1 &lt;= N &lt;= 100对于60%的数据，1 &lt;= N &lt;= 1000对于100%的数据，1 &lt;= N &lt;=100000 0 &lt;= Ai, Bi, Ci &lt;= 100000 【输出格式】 一个整数表示答案 【输入样例】31 1 12 2 23 3 3 【输出样例】27 资源约定： 峰值内存消耗（含虚拟机） &lt; 256M CPU消耗 &lt; 1000ms 请严格按要求输出，不要画蛇添足地打印类似：“请您输入…” 的多余内容。 所有代码放在同一个源文件中，调试通过后，拷贝提交该源码。不要使用package语句。不要使用jdk1.7及以上版本的特性。 主类的名字必须是：Main，否则按无效代码处理。 程序源代码： 123456789101112131415161718192021222324252627282930313233package 蓝桥杯2018省赛;import java.util.Scanner;public class 递增三元组 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int[] a = new int[n+1]; int[] b = new int[n+1]; int[] c = new int[n+1]; for(int i = 1; i &lt;= n; i++) &#123; a[i] = sc.nextInt(); &#125; for(int i = 1; i &lt;= n; i++) &#123; b[i] = sc.nextInt(); &#125; for(int i = 1; i &lt;= n; i++) &#123; c[i] = sc.nextInt(); &#125; int count = 0; for(int i = 1; i &lt;= n; i++) &#123; for(int j = 1; j &lt;= n; j++) &#123; for(int k = 1; k &lt;= n; k++) &#123; if(a[i] &lt; b[j] &amp;&amp; b[j] &lt; c[k]) &#123; count++; &#125; &#125; &#125; &#125; System.out.println(count); &#125;&#125; 第七题：螺旋折线 如图所示的螺旋折线经过平面上所有整点恰好一次。 对于整点(X, Y)，我们定义它到原点的距离dis(X,Y)是从原点到(X, Y)的螺旋折线段的长度。 例如dis(0, 1)=3, dis(-2, -1)=9 给出整点坐标(X, Y)，你能计算出dis(X, Y)吗？ 【输入格式】 X和Y 对于40%的数据，-1000 &lt;= X, Y &lt;= 1000对于70%的数据，-100000 &lt;= X， Y &lt;= 100000对于100%的数据, -1000000000 &lt;= X, Y &lt;= 1000000000 【输出格式】 输出dis(X, Y) 【输入样例】 0 1 【输出样例】 3 资源约定： 峰值内存消耗（含虚拟机） &lt; 256M CPU消耗 &lt; 1000ms 请严格按要求输出，不要画蛇添足地打印类似：“请您输入…” 的多余内容。 所有代码放在同一个源文件中，调试通过后，拷贝提交该源码。 不要使用&gt; package语句。不要使用jdk1.7及以上版本的特性。主类的名字必须是：Main，否则按无效代码处理。 程序源代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package 蓝桥杯2018省赛;import java.util.Scanner;public class 螺旋折线 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int x = sc.nextInt(); int y = sc.nextInt(); System.out.println(dis(x, y)); &#125; private static int dis(int x, int y) &#123; if(x &gt;= 0 &amp;&amp; y &gt;=0 &amp;&amp; y &lt;=x) &#123; int num = 0; for(int i = 1; i &lt; x*2; i++) &#123; num += i*2; &#125; return num + x*3 - y; &#125; if(y &gt;= 0 &amp;&amp; x &gt;=0 &amp;&amp; y &gt; x) &#123; int num = 0; for(int i = 1; i &lt; y*2; i++) &#123; num += i*2; &#125; return num + y + x; &#125; if(x &lt; 0 &amp;&amp; y &gt; 0 &amp;&amp; Math.abs(x) &lt;= y) &#123; int num = 0; for(int i = 1; i &lt; y*2; i++) &#123; num += i*2; &#125; return num + y - Math.abs(x); &#125; if(x &lt; 0 &amp;&amp; y &gt;= 0 &amp;&amp; Math.abs(x) &gt; y) &#123; int num = 0; for(int i = 1; i &lt; Math.abs(x)*2; i++) &#123; num += i*2; &#125; return num - Math.abs(x) + y; &#125; if(x &lt; 0 &amp;&amp; y &lt; 0 &amp;&amp; Math.abs(x) &gt; Math.abs(y)) &#123; int num = 0; for(int i = 1; i &lt; Math.abs(x)*2; i++) &#123; num += i*2; &#125; return num - Math.abs(x) - Math.abs(y) ; &#125; if(x &lt;= 0 &amp;&amp; y &lt; 0 &amp;&amp; Math.abs(x) &lt;= Math.abs(y)) &#123; int num = 0; for(int i = 1; i &lt;= Math.abs(y)*2; i++) &#123; num += i*2; &#125; return num + Math.abs(x) + Math.abs(y); &#125; if(x &gt;= 0 &amp;&amp; y &lt; 0 &amp;&amp; x &lt;= Math.abs(y)) &#123; int num = 0; for(int i = 1; i &lt;= Math.abs(y)*2; i++) &#123; num += i*2; &#125; return num + Math.abs(y) - x; &#125; if(x &gt; 0 &amp;&amp; y &lt; 0 &amp;&amp; x &gt; Math.abs(y)) &#123; int num = 0; for(int i = 1; i &lt;= x*2; i++) &#123; num += i*2; &#125; return num - x + Math.abs(y); &#125; return 0; &#125;&#125; 第八题：日志统计 小明维护着一个程序员论坛。现在他收集了一份”点赞”日志，日志共有N行。其中每一行的格式是： ts id 表示在ts时刻编号id的帖子收到一个”赞”。 现在小明想统计有哪些帖子曾经是”热帖”。如果一个帖子曾在任意一个长度为D的时间段内收到不少于K个赞，小明就认为这个帖子曾是”热帖”。 具体来说，如果存在某个时刻T满足该帖在[T, T+D)这段时间内(注意是左闭右开区间)收到不少于K个赞，该帖就曾是”热帖”。 给定日志，请你帮助小明统计出所有曾是”热帖”的帖子编号。 【输入格式】 第一行包含三个整数N、D和K。 以下N行每行一条日志，包含两个整数ts和id。 对于50%的数据，1 &lt;= K &lt;= N &lt;= 1000对于100%的数据，1 &lt;= K &lt;= N &lt;= 1000000 &lt;= ts&lt;= 100000 0 &lt;= id &lt;= 100000 【输出格式】 按从小到大的顺序输出热帖id。每个id一行。 【输入样例】 7 10 20 10 1010 1010 19 1100 3100 3 【输出样例】 1 3 资源约定： 峰值内存消耗（含虚拟机） &lt; 256M CPU消耗 &lt; 1000ms 请严格按要求输出，不要画蛇添足地打印类似：“请您输入…” 的多余内容。 所有代码放在同一个源文件中，调试通过后，拷贝提交该源码。 不要使用package语句。不要使用jdk1.7及以上版本的特性。主类的名字必须是：Main，否则按无效代码处理。 程序代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package 蓝桥杯2018省赛;import java.util.ArrayList;import java.util.Collections;import java.util.Iterator;import java.util.List;import java.util.Scanner;public class 日志统计 &#123; @SuppressWarnings("unchecked") public static void main(String[] args) &#123; //读取输入数据 Scanner sc = new Scanner(System.in); int N = sc.nextInt(); int D = sc.nextInt(); int K = sc.nextInt(); int [] ts = new int[N+1]; int [] id = new int[N+1]; for(int i = 1; i &lt;= N; i++) &#123; ts[i] = sc.nextInt(); id[i] = sc.nextInt(); &#125; //用来存放热点ID List&lt;Integer&gt; hotspotID = new ArrayList&lt;Integer&gt;(); //idList:用来将日志中的所有id过滤出来 List idList = new ArrayList&lt;Integer&gt;(); for(int i = 1; i &lt; N; i++) &#123; if(!idList.contains(id[i])) &#123; idList.add(id[i]); &#125; &#125; /* * 遍历idList里面的id号，对每个id号进行分段查询统计，看是否为热点id */ Iterator&lt;Integer&gt; iterator = idList.iterator(); while(iterator.hasNext()) &#123; int ID = iterator.next(); //time用来存放每个id对应的点赞时间集合 List time = new ArrayList&lt;Integer&gt;(); for(int i = 1; i &lt;= N; i++) &#123; if(ID == id[i]) &#123; time.add(ts[i]); &#125; &#125; //对时间集合进行排序，方便按时间段统计热点次数 Collections.sort(time); //时间集合里面的最小时间 int beginTime = (int) time.get(0); //时间集合里面的最大时间 int endTime = (int) time.get(time.size()-1); //从开始时间（T , T+D）每个时间段的热点进行循环统计 for(int i = beginTime; i &lt;= endTime ; i += D) &#123; beginTime = i; //用来存放当前统计时间段的点赞次数 List&lt;Integer&gt; hotspot = new ArrayList&lt;Integer&gt;(); for(int j = 0; j &lt; time.size(); j++) &#123; int curTime = (int) time.get(j); if(beginTime &lt;= curTime &amp;&amp; curTime &lt; beginTime+10) &#123; hotspot.add(curTime); &#125; &#125; //如果当前时间段的点赞次数满足大于热点次数K， //则将该ID号添加到热点ID序列中。同时跳出循环。 if(hotspot.size() &gt;= K) &#123; hotspotID.add(ID); break; &#125; &#125; &#125; for(int i = 0 ; i &lt; hotspotID.size(); i++) &#123; if(i == hotspotID.size()) &#123; System.out.println(hotspotID.get(i)); &#125;else &#123; System.out.print(hotspotID.get(i) + " "); &#125; &#125; &#125;&#125; 第九题：全球变暖 你有一张某海域NxN像素的照片，”.”表示海洋、”#”表示陆地，如下所示： ……..##…..##…. ….##...####.…###. ……. 其中”上下左右”四个方向上连在一起的一片陆地组成一座岛屿。例如上图就有2座岛屿。 由于全球变暖导致了海面上升，科学家预测未来几十年，岛屿边缘一个像素的范围会被海水淹没。具体来说如果一块陆地像素与海洋相邻(上下左右四个相邻像素中有海洋)，它就会被淹没。 例如上图中的海域未来会变成如下样子： …….…….…….…….….#..…….……. 请你计算：依照科学家的预测，照片中有多少岛屿会被完全淹没。 【输入格式】 第一行包含一个整数N。 (1 &lt;= N &lt;= 1000) 以下N行N列代表一张海域照片。 照片保证第1行、第1列、第N行、第N列的像素都是海洋。 【输出格式】 一个整数表示答案。 【输入样例】 7……..##…..##….….##...####.…###.……. 【输出样例】 1 资源约定： 峰值内存消耗（含虚拟机） &lt; 256M CPU消耗 &lt; 1000ms 请严格按要求输出，不要画蛇添足地打印类似：“请您输入…” 的多余内容。 所有代码放在同一个源文件中，调试通过后，拷贝提交该源码。 不要使用package语句。不要使用jdk1.7及以上版本的特性。主类的名字必须是：Main，否则按无效代码处理。 第十题：堆的记数 我们知道包含N个元素的堆可以看成是一棵包含N个节点的完全二叉树。 每个节点有一个权值。对于小根堆来说，父节点的权值一定小于其子节点的权值。 假设N个节点的权值分别是1~N，你能求出一共有多少种不同的小根堆吗？ 例如对于N=4有如下3种： 123456&gt; 1&gt; / \&gt; 2 3&gt; /&gt; 4&gt; 123456&gt; 1&gt; / \&gt; 3 2&gt; /&gt; 4&gt; 123456&gt; 1&gt; / \&gt; 2 4&gt; /&gt; 3&gt; 由于数量可能超过整型范围，你只需要输出结果除以1000000009的余数。 【输入格式】 一个整数N。对于40%的数据，1 &lt;= N &lt;= 1000对于70%的数据，1 &lt;= N &lt;= 10000对于100%的数据，1 &lt;= N &lt;= 100000 【输出格式】 一个整数表示答案。 【输入样例】 4 【输出样例】 3 资源约定： 峰值内存消耗（含虚拟机） &lt; 256M CPU消耗 &lt; 1000ms 请严格按要求输出，不要画蛇添足地打印类似：“请您输入…” 的多余内容。 所有代码放在同一个源文件中，调试通过后，拷贝提交该源码。 不要使用package语句。不要使用jdk1.7及以上版本的特性。主类的名字必须是：Main，否则按无效代码处理。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度优先遍历和广度优先遍历]]></title>
    <url>%2F2018%2F05%2F14%2F%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E9%81%8D%E5%8E%86%E5%92%8C%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[深度优先遍历深度优先遍历(Depth-First Traversal)简称DFS。 算法思想： 首先以一个未被访问过的顶点作为起始顶点，沿当前顶点的边走到未访问过的顶点； 当没有未访问过的顶点时，则回到上一个顶点，继续试探别的顶点，直到所有的顶点都被访问过。 图：深度优先遍历示例图 如上图，采用图的深度优先遍历的话，从0号节点遍历的顺序应该是：0,1,2,3,4. 程序源代码示例： 1234567891011121314151617181920212223242526public class DeepTravel &#123; public static void main(String[] args) &#123; //图的邻接矩阵表示 int[][] a = &#123; &#123;0,1,1,1,0&#125;, &#123;1,0,1,1,1&#125;, &#123;1,1,0,0,0&#125;, &#123;1,1,0,0,0&#125;, &#123;0,1,0,0,0&#125;&#125;; //需要一个数字，来记录染色信息，染色的节点代表已经遍历 int[] color = new int[a.length]; System.out.println("深度优先遍历的结果为："); dfs(a, color, 0); &#125; //用递归的方法进行遍历 private static void dfs(int[][] a, int[] color, int k) &#123; System.out.print(k + " ");//打印出k号节点 color[k] = 1;//给k号节点标记为1 for(int i = 0; i &lt; a[k].length; i++) if(a[k][i] == 1 &amp;&amp; color[i] == 0) dfs(a, color, i); &#125;&#125; 程序运行结果： 12深度优先遍历的结果为：0 1 2 3 4 广度优先遍历广度优先搜索算法（英语：Breadth-First-Search，缩写为BFS）。 其过程检验来说是对每一层节点依次访问，访问完一层进入下一层，而且每个节点只能访问一次。 程序示例： 图：广度优先遍历示例图 如上图，，采用图的广度优先遍历的话，从0号节点遍历的顺序应该是：0,1,2,3,6,5,4 程序源代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.ArrayList;import java.util.HashSet;import java.util.Set;public class BreadthTravel &#123; public static void main(String[] args) &#123; //图的邻接定义 int[][] g = &#123; &#123;0,1,1,0,0,0,0&#125;, &#123;1,0,0,1,0,0,1&#125;, &#123;1,0,0,0,0,1,1&#125;, &#123;0,1,0,0,1,0,0&#125;, &#123;0,0,0,1,0,1,1&#125;, &#123;0,0,1,0,1,0,0&#125;, &#123;0,1,1,0,1,0,0&#125;&#125;; //广度优先遍历 System.out.println("广度优先遍历的结果："); bfs(g); &#125; private static void bfs(int[][] g) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();//等待遍历的节点 Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;();//已经遍历的节点 list.add(0);//从0号节点开始遍历 while (true) &#123; //如果列表为空，则遍历完成 if(list.isEmpty()) break; int node = list.get(0); System.out.print(node + " "); set.add(node); list.remove(0); for(int i = 0; i &lt; g[node].length; i++) &#123; if(g[node][i] == 1 &amp;&amp; set.contains(i) == false &amp;&amp; list.indexOf(i)&lt;0) list.add(i); &#125; &#125; &#125;&#125; 程序运行结果： 12广度优先遍历的结果：0 1 2 3 6 5 4 最短路径树迪杰斯特拉算法简介迪杰斯特拉算法是由荷兰计算机科学家狄克斯特拉于1959 年提出的，因此又叫狄克斯特拉算法。是从一个顶点到其余各顶点的最短路径算法，解决的是有向图中最短路径问题。迪杰斯特拉算法主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。 程序示例： 图：最短路径树示例拓扑 如上图，从求0号节点开始到所有节点的最短路径。 程序源代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import java.util.ArrayList;import java.util.HashMap;import java.util.Iterator;import java.util.Map;public class 最短路径树 &#123; static class Cell&#123; int node; //连接到哪个节点 int weight; //边的权值 public Cell(int node, int weight) &#123; this.node = node; this.weight = weight; &#125; &#125; @SuppressWarnings("unchecked") public static void main(String[] args) &#123; //图的邻接表 ArrayList[] g = new ArrayList[11]; for(int i = 0; i &lt; g.length; i++) g[i] = new ArrayList(); g[0].add(new Cell(1, 3)); g[0].add(new Cell(4, 1)); g[1].add(new Cell(2, 1)); g[1].add(new Cell(6, 3)); g[1].add(new Cell(5, 5)); g[1].add(new Cell(0, 3)); g[1].add(new Cell(9, 4)); g[2].add(new Cell(1, 1)); g[2].add(new Cell(3, 1)); g[2].add(new Cell(6, 7)); g[3].add(new Cell(2, 1)); g[3].add(new Cell(10, 2)); g[4].add(new Cell(0, 1)); g[4].add(new Cell(5, 2)); g[5].add(new Cell(4, 2)); g[5].add(new Cell(1, 5)); g[5].add(new Cell(7, 2)); g[5].add(new Cell(8, 3)); g[6].add(new Cell(1, 3)); g[6].add(new Cell(2, 3)); g[6].add(new Cell(8, 2)); g[6].add(new Cell(10, 1)); g[7].add(new Cell(5, 2)); g[8].add(new Cell(5, 3)); g[8].add(new Cell(6, 2)); g[9].add(new Cell(1, 4)); g[9].add(new Cell(10, 2)); g[10].add(new Cell(3, 2)); g[10].add(new Cell(6, 1)); g[10].add(new Cell(9, 2)); //求0号节点开始的所有最小路径 Dijkstra(g); &#125; public static void Dijkstra(ArrayList[] g) &#123; //节点号--&gt;最小路径值 Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); while(true) &#123; int min = Integer.MAX_VALUE; //最小路径值 int min_no = -1; //对应的节点号 //所有与0号节点邻接，并且不在集合map中的点 for(int i = 0; i &lt; g[0].size(); i++) &#123; Cell t = (Cell) g[0].get(i); if(map.get(t.node) == null &amp;&amp; t.weight &lt; min) &#123; min_no = t.node; min = t.weight; &#125; &#125; //与map中点邻接的所有不在map中的点 Iterator it = map.keySet().iterator(); while(it.hasNext()) &#123; int k = (int)it.next(); //集合中的点对应的最小路径的值 int v = (int)map.get(k); for(int i = 0; i &lt; g[k].size(); i++) &#123; Cell t = (Cell)g[k].get(i); if(map.get(t.node) == null &amp;&amp; t.weight + v &lt; min) &#123; min_no = t.node; min = t.weight + v; &#125; &#125; &#125; if(min &lt; Integer.MAX_VALUE) map.put(min_no, min); else break; &#125; System.out.println(map); &#125;&#125; 程序运行结果： 1&#123;0=2, 1=3, 2=4, 3=5, 4=1, 5=3, 6=6, 7=5, 8=6, 9=7, 10=7&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop的优化与发展]]></title>
    <url>%2F2018%2F05%2F11%2FHadoop%E7%9A%84%E4%BC%98%E5%8C%96%E4%B8%8E%E5%8F%91%E5%B1%95%2F</url>
    <content type="text"><![CDATA[Hadoop1.0的缺陷与不足：Hadoop1.0的核心组件（仅指MapReduce和HDFS，不包括Hadoop生态系统内的Pig、Hive、HBase等其他组件），主要存在以下不足： 抽象层次低，需人工编码 表达能力有限 开发者自己管理作业（Job）之间的依赖关系 难以看到程序整体逻辑 执行迭代操作效率低 资源浪费（Map和Reduce分两阶段执行） 实时性差（适合批处理，不支持实时交互式） 针对Hadoop的改进与提升：Hadoop的优化与发展主要体现在两个方面： 一方面是Hadoop自身两大核心组件MapReduce和HDFS的架构设计改进。 另一方面是Hadoop生态系统其它组件的不断丰富，加入了Pig、Tez、Spark和Kafka等新组件。 Hadoop框架自身的改进：从1.0到2.0： 不断完善的Hadoop生态系统： HDFS HA： HDFS HA（High Availability）是为了解决单点故障问题。 HA集群设置两个名称节点，“活跃（Active）”和“待命（Standby）”。 两种名称节点的状态同步，可以借助于一个共享存储系统来实现。 一旦活跃名称节点出现故障，就可以立即切换到待命名称节点。 Zookeeper确保一个名称节点在对外服务。 名称节点维护映射信息，数据节点同时向两个名称节点汇报信息。 HDFS Federation：HDFS1.0中存在的问题： 单点故障问题。 不可以水平扩展（是否可以通过纵向扩展来解决？）。 系统整体性能受限于单个名称节点的吞吐量。 单个名称节点难以提供不同程序之间的隔离性。 HDFS HA是热备份，提供高可用性，但是无法解决可扩展性、系统性能和隔离性。 HDFS Federation的设计： 在HDFS Federation中，设计了多个相互独立的名称节点，使得HDFS的命名服务能够水平扩展，这些名称节点分别进行各自命名空间和块的管理，相互之间是联盟（Federation）关系，不需要彼此协调。并且向后兼容。 HDFS Federation中，所有名称节点会共享底层的数据节点存储资源，数据节点向所有名称节点汇报。 属于同一个命名空间的块构成一个“块池”。 HDFS Federation的访问方式： 对于Federation中的多个命名空间，可以采用客户端挂载表（Client SideMount Table）方式进行数据共享和访问。 客户可以访问不同的挂载点来访问不同的子命名空间。 把各个命名空间挂载到全局“挂载表”（mount-table）中，实现数据全局共享。 同样的命名空间挂载到个人的挂载表中，就成为应用程序可见的命名空间。 HDFS Federation相对HDFS1.0的优势： HDFS Federation设计可解决单名称节点存在的以下几个问题： HDFS集群扩展性。多个名称节点各自分管一部分目录，使得一个集群可以扩展到更多节点，不再像HDFS1.0中那样由于内存的限制制约文件存储数目 。 性能更高效。多个名称节点管理不同的数据，且同时对外提供服务，将为用户提供更高的读写吞吐率 。 良好的隔离性。用户可根据需要将不同业务数据交由不同名称节点管理，这样不同业务之间影响很小。 需要注意的，HDFS Federation并不能解决单点故障问题，也就是说，每个名称节点都存在在单点故障问题，需要为每个名称节点部署一个后备名称节点，以应对名称节点挂掉对业务产生的影响。 MapReduce1.0的缺陷： 存在单点故障。 JobTracker“大包大揽”导致任务过重（任务多时内存开销大，上限4000节点）。 容易出现内存溢出（分配资源只考虑MapReduce任务数，不考虑CPU、内存）。 资源划分不合理（强制划分为slot ，包括Map slot和Reduce slot）。 YARN的设计思路：YARN架构思路：将原JobTacker三大功能拆分 MapReduce1.0既是一个计算框架，也是一个资源管理调度框架。 到了Hadoop2.0以后，MapReduce1.0中的资源管理调度功能，被单独分离出来形成了YARN，它是一个纯粹的资源管理调度框架，而不是一个计算框架。 被剥离了资源管理调度功能的MapReduce 框架就变成了MapReduce2.0，它是运行在YARN之上的一个纯粹的计算框架，不再自己负责资源调度管理服务，而是由YARN为其提供资源管理调度服务。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yarn技术原理]]></title>
    <url>%2F2018%2F05%2F11%2FYarn%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Yarn的基本介绍Yarn基本定义：Apache Hadoop YARN（Yet Another Resource Negotiator,另一种资源协调者）是一种新的Hadoop资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来的巨大的好处。 YARN在产品中的位置： 图：Yarn在FusionInsight产品中的位置 YARN是Hadoop2.0中的资源管理系统，它是一个通用的资源管理模块，可为各类应用程序提供资源管理和调度功能。 Yarn是轻量级弹性计算平台，除了MapReduce框架，还可以支持其他框架，如Spark、Storm等。 多种框架统一管理，共享集群资源的优点： 资源利用率高 运维成本低 数据共享方便 YARN的设计思路：YARN的设计是为了解决MapReduce1.0中的一些缺陷。 存在单点故障。 JobTracker“大包大揽”导致任务过重（任务多时内存开销大，上限4000节点）。 容易出现内存溢出（分配资源只考虑MapReduce任务数，不考虑CPU、内存）。 资源划分不合理（强制划分为slot ，包括Map slot和Reduce slot）。 Yarn架构思路： 图：Yarn的架构思路：将原Job Tacker三大功能拆分 Yarn的组件架构Yarn的组件架构： 图：YARN的组件架构图 三大组件的主要功能介绍： （1）ResourceManager： 处理客户端请求 启动/监控ApplicationMaster 监控NodeManager 资源分配与调度 （2）ApplicationMaster： 为应用程序申请资源，并分配给内部任务 任务调度、监控与容错 （3）NodeManager： 单个节点上的资源管理 处理来自ResourceManger的命令 处理来自ApplicationMaster的命令 ResourceManager：ResourceManager（RM）是一个全局的资源管理器，负责整个系统的资源管理和分配，主要包括两个组件，即调度器（Scheduler）和应用程序管理器（Applications Manager）。 调度器接收来自ApplicationMaster的应用程序资源请求，把集群中的资源以“容器”的形式分配给提出申请的应用程序，容器的选择通常会考虑应用程序所要处理的数据的位置，进行就近选择，从而实现“计算向数据靠拢”。 容器（Container）作为动态资源分配单位，每个容器中都封装了一定数量的CPU、内存、磁盘等资源，从而限定每个应用程序可以使用的资源量。 调度器被设计成是一个可插拔的组件，YARN不仅自身提供了许多种直接可用的调度器，也允许用户根据自己的需求重新设计调度器。 应用程序管理器（Applications Manager）负责系统中所有应用程序的管理工作，主要包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动等。 ApplicationMaster：ResourceManager接收用户提交的作业，按照作业的上下文信息以及从NodeManager收集来的容器状态信息，启动调度过程，为用户作业启动一个ApplicationMaster。 ApplicationMaster的主要功能是： （1）当用户作业提交时，ApplicationMaster与ResourceManager协商获取资源，ResourceManager会以容器的形式为ApplicationMaster分配资源； （2）把获得的资源进一步分配给内部的各个任务（Map任务或Reduce任务），实现资源的“二次分配”； （3）与NodeManager保持交互通信进行应用程序的启动、运行、监控和停止，监控申请到的资源的使用情况，对所有任务的执行进度和状态进行监控，并在任务发生失败时执行失败恢复（即重新申请资源重启任务）； （4）定时向ResourceManager发送“心跳”消息，报告资源的使用情况和应用的进度信息； （5）当作业完成时，ApplicationMaster向ResourceManager注销容器，执行周期完成。 NodeManager：NodeManager是驻留在一个YARN集群中的每个节点上的代理，主要负责： 容器生命周期管理。 监控每个容器的资源（CPU、内存等）使用情况。 跟踪节点健康状况。 以“心跳”的方式与ResourceManager保持通信。 向ResourceManager汇报作业的资源使用情况和每个容器的运行状态。 接收来自ApplicationMaster的启动/停止容器的各种请求 。 需要说明的是，NodeManager主要负责管理抽象的容器，只处理与容器相关的事情，而不具体负责每个任务（Map任务或Reduce任务）自身状态的管理，因为这些管理工作是由ApplicationMaster完成的，ApplicationMaster会通过不断与NodeManager通信来掌握各个任务的执行状态。 YARN的部署： 图：Yarn和Hadoop平台其他组件的统一部署 在集群部署方面，YARN的各个组件是和Hadoop集群中的其他组件进行统一部署的. Yarn的工作流程： 图：YARN的工作流程图 Yarn的工作流程如下： 用户编写客户端应用程序，向YARN提交应用程序，提交的内容包括ApplicationMaster程序，启动ApplicationMaster的命令、用户程序等。 YARN中的ResourceManager负责接收和处理来自客户端的请求，为应用程序分配一个容器，在该容器中启动一个ApplicationMaster。 ApplicationMaster被创建后会首先向ResourceManager注册。 ApplicationMaster采用轮询的方式向ResourceManager申请资源。 ResourceManager以“容器”的形式向提出申请的ApplicationMaster分配资源。 在容器中启动任务（运行环境、脚本）。 各个任务向ApplicationMaster汇报自己的状态和进度。 应用程序运行完成后，ApplicationMaster向ResourceManager的应用程序管理器注销并关闭自己。 Yarn框架与MapReduce1.0框架的对比分析从MapReduce1.0框架发展到YARN框架，客户端并没有发生变化，其大部分调用API及接口都保持兼容，因此，原来针对Hadoop1.0开发的代码不用做大的改动，就可以直接放到Hadoop2.0平台上运行。 总体而言，YARN相对于MapReduce1.0来说具有以下优势： 大大减少了承担中心服务功能的ResourceManager的资源消耗。 ApplicationMaster来完成需要大量资源消耗的任务调度和监控。 多个作业对应多个ApplicationMaster，实现了监控分布化。 MapReduce1.0既是一个计算框架，又是一个资源管理调度框架，但是，只能支持MapReduce编程模型。而YARN则是一个纯粹的资源调度管理框架，在它上面可以运行包括MapReduce在内的不同类型的计算框架，只要编程实现相应的ApplicationMaster。 YARN中的资源管理比MapReduce1.0更加高效。 以容器为单位，而不是以slot为单位。 Yarn的发展目标：YARN的目标就是实现“一个集群多个框架”。 一个企业当中同时存在各种不同的业务应用场景，需要采用不同的计算框架。 MapReduce实现离线批处理 使用Impala实现实时交互式查询分析 使用Storm实现流式数据实时分析 使用Spark实现迭代计算 这些产品通常来自不同的开发团队，具有各自的资源调度管理机制。 为了避免不同类型应用之间互相干扰，企业就需要把内部的服务器拆分成多个集群，分别安装运行不同的计算框架，即“一个框架一个集群”。 导致问题 集群资源利用率低 数据无法共享 维护代价高 图：在Yarn上部署各种计算框架 YARN的目标就是实现“一个集群多个框架”，即在一个集群上部署一个统一的资源。调度管理框架YARN，在YARN之上可以部署其他各种计算框架 由YARN为这些计算框架提供统一的资源调度管理服务，并且能够根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩。 可以实现一个集群上的不同应用负载混搭，有效提高了集群的利用率。 不同计算框架可以共享底层存储，避免了数据集跨集群移动。 ##Yarn HA： 图：YARN HA方案 Yarn中的ResourceManager负责整个集群的资源管理和任务调度，Yarn高可用性方案通过引入冗余的ResourceManager节点的方式，解决了ResourceManager单点故障问题。 Yarn APPMaster容错机制： 图：Yarn APPMaster容错机制 Yarn的资源管理和任务调度资源管理：当前Yarn支持内存和CPU两种资源类型的管理和分配。 每个NodeManager可分配的内存和CPU的数量可以通过配置选项设置（可在Yarn服务配置页面配置）。 yarn.nodemanager.resource.memory-mb yarn.nodemanager.vmem-pmem-ratio yarn.nodemanager.resource.cpu-vcore 资源分配模型： 图：资源分配模型 调度器维护一群队列的信息、用户可以向一个或多个队列提交应用。 每次NM心跳的时候，调度器根据一定的规则选择一个队列，再在队列上选择一个应用，尝试在这个应用上分配资源。 调度器会优先匹配本地资源的申请请求，其次是同机架的，最后是任意机器的。 容量调度器：容量调度器的介绍：容量调度器使得Hadoop应用能够共享的、多用户的、操作简便的运行在集群上，同时最大化集群的吞吐量和利用率。 容量调度器以队列为单位划分资源，每个队列都有资源使用的下限和上限。每个用户可以设定资源使用上限。管理员可以约束单个队列、用户或者作业的资源使用、支持作业优先级，但不支持抢占。 容量调度器的特点： 容量保证：管理员可为每个队列设置资源最低保证和资源使用上限，所有提交到该队列的应用程序共享这些资源。 灵活性：如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，当该队列有新的应用程序提交，则其他队列释放的资源会归还给该队列。 支持优先级：队列支持任务优先级调度（默认是FIFO）。 多重租赁：支持多用户共享集群和多应用程序同时运行。为防止单个应用程序、用户或者队列独占集群资源，管理员可以为之增加多重约束。 动态更新配置参数：管理员可以根据需要动态修改配置参数，以实现在线集群管理。 容量调度器的任务选择：调度时，首先按照以下策略选择一个合适队列： 资源利用最低的队列优先，比如同级的两个队列Q1和Q2，它们的容量均为30，而Q1已经使用10，Q2已使用12，则会优先将资源分配给Q1. 最小队列层级优先。例如：QueueA与QueueB.childQueueB，则QueueA优先。 资源回收请求队列优先。 然后按以下策略选择该任务中一个任务： 按照任务优先级和提交时间顺序选择，同时考虑用户资源量限制和内存限制。 队列资源限制：队列的创建是在多租户页面，当创建一个租户关联Yarn服务时，会创建同名的队列。比如先创建QueueA，QueueB两个租户即对应Yarn两个队列。 队列的资源容量（百分比）： 例如，有default，QueueA，QueueB三个队列，每个队列都有一个[队列名].capacity配置。 Default队列容量为整个集群资源的20%。 QueueA队列容量为整个集群资源的10%。 QueueB队列容量为整个集群资源的10%，后台有个影子队列root-default使队列之和达到100%。 共享空闲资源： 由于存在资源共享，因此一个队列使用的资源可能超过其容量，而最多使用资源量可通过该参数限制。 如果某个队列任务较少，可将剩余资源共享给其他队列。例如QueueA的maximum-capacity配置为100，假设当前只有QueueA在运行任务，理论上QueueA可以占用整个集群100%的资源。 用户限制：每个用户最低资源保障（百分比） 任何时刻，一个队列中每个用户可使用的资源量均由一定的限制，当一个队列中同时运行多个用户的任务时，每个用户的可使用资源量在一个最小值与最大值之间浮动，其中，最大值取决于正在运行的任务数据，而最小值则由minimum-user-limit-percent决定。 例如：设置队列A的这个值为25，即yarn.scheduler.capacity.root.AueueA.minimum-user-limit-percent=25，那么随着任务的用户增加，队列资源的调整如下： 每个用户最多可使用的资源量（所在队列容量的倍数） queue容量的倍数，用来设置一个user可以获取更多的资源。yarn.scheduler.capacity.root.QueueD.user-limit-factor=1.默认值为1，表示一个user获取的资源容量不能超过queue配置的capacity，无论集群有多少空闲字眼，最多不超过maximum-capacity。 任务限制： 最大活跃任务数：整个集群中允许的最大活跃任务数，包括运行或挂起状态的所有任务，当提交的任务申请数据达到限制以后，新提交的任务将会被拒绝。默认10000。yarn.scheduler.capacity.maximum-applications=10000. 每个队列最大任务数：对于每个队列，可以提交的最大任务数，以QueueA为例，可以在队列配置页面配置，默认是1000，即此队列允许最多1000个活跃任务。 每个用户可以提交的最大任务数：这个数值依赖每个队列最大任务数。假设根据上面的结果，QueueA最多可以提交1000个任务，那么对于每个用户而言，可以向QueueA提交的最大任务数为：1000 yarn.scheduler.capacity.root.QueueA.minimum-user-limit-percent yarn.scheduler.capacity.root.QueueA.user-limit-factor. Yarn的增强特性Yarn动态内存管理： 图：Yarn动态内存管理 Yarn基于标签调度： 图：Yarn基于标签调度 常用维护命令 常用性能调优参数：]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce技术原理]]></title>
    <url>%2F2018%2F05%2F11%2FMapReduce%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[MapReduce基本介绍MapReduce基本定义：MapReduce是面向大数据并行处理的计算模型、框架和平台。 它包含以下三层含义： MapReduce是一个基于集群的高性能并行计算平台（Cluster Infrastructure）。 MapReduce是一个并行计算与运行软件框架（Software Framework）。 MapReduce是一个并行程序设计模型与方法（Programming Model &amp; Methodology）。 MapReduce模型简介： MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数：Map和Reduce。 编程容易，不需要掌握分布式并行编程细节，也可以很容易把自己的程序运行在分布式系统上，完成海量数据的计算。 MapReduce采用“分而治之”策略，一个存储在分布式文件系统中的大规模数据集，会被切分成许多独立的分片（split），这些分片可以被多个Map任务并行处理。 MapReduce设计的一个理念就是“计算向数据靠拢”，而不是“数据向计算靠拢”，因为，移动数据需要大量的网络传输开销。 MapReduce框架采用了Master/Slave架构，包括一个Master和若干个Slave。Master上运行JobTracker，Slave上运行TaskTracker。 Hadoop框架是用Java实现的，但是，MapReduce应用程序则不一定要用Java来写。 MadReduce的特点：MapReduce基于Google发布的并行计算框架。MapReduce论文设计开发，用于大规模数据集（大于1TB）的并行计算，具有如下特点： 易于编程：程序员仅需描述做什么，具体怎么做由系统的执行框架处理。 良好的扩展性：可通过添加结点以扩展集群能力。 高容错性：通过计算迁移或数据迁移等策略提高集群的可用性与容错性。 MapReduce与传统并行计算框架的对比： 传统并行计算框架 MapReduce 集群架构/容错性 共享式（共享内存、共享存储），容错性差 非共享式，容错性好 硬件/价格/扩展性 刀片服务器、高速网、SAN，价格贵，扩展性差 普通PC机，便宜，扩展性好 编程/学习难度 what-how，难 what，简单 实时、细粒度计算、计算密集型 批处理、非实时、数据密集型 Map和Reduce函数： MapReduce的体系结构MapReduce的体系结构构成：MapReduce体系结构主要由四个部分组成，分别是：Client、JobTracker、TaskTracker以及Task。 图：MapReduce的体系结构 MapReduce主要有以下4个部分组成： （1）Client: 用户编写的MapReduce程序通过Client提交到JobTracker端。 用户可通过Client提供的一些接口查看作业运行状态。 （2）JobTracker: JobTracker负责资源监控和作业调度。 JobTracker 监控所有TaskTracker与Job的健康状况，一旦发现失败，就将相应的任务转移到其他节点。 JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源。 （3）TaskTracker： TaskTracker 会周期性地通过“心跳”将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接收JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）。 TaskTracker 使用“slot”等量划分本节点上的资源量（CPU、内存等）。一个Task 获取到一个slot 后才有机会运行，而Hadoop调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。slot 分为Map slot 和Reduce slot 两种，分别供MapTask 和Reduce Task 使用。 （4）Task： Task 分为Map Task 和Reduce Task 两种，均由TaskTracker 启动。 MapReduce工作流程工作流程概述： 图：MapReduce工作流程图 不同的Map任务之间不会进行通信。 不同的Reduce任务之间也不会发生任何信息交换。 用户不能显式地从一台机器向另一台机器发送消息。 所有的数据交换都是通过MapReduce框架自身去实现的。 MapReduce各个执行阶段： 图：MapReduce各个执行阶段 Split（分片）： 图:分片 HDFS 以固定大小(默认为128MB)的block 为基本单位存储数据，而对于MapReduce 而言，其处理单位是split。split 是一个逻辑概念，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定。 Map任务的数量： Hadoop为每个split创建一个Map任务，split 的多少决定了Map任务的数目。大多数情况下，理想的分片大小是一个HDFS块。 Reduce任务的数量： 最优的Reduce任务个数取决于集群中可用的reduce任务槽(slot)的数目。通常设置比reduce任务槽数目稍微小一些的Reduce任务个数（这样可以预留一些系统资源处理可能发生的错误）。 Shuffle过程详解： 图：Shuffle过程 Map端的Shuffle过程： 图：Map端的Shuffle过程 每个Map任务分配一个缓存. MapReduce默认100MB缓存. 设置溢写比例0.8。 分区默认采用哈希函数。 排序是默认的操作。 排序后可以合并（Combine）。 合并不能改变最终结果。 在Map任务全部结束之前进行归并。 归并得到一个大的文件，放在本地磁盘。 文件归并时，如果溢写文件数量大于预定值（默认是3）则可以再次启动Combiner，少于3不需要。 JobTracker会一直监测Map任务的执行，并通知Reduce任务来领取数据。 合并（Combine）和归并（Merge）的区别： 两个键值对&lt;“a”,1&gt;和&lt;“a”,1&gt;，如果合并，会得到&lt;“a”,2&gt;，如果归并，会得到&lt;“a”,&lt;1,1&gt;&gt; Reduce端的shuffle过程： 图：Reduce端的shuffle过程 Reduce任务通过RPC向JobTracker询问Map任务是否已经完成，若完成，则领取数据。 Reduce领取数据先放入缓存，来自不同Map机器，先归并，再合并，写入磁盘。 多个溢写文件归并成一个或多个大文件，文件中的键值对是排序的。 当数据很少时，不需要溢写到磁盘，直接在缓存中归并，然后输出给Reduce。 MapReduce应用程序执行过程： 图：MapReduce程序执行过程 MapRduce过程详解：]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS技术原理]]></title>
    <url>%2F2018%2F05%2F10%2FHDFS%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[HDFS概述及应用场景HDFS概述：HDFS(Hadoop Distributed File System)基于Google发布的GFS论文设计开发，运行在通用硬件平台上的分布式文件系统。 其除具有其他分布式文件系统的相同特性外，还有自己特有的特性： 高容错性：认为硬件总是不可靠的。 高吞吐量：为大量数据访问的应用提供高可用吞吐量支持。 大文件存储：支持存储TB-PB级别的数据。 HDFS适合做：大文件存储、流式数据访问。 HDFS不适合做：大量小文件、随机写入、低延迟读取。 HDFS应用场景举例：HDFS是Hadoop技术框架中的分布式文件系统，对部署在多台独立物理机器上的文件进行管理。 可应用与以下几种场景： 网站用户行为数据存储。 生态系统数据存储。 气象数据存储。 HDFS在FusionInsight产品的位置： 图：HDFS在FusionInsight产品中的位置 FusionInsight HD 提供大数据处理环境，基于社区开源软件增强，按照场景选择业界最佳实践。 HDFS作为Hadoop的基础存储设施，实现了一个分布式、高容错、可线性扩展的文件系统。 HDFS系统架构系统设计目标：（1）硬件失效： 硬件的异常比软件的异常更加常见。 对于有上百台服务器的数据中心来说，认为总有服务器异常，硬件异常是常态。 HDFS需要监测这些异常，并自动恢复数据。 （2）流式数据访问： 基于HDFS的应用仅采用流式方式读数据。 运行在HDFS上的应用并非以通用业务为目的的应用程序。 应用程序关注的是吞吐量，而非响应时间。 非POSIX标准接口的数据访问。 （3）存储数据大： 运行在HDFS的应用程序有较大的数据需要处理。 典型的文件大小为GP到TB级别。 （4）数据一致性: 应用程序采用WORM（Write Once Read Many）的数据读写模型。 文件仅支持追加，而不允许修改。 （5）多硬件平台： HDFS可运行在不同的硬件平台上。 （6）移动计算能力： 计算和存储能力采用就近原则，计算离数据最近。 就近原则将有效减少网络的负载，降低网络拥塞。 基本系统架构： 图：HDFS系统架构图 HDFS架构包含三个部分：（NameNode，DateNode，Client） NameDode：用于存储、生成文件系统的元数据、运行一个实例。 DateNode：用于存储实际的数据，将自己管理的数据块上报给NameNode，运行多个实例。 Client：支持业务访问HDFS，从NameNode，DateNode获取数据返回给业务。多个实例，和业务一起运行。 HDFS数据写入流程： 图：HDFS数据写入流程图 HDFS数据写入流程如下： 业务应用调用HDFS Client提供的API创建文件，请求写入。 HDFS Client联系NameNode，NameNode在元数据中创建文件节点。 业务应用调用write API写入文件。 HDFS Client收到业务数据后，从NameNode获取到数据块编号、位置信息后，联系DateNode，并将要写入数据的DateNode建立起流水线。完成后，客户端再通过自有协议写入数据到DateNode1，再由DateNode1复制到NateNode2，DateNode3. 写完的数据，将返回确认信息给HDFS Client。 所有数据确认完成后，业务调用HDFS CLient关闭文件。 业务调用close，flush后HDFS Client联系NameNode，确认数据写完成，NameNode持久化元数据。 HDFS数据读取流程： 图：HDFS数据读取流程图 HDFS数据读取流程如下： 业务调用HDFS Client提供的API打开文件。 HDFS Client 联系 NmaeNode，获取到文件信息（数据块、DateNode位置信息）。 业务应用调用read API读取文件。 HDFS Client根据从NmaeNode获取到的信息，联系DateNode，获取相应的数据块。（Client采用就近原则读取数据）。 HDFS Client会与多个DateNode通讯获取数据块。 数据读取完成后，业务调用close关闭连接。 HDFS关键特性介绍HDFS架构关键设计： 图：HDFS架构关键设计 元数据持久化： 图：元数据持久化流程图 元数据持久化流程如下： 备NmaeNode通知主NameNode生成新的日志文件，以后的日志写到Editlog.new中，并获取旧的Editlog。 备NameNode从注NameNode上获取FSImage文件及位于JournalNode上面的旧Editlog。 备NmaeNode将日志和旧的元数据合并，生成新的元数据FSImage.ckpt。 备NameNode将元数据上传到主NameNode。 主NameNode将上传的原书记进行回滚。 循环步骤1. 元数据持久化健壮机制：HDFS主要目的是保证存储数据完整性，对于各组件的失效，做了可靠性处理。 重建失效数据盘的副本数据 DateNode向NmaeNode周期上报失败时，NmaeNode发起副本重建动作以恢复丢失副本。 集群数据均衡 HDFS架构设计了数据均衡机制，此机制保证数据在各个DateNode上分布式平均的。 数据有效性保证 DateNode数据在读取时校验失败，则从其他数据节点读取数据。 元数据可靠性保证 采用日志机制操作元数据，同时元数据存放在主备NameNode上。 快照机制实现了文件系统常见的快照机制，保证数据误操作时，能及时恢复。 安全模式 HDFS提供独有的安全模式机制，在数据节点故障时，能防止故障扩散。 HDFS高可靠性(HA)： 图；HDFS高可靠性原理 HA解决的是一个热备份的问题。 HDFS的高可靠性（HA）架构在基本架构上增加了一下组件： ZooKeeper：分布式协调，主要用来存储HA下的状态文件，主备信息、ZK个数建议3个及以上且为奇数个。 NmaeNode主备：NmaeNode主备模式，主提供服务，备合并元数据并作为主的热备。 ZKFC（Zookeeper Failover Controller）用于控制NmaeNode节点的主备状态。 JN（JournalNode）日志节点：用于共享存储NmaeNode生成的Editlog。 图：HA原理 处于待命状态的名称节点和处于活状态的名称节点，它们元数据的两个方面的信息是怎么同步的： 处于待命状态的名称节点当中，它的两方面元数据，一个就是Editlog，它是通过共享存储系统来获得同步的，处于活跃状态的名称节点已发生变化，马上写入到共享存储系统，然后这共享存储系统会通知待命的名称节点把它取走，这样可以保证Editlog上两者可以保持同步。对于映射表信息而言，也就是一个文件包含几个块，这些块被保存到哪个数据节点上面。这种映射信息，它的 实时的维护是通过底层数据节点，不断同时向活跃名称节点和待命节点名称节点汇报来进行维护的。这就是它的基本原理。 HDFS联邦（Federation）： 图；HDFS联邦 HDFS Federation主要能够解决，单名称节点中存在的以下问题： HDFS集群的扩展性问题。 有了多个名称节点，每个名称节点都可以各自的去管理一部分目录。管理自己对应的子命名空间的子目录，这样就可以让一个集群扩展到更多节点。 在HDFS1.0中会受到内存的限制，制约文件存储数目等限制。一个名称节点存储的文件数目是有限的。 性能更高效 多个名称节点各自都管理它不同的数据，而且可以同时对外服务，所以可以提供更高的数据的吞吐率。 良好的隔离性 因为它已经根据不同业务数据要求，进行了子空间的划分，某种业务数据可能归某个名称节点管理，另外一种业务数据属于另外一个命名空间，归另外一个名称节点管理。所以不同数据都分给不同名称节点去管理，这样就可以有效地对不同应用程序进行隔离。不会导致一个应用程序消耗过多资源，而影响另外一个应用程序运行的问题。 HDFS不能解决单点故障问题。 数据副本机制： 图：数据副本机制 副本距离计算公式： Distance（Rack1/D1,Rack1/D1）= 0 ,同一台服务器的距离为0. Distance (Rack1/D1, Rack1/D3) = 2;同一机架不同的服务器距离为2. DIstance（Rack1/D1, Rack2/D1）= 4 ；不同机架的服务器距离为4. 副本放置策略： 第一个副本在本地机器。 第二个副本在远端机架的节点。 第三个副本看之前连个副本是否在同一机架，如果是则选择其他机架，否则选择和第一个副本相同机架的不同节点。 第四个及以上，随机选择副本存放位置。 配置HDFS数据存储策略：默认情况下，HDFS NmaeNode自动选择DateNode保存数据的副本。在实际义务中，存在以下场景： DateNode上存在的不同存储设备，数据需要选择一个合适的设备分级存储数据。 DateNode不同目录中的数据重要程度不同，数据需要根据目录标签选择一个格式的DateNode节点保存。 DateNode集群使用了异构服务器，关键数据需要保存在具有高度可靠性的节点组中。 配置DateNode使用分级存储： HDFS的分级存储框架提供了RAM_DISK(内存盘)、DISK（机械硬盘）、ARCHIVE（高密度低成本存储介质）、SSD（固态硬盘）四种存储类型的存储设备。 通过对四种存储类型进行合理组合，即可形成使用与不公场景的存储策略。 配置标签存储策略： 图；标签存储策略 配置DateNode使用标签存储： 用户通过数据特征灵活配置HDFS数据块存放策略，即为一个HDFS目录设置一个标签表达式，每个DateNode可以对应一个或多个标签；当基于标签的数据块存放策略为指定目录下的文件选择DateNode节点进行存放时，根据文件的标签表达式选择出将要存放的DateNode节点范围，然后在这个DateNode节点范围内，遵守下一个指定的数据块存放策略进行存放。 配置DateNode使用节点组存储： 图：节点组存储 配置DateNode使用节点组存储： 关键数据根据实际业务需要保存在具有高度可靠性的节点中，此时DateNode组成了异构集群。通过修改DateNode的存储策略，系统可以将数据强制保存在指定的节点组中。 使用约束： 第一份副本将从强制机架组（机架组2）中选出，如果在强制机架组中没用可用节点，则写入失败。 第二份副本将从本地客户端机器或机架组中的随机节点（当客户端机架组不为强制机架组时）选出。 第三份副本将从其他机架组中选出。 各副本应放在不同的机架组中。如果所需副本的数量大于可用的机架组数量，则会将多出的副本存放在随机机架组中。 Colocation同分布：同分布（Colocation）的定义：将存在关联关系的数据或可能要进行关联操作的数据存储在相同的存储节点上。 按照下图存放，假设要将文件A和文件D进行关联操作，此时不可避免地要进行大量的数据搬迁，整个集群将由于数据传输占用大量网络带宽，严重影响大数据的处理速度与系统性能。 HDFS文件同分布的特性，将那些需要进行关联操作的文件存放在相同的数据节点上，在进行关联操作计算是避免了到其他数据节点上获取数据，大大降低了网络带宽的占用。 使用同分布特性，文件A、D进行join时，由于其对应的block都在相同的节点，因此大大降低了资源消耗。如下图： 图：Colocation同分布效果图 HDFS架构其他关键设计要点说明： 统一的文件系统： HDFS对外仅呈现一个统一的文件系统。 统一的通讯协议： 统一采用RPC方式通信、NmaeNode被动的接收Client，DateNode的RPC请求。 空间回收机制： 支持回收站机制，以及副本数的动态设置机制。 数据组织： 数据存储以数据块为单位，存储在操作系统的HDFS文件系统上。 访问方式： 提供Java API，http，shell方式访问HDFS数据。 常用的shell命令： HDFS主要组件的功能NameNode和DateNode的对比： NameNode DateNode 存储文件内容 文件内容保存在磁盘 保存文件，block，DateNode之间的映射关系 维护了block id到datenode本地文件的映射关系。 名称节点的数据结构： 在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即FsImage和EditLog FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据 操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作 名称节点记录了每个文件中各个块所在的数据节点的位置信息 图：名称节点的数据结构 FsImage文件：FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据. FsImage文件没有记录块存储在哪个数据节点。而是由名称节点把这些映射保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的。 名称节点的启动： 在名称节点启动的时候，它会将FsImage文件中的内容加载到内存中，之后再执行EditLog文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。 一旦在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件。 名称节点起来之后，HDFS中的更新操作会重新写到EditLog文件中，因为FsImage文件一般都很大（GB级别的很常见），如果所有的更新操作都往FsImage文件中添加，这样会导致系统运行的十分缓慢，但是，如果往EditLog文件里面写就不会这样，因为EditLog 要小很多。每次执行写操作之后，且在向客户端发送成功代码之前，edits文件都需要同步更新。 名称节点运行期间Editlog不断变大的问题： 在名称节点运行期间，HDFS的所有更新操作都是直接写到EditLog中，久而久之， EditLog文件将会变得很大。 虽然这对名称节点运行时候是没有什么明显影响的，但是，当名称节点重启的时候，名称节点需要先将FsImage里面的所有内容映像到内存中，然后再一条一条地执行EditLog中的记录，当EditLog文件非常大的时候，会导致名称节点启动操作非常慢，而在这段时间内HDFS系统处于安全模式，一直无法对外提供写操作，影响了用户的使用。 如何解决？答案是：SecondaryNameNode第二名称节点 第二名称节点是HDFS架构中的一个组成部分，它是用来保存名称节点中对HDFS 元数据信息的备份，并减少名称节点重启的时间。SecondaryNameNode一般是单独运行在一台机器上。 SecondaryNameNode的工作情况：（1）SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件edit.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别；（2）SecondaryNameNode通过HTTP GET方式从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下；（3）SecondaryNameNode将下载下来的FsImage载入到内存，然后一条一条地执行EditLog文件中的各项更新操作，使得内存中的FsImage保持最新；这个过程就是EditLog和FsImage文件合并；（4）SecondaryNameNode执行完（3）操作之后，会通过post方式将新的FsImage文件发送到NameNode节点上（5）NameNode将从SecondaryNameNode接收到的新的FsImage替换旧的FsImage文件，同时将edit.new替换EditLog文件，通过这个过程EditLog就变小了。 数据节点： 数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客户端或者是名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的块的列表。 每个数据节点中的数据会被保存在各自节点的本地Linux文件系统中。 HDFS体系结构HDFS体系结构概述：HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点（NameNode）和若干个数据节点（DataNode）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地Linux文件系统中的。 HDFS命名空间管理： HDFS的命名空间包含目录、文件和块。 在HDFS1.0体系结构中，在整个HDFS集群中只有一个命名空间，并且只有唯一一个名称节点，该节点负责对这个命名空间进行管理。 HDFS使用的是传统的分级文件体系，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录间转移文件，重命名文件等。 通信协议： HDFS是一个部署在集群上的分布式文件系统，因此，很多数据需要通过网络进行传输。 所有的HDFS通信协议都是构建在TCP/IP协议基础之上的。 客户端通过一个可配置的端口向名称节点主动发起TCP连接，并使用客户端协议与名称节点进行交互。 名称节点和数据节点之间则使用数据节点协议进行交互。 客户端与数据节点的交互是通过RPC（Remote Procedure Call）来实现的。在设计上，名称节点不会主动发起RPC，而是响应来自客户端和数据节点的RPC请求。 客户端： 客户端是用户操作HDFS最常用的方式，HDFS在部署时都提供了客户端。 HDFS客户端是一个库，暴露了HDFS文件系统接口，这些接口隐藏了HDFS实现中的大部分复杂性。 严格来说，客户端并不算是HDFS的一部分。 客户端可以支持打开、读取、写入等常见的操作，并且提供了类似Shell的命令行方式来访问HDFS中的数据。 此外，HDFS也提供了Java API，作为应用程序访问文件系统的客户端编程接口。 HDFS体系结构的局限性：HDFS只设置唯一一个名称节点，这样做虽然大大简化了系统设计，但也带来了一些明显的局限性，具体如下： 命名空间的限制：名称节点是保存在内存中的，因此，名称节点能够容纳的对象（文件、块）的个数会受到内存空间大小的限制。 性能的瓶颈：整个分布式文件系统的吞吐量，受限于单个名称节点的吞吐量。 隔离问题：由于集群中只有一个名称节点，只有一个命名空间，因此，无法对不同应用程序进行隔离。 集群的可用性：一旦这个唯一的名称节点发生故障，会导致整个集群变得不可用。 HDFS常用参数配置 HDFS常用维护命令]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用JavaAPI详解]]></title>
    <url>%2F2018%2F04%2F30%2F%E5%B8%B8%E7%94%A8JavaAPI%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Java日期与时间的处理Date类：在 JDK 1.1 之前，类 Date 有两个其他的函数。它允许把日期解释为年、月、日、小时、分钟和秒值。它也允许格式化和解析日期字符串。不过，这些函数的 API 不易于实现国际化。从 JDK 1.1开始，应该使用 Calendar 类实现日期和时间字段之间转换，使用 DateFormat 类来格式化和解析日期字符串。Date 中的相应方法已废弃。 在类 Date 所有可以接受或返回年、月、日期、小时、分钟和秒值的方法中，将使用下面的表示形式： 年份 y 由整数 y - 1900 表示。 月份由从 0 至 11 的整数表示；0 是一月、1 是二月等等；因此 11 是十二月。 日期（一月中的某天）按通常方式由整数 1 至 31 表示。 小时由从 0 至 23 的整数表示。因此，从午夜到 1 a.m. 的时间是 0 点，从中午到 1 p.m. 的时间是 12 点。 分钟按通常方式由 0 至 59 的整数表示。 秒由 0 至 61 的整数表示；值 60 和 61 只对闰秒发生，尽管那样，也只用在实际正确跟踪闰秒的 Java 实现中。于按当前引入闰秒的方式，两个闰秒在同一分钟内发生是极不可能的，但此规范遵循 ISO C 的日期和时间约定。 在所有情形中，针对这些目的赋予方法的参数不需要在指定的范围内；例如，可以把日期指定为 1 月 32 日，并把它解释为 2 月 1 日的相同含义。 Calendar类：Calendar 类是一个抽象类，它为特定瞬间与一组诸如 YEAR、MONTH、DAY_OF_MONTH、HOUR 等 日历字段之间的转换提供了一些方法，并为操作日历字段（例如获得下星期的日期）提供了一些方法。瞬间可用毫秒值来表示，它是距历元（即格林威治标准时间 1970 年 1 月 1 日的 00:00:00.000，格里高利历）的偏移量。 该类还为实现包范围外的具体日历系统提供了其他字段和方法。这些字段和方法被定义为 protected。 与其他语言环境敏感类一样，Calendar 提供了一个类方法 getInstance，以获得此类型的一个通用的对象。Calendar 的 getInstance 方法返回一个 Calendar 对象，其日历字段已由当前日期和时间初始化： 12&gt; Calendar rightNow = Calendar.getInstance();&gt; 程序示例：12345678910111213141516171819package 常用JavaAPI;import java.sql.Date;import java.util.Calendar;public class TimeDame &#123; public static void main(String[] args) &#123; long now = System.currentTimeMillis(); System.out.println("now = " + now); Date d1 = new Date(now); System.out.println("d1 = " + d1); Calendar c1 = Calendar.getInstance(); System.out.println("c1 = " + c1.getTime().toString()); &#125;&#125; 时间和日期的基本操作：123456789101112131415161718192021222324252627282930313233343536373839404142package 常用JavaAPI;import java.sql.Date;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Calendar;public class DateDame &#123; public static void main(String[] args) throws ParseException &#123; Date d1 = new Date(System.currentTimeMillis()); Calendar c1 = Calendar.getInstance(); //格式化 SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss"); System.out.println("格式化前的d1 = " + d1.toString()); System.out.println("格式化后的d1 = " + sdf.format(d1)); //String和Date的转换 String date = "2018-04-30"; SimpleDateFormat sdf1 = new SimpleDateFormat("yyyy-MM-dd"); java.util.Date d2 = sdf1.parse(date); System.out.println("Sting转化为Date， d2 = " + d2.toString()); //由Date类型转换为String类型 String s1 = sdf1.format(d2); System.out.println("Date转换为String，s1 = " + s1); //Date和Calendar转换 c1.setTime(d2);//Date转换到Calendar类 c1.getTime();//Calendar转换到Date类 &#125;&#125;//程序执行结果：格式化前的d1 = 2018-04-30格式化后的d1 = 2018-04-30 05:39:00Sting转化为Date， d2 = Mon Apr 30 00:00:00 CST 2018Date转换为String，s1 = 2018-04-30 日期应用小示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package 常用JavaAPI;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.GregorianCalendar;public class Date &#123; public static void main(String[] args) throws ParseException &#123; //程序示例： //设定女朋友的生日，并在提前两个星期的星期六提醒 //1.设定生日，String String birthday = "2018-4-30"; //2.将String类型转换为日期 SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); java.util.Date date = sdf.parse(birthday); //3.对日期进行计算 java.util.Date spec = preapareBirthdayDay(date); //4.将计算后的结果，转换为String类型输出 String s2 = sdf.format(spec); System.out.println(birthday + "提前两周的周六为 : " + s2); &#125; /* * 传入1个日期，计算出该日期的2个星期前的 周六的日期 * @param birthdayDate 传入的日期 * @return 2周前的周六的日期 */ public static java.util.Date preapareBirthdayDay(java.util.Date birthdayDate) &#123; //GregorianCalendar是 Calendar 的一个具体子类， //提供了世界上大多数国家/地区使用的标准日历系统。 //父类声明，创建子类对象 Calendar calendar = new GregorianCalendar(); //接收传入的date日期，转换为Calendar类 calendar.setTime(birthdayDate); calendar.add(Calendar.WEEK_OF_MONTH, -2);//提前两周 //调整为当前日期的周六 calendar.set(Calendar.DAY_OF_WEEK, Calendar.SATURDAY);//调整为当前日期的周六 return calendar.getTime(); &#125;&#125;//程序运行结果：2018-4-30提前两周的周六为 : 2018-04-21 日期计算示例：123456789101112131415161718192021222324252627package 常用JavaAPI;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Calendar;public class Time &#123; public static void main(String[] args) throws ParseException &#123; String s1 = "2018-5-1 "; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); Calendar c1 = Calendar.getInstance(); //计算一个日期加指定天数 c1.set(2018, 5, 1); c1.add(Calendar.DAY_OF_WEEK, 20); System.out.println(c1.getTime()); //计算两日期之差 String s2 = "2018-5-5"; java.util.Date d1 = sdf.parse(s1); java.util.Date d2 = sdf.parse(s2); long diff = d1.getTime() - d2.getTime(); long days = diff / (1000 * 60 * 60 * 24); System.out.println(days); &#125;&#125; 高精度加法： 问题描述 输入两个整数a和b，输出这两个整数的和。a和b都不超过100位。 算法描述 由于a和b都比较大，所以不能直接使用语言中的标准数据类型来存储。对于这种问题，一般使用数组来处理。 定义一个数组A，A[0]用于存储a的个位，A[1]用于存储a的十位，依此类推。同样可以用一个数组B来存储b。 计算c = a + b的时候，首先将A[0]与B[0]相加，如果有进位产生，则把进位（即和的十位数）存入r，把和的个位数存入C[0]，即C[0]等于(A[0]+B[0])%10。然后计算A[1]与B[1]相加，这时还应将低位进上来的值r也加起来，即C[1]应该是A[1]、B[1]和r三个数的和．如果又有进位产生，则仍可将新的进位存入到r中，和的个位存到C[1]中。依此类推，即可求出C的所有位。 最后将C输出即可。 输入格式 输入包括两行，第一行为一个非负整数a，第二行为一个非负整数b。两个整数都不超过100位，两数的最高位都不是0。 输出格式 输出一行，表示a + b的值。 样例输入 201001222010012212345678902010012220100122 样例输出 20100122203011233454668012 源代码： 1234567891011121314151617181920212223242526272829303132333435363738import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;public class 高精度加法 &#123; public static void main(String[] args) throws IOException &#123; BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String s1 = br.readLine(); String s2 = br.readLine(); br.close(); int[] a = new int [100]; int[] b = new int [100]; int len1 = s1.length(); int len2 = s2.length(); for(int i = 0; i &lt; len1; i++) //Character.getNumericValue(s1.charAt(i)) //返回指点字符的int值。 a[len1-1-i] = Character.getNumericValue(s1.charAt(i)); for(int i = 0; i &lt; len2; i++) b[len2-1-i] = Character.getNumericValue(s2.charAt(i)); int max = len1 &gt; len2 ? len1 : len2; int[] c = new int[max+1]; int r = 0; for(int i = 0; i &lt; max; i++) &#123; c[i] = a[i] + b[i] + r; r = 0; //回溯，r归0 if(c[i] &gt; 9) &#123; r = c[i] / 10; c[i] = c[i] % 10; &#125; &#125; for(int i = max-1; i&gt;=0; i--) &#123; System.out.print(c[i]); &#125; &#125;&#125; Huffuman树： 问题描述 Huffman树在编码中有着广泛的应用。在这里，我们只关心Huffman树的构造过程。 给出一列数{pi}={p0, p1, …, pn-1}，用这列数构造Huffman树的过程如下： 1. 找到{pi}中最小的两个数，设为pa和pb，将pa和pb从{pi}中删除掉，然后将它们的和加入到{pi}中。这个过程的费用记为pa + pb。 2. 重复步骤1，直到{pi}中只剩下一个数。 在上面的操作过程中，把所有的费用相加，就得到了构造Huffman树的总费用。 本题任务：对于给定的一个数列，现在请你求出用该数列构造Huffman树的总费用。 例如，对于数列{pi}={5, 3, 8, 2, 9}，Huffman树的构造过程如下： 1. 找到{5, 3, 8, 2, 9}中最小的两个数，分别是2和3，从{pi}中删除它们并将和5加入，得到{5, 8, 9, 5}，费用为5。 2. 找到{5, 8, 9, 5}中最小的两个数，分别是5和5，从{pi}中删除它们并将和10加入，得到{8, 9, 10}，费用为10。 3. 找到{8, 9, 10}中最小的两个数，分别是8和9，从{pi}中删除它们并将和17加入，得到{10, 17}，费用为17。 4. 找到{10, 17}中最小的两个数，分别是10和17，从{pi}中删除它们并将和27加入，得到{27}，费用为27。 5. 现在，数列中只剩下一个数27，构造过程结束，总费用为5+10+17+27=59。 输入格式 输入的第一行包含一个正整数n（n&lt;=100）。 接下来是n个正整数，表示p0, p1, …, pn-1，每个数不超过1000。 输出格式 输出用这些数构造Huffman树的总费用。 样例输入 55 3 8 2 9 样例输出 59 源代码： 123456789101112131415161718192021import java.util.Arrays;import java.util.Scanner;public class Huffuman树 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int [] pi = new int[n]; for(int i = 0; i &lt; n; i++) pi[i] = sc.nextInt(); int sum = 0, num = 0; for(int i = 0; i &lt; n-1; i++) &#123; Arrays.sort(pi); num = pi[i] + pi[i+1]; pi[i+1] = num; sum += num; &#125; System.out.println(sum); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java编程</tag>
        <tag>Java笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防火墙双机热备技术]]></title>
    <url>%2F2018%2F04%2F27%2F%E9%98%B2%E7%81%AB%E5%A2%99%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[双机热备技术原理双机热备技术产生的原因：传统组网中，只有一台防火墙部署在出口，当防火墙出现故障后，内部网络中所有以防火墙作为默认网关的主机与外部网络之间的通讯中断，通讯可靠性无法保证。 双机热备份技术的出现改变了可靠性难以保证的尴尬状态，通过在网络出口位置部署两台或多台网关设备，保证了内部网络于外部网络之间的通讯畅通。 USG防火墙作为安全设备，一般会部署在需要保护的网络和不受保护的网络之间，即位于业务接口点上。在这种业务点上，如果仅仅使用一台USG防火墙设备，无论其可靠性多高，系统都可能会承受因为单点故障而导致网络中断的风险。为了防止一台设备出现意外故障而导致网络业务中断，可以采用两台防火墙形成双机备份。 双机热备在路由器上部署： 图：路由器组网中通过VRRP协议实现双机热备份 为了避免路由器传统组网所引起的单点故障的发生，通常情况可以采用多条链路的保护机制，依靠动态路由协议进行链路切换。但这种路由协议来进行切换保护的方式存在一定的局限性，当不能使用动态路由协议时，仍然会导致链路中断的问题，因此推出了另一种保护机制VRRP（虚拟路由冗余协议）来进行。采用VRRP的链路保护机制比依赖动态路由协议的广播报文来进行链路切换的时间更短，同时弥补了不能使用动态路由情况下的链路保护。 VRRP（Virtual Router Redundancy Protocol）是一种基本的容错协议。 备份组：同一个广播域的一组路由器组织成一个虚拟路由器，备份组中的所有路由器一起，共同提供一个虚拟IP地址，作为内部网络的网关地址。 主（Master）路由器：在同一个备份组中的多个路由器中，只有一台处于活动状态，只有主路由器能转发以虚拟IP地址作为下一跳的报文。 备份（Backup）路由器：在同一个备份组中的多个路由器中，除主路由器外，其他路由器均为备份路由器，处于备份状态。 主路由器通过组播方式定期向备份路由器发送通告报文（HELLO），备份路由器则负责监听通告报文，以此来确定其状态。由于VRRP HELLO报文为组播报文，所以要求备份组中的各路由器通过二层设备相连，即启用VRRP时上下行设备必须具有二层交换功能，否则备份路由器无法收到主路由器发送的HELLO报文。如果组网条件不满足，则不能使用VRRP。 VRRP在多区域防火墙组网中的应用： 图：VRRP在多区域防火墙组网中的应用 当防火墙上多个区域需要提供双机备份功能时，需要在一台防火墙上配置多个VRRP备份组。 由于USG防火墙是状态防火墙，它要求报文的来回路径通过同一台防火墙。为了满足这个限制条件，就要求在同一台防火墙上的所有VRRP备份组状态保持一致，即需要保证在主防火墙上所有VRRP备份组都是主状态，这样所有报文都将从此防火墙上通过，而另外一台防火墙则充当备份设备。 VRRP在防火墙应用中存在的缺陷： 传统VRRP方式无法实现主、备份防火墙状态的一致性。 如图所示，假设USG A和USG B的VRRP状态一致，即USG A的所有接口均为主用状态，USG B的所有接口均为备用状态。 此时，Trust区域的PC1访问Untrust区域的PC2，报文的转发路线为(1)-(2)-(3)-(4)。USG A转发访问报文时，动态生成会话表项。当PC2的返回报文经过(4)-(3)到达USG A时，由于能够命中会话表项，才能再经过(2)-(1)到达PC1，顺利返回。同理，当PC2和DMZ区域的Server也能互访。 假设USG A和USG B的VRRP状态不一致，例如，当USG B与Trust区域相连的接口为备用状态，但与Untrust区域的接口为主用状态，则PC1的报文通过USG A设备到达PC2后，在USG A上动态生成会话表项。PC2的返回报文通过路线(4)-(9)返回。此时由于USG B上没有相应数据流的会话表项，在没有其他报文过滤规则允许通过的情况下，USG B将丢弃该报文，导致会话中断。 问题产生的原因：报文的转发机制不同。 路由器：每个报文都会查路由表当匹配上后才进行转发，当链路切换后，后续报文不会受到影响，继续进行转发。 状态检测防火墙：如果首包允许通过会建立一条五元组的会话连接，只有命中该会话表项的后续报文（包括返回报文）才能够通过防火墙；如果链路切换后，后续报文找不到正确的表项，会导致业务中断。 注意：当路由器配置NAT后也会存在同样的问题，因为在进行NAT后会形成一个NAT转换后的表项。 VRRP用于防火墙多区域备份：VRRP在防火墙中应用的要求： VRRP状态的一致性。 会话表状态备份 VGMP提出VRRP管理组的概念，将同一台防火墙上的多个VRRP备份组都加入到一个VRRP管理组，由管理组统一管理所有VRRP备份组。通过统一控制各VRRP备份组状态的切换，来保证管理组内的所有VRRP备份组状态都是一致的。 VGMP基础VFMP基本原理： 图：VGMP 当防火墙上的VGMP为Master状态时，组内所有VRRP备份组的状态统一为Master状态，所有报文都将从该防火墙上通过，该防火墙成为主用防火墙。此时另外一台防火墙上对应的VGMP为备状态，该防火墙成为备用防火墙。 通过指定VGMP组的优先级来决定谁将成为主防火墙或备用防火墙。 VGMP的优先级会根据组内的VRRP备份组成员的状态动态调整，以此完成两台防火墙的主备倒换。 与VRRP类似，状态为Master的VGMP也会定期向对端发送HELLO报文，通知Slave端本身的运行状态（包括优先级、VRRP成员状态等）。与VRRP不同的是，Slave端收到HELLO报文后，会回应一个ACK消息，该消息中也会携带本身的优先级、VRRP成员状态等。 VGMP HELLO报文发送周期缺省为1秒。当Slave端三个HELLO报文周期没有收到对端发送的HELLO报文时，会认为对端出现故障，从而将自己切换到Master状态。 VGMP组管理：状态一致性管理 各备份组的主/备状态变化都需要通知其所属的VGMP管理组，由VGMP管理组决定是否允许VRRP备份组进行主/备状态切换。如果需要切换，则VGMP管理组控制所有的VRRP备份组统一切换。**VRRP备份组加入到管理组后，状态不能自行单独切换。** 抢占管理 VRRP备份组本身具有抢占功能。即当原来出现故障的主设备故障恢复时，其优先级也会恢复，此时可以重新将自己的状态抢占为主。 VGMP管理组的抢占功能和VRRP备份组类似，当管理组中出现故障的备份组故障恢复时，管理组的优先级也将恢复。此时VGMP可以决定是否需要重新抢占称为主设备。 当VRRP备份组加入到VGMP管理组后，备份组上原来的抢占功能将失效，抢占行为发生与否必须由VGMP管理组统一决定。 HRP基本HRP基本概念：HRP（Huawei Redundancy Protocol）华为冗余协议，用来将主防火墙关键配置和连接状态等数据向备份防火墙上同步。 图：HRP在防火墙备份中的应用 ​ 在双机热备组网中，当主防火墙出现故障时，所有流量都将切换到备防火墙。因为USG防火墙是状态防火墙，如果备防火墙上没有原来主防火墙上的会话表等连接状态数据，则切换到备防火墙的流量将无法通过防火墙，造成现有的连接中断，此时用户必须重新发起连接。 ​ HRP模块提供了基础的数据备份机制和传输功能。各个应用模块收集本模块需要备份的数据，提交给HRP模块，HRP模块负责将数据发送到对端防火墙的对应模块，应用模块需要再将HRP模块提交上来的数据进行解析，并加入到防火墙的动态运行数据池中。 备份内容：要备份的连接状态数据包括TCP/UDP的会话表、ServerMap表项、动态黑名单、NO-PAT表项、ARP表项等。 备份方向:防火墙上有状态为主的VGMP管理组，向对端备份。 备份方式：分为三种 批量备份：在两台设备第一次协商完成后，批量备份所有信息 实时备份：在设备运行过程中，新建或者刷新的数据实时备份 配置批量备份需要消耗较多的资源，缺省情况下是关闭的。 备份通道：一般情况下，在两台设备上直连的端口作为备份通道，有时也称为“心跳线”（VGMP也通过该通道进行通信）。 HRP会话快速备份： 首包会话快速备份。 更新报文会话快速备份。 在来回路径不一致的组网中，业务流的来回报文有可能不会从同一个防火墙上经过。为了支持来回路径不一致的组网，防火墙增加了会话快速备份功能。即在首包创建会话时，立即将会话数据打包备份到对端，然后再将报文转发出去，保证了当回应的报文到达对端防火墙时，对端防火墙上已经接收到备份过来的会话数据并加入到会话表中。比如对于TCP三次握手的报文，SYN+ACK报文从另一台设备回来时，由于查不到会话，报文会被丢弃，导致连接建立失败。对于UDP会话，第一个反向报文过来时，在另一台上也会因为查不到会话，需要走包过滤流程，有可能会被丢弃。 通常情况下，对于TCP连接、状态改变的报文命中会话之后立即备份到对端，包括三次握手报文和fin、rst报文；对于UDP会话，快速备份是创建会话之后立即备份到对端，后续报文也进行备份以避免会话信息的老化。]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>组网</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防火墙安全策略]]></title>
    <url>%2F2018%2F04%2F26%2F%E9%98%B2%E7%81%AB%E5%A2%99%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[包过滤技术基础包过滤技术简介：对需要转发的数据包，先获取报头信息，然后和设定的规则进行比较，根据比较的结果对数据包进行转发或丢弃。 实现包过滤的核心技术是访问控制列表。 包过滤作为一种网络安全保护机制，主要用于对网络中各种不同的流量是否转发做一个最基本的控制。 传统的包过滤防火墙对于需要转发的报文，会先获取报文头信息，包括报文的源IP地址、目的IP地址、IP层所承载的上层协议的协议号、源端口号和目的端口号等，然后和预先设定的过滤规则进行匹配，并根据匹配结果对报文采取转发或丢弃处理。 包过滤防火墙的转发机制是逐包匹配包过滤规则并检查，所以转发效率低下。目前防火墙基本使用状态检查机制，将只对一个连接的首包进行包过滤检查，如果这个首包能够通过包过滤规则的检查，并建立会话的话，后续报文将不再继续通过包过滤机制检测，而是直接通过会话表进行转发。 包过滤的基础： 图：包过滤基础-五元素 包过滤能够通过报文的源MAC地址、目的MAC地址、源IP地址、目的IP地址、源端口号、目的端口号、上层协议等信息组合定义网络中的数据流，其中源IP地址、目的IP地址、源端口号、目的端口号、上层协议就是在状态检测防火墙中经常所提到的五无组，也是组成TCP/UDP连接非常重要的五个元素。 防火墙安全策略：定义： 安全策略是按一定规则检查数据流是否可以通过防火墙的基本安全控制机制。 规则的本质是包过滤。 主要应用： 对跨防火墙的网络互访进行控制。 对设备本身的访问进行控制。 防火墙的基本作用是保护特定网络免受“不信任”的网络的攻击，但是同时还必须允许两个网络之间可以进行合法的通信。安全策略的作用就是对通过防火墙的数据流进行检验，符合安全策略的合法数据流才能通过防火墙。 通过防火墙安全策略可以控制内网访问外网的权限、控制内网不同安全级别的子网间的访问权限等。同时也能够对设备本身的访问进行控制，例如限制哪些IP地址可以通过Telnet和Web等方式登录设备，控制网管服务器、NTP服务器等与设备的互访等。 防火墙安全策略的原理：过程： 入数据流经过防火墙 查找防火墙安全策略，判断是否允许下一步操作。 防火墙根据安全策略定义规则对包进行处理。 防护墙安全策略的作用： 根据定义的规则对经过防火墙的流量进行筛选，并根据关键字确定筛选出的流量如何进行下一步操作。 安全策略分类： 域间安全策略 域间安全策略用于控制域间流量的转发（此时称为转发策略），适用于接口加入不同安全区域的场景。域间安全策略按IP地址、时间段和服务（端口或协议类型）、用户等多种方式匹配流量，并对符合条件的流量进行包过滤控制（permit/deny）或高级的UTM应用层检测。域间安全策略也用于控制外界与设备本身的互访（此时称为本地策略），按IP地址、时间段和服务（端口或协议类型）等多种方式匹配流量，并对符合条件的流量进行包过滤控制（permit/deny），允许或拒绝与设备本身的互访。 域内安全策略 缺省情况下域内数据流动不受限制，如果需要进行安全检查可以应用域内安全策略。与域间安全策略一样可以按IP地址、时间段和服务（端口或协议类型）、用户等多种方式匹配流量，然后对流量进行安全检查。例如：市场部和财务部都属于内网所在的安全区域Trust，可以正常互访。但是财务部是企业重要数据所在的部门，需要防止内部员工对服务器、PC等的恶意攻击。所以在域内应用安全策略进行IPS检测，阻断恶意员工的非法访问。 接口包过滤 当接口未加入安全区域的情况下，通过接口包过滤控制接口接收和发送的IP报文，可以按IP地址、时间段和服务（端口或协议类型）等多种方式匹配流量并执行相应动作（permit/deny）。基于MAC地址的包过滤用来控制接口可以接收哪些以太网帧，可以按MAC地址、帧的协议类型和帧的优先级匹配流量并执行相应动作（permit/deny）。硬件包过滤是在特定的二层硬件接口卡上实现的，用来控制接口卡上的接口可以接收哪些流量。硬件包过滤直接通过硬件实现，所以过滤速度更快。 防火墙转发原理防火墙域间转发： 早期包过滤防火墙采取的是“逐包检测”机制，即对设备收到的所有报文都根据包过滤规则每次都进行检查以决定是否对该报文放行。这种机制严重影响了设备转发效率，使包过滤防火墙成为网络中的转发瓶颈。 于是越来越多的防火墙产品采用了“状态检测”机制来进行包过滤。“状态检测”机制以流量为单位来对报文进行检测和转发，即对一条流量的第一个报文进行包过滤规则检查，并将判断结果作为该条流量的“状态”记录下来。对于该流量的后续报文都直接根据这个“状态”来判断是转发还是丢弃，而不会再次检查报文的数据内容。这个“状态”就是我们平常所述的会话表项。这种机制迅速提升了防火墙产品的检测速率和转发效率，已经成为目前主流的包过滤机制。 在防火墙一般是检查IP报文中的五个元素，又称为“五元组”，即源IP地址和目的IP地址，源端口号和目的端口号，协议类型。通过判断IP数据报文报文的五元组，就可以判断一条数据流相同的IP数据报文。 其中TCP协议的数据报文，一般情况下在三次握手阶段除了基于五元组外，还会计算及检查其它字段。三次握手建立成功后，就通过会话表中的五元组对设备收到后续报文进行匹配检测，以确定是否允许此报文通过。 查询和创建会话： 图：创建会话过程 可以看出，对于已经存在会话表的报文的检测过程比没有会话表的报文要短很多。而通常情况下，通过对一条连接的首包进行检测并建立会话后，该条连接的绝大部分报文都不再需要重新检测。这就是状态检测防火墙的“状态检测机制”相对于包过滤防火墙的“逐包检测机制”的改进之处。这种改进使状态检测防火墙在检测和转发效率上有迅速提升。 状态监测机制： 状态监测机制开启状态下，只有首包通过设备才能建立会话表项，后续包直接匹配会话表项进行转发。 状态监测机制关闭状态下，即使首包没有经过设备，后续好只要通过设备也可以生成会话表项。 对于TCP报文 开启状态检测机制时，首包（SYN报文）建立会话表项。对除SYN报文外的其他报文，如果没有对应会话表项（设备没有收到SYN报文或者会话表项已老化），则予以丢弃，也不会建立会话表项。 关闭状态检测机制时，任何格式的报文在没有对应会话表项的情况下，只要通过各项安全机制的检查，都可以为其建立会话表项。 对于UDP报文 UDP是基于无连接的通信，任何UDP格式的报文在没有对应会话表项的情况下，只要通过各项安全机制的检查，都可以为其建立会话表项。 对于ICMP报文 开启状态检测机制时，没有对应会话的ICMP应答报文将被丢弃。 关闭状态检测机制时，没有对应会话的应答报文以首包形式处理 会话表项： 图：会话表项示例 会话是状态检测防火墙的基础，每一个通过防火墙的数据流都会在防火墙上建立一个会话表项，以五元组（源目的IP地址、源目的端口、协议号）为Key值，通过建立动态的会话表提供域间转发数据流更高的安全性。 防火墙安全策略及应用域间安全策略的匹配规则： 域间缺省包过滤 当数据流无法匹配域间安全策略时，会按照域间缺省包过滤规则来转发或丢弃该数据流的报文。 转发策略 转发策略是指控制哪些流量可以经过设备转发的域间安全策略，对域间（除Local域外）转发流量进行安全检查，例如控制哪些Trust域的内网用户可以访问Untrust域的Internet。 本地策略 本地策略是指与Local安全区域有关的域间安全策略，用于控制外界与设备本身的互访。 域间安全策略业务流程： 图：域间安全策略业务流程 报文入站后，将首先匹配会话表，如果命中会话表，将进入后续包处理流程，刷新会话表时间，并直接根据会话表中的出接口，转发数据。 报文入站后，将首先匹配会话表，如果没有命中会话表，将进入首包包处理流程。依次进行黑名单检查，查找路由表，匹配域间安全策略，新建会话表，转发数据。 黑名单的实现原理就是：设备上建立一个黑名单表。对于接收到的报文的源IP地址存在于黑名单中，就将该报文予以丢弃。 黑名单分类： 静态黑名单 管理员可以通过命令行或Web方式手工逐个将IP地址添加到黑名单中。 动态黑名单 转发策略和缺省域间包过滤优先级 转发策略优先于缺省域间包过滤匹配。设备将首先查找域间的转发策略，如果没有找到匹配项将匹配缺省包过滤进行处理。 刷新会话表 刷新会话表主要是刷新会话表老化时间，老化时间决定会话在没有相应的报文匹配的情况下，何时被系统删除。 配置转发策略流程： 图：配置转发策略的流程图 基于IP地址的转发策略配置示例：实验拓扑： 图：实验拓扑图 实验要求：如上图，防火墙的Gi0/0/0口在Trust区域，Gi0/0/01在UNtrust区域，通过配置策略，使得内网中除了PC1:192.168.1.2可以访问服务器，其他主机都不能访问服务器。 配置文件：FW配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960[FW]dis current-configuration 23:45:46 2018/04/26#interface GigabitEthernet0/0/0 ip address 192.168.1.1 255.255.255.0#interface GigabitEthernet0/0/1 ip address 10.1.1.1 255.255.255.0#firewall zone local set priority 100#firewall zone trust set priority 85 add interface GigabitEthernet0/0/0#firewall zone untrust set priority 5 add interface GigabitEthernet0/0/1#firewall zone dmz set priority 50# //配置地址集ip address-set ip_deny type object address 1 192.168.1.3 0 address 2 192.168.1.4 0# sysname FW# firewall packet-filter default permit interzone local trust direction inbound firewall packet-filter default permit interzone local trust direction outbound firewall packet-filter default permit interzone local untrust direction outbound firewall packet-filter default permit interzone local dmz direction outbound## firewall statistic system enable //防火墙状态检测默认开启#//防火墙策略policy interzone trust untrust inbound policy 0 action permit policy destination 192.168.1.2 0 policy 1 action permit policy source 192.168.1.2 0#policy interzone trust untrust outbound policy 0 action deny policy source address-set ip_deny policy 1 action permit policy source 192.168.1.2 0#return 配置成功后测试： 图：PC1可以ping通服务器 图：PC2不能ping通服务器 图：防火墙策略 图：会话表]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>组网</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WLAN组网配置]]></title>
    <url>%2F2018%2F04%2F26%2FWLAN%E7%BB%84%E7%BD%91%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[WLAN配置流程 图：WLAN业务配置流程示意图 WLAN业务的配置流程可以分为5个部分： AC基础配置 配置AC与AP的互通 配置AP的射频 配置AP的服务集 配置VAP，下发WLAN服务 WLAN业务配置示例实验拓扑： 图：WLAN实验拓扑 实验要求：如上图，两个AP需要释放两个信号，huawei-1和huawei-2，分别属于不同的网段。AP采用直接转发模式。同时上网需要认证，采用radius结合dot1x认证。无线终端通过连接无线信号，可以访问外网1.1.1.1。 配置思路： 配置接入交换机、汇聚交换机和AC，实现AP和AC互通 配置AC的基本功能，包括: 配置AC运营商标识和ID。 AC与AP之间通信的源接口，实现AC作为DHCP Server功能配置AP上线的认证方式，并把AP加入AP域中，实现AP正常工作 配置VAP，下发WLAN业务，实现STA访问WLAN网络功能。 其中配置VAP，需要： 配置WLAN-ESS接口，并在服务集下绑定该接口，实现无线侧报文到达AC后能够送至WLAN业务处理模块功能。 配置AP对应的射频模板，并在射频下绑定该模板，实现STA与AP之间的无线通信参数配置。 配置AP对应的服务集，并在服务集下配置数据直接转发模式，绑定安全模板、流量模板，实现STA接入网络安全策略及QoS控制。 配置VAP并下发，实现STA访问WLAN网络功能。 配置文件：AC1配置文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;AC6005&gt;display current-configuration #vlan batch 10 20 100#dhcp enable#radius-server template defaultradius-server template huawei radius-server shared-key cipher %^%#l|h=&gt;d:x$9mh2v:X$&gt;@#~Wq3Wc2/0LTV,79/n&amp;:1%^%# radius-server authentication 192.168.0.1 1812 source ip-address 192.168.0.1 weight 80 radius-server accounting 192.168.0.1 1813 source ip-address 192.168.0.1 weight 80 undo radius-server user-name domain-included#aaa authentication-scheme radius authentication-mode radius authorization-scheme radius accounting-scheme radius accounting-mode radius domain default authentication-scheme radius authorization-scheme radius radius-server huawei domain default_admin local-user admin password irreversible-cipher $1a$gNv(Ja|oy4$l11l;`1&#125;P3/\s&amp;FoRD%520:"C&#125;uAlQ,EN,NZp#dN$#interface Vlanif10 ip address 192.168.10.1 255.255.255.0 dhcp select interface#interface Vlanif20 ip address 192.168.20.1 255.255.255.0 dhcp select interface#interface Vlanif100 ip address 192.168.0.1 255.255.255.0 dhcp select interface#interface GigabitEthernet0/0/1 port link-type trunk port trunk pvid vlan 100 port trunk allow-pass vlan 10 20 100#ip route-static 0.0.0.0 0.0.0.0 192.168.0.4 //配置去网外网的缺省路由#capwap source interface vlanif100//配置AC与AP建立CAPWAP隧道的源接口。#wlan security-profile name sec1 wep default-key 1 ssid-profile name ssid1 ssid huawei-1 //配置当前SSID模板中的服务组合识别码SSID。 ssid-profile name ssid2 ssid hauwei-2 vap-profile name vap1 service-vlan vlan-id 10 //配置VAP的业务VLAN。 ssid-profile ssid1 security-profile sec1 vap-profile name vap2 service-vlan vlan-id 20 ssid-profile ssid2 security-profile name sec1 security wep share-key wep key 1 wep-40 pass-phrase %^%#ivrLDWUr5E[ym)AVIdR=i\5w7A-WXS'owC&gt;$\WK.%^%# wep default-key 1 security-profile name sec2 security wpa-wpa2 dot1x aes//配置dot1x认证 regulatory-domain-profile name domain1 ap-group name group1 regulatory-domain-profile domain1 radio 0 vap-profile vap1 wlan 1 //绑定vap模板 vap-profile vap2 wlan 2 ap-id 0 type-id 69 ap-mac 00e0-fc14-64e0 ap-sn 210235448310DB07065C ap-name ap1 //配置ap的名字 ap-group group1 //划分ap进组 ap-id 1 type-id 69 ap-mac 00e0-fcd4-31d0 ap-sn 210235448310F7580D06 ap-name ap2 ap-group group1#return SW1配置文件：1234567891011121314151617181920212223242526&lt;SW1&gt;dis current-configuration #sysname SW1#vlan batch 10 20 100#interface Vlanif100 ip address 192.168.0.2 255.255.255.0#interface GigabitEthernet0/0/1 port link-type trunk port trunk pvid vlan 100 port trunk allow-pass vlan 10 20 100#interface GigabitEthernet0/0/2 port link-type access port default vlan 100#interface GigabitEthernet0/0/3 port link-type trunk port trunk pvid vlan 100 port trunk allow-pass vlan 10 20 100#ip route-static 0.0.0.0 0.0.0.0 192.168.0.4#return SW2配置文件：123456789101112131415161718192021222324252627[SW2]display current-configuration #sysname SW2#vlan batch 10 20 100#interface Vlanif100 ip address 192.168.0.3 255.255.255.0#interface Ethernet0/0/1 port link-type trunk port trunk pvid vlan 100 port trunk allow-pass vlan 10 20 100#interface Ethernet0/0/2 port link-type trunk port trunk pvid vlan 100 port trunk allow-pass vlan 10 20 100#interface Ethernet0/0/3 port link-type trunk port trunk pvid vlan 100 port trunk allow-pass vlan 10 20 100#ip route-static 0.0.0.0 0.0.0.0 192.168.0.4#return AR1配置文件：1234567891011[Huawei]display current-configuration #interface GigabitEthernet0/0/0 ip address 192.168.0.4 255.255.255.0 #interface LoopBack0 ip address 1.1.1.1 255.255.255.255 #ip route-static 192.168.0.0 255.255.0.0 192.168.0.1#return 配置成功后的状态： 图：配置成功后的状态 配置成功后，两个AP会释放出无限信号。并且无限终端上可以搜索到两个无限信息。同时会进行认证。连接到响应的信号后，会获取相应网段的地址。最后在无线终端上可以顺利访问1.1.1.1。如下图所示： 图：终端状态 图：主机端状态]]></content>
      <categories>
        <category>无线</category>
      </categories>
      <tags>
        <tag>WLAN</tag>
        <tag>组网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WLAN组网介绍]]></title>
    <url>%2F2018%2F04%2F25%2FWLAN%E7%BB%84%E7%BD%91%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[WLAN组网方式介绍胖AP设备的典型组网：家庭网络组网模式： 图：家庭或SOHO网络的组网模式 在家庭或者SOHO中，由于所需要的无线覆盖范围小，一般采用胖AP组网。而胖AP可以不仅实现无线覆盖的要求，还可以同时作为路由器，实现对有线网络的路由转发。 企业网络组网模式： 图：企业网络的组网模式 在企业网络或者其他大型场所中，所需要的无线覆盖范围比较大，若采用胖AP组网，则可以将AP接入到接入交换机端，数据通过交换机的转发，到达企业核心网。在企业核心网也可以架设起网管系统，便于对AP的统一管理。 瘦AP+AC组网方式：根据AP与AC之间的架构可分为：二层组网和三层组网。 根据AC在网络中的位置可分为：直连式组网和旁挂式组网。 无线控制器＋FIT AP控制架构（瘦AP）对设备的功能进行了重新划分，其中无线控制器负责无线网络的接入控制，转发和统计、AP的配置监控、漫游管理、AP的网管代理、安全控制；FIT AP负责802.11报文的加解密、802.11的物理层功能、接受无线控制器的管理、RF空口的统计等简单功能。 二层网络连接模式： 当AP与AC之间的网络为直连或者二层网络时，此组网方式为二层组网。 由于二层组网比较简单，适用于简单临时的组网，能够进行比较快速的组网配置，但不适用于大型组网架构。 三层网络连接模式： 当AP与AC之间的网络为三层网络时，WLAN组网为三层组网。 在实际组网中，一台AC可以连接几十甚至几百台AP，组网一般比较复杂。比如在企业网络中，AP可以布放在办公室，会议室，会客间等场所，而AC可以安放在公司机房，这样，AP和AC之间的网络就是比较复杂的三层网络。因此，在大型组网中一般采用三层组网。 AC部署方式：直连式组网： 直连式组网可以认为AP、AC与上层网络串联在一起，所有数据必须通过AC到达上层网络。 采用这种组网方式，对AC的吞吐量以及处理数据能力比较高，否则AC会是整个无线网络带宽的瓶颈。但用此种组网，组网架构清晰，组网实施起来简单。 旁挂式组网： 旁挂式组网，AC旁挂在AP与上行网络的直连网络中，不再直接连接AP。 由于实际组网中，大部分不是早期就规划好无线网络，无线网络的覆盖架设大部分是后期在现有网络中扩展而来。而采用旁挂式组网就比较容易进行扩展，只需将AC旁挂在现有网络中，比如旁挂在汇聚交换机上，就可以对终端AP进行管理。所以此种组网方式使用率比较高。 在旁挂式组网中，AC只承载对AP的管理功能，管理流封装在CAPWAP隧道中传输。数据业务流可以通过CAPWAP数据隧道经AC转发，也可以不经过AC转发直接转发，后者无线用户业务流经汇聚交换机由汇聚交换机传输至上层网络。 敏捷分步Wi-Fi方案组网：敏捷分布式WLAN组网包括AC+中心AP+RRU，RRU收发无线报文，并二层透传给中心AP进行处理。中心AP通过网线连接RRU，相比于普通AP通过馈线连接天线，网线能够提供更长的部署距离，方便在离中心AP更远的位置部署RRU。 敏捷分布Wi-Fi方案架构通过AC集中管理和控制多个中心AP，每个中心AP集中管理和控制多个RRU。 图： 敏捷分步Wi-Fi方案组网 所有无线接入功能由RRU（Remote Radio Unit）、中心AP和AC共同完成： AC集中处理所有的安全、控制和管理功能，例如移动管理、身份验证、VLAN划分、射频资源管理和数据包转发等。 RRU负责802.11报文的收发，并透传给中心AP，中心AP完成其他功能，例如无线信号发射与探测响应、数据加密解密、数据传输确认等。 中心AP和AC之间以及RRU和中心AP之间都采用CAPWAP协议进行通讯，中心AP与AC间可以跨越二层网络或三层网络，RRU和中心AP之间跨越二层网络。 用户接入无线网络的过程分三步： 中心AP与AC建立CAPWAP隧道。 RRU和中心AP建立CAPWAP隧道。 STA与RRU和中心AP的关联过程。 转发方式介绍数据转发方式：WLAN网络中的数据包括控制消息和数据消息，其中数据消息转发方式包括： 直接转发（又称为“本地转发”） CAPWAP隧道转发（又称为“集中转发”） AC承载管理流和数据业务流，管理流必须封装在CAPWAP（Control And Provisioning of Wireless Access Points）隧道传输，数据流可以根据实际情况选择是否封装在CAPWAP隧道中传输。 CAPWAP定义了无线接入点（AP）与无线控制器（AC）之间的通信规则，为实现AP和AC之间的互通性提供通用封装和传输机制。 CAPWAP数据隧道封装发往AC6605的802.11协议的数据包。 CAPWAP管理隧道提供远程AP配置和WLAN管理。 根据数据流（也称业务流）是否封装在CAPWAP隧道中转发，可以分为两种转发模式： 直接转发：也称本地转发或分布转发。 隧道转发：也称集中转发，通常用于集中控制无线用户流量的场景。 AP与AC间的控制报文必须采用CAPWAP隧道进行转发，而数据报文则除了可以采用CAPWAP隧道转发之外，还可以采用直接转发方式。 当AC为旁挂式组网（即AC的业务接入端口和上行端口为同一个以太网端口）时，如果数据是直接转发，则数据流不经过AC；如果数据是隧道转发模式，则数据流经过AC。 无论直连式组网还是旁挂式组网，都可以根据需要自行选择，AC支持两种模式混合，即根据需要将部分AP配置为直接转发模式，部分AP配置为隧道转发模式。由于隧道转发模式下，所有无线用户流量都将汇聚到AC上处理，存在交换瓶颈的风险，在企业网中不常采用。 直连式组网： 图：直连式组网拓扑 直连式组网是指AC6605下直接接入AP或接入交换机，同时扮演AC和汇聚交换机功能，AP的数据业务和管理业务都由AC6605集中转发和处理。 直连式组网方式中，AP和AC6605之间建立CAPWAP管理隧道，AC通过该CAPWAP管理隧道实现对AP的集中配置和管理。无线用户的业务数据可以通过CAPWAP数据隧道在AP与AC之间转发（隧道转发模式），也可以由AP直接转发（直接转发模式）。 由于直连式组网中，AC自然串接在线路中，故多采用直接转发模式，用户业务数据在AP上实现转发。 AC6605启动DHCP Server功能，给AP分配IP地址，AP通过DNS或DHCP option43的方式或二层发现协议发现AC6605，建立数据业务通道。 直连式组网-直接转发： ###直连式组网-隧道转发： 旁挂式组网： 图：旁挂式组网拓扑 旁挂式组网是指AC6605旁挂在现有网络中（多在汇聚交换机旁边），实现对AP的WLAN业务管理。 在旁挂式组网中，AC6605只承载对AP的管理功能，管理流封装在CAPWAP隧道中传输。数据业务流可以通过CAPWAP数据隧道经AC转发，也可以不经过AC转发直接转发，后者无线用户业务流经汇聚交换机传输至上层网络。 旁挂式组网-直接转发： 直接转发又称为数据本地转发，即AP与AC间的报文没有经过CAPWAP隧道封装，直接转发到上层网络，从而提高报文的转发效率。 直接转发指AP不会对数据报文进行任何处理，发送原始报文。 采用直接转发，可以很容易的突破AC的带宽限制，而且配置CAPWAP断链保持以后，可以减少无线用户断网的风险。 旁挂式组网-隧道转发： 隧道转发又称为集中转发，即AP与AC间的报文经过CAPWAP隧道封装后再转发到上层网络，从而提高报文的转发安全性。 隧道转发，所有数据报文都要经过CAPWAP隧道封装后到达AC，再由AC转发到上层网络。 采用此种数据转发方式，可以大大提高数据的安全性，还可以对数据进行集中控制，比如QoS等。 VLAN在WLAN业务中的应用管理VLAN：管理VLAN主要用来传送AC与AP之间的管理数据。 图；管理VLAN 管理VLAN： 对于二层交换机而言，一般只能设置一个三层虚接口，所以必须设置一个VLAN作为三层虚接口的管理VLAN。管理VLAN中绑定了一个IP地址，这样我们可以远程管理交换机，例如登录交换机查看相应的LOG日志，分析交换机状态，处理某些故障等。 对于WLAN来说，管理VLAN主要是用来传送AC与AP之间的管理数据，如AP DHCP报文、AP ARP报文、AP CAPWAP报文（包含控制CAPWAP报文和数据CAPWAP报文）。AC内部XGE口的PVID和TRUNK VLAN与交换机普通物理端口的PVID和TRUNK VLAN相同，在部署AC时，需要配置PVID为管理VLAN ID并允许管理VLAN的报文通过TRUNK接口。 业务VLAN:业务VLAN主要负责传送WLNA用户上网时的数据。 从WLAN整体来看：业务VLAN是基于VAP的区域业务VLAN，与位置有关，与用户无关，VAP内的用户使用此业务VLAN封装用户。主要负责传送WLAN用户上网时的数据。 从AP角度看： 直接转发模式下，业务VLAN是指AP给数据报文加的VLAN。 隧道转发模式下，业务VLAN是指CAPWAP隧道内用户报文的VLAN。 从AC角度看：VAP模板中的Service VLAN：AP上传的用户报文VLAN，始终为当前用户的业务VLAN。 用户VLAN：用户VLAN是指基于用户权限的VLAN。 用户VLAN是指基于用户权限的VLAN，WLAN中使用的用户VLAN具体可以分为以下几种： 用户在使用802.1X方式进行用户接入安全认证时，会涉及到以下的VLAN： Guest VLAN： Guest VLAN的基本功能是使用户在没有经过认证的情况下也能访问GuestVLAN内部的部分资源。例如，当用户没有安装客户端软件时，可以通过访问Guest VLAN的资源下载并安装客户端，通过认证后，才能进行正常的网络访问。 Restrict VLAN： Restrict VLAN功能允许用户在认证失败的情况下可以访问某一特定VLAN中的资源，这个VLAN称之为Restrict VLAN。需要注意的是，这里的认证失败是认证服务器因某种原因明确拒绝用户认证通过，比如用户密码错误，而不是认证超时或网络连接等原因造成的认证失败（即AC收到RADIUS服务器下发的Radius-reject报文）。 授权VLAN： 传统的静态VLAN部署不仅管理复杂，而且难以解决移动办公用户的VLAN控制问题。可以通过在用户接入网络时动态指定该用户所属的VLAN，实现基于用户的VLAN划分。例如，在企业网中，通过动态VLAN下发，可以保证在无线用户在一个AP的覆盖区域漫游到另外一个AP的覆盖区域时，用户均属于同一个业务VLAN，保证用户正常业务不被中断。 VLAN部署原则： 当WLAN系统同时设置了用户VLAN和管理、业务VLAN后，原则如下： 无论在认证、重认证、漫游重认证还是CoA动态下发VLAN过程中，授权VLAN都有最高优先级，且为即时启用。 如果认证、重认证、漫游重认证还是CoA动态下发VLAN过程中没有授权VLAN，则取用当前所在地的业务VLAN。 总体而言，用户VLAN优先于业务VLAN，在系统同时设置有授权VLAN、Guest VLAN、Restrict VLAN等用户VLAN的情况下，优先启用授权VLAN。]]></content>
      <categories>
        <category>无线</category>
      </categories>
      <tags>
        <tag>WLAN</tag>
        <tag>组网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAPWAP基础原理]]></title>
    <url>%2F2018%2F04%2F25%2FCAPWAP%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[AP技术介绍AP介绍：无线局域网络的架构主要分为： 基于控制器的AP架构（瘦AP，FitAP） 传统的独立AP架构（胖AP，Fat AP） 胖AP： 所谓的胖AP，典型的例子为无线路由器。无线路由器与纯AP不同，除无线接入功能外，一般具备WAN、LAN两个接口，多支持DHCP服务器、DNS和MAC地址克隆，以及VPN接入、防火墙等安全功能。 瘦AP： 瘦AP是“代表自身不能单独配置或者使用的无线AP产品，这种产品仅仅是一个WLAN系统的一部分，负责管理安装和操作”。 对于可运营的WLAN，从组网的角度，为了实现WLAN网络的快速部署、网络设备的集中管理、精细化的用户管理，相比胖AP（自治性AP）方式，企业用户以及运营商更倾向于采用集中控制性WLAN组网（瘦AP+AC），从而实现WLAN系统、设备的可运维、可管理。 AC和瘦AP之间运行的协议一般为CAPWAP协议。 胖AP与瘦AP比较： CAPWAP隧道介绍CAPWAP背景：传统的WLAN体系结构已经无法满足大规模组网的需求，因此，IETF成立的CAPWAP（Control And Provisioning of Wireless Access Points 无线接入点的控制和配置协议）工作组，研究打过没WLAN的解决方案。以实现各个厂家控制器与AP间的互通。 CAPWAP的起源： CAPWAP工作组对以上四种通信协议进行评测后，最终采用LWAPP协议作为基础进行扩展，使用DTLS安全技术，加入其他三种协议的有用特性，制定了CAPWAP协议。 CAPWAP介绍：CAPWAP（无线接入点控制和配置协议），用于无线终端接入点（AP）和无线网络控制器（AC）之间的通信交互，实现AC对其所关联的AP集中管理和控制。 该协议包含的主要内容有： AP对AC的自动发现及AP和AC的状态机运行、维护。 AC对AP进行管理，业务配置下发。 STA数据封装CAPWAP隧道进行转发。 CAPWAP模式：CAPWAP协议支持两种操作模式：SPlit MAC和Local MAC。 Split MAC模式： 在Split MAC模式下，所有二层的无线数据和管理帧都被CAPWAP协议封装，在AC和AP之间交互。 从STA收到的无线帧，直接封装，转发给AC。 在split MAC模式下，无线报文不经过报文转换，直接到达AC。 Local MAC模式： 本地转发模式允许数据帧可以用本地桥或者使用802.3的帧形式用隧道转发。二层无线管理帧在AP本地处理，然后再转发给AC。 STA传送的无线帧在AP被封装成802.3数据帧。 CAPWAP报文格式： CAPWAP是基于UDP端口的应用层协议。 CAPWAP协议传输层运输两种类型的负载： 数据消息，封装转发无线帧 。 控制消息，管理AP和AC之间交换的管理消息 。 CAPWAP数据和控制报文基于不同的UDP端口发送： 控制报文端口为UDP端口5246。 数据报文端口为UDP端口5247。 瘦AP发现AC：瘦AP发现AC的流程： 图：瘦AP发现AC的流程 AP上电后，当存在预配置的AC IP列表时，则AP直接启动预配置静态发现流程并与指定的AC连接。 如果未配置AC IP列表，则启动AP动态发现AC机制，执行DHCP/DNS/广播发现流程后与AC连接。 瘦AP发现AC的过程： 图：瘦AP发现AC的过程 AP启动以后会通过DHCP获取IP地址、DNS server、域名。 AP发出L2广播的发现请求报文试图联系一个AC。 如果长时间（30秒）没有响应,AP会启动L3发现。AP会从DHCP Server通过Option43获得AC的IP，或者通过Option15获得AC的域名，AP向该IP地址（域名）发送发现请求。 接收到发现请求报文的AC会检查该AP是否有接入本机的权限，如果有则回应发现响应。 AC和AP间建立CAPWAP隧道。 CAPWAP隧道建立： 图：CAPWAP隧道建立的总体过程 CAPWAP隧道建立过程有： Discovery阶段 DTLS协商阶段（可选） Join阶段 Image data阶段（可选） configure Data check阶段 Run（Data）阶段 Run（Control）阶段 CAPWAP隧道建立-DHCP: 图：DHCP的四步交互 DHCP的四步交互： 在没有预配置AC IP列表时，则启动AP动态AC发现机制。通过DHCP获取IP地址，并通过DHCP协议中的option返回AC地址列表。 首先是AP发送discover广播报文，请求DHCP server响应，在DHCP服务器侦听到discover报文后，它会从没有租约的地址范围中，选择最前面的空置IP，连同其他TCP/IP设定，响应AP一个DHCP offer报文，该报文中会包含一个租约期限的信息。 由于DHCP offer报文既可以是单播报文，也可以是广播报文，当AP端收到多台DHCP Server的响应时，只会挑选其中一个offer(通常是最先抵达的那个)，然后向网络中发送一个DHCP request广播报文，告诉所有的offer，并重新发送DHCP，DHCP server它将指定接收哪一台服务器提供的IP地址，同时，AP也会向网络发送一个ARP封包，查询网络上面有没有其他机器使用该IP地址，如果发现该IP已被占用，AP会发送出一个DHCP Decline封包给DHCP服务器，拒绝接收其DHCP discover 报文。 当DHCP Server接收到AP的request报文之后，会向AP发送一个DHCP Ack响应，该报文中携带的信息包括了AP的IP地址，租约期限，网关信息，以及DNS server IP等，以此确定租约的正式生效，就此完成DHCP的四步交互工作。 CAPWAP隧道建立-Discovery： 图：AC发现机制 AC发现机制： AP使用AC发现机制来获知哪些AC是可用的，决定与最佳AC来建立CAPWAP的连接。（当然，AP的发现过程是可选的，如果在AP上已经静态配置了AC，那么就不需要完成AC的发现过程。） AP启动CAPWAP协议的发现机制，以单播或广播的形式发送发现请求报文试图关联AC，AC收到AP的discovery request以后，会发送一个单播discover response 给AP，AP可以通过discover response中所带的AC优先级或者AC上当前AP的个数等，确定与哪个AC建立会话。 CAPWAP隧道建立-DTLS（可选）： 图；DTLS握手 DTLS握手： AP根据此IP地址与AC协商，AP接收到响应消息后开始与AC建立CAPWAP隧道，这个阶段可以选择CAPWAP隧道是否采用DTLS加密传输UDP报文。 DTLS: Datagram Transport Layer Security（数据报传输层安全协议） CAPWAP隧道建立-join： 图：Join过程 Join： 在完成DTLS握手后，AC与AP开始建立控制通道，在建立控制的交互过程中，AC回应的Join response报文中会携带用户配置的升级版本号，握手报文间隔/超时时间，控制报文优先级等信息。AC会检查AP的当前版本，如果AP的版本无法与AC要求的相匹配时，AP和AC会进入Image Data状态做固件升级，以此来更新AP的版本，如果AP的版本符合要求，则进入configuration状态。 CAPWAP隧道建立-image date（可选）： 图：image date image data： AP根据协商参数判断当前版本是否是最新版本，如果不是最新版本，则AP将在CAPWAP隧道上开始更新软件版本。 AP在软件版本更新完成后重新启动，重复进行AC发现、建立CAPWAP隧道、加入过程。 CAPWAP隧道建立-configure： 图：Configure过程 Configuration： 进入Configuration状态后是为了做AP的现有配置和AC设定配置的匹配检查，AP发送configuration request到AC，该信息中包含了现有AP的配置，当AP的当前配置与AC要求不符合时，AC会通过configuration response通知AP。 CAPWAP隧道建立-date check： 图：date check过程 Data Check ： 当完成configuration后，AP发送change state event request信息，其中包含了radio，result，code等信息，当AC接收到change state event request后，开始回应change state event response 。 至此完成data check 后，已经完成管理隧道建立的过程，开始进入run状态。 CAPWAP隧道维护-run（date）： 图；Run数据过程 Run： AP发送keepalive到AC，AC收到keepalive后表示数据隧道建立，AC回应keepalive，AP进入“normal”状态，开始正常工作。 CAPWAP隧道维护-run(control): 图：run（控制）过程 管理隧道维护： AP进入run状态后，同时发送echo request报文给AC，宣布建立好CAPWAP管理隧道并启动echo发送定时器和隧道检测超时定时以检测管理隧道时候异常。 当AC收到echo request报文后，同样进入run状态，并回应echo response报文给AP，启动隧道超时定时器。 到AP收到echo response报文后，会重设检验隧道超时的定时器。]]></content>
      <categories>
        <category>无线</category>
      </categories>
      <tags>
        <tag>WLAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WLAN拓扑介绍]]></title>
    <url>%2F2018%2F04%2F25%2FWLAN%E6%8B%93%E6%89%91%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[802.11基本概念介绍802.11基本元素综述： SSID（Service Set Identifier）服务集标识符。 SSID技术可以将一个无线局域网分为几个需要不同身份验证的子网络，每一个子网络都需要独立的身份验证，只有通过身份验证的用户才可以进入相应的子网络，防止未被授权的用户进入本网络。 BSA（Basic Server Area）：BSS的覆盖范围称为基本服务区。 BSS（Basic Service Set）基本服务集： 是802.11网络的基本组件，由一组相互通信的工作站所构成。工作站之间的通信在某个模糊地带进行着，称为基本服务区域（Basic Service Area），此区域受限于所使用的无线媒介的传播特性。只要位于基本服务区域，工作站就可以跟同一个BSS的其他成员通信。 ESS（Extended Service Set）扩展服务集： 是采用相同的SSID的多个BSS形成的更大规模的虚拟BSS。 BSSID（Basic Service Set Identifier）基本服务集标识： 实际上就是AP的MAC地址，用来标识AP管理的BSS，在同一个AP内BSSID和SSID一一映射。在一个ESS内SSID是相同的，但对于ESS内的每个AP与之对应的BSSID是不相同的。如果一个AP可以同时支持多个SSID的话，则AP会分配不同的BSSID来对应这些SSID。 SSID：服务集标识符SSID（Service Set Identifier）：表示无线网络的标识，用来区分不同的无线网络。例如，当我们在笔记本电脑上搜索可接入无线网络时，显示出来的网络名称就是SSID。SSID由最多32个字符组成，且区分大小写，配置在所有AP与STA的无线射频卡中。 BSA(Basic Service Area):基本服务区域，相当于一个无线单元。在该覆盖区域内的成员站点之前可以保持相互通信。由于周围环境经常会发生变化，BSA的尺寸和形状并非总是固定不变的。 AP支持多SSID: 图：AP支持多SSID的示意图 早期的802.11芯片只能够创建单一BSS（基本服务集）。即为用户提供一个逻辑网络。随着WLAN用户数目的增加，单一逻辑网络无法满足不同种类的用户需求。 多SSID技术可以将一个无线局域网分为几个子网络，每个子网络都需要独立的身份验证，只有通过身份验证的用户才可以接入相应的子网络，防止未授权用户进入该网络。 如上图，AP上配置两个扩展服务集，也就是两个SSID，一个是Internal给内部员工使用，一个是Guest给访客使用，在此AP中，各SSID被分别关联至不同的VLAN，而不同的VLAN有不同的访问权限。这样就用同一个AP实现了不同用户的无线接入。 BSS: 工作站STA（Station）：支持802.11标准的终端设备。 接入点AP（Access Point）：为STA提供基于802.11标准的无线接入服务，起到有线网络和无线网络的桥接作用。 基本服务集BSS（Basic Service Set）：一个AP所覆盖的范围。在一个BSS的服务区域内，STA可以相互通信。 BSS分为：Independent BSS和Infrastructure BSS两种。BSS的服务范围可以涵盖整个小型办公室或家庭，不过无法服务较广的区域。 独立基本服务集（Independent BSS 简称IBSS）。在IBSS中，工作站相互之间可以直接通信，但两者间的距离必须在可以通信的范围内。最低限度的802.11网络是由两个工作站所组成的IBSS。通常，IBSS是由少数几个工作站为了特定目的而组成的暂时性网络。比如：在会议室中支持个别会议之用。会议开始，与会人相互形成一个IBSS以便传输数据；当会议结束，IBSS随即瓦解。正因为持续时间不长，规模小且目的特殊，IBSS有时被称为特设BSS（ad hoc BSS）或特设网络（ad hoc network）。 注：“ad hoc”系拉丁文，原意是“特别的”、“针对特殊情况的”，由于ad hoc网络的点对点性质，亦称为点对点网络。 Infrastructure BSS（基础结构模式基本服务集）。判断是否为基础结构型网络，只要查看是否有接入点参与其中即可。接入点负责基础结构性网络所有的通信，包括统一服务区域中所有移动节点之间的通信。 ESS:扩展服务集ESS（Extend Service Set）：由一个或多个BSS组成。 802.11允许我们将几个BSS串联为扩展服务集（Extended Service Set，简称ESS），借此扩展无线网络的覆盖区域。所谓ESS，就是利用骨干网络将几个BSS串联在一起。最常见的ESS由多个接入点构成，接入点的覆盖小区之间部分重叠，以实现客户端的无缝漫游。华为建议信号覆盖重叠区域至少应保持在15%~25%以上。 BSSID： 所有位于同一个ESS的接入点将会使用相同的服务组标示符（Service Set Identifier，简称SSID）,通常就是用户所谓的网络“名称”。802.11并未规定非得使用何种骨干技术，只要求骨干技术必须提供一组特定的服务功能。 SSID是Service Set Identifier的缩写，意思是：服务组标示符。SSID技术可以将一个无线局域网分为几个需要不同身份验证的子网络，每一个子网络都需要独立的身份验证，只有通过身份验证的用户才可以进入相应的子网络，防止未被授权的用户进入本网络。 BSSID实际上就是AP的MAC地址，用来标识AP管理的BSS，在同一个AP内BSSID和SSID一一映射。在一个ESS内SSID是相同的，但对于ESS内的每个AP与之对应的BSSID是不相同的。如果一个AP可以同时支持多个SSID的话，则AP会分配不同的BSSID来对应这些SSID。 WLAN拓扑结构介绍Ad-Hoc拓扑： 图：Ad-Hoc拓扑结构 Ad-Hoc拓扑的无线网络是由无线工作站组成，用于一台无线工作站和另一台或多台其他无线工作站的直接通讯，该网络无法接入到有线网络中，只能独立使用。无需AP，安全由各个客户端自行维护。 采用这种拓扑结构的网络，各站点竞争公用信道，但站点数过多时，信道竞争成为限制网络性能的要害，因此，这种拓扑结构比较适合小规模、小范围的WLAN系统组网。 点对点模式中的一个节点必须能同时“看”到网络中的其他节点，否则就认为网络中断，因此对等网络只能用于少数用户的组网环境，比如4至8个用户。 基础架构组网拓扑：DS基本概念： 分布式系统（DIstribution System）是接入点间转发帧的骨干网络，因此通常称为骨干网络。 当几个接入点串联以覆盖较大区域时，彼此之间必须相互通信以掌握移动式工作站的行踪。分布式系统属于802.11的逻辑组件，负责将帧转送至目的地。分布式系统是接入点间转发帧的骨干网络，因此通常就称为骨干网络（backbone network）有在商业上获得成功的产品几乎都是以Ethernet为骨干网络。 分布式系统必须负责追踪工作站实际的位置以及帧的传送，若要传送帧给某个移动工作站，分布式系统必须负责将之传递给服务改移动工作站的接入点。如图所示：如果STA1想要访问STA3，那么STA1将帧传给AP1，AP1连接的分布式系统必须负责将帧传送给STA3连接的AP2，再由AP2将帧传送给STA3。 基本架构拓扑： 图：基础架构拓扑图 802.3网络引入一个AP，无线网络中所有主机通过AP来通信。 无线接入点也为半双工的模式，用于在无线STA和有线网络之间接收、缓存和转发数据，所有的无线通讯都经过AP完成。 无线接入点通常能够覆盖几十用户，覆盖半径可达百米。AP可以连接到有线网络，实现无线网络和有线网络的互联。 由多个AP以及连接它们的分布式系统(DS)组成的基础架构模式网络，也称为扩展服务区（ESS）。扩展服务区内的每个AP都是一个独立的无线网络基本服务区(BSS)，所有AP共享同一个扩展服务区标示符（ESSID）。 相同ESSID的无线网络间可以进行漫游，不同ESSID的无线网络形成逻辑子网。 AP之间使用互相不重叠的信道，AP之间信号覆盖重叠区域为10%-15%。 WDS组网拓扑：WDS基本概念： WDS(Wireless Distibution System)无线分布式系统：通过无线链路连接两个或者多个独立的优先局域网或者无线局域网， 组建一个互通的网络，从而实现数据访问。 无线WDS技术提高了整个网络结构的灵活性和便捷性。 在WDS部署中，网络结构可分为：点对点方式和点对多点方式。 WDS工作原理： WDS可把有线网络的资料，透过无线网路当中继架构来传送，借此可将网络资料传送到另外一个无线网络环境，或者是另外一个有线网络。因为透过无线网络形成虚拟的网络线，所以称为无线网络桥接功能。 无线网络桥接功能通常是指的是一对一，但是WDS架构可以做到一对多，并且桥接的对象可以是无线网络卡或者是有线系统。所以WDS最少要有两台同功能的AP，最多数量则要看厂商设计的架构来决定。即WDS可以让无线AP之间通过无线进行桥接（中继），在这同时并不影响其无线AP覆盖的功能。 相比传统的有线网络，WDS具有以下优势： WDS无需架线挖槽，可以实现快速部署和扩容。 有线网络连接除电信部门外，其它单位的通信系统在公共场所没有敷设电缆的权力，而无线桥接方式则可根据客户需求使用2.4G和5.8G免许可的ISM频段灵活定制专网。 有线网络运维故障排查难度大，而WDS只需维护桥接设备，故障定位和修复快捷。 WDS组网快，支持临时、应急、抗灾通信保障。 WDS应用场景： 图:上图应用场景为室外P2P组网方式。 WDS应用场景举例： 在室内场景部署WDS，可以根据业务需求及室内建筑布局，灵活选择P2P、P2MP等多种组网方式。在室内网线敷设困难或覆盖区域与交换机距离过远时，采用WDS桥接可以作为一种有效的解决方案，但通常受限于建筑障碍物的遮挡，使得WDS在室内的应用受到较大约束。 在室外场景部署WDS，可以根据业务需求及室外建筑布局，灵活选择P2P、P2MP等多种组网方式。当需要连接的两个局域网之间有障碍物遮挡或者传输距离太远时，可以考虑使用无线中继的方法来完成两点之间的无线桥接。 WDS组网拓扑-点对点： 图：WDS点对点组网拓扑 WDS通过两台设备实现了两个网络无线桥接，最终实现两个网络的互通。实际应用中，每一台设备可以通过配置的对端设备的MAC地址，确定需要建立的桥接链路。 P2P无线网桥可用来连接两个分别位于不同地点的网络，Root AP和Leaf AP应设置成相同的信道。 WDS组网拓扑-点对多点： 图：点对多点 点对多点的无线网桥能够把多个离散的远程的网络连成一体，结构相对于点对点无线网桥来说较复杂。在点到多点的组网环境中，一台设备作为中心设备，其他所有的设备都只和中心设备建立无线桥接，实现多个网络的互联。但是多个分支网络的互通都要通过中心桥接设备进行数据转发。 例如：图中LAN Segment 2想要跟LAN Segment 3通信的话需要通过AP1(Root AP)。 WDS组网拓扑-手拉手： 图:手拉手模式 根据AP在WDS网络中的实际位置，AP射频网桥的工作模式有三种，分别为root模式、middle模式、leaf模式。 root模式：AP作为根节点直接与AC通过有线相连，另以AP型网桥向下供STA型网桥接入。 middle模式：AP作为中间节点以STA型网桥向上连接AP型网桥、以AP型网桥向下供STA型网桥接入。 leaf模式：AP作为叶子节点以STA型网桥向上连接AP型网桥。 手拉手模式为WDS典型室内组网场景，在家庭、仓库、地铁或者公司内部，由于不规则的布局，墙体等物体对WLAN信号的衰减，导致一台AP的覆盖效果很不理想，许多地方存在信号盲区，这时采用WDS技术，通过WDS桥接AP，不仅可以有效地扩大无线网络覆盖范围，还可以避免因重新布线带来的经济损耗。 对于对带宽要求不是很敏感的用户来说，此方式较为经济实用的。 WDS组网拓扑-背靠背： 图：背靠背模式 背靠背模式为WDS典型室外组网场景，当需要连接的网络之间有障碍物或者传输距离太远时，可以采用背靠背组网方式，通过两个WDS AP有线级联背靠背组成中继网桥。这种组网方式可以保证长距离网络传输中保证无线链路带宽。 对带宽要求较高的用户，可采用两个WDS AP背靠背有线直连作为Repeater AP， 两个方向工作于不同的信道，保证无线链路带宽。 Mesh组网拓扑：Mesh基概念： 图：Mesh组网拓扑 无线Mesh网络WMN（Wireless Mesh Network）是指利用无线链路将多个AP连接起来，并最终通过一个或两个Portal节点接入有线网络的一种星型动态自组织自配置的无线网络。 传统的WLAN网络中，STA与AP之间是以无线信道为传输介质，AP的上行链路则是有线网络。如果组建WLAN网络前没有有线网络基础，大量的时间和成本消耗在构建有线网络过程中，对于组建后的WLAN网络，如果需要对其中某些AP位置进行调整，则需要调整相应的有线网络，操作困难。综上所述，传统WLAN网络的建设周期长、成本高、灵活性差的弊端，使其在应急通信、无线城域网或有线网络薄弱地区等应用场合不适合部署。而Mesh网络只需要安装AP，建网速度非常快。 Mesh网络中AP的三种角色： MPP(Mesh Portal Point)：连接无线Mesh网络和其它类型的网络，并与Mesh网络内部MP/MAP节点进行通信。这个节点具有Portal功能，通过这个节点，Mesh内部的节点可以和外部网络通信。 lMP(Mesh Point)：在Mesh网络中，使用IEEE 802.11MAC和PHY协议进行无线通信，并且支持Mesh功能的节点。该节点支持自动拓扑、路由的自动发现、数据包的转发等功能。MP节点可以同时提供Mesh服务和用户接入服务。 MAP(Mesh Access Point)：任何支持AP功能的Mesh Point，可以为STA提供接入功能。 Mesh组网拓扑： 图：Mesh组网拓扑 红色虚线代表Mesh回传链路，圆圈代表用户接入信号覆盖。 在Mesh网络，AP之间通过无线连接，可以解决单点故障问题。Mesh网络的优点包括： 快速部署：Mesh网络设备安装简便，可以在几小时内组建，而传统的无线网络需要更长的时间。 动态增加网络覆盖范围：随着Mesh节点的不断加入，Mesh网络的覆盖范围可以快速增加。 健壮性：Mesh网络是一个对等网络，不会因为某个节点产生故障而影响到整个网络。如果某个节点发生故障，报文信息会通过其他备用路径传送到目的节点。 灵活组网：AP可以根据需要随时加入或离开网络，这使得网络更加灵活。 应用场景广：Mesh网络除了可以应用于企业网、办公网、校园网等传统WLAN网络常用场景外，还可以广泛应用于大型仓库、港口码头、城域网、轨道交通、应急通信等应用场景。 高性价比：Mesh网络中，只有Portal节点需要接入到有线网络，对有线的依赖程度被降到了最低，省却了购买大量有线设备以及布线安装的投资开销。 室外Mesh组网典型应用场景： 图：室外Mesh组网典型应用场景 室外场景一般范围开阔，通过选取不同的天线，两台MP 可以相距几十公里实现网络互连。因此，Mesh 技术可以用于跨建筑物或者跨区域的数据传输，解决了有线网络部署受施工条件限制，以及部署成本高，灵活性低的问题。所以Mesh 组网适用于校园、种植园、山区、高楼等场景中。 注意：室外场景中的障碍物主要为树木、高大建筑物等，如果传输距离很远，还要考虑地球的球面弧度， 因此实际组网中要根据实际情况灵活选用和安放天线。]]></content>
      <categories>
        <category>无线</category>
      </categories>
      <tags>
        <tag>WLAN</tag>
        <tag>组网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SDN基本概述]]></title>
    <url>%2F2018%2F04%2F16%2FSDN%E5%9F%BA%E6%9C%AC%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[SDN的概念与体系结构传统网络数据控制与转发：传统网络是分布式控制的架构，每台设备都包含独立的控制平面，数据平面。 传统网络是分布式控制的架构： 这里的分布式控制指在传统IP网络中，用于协议计算的控制平面和报文转发的数据平面位于同一台设备中。 路由计算和拓扑变化后，每台设备都要重新进行路由计算过程，并称为分布式控制过程。 在传统IP网络中，每台设备都是独立收集网络信息，独立计算，并且都只关心自己的选路。 这种模型的弊端就是所有设备在计算路径时缺乏统一性。 传统网络结构体系： 图：传统网络结构体系 传统网络的管理平面、控制平面、数据平面： 管理平面：管理设备（SNMP） 控制平面：路由协议(IGP、BGP) 数据平面：转发表（FIB） OSS：Operation Support System，运营支撑系统。 NMS：Network Management Server，网络管理服务器。 传统网络架构： 传统网络分为管理平面、控制平面和数据平面。 管理平面主要包括设备管理系统和业务管理系统，设备管理系统负责网络拓扑、设备接口、设备特性的管理，同时可以给设备下发配置脚本。业务管理系统用于对业务进行管理，比如业务性能监控、业务告警管理等。 控制平面负责网络控制，主要功能为协议处理与计算。比如路由协议用于路由信息的计算、路由表的生成。 数据平面是指设备根据控制平面生成的指令完成用户业务的转发和处理。例如路由器根据路由协议生成的路由表对接收的数据包从相应的出接口转发出去。 传统网络局限性： 流量路径的灵活调整能力不足。 网络协议实现复杂，运维难度较大。 网络新业务升级速度较慢。 传统网络通常部署网管系统作为管理平面，而控制平面和数据平面分布在每个设备上运行。 流量路径的调整需要通过在网元上配置流量策略来实现，但对于大型网络的流量进行调整，不仅繁琐而且还很容易出现故障；当然也可以通过部署TE隧道来实现流量调整，但由于TE隧道的复杂性，对于维护人员的技能要求很高。 传统网络协议较复杂，有IGP、BGP、MPLS、组播协议等，而且还在不断增加。 设备厂家除标准协议外都有一些私有协议扩展，不仅设备操作命令繁多，而且不同厂家设备操作界面差异较大，运维复杂。 传统网络中由于设备的控制面是封闭式的，且不同厂家设备实现机制也可能有所不同，所以一种新功能的部署可能会造成周期较长；且如果需要对设备软件进行升级，还需要在每台设备上进行操作，大大降低了工作效率。 SDN概述：SDN（Software Defined Netrork）软件定义网络。 2006年，以斯坦福大学教授Nike Mckewn为首的团队提出了OpenFlow的概念，并基于OpenFlow技术实现网络的可编程能力，是网络像软件一样灵活编程，SDN技术应运而生。 SDN的三个主要特征： 转控分离：网元的控制平面在控制器上，负责协议计算，产生流表；而转发平面只在网络设备上。 集中控制：设备网元通过控制器集中管理和下发流表，这样就不需要对设备进行逐一操作，只需要对控制器进行配置即可。 开放接口：第三方应用只需要通过控制器提供的开放接口，通过编程方式定义一个新的网络功能，然后在控制器上运行即可。 SDN控制器既不是网管，也不是规划工具： 网管没有实现转控分离：网管只负责管理网络拓扑、监控设备告警和性能、下发配置脚本等操作，但这些仍然需要设备的控制平面负责产生转发表项。 规划工具的目的和控制器不同：规划工具是为了下发一些规划表项，这些表项并非用于路由器转发，是一些为网元控制平面服务的参数，比如IP地址，VLAN等。控制器下发的表项是流表，用于转发器转发数据包。 SDN网络体系架构：SDN是对传统网络架构的一次重构，由原来分布式控制的网络架构重构为集中控制的网络架构。 SDN网络体系架构的三层模型： 图：SDN网络体系架构图 协同应用层：这一层主要是体现用户意图的各种上层应用程序，此类应用程序称为协同层应用程序，典型的应用包括OSS（Operation support system 运营支撑系统）、Openstack等。传统的IP网络同样具有转发平面、控制平面和管理平面，SDN网络架构也同样包含这3个平面，只是传统的IP网络是分布式控制的，而SDN网络架构下是集中控制的。 控制层：控制层是系统的控制中心，负责网络的内部交换路径和边界业务路由的生成，并负责处理网络状态变化事件。 转发层：转发层主要由转发器和连接器的线路构成基础转发网络，这一层负责执行用户数据的转发，转发过程中所需要的转发表项是由控制层生成的。 SDN架构下的接口：NBI（North Bound Interface）北向接口。 SBI（South Bound Interface）南向接口。 图：SDN接口 Restful接口： Restful接口为控制器与上层APP的北向接口，开放的API、设备私有接口，所有满足rest架构的互联网软件架构都是restful。 Rest为“表现层状态转化”，表现层就是资源的表现，即rest是被访问的资源（文本，图片，音乐，视频等），从一种形式的状态迁移到另一种形式的状态，本质就是一种互联网资源访问的协议。 OpenFlow接口： OpenFlow接口是控制器与下层转发器之间的一种基于芯片的接口协议。OpenFlow协议基于TCP/IP，用于转发器与控制器之间的通信。 BGP接口： BGP接口是在BGP协议基础上添加一些BGP路由属性（比如Additional Path属性和BGP Flowspecification属性），用于下发BGP的一些路由特性，从而使得IDC数据中心出口路由器根据这些特性实现流量调优。 PCE接口： PCE接口用于控制器根据网络可用带宽计算出流量工程路径，用于数据中心AS内部的TE隧道的建立。 运营商网络已经大规模部署了传统分布式网络，不能在较短时间内升级到SDN网络，与传统网络互通就是必要的。SDN控制器必须支持各种传统的跨域路由协议，以便解决和传统网络互通问题。 东西向协议是必须的，在SDN控制器上运行东西向协议，通过简单的修改或升级控制器程序就能提供新业务。另一方面，东西向协议为SDN控制器跨域互联及SDN控制器分层部署提供了接口。 SDN基本工作原理： 图：SDN基本工作原理 网元资源信息收集： 转发器注册信息 上报资源过程 MPLS标签信息 VLAN资源信息 接口资源信息 拓扑信息收集：节点对象、接口对象、链路对象（LLDP、IGP、BGP-LS）。 SDN网络内部交路由的生成。 通常控制器作为服务端，转发器主动向控制器发起控制协议建立，通过认证后，控制协议即建立连接。 注册信息中的设备信息包括资源信息（接口、标签、VLAN资源等）、设备厂家信息（设备类型信息和设备版本号以及设备ID信息）。控制器采集这些信息是为了根据这些信息来进行本地搜索和加载相应驱动程序。 网络拓扑是描述网络中节点和链路以及节点之间连接关系的信息。 控制器收集拓扑信息的目的是为了根据网络资源，计算合理的路径信息，通过流表方式下发给转发器。 OpenFlow的思想和功能： 两个角色： OpenFlow Controller：用于控制OpenFlow Switch，计算路径，维护状态和将信息流规则下发给交换机。 OpenFlow Switch：从OpenFlow Controller控制器接收命令或者流信息，以及返回状态信息。 OpenFlow Switch基于流表并根据流规则进行转发、处理数据。 “Flow”指的是一组具有相同性质的数据包，例如“五元组”（SIP、DIP、SPORT、DPORT、Protocol）。 OpenFlow协议是控制器和转发器之间的控制协议。 交换机与控制器之间可以通过加密的OpenFlow协议通信。 OpenFlow交换机是数据平面，基于Flow Table进行数据转发，并负责网络策略的具体执行。 OpenFlow Controller是控制平面设备，负责生成OpenFlow交换机上的Flow Table，以及对Flow Table的更新和维护。 OpenFlow Switch的基本组成： Flow Table：保存对每一个流的定义及相应处理行为。 安全网络通道：连接交换机和控制器，用于传输控制信令。当一个新数据包第一次到达交换机时，交换机通过这个隧道将数据包送往控制器进行路由解析。 OpenFlow协议：一套公开标准接口，用于读写Flow Table的内容。 OpenFlow网络交换模型：该模型的指导思想是：底层的数据通信（交换机、路由器）是“简化的”，并定义一个对外开放的关于流表FLowTable的公用API（应用程序接口），同时采用控制器来控制整个网络。 SDN的价值网络业务快速创新：SDN的可编程性和开放性，使得我们可以快速开发新的网络业务和加速业务创新。如果希望在网络上部署新业务，可以通过针对SDN软件的修改实现网络快速编程，业务快速上线。 SDN网络关键的地方是在网络架构中增加了一个SDN控制器，把原来的分布式控制平面集中到一个SDN控制器上，由这个集中的控制器来实现网络集中控制。SDN网络架构具备3个基本特征：转控分离、集中控制、开放接口。 SDN通过在网络中增加一个集中的SDN控制器，可以简化网络和快速进行业务创新。但是其本质的技术原理是通过SDN控制器的网络软件化过程来提升网络可编程能力。通信平面仍包含管理平面、控制平面和数据平面，SDN网络架构只是把系统的三个平面的功能进行了重新分配，传统网络控制平面是分布式的，分布在每个转发设备上，而SDN网络架构则是把分布式控制平面集中到一个SDN控制器内，实现集中控制，而管理平面和数据平面并没有太多什么变化。 SDN网络具备快速网络创新能力，如果这个新业务有价值则保留，没有价值可以快速下线。不像传统网络那样，一个新业务上线需要经过需求提出、讨论和定义开发商开发标准协议，然后在网络上升级所有的网络设备，经过数年才能完成一个新业务。SDN使得新业务的上线速度从几年提升到几个月或者更快。 简化网络：SDN的网络架构简化了网络，消除了很多IETF的协议。协议的去除，意味着学习成本的下降，运行维护成本下降，业务部署快速提升。这个价值主要得益于SDN网络架构下的网络集中控制和转控分离。 因为SDN网络架构下的网络集中控制，所以被SDN控制器所控制的网络内部很多协议基本就不需要了，比如RSVP协议、LDP协议、MBGP协议、PIM组播协议等等。原因是网络内部的路径计算和建立全部在控制器完成，控制器计算出流表，直接下发给转发器就可以了，并不需要协议。未来大量传统的东西向协议会消失，而南北向控制协议比如Openflow协议则会不断的演进来满足SDN网络架构需求。 网络设备白牌化：基于SDN架构，如果标准化了控制器和转发器之间的接口，比如OpenFlow协议逐渐成熟，那么网络设备的白牌化将成为可能，比如专门的OpenFlow转发芯片供应商，控制器厂商等，这也正是所谓的系统从垂直集成开发走向水平集成。 垂直集成是一个厂家供应从软件到硬件到服务。水平集成则是把系统水平分工，每个厂家都完成产品的一个部件，有的集成商把他们集成起来销售。水平分工有利于系统各个部分的独立演进和更新，快速进化，促进竞争，促进各个部件的采购价格的下降。 业务自动化：SDN网络架构下，由于整个网络归属控制器控制，那么网络业务网自动化就是理所当然的，不需要另外的系统进行配置分解。在SDN网络架构下，SDN控制器可以自己完成网络业务部署，提供各种网络服务，比如L2VPN、L3VPN等，屏蔽网络内部细节，提供网络业务自动化能力。 网络路径流量优化：通常传统网络的路径选择依据是通过路由协议计算出的“最优”路径，但结果可能会导致“最优”路径上流量拥塞，其他非“最优”路径空闲。当采用SDN网络架构时，SDN控制器可以根据网络流量状态智能调整网络流量路径，提升网络利用率。 传统网络向SDN的演进方式仅交换网SDN化： 交换网SDN化是指把域内交换网的路径计算功能进行集中控制。 控制器：仅负责域内路径计算和控制。 仅业务SDN化： 此方案仅仅将自治域AS所接入的业务由控制器接管，域内路径计算和控制依然由转发器负责。 统一部署增值业务VAS资源池，通过SDN COntroller业务链解决方案，集中控制管理，同时实现VAS资源共享。 提升增值业务快速创新能力，提供新的创收来源。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>SDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFV基本概述]]></title>
    <url>%2F2018%2F04%2F16%2FNFV%E5%9F%BA%E6%9C%AC%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[NFV介绍定义：NFV，即网络功能虚拟化，Network Function Virtualization。通过使用x86等通用性硬件以及虚拟化技术，来承载很多功能的软件处理。从而降低网络昂贵的设备成本。可以通过软硬件解耦及功能抽象，使网络设备功能不再依赖于专用硬件，资源可以充分灵活共享，实现新业务的快速开发和部署，并基于实际业务需求进行自动部署、弹性伸缩、故障隔离和自愈等。 目标：NFV的目标是取代通信网络中私有、专用和封闭的网元，实现统一通用硬件平台+业务逻辑软件的开放架构。 NFV与SDN结合使用将对未来通信网络的发展带来重大的影响，同时也带来新的问题和挑战。 NFV发展缘由： 网络运营商的网络通常是由大规模并且迅速增长的多种多样的硬件设备组成。开发一个新的网络业务经常需要新类型的设备，而为这些盒子需找空间、提供电源变得越来越困难；同时还伴随着能源成本的增加、投资额的挑战，基于硬件设备的复杂度提升，也增加了对设计、集成、运营所需要的各种稀有技能的要求。 更严重的问题是，基于硬件的设备很快就到了生命周期，这需要更多的“设计-集成-部署”循环，但收益甚少。糟糕的是，硬件生命周期变得越来越短而业务创新则在不断加速，所以这抑制了新增值业务的部署，并且限制了不断增长的网络为中心领域的创新。 网络虚拟化通过借用IT的虚拟化技术，许多类型的网络设备类型可以合并入工业界标准中，如servers、switches和storage，可以部署在数据中心、网络节点或是用户家里。网络虚拟化适用于固定、移动网络中任何数据面的分组处理和控制面功能。 NFV基本概念来自企业、运营商、家庭用户的需求： 随着云服务的不断发展和需求的不断增加，运营商只需要为企业私有云和公有云提供管道传输，因此运营商有被管道化的风险。 家庭用户在体验上不支持多屏应用、室外应用，业务开通周期长，费用昂贵。 企业用户需要高IT投入购买大量通信设备（路由器、交换机、服务器、存储设备）。 系统扩容需要更新设备，重复投资。 CPE（customer premises equipment）多为企业网的网关，对接运营商的PE设备。 什么是NFV：NFV即网络功能虚拟化（Network Functions Virtualization），将许多类型的网络设备（如servers，switches和storage等）构建为一个Data Center Network，通过借用IT的虚拟化技术虚拟化形成VM（虚拟机，Virtual Machine），然后将传统的CT业务部署到VM上。 在NFV出现之前设备的专业化很突出，具体设备都有其专门的功能实现，而之后设备的控制平面与具体设备进行分离，不同设备的控制平面基于虚拟机，虚拟机基于云操作系统，这样当企业需要部署新业务时只需要在开放的虚拟机平台上创建相应的虚机，然后在虚拟机上安装相应功能的软件包即可。这种方式我们就叫做网络功能虚拟化。 网络功能虚拟化的优点和面临的挑战：网络功能虚拟化的优点： 通过设备合并、借用IT的规模化经济，减少设备成本、能源开销。 缩短网络运营的而业务创新周期，提升投放市场的速度，是运营商极大的减少网络成熟周期。 网络设备可以多版本、多租户共存，且单一平台为不同的应用、用户、租户提供服务，允许运营商跨服务和跨不同客户群共享资源。 基于地理位置、用户群引入精准服务，同时可以根据需要对服务进行快速扩张/收缩。 更广泛、多样的生态系统使能，促进开放，将开放虚拟装置给纯软件开发者、小商户、学术界，鼓励更多的创新，引入新业务，更低的风险带来新的收入增长。 NFV同样面临着很多技术挑战： 虚拟网络装置运行在不同的硬件厂商、不同的Hypervisor上，如何获取更高的性能。 基于网络平台的硬件同时允许迁移到虚拟化的网络平台中，两者并能共存，重用运营商当前的OSS/BSS。 管理和组织诸多虚拟网络装置（尤其是管理系统），同时避免安全攻击和错误配置。 保证一定级别的硬件、软件可靠性。 不同运营商的虚拟装置（VA）集成。网络运营商需要能“混合和匹配”不同厂家的硬件、不同厂家的Hypervisors、不同厂家的虚拟装置（VA），而没有巨大的集成成本、避免与厂家绑定。 NFV架构NFV本质：重新定义网络设备架构： 图：NFV重新定义网络设备架构 Huawei CloudEdge方案包括四个层面以及对应的亮点如下： 软件应用层：华为提供丰富完善的电信业务应用，并且向第三方开放，加快业务创新和部署。 虚拟层面Cloud OS：实现设备资源的高效利用和业务的快速部署。 自动维护管理层MANO (Management And Network Orchestration)：自动的网络伸缩，简化管理。 硬件设备层：高可靠、高性能、多规格的COTS Server，充分满足电信级部署的需求，并支持多厂家的COTS Server部署。 在NFV架构中，底层为具体物理设备，如服务器，存储设备，网络设备。 计算虚拟化即虚拟机，在一台服务器上创建多个虚拟系统。 存储虚拟化，即多个存储设备虚拟化为一台逻辑上的存储设备。 网络虚拟化，即网络设备的控制平面与底层硬件分离，将设备的控制平面安装在服务器虚拟机上。 在虚拟化的设备层面上可以安装各种服务软件。 NFV开放接口： 图：NFV开放的接口 NFVI：提供VNF的运行环境，包括所需的硬件及软件。硬件包括计算、网络、存储资源；软件主要包括Hypervisor、网络控制器、存储管理器等工具，NFVI将物理资源虚拟化为虚拟资源，供VNF使用。 VNF：包括VNF和EMS，VNF网络功能，EMS为单元管理系统，对VNF的功能进行配置和管理。一般情况下，EMS和VNF是一一对应的。 VIM：NFVI管理模块，通常运行于对应的基础设施站点中，主要功能包括：资源的发现、虚拟资源的管理分配、故障处理等，为VNF运行提供资源支持。 VNFM：VNF管理模块，主要对VNF的生命周期（实例化、配置、关闭等）进行控制，一般情况下与VNF一一对应。 NFVO：NS生命周期的管理模块，同时负责协调NS、组成NS的VNFs以及承载各VNF的虚拟资源的控制和管理。 OSS/BSS：服务提供商的管理功能，不属于NFV框架内的功能组件，但NFVO需要提供对OSS/BSS的接口。 NFV简化网络运营： 图：NFV简化网络运营 OPEX（Operating Expense）即运营成本，计算公式为：OPEX=维护费用+营销费用+人工成本+折旧）。 CAPEX（Capital Expenditure）即资本性支出，计算公式为：CAPEX=战略性投资+滚动性投资。资本性投资支出指用于基础建设、扩大再生产等方面的需要在多个会计年度分期摊销的资本性支出。 STB(Set Top Box)：机顶盒STB是指用来增强或扩展电视机功能的一种信息设备，由于人们通常将它放在电视机的上面，所以又被称为机顶盒或顶置盒，可接收通过卫星广播和电缆传递过来的节目，并可提供附加服务，如在Internet上选择想看的电影，享受卫星的VOD（按需点播）服务，还能进行家庭银行等电子商务交易。 RGW(Residential Gateway)：住宅网关一种接入网关设备。直接连到用户已有设备CPE（POTS，ISDN电话装置、PC电话）上，它允许直接在数据网络上传输来自个别住宅用户的语音呼叫。 NFV企业网解决方案： SME：（Small and medium enterprises）中小型企业。 Advanced AR，当前网络中：SME直接向第三方购买业务，绕过运营商。 对于运营商来说，不产生收入。 对于SME来说，业务和设备运维复杂，成本高。 Very Simple AR引入vAR后：运营商从云端提供企业业务。 对于运营商来说，带来了大量的潜在收入 对于SME，简化了运维管理。 在vAR的场景里，将AR路由器的高级功能，比如防火墙，VOIP，NAT等虚拟化到server上，server的物理位置可以在运营商的机房。 vAR解决方案的目的就是简化CPE的功能特性，集中管理高级特性等。在实际项目场景中，一个运营商的一个VIP的客户的网络可能CPE设备就有上千台，分散在不同的branches，虚拟化后的便捷性显而易见。 SDN与NFV的关系SDN与NFV的关系: 图：SDN与NFV的关系 NFV不依赖与SDN，但是SDN中控制和数据转发的分离可以改善NFV网络性能。 SDN也可以通过使用通用硬件作为SDN的控制器和服务交换机以虚拟化形式实现。 结论：以移动网络，NFV是网络演进的主要架构。在一些特定场景，将引入SDN。 SDN与NFV对比： 类型 SDN NFV 主要主张 转发与控制分离，控制面集中，网络可编程化 将网络功能从原来专用的设备移到通用设备上。 校园网，数据中心、云。 运营商网络 商用服务器和交换机 专用服务器和交换机 云资源调度和网络 路由器、防火墙、网关、CND、广域网加速器、SLA保证等 通用协议 OpenFlow 尚没有 ONF（Open Networking Forun）组织 ETSI NFV工作组 NFV是具体设备的虚拟化，将设备控制平面运行在服务器上，这样设备是开放的兼容的。 SDN是一种全新的网络架构，SDN的思想是取消设备控制平面，由控制器统一计算，下发流表，SDN是全新的网络架构。 NFV和SDN是高度互补关系，但并不互相依赖。网络功能可以在没有SDN的情况下进行虚拟化和部署，然而这两个理念和方案结合可以产生潜在的、更大的价值。 网络功能虚拟化（NFV）的目标是可以不用SDN机制，仅通过当前的数据中心技术去实现。但从方法上有赖于SDN提议的控制和数据转发平面的分离，可以增强性能、简化与已存在设备的兼容性、基础操作和维护流程。 NFV可以通过提供给SDN软件运行的基础设施的方式来支持SDN。而且，NFV和SDN在都利用用基础的服务器、交换机去达成目标，这一点上是很接近的。 基于SDN的NFV解决方案： 图：基于SDN的NFV解决方案 SDN控制器北向对接云平台接收配置信息，根据云平台需求计算流表，南向下发流表至CE设备。 SDN控制器通过NFV实现，底层为E9000/RH2288服务器，平台为SUSE Linux系统，上层为VRP通用路由平台，VRP负责计算转发表。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>NFV</tag>
        <tag>SDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VXLAN基本概述]]></title>
    <url>%2F2018%2F04%2F15%2FVXLAN%E5%9F%BA%E6%9C%AC%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[VXLAN简介定义：RFC7348定义了VLAN扩展方案VXLAN（Virtual eXtensible Local Area Network，虚拟扩展局域网）。VXLAN采用MAC in UDP（User Datagram Protocol）封装方式，是NVO3（NetworkVirtualization over Layer 3）中的一种网络虚拟化技术。 起源：随着网络技术的发展，云计算凭借其在系统利用率高、人力/管理成本低、灵活性/可扩展性强等方面表现出的优势，已经成为目前企业IT建设的新趋势。而服务器虚拟化作为云计算的核心技术之一，得到了越来越多的应用。 服务器虚拟化技术的广泛部署，极大地增加了数据中心的计算密度；同时，为了实现业务的灵活变更，虚拟机VM（VirtualMachine）需要能够在网络中不受限迁移，这给传统的“二层+三层”数据中心网络带来了新的挑战。 虚拟机规模受网络设备表项规格的限制 在传统二层网络环境下，数据报文是通过查询MAC地址表进行二层转发。服务器虚拟化后，VM的数量比原有的物理机发生了数量级的增长，伴随而来的便是VM网卡MAC地址数量的空前增加。而接入侧二层设备的MAC地址表规格较小，无法满足快速增长的VM数量。 网络隔离能力有限 VLAN作为当前主流的网络隔离技术，在标准定义中只有12比特，因此可用的VLAN数量仅4096个。对于公有云或其它大型虚拟化云计算服务这种动辄上万甚至更多租户的场景而言，VLAN的隔离能力无法满足。 虚拟机迁移范围受限 由于服务器资源等问题（如CPU过高，内存不够等），虚拟机迁移已经成为了一个常态性业务。 虚拟机迁移是指将虚拟机从一个物理机迁移到另一个物理机。为了保证虚拟机迁移过程中业务不中断，则需要保证虚拟机的IP地址、MAC地址等参数保持不变，这就要求虚拟机迁移必须发生在一个二层网络中。而传统的二层网络，将虚拟机迁移限制在了一个较小的局部范围内。 针对虚拟机规模受设备表项规格限制 VXLAN将管理员规划的同一区域内的VM发出的原始报文封装成新的UDP报文，并使用物理网络的IP和MAC地址作为外层头，这样报文对网络中的其他设备只表现为封装后的参数。因此，极大降低了大二层网络对MAC地址规格的需求。 针对网络隔离能力限制 VXLAN引入了类似VLAN ID的用户标识，称为VXLAN网络标识VNI（VXLAN Network Identifier），由24比特组成，支持多达16M的VXLAN段，有效得解决了云计算中海量租户隔离的问题。 针对虚拟机迁移范围受限 VXLAN将VM发出的原始报文进行封装后通过VXLAN隧道进行传输，隧道两端的VM不需感知传输网络的物理架构。这样，对于具有同一网段IP地址的VM而言，即使其物理位置不在同一个二层网络中，但从逻辑上看，相当于处于同一个二层域。即VXLAN技术在三层网络之上，构建出了一个虚拟的大二层网络，只要虚拟机路由可达，就可以将其规划到同一个大二层网络中。这就解决了虚拟机迁移范围受限问题。 传统数据中心网络所面临的挑战数据中心的基本概念及特点： 数据中心（Data Center）是一套完整、复杂的集合系统，它不仅包括计算机系统和其它与之配套的设备（例如通信和存储系统），还包含数据通信系统、环境控制设备、监控设备以及各种安全装置。 数据中心通常是指在一个物理空间内实现信息集中处理、存储、传输、交换、管理的场所。 服务器、网络设备、存储设备等通常都是数据中心的关键设备。 设备运行所需要的环境因素，如供电系统、制冷系统、机柜系统、消防系统、监控系统等通常都被认为是关键物理基础设施。 互联网数据中心（Internet Data Center，IDC）是互联网中数据存储和处理的中心，是互联网中数据交互最为集中的地方。 数据中心的四大焦点：可靠、灵活、绿色、高效。 传统数据中心网络结构： 传统网络模型在很长一段时间内，支撑了各种类型的数据中心。 按照功能模块划分，传统数据中心可分为核心区、外网服务器区、内网服务器区、互联网服务器区、数据中心管理区、数据交换&amp;测试服务器区、数据存储功能区、数据容灾功能区等。 在服务器区，再根据不同的应用类型划分不同的层次，例如，数据库层、应用服务器层、WEB服务器层等。 传统数据中心的网络结构是按照经典的三层架构（接入、汇聚、核心）进行部署的。 计算节点低延迟需求： 流量 需要经过多层交换机转发。 大量虚拟你相互访问需求。 东西向流量延迟较大。 同一物理服务器部署大量虚拟机，造成流量并发量大增。 数据流量模型也从传统的南北向流量转变为东西向流量。 网络中存在大量多对一、多对多的东西向流量。 对接入层和汇聚层设备的处理能力提出了更高的要求。 虚拟化应用大量应用：###虚拟化应用大量部署： 图：虚拟化技术 传统的数据中心内，服务器主要用于对外提供服务，不同业务区域之间可通过划分为不同的安全分区或VLAN进行隔离。 一个分区通常集中了该业务所需的计算、网络及存储资源，不同的分区之间或者禁止互访，或者经由三层网络进行互访，数据中心的网络流量大部分集中于南北向。在这种设计下，不同分区间计算资源无法共享，资源利用率低下的问题越来越突出。 通过虚拟化技术、云计算管理技术等，将各个分区间的资源进行池化，实现数据中心资源的有效利用。 随着这些新技术的兴起和应用，新的业务需求如虚拟机迁移、数据同步、数据备份、协同计算等在数据中心内开始实现部署，数据中心内部东西向流量开始大幅度增加。 虚拟机动态迁移技术在实际应用中很常见，比如需要对一台服务器进行升级和维护时，可以通过VM迁移技术将这台服务器上的VM先迁移到另一台服务器上，其间所提供的服务不中断，然后等服务器升级和维护结束后再将VM迁移回来即可。 虚拟机动态迁移技术还可以充分利用计算资源，比如某公司的网购平台在某段时间内在某片区域提供促销活动，其间业务量大大增加，这样可以将其他业务量小的区域内的VM动态迁移过来，这样不会中断其他区域服务的情况下，集中利用资源，活动结束后再将VM调整回原先的区域。 传统三层架构下虚拟机动态迁移带来的问题： 虚拟机动态迁移，就是在保证虚拟机上服务正常运行的同时，将一个虚拟机系统从一个物理服务器移动到另一个物理服务器的过程。 该过程对于最终用户来说是无感知的，从而使得管理员能够在不影响用户正常使用的情况下，灵活调配服务器资源，或者对物理服务器进行维修和升级。 一旦服务器跨二层网络迁移，就需要变更IP地址，那么原来这台服务器所承载的业务就会中断，而且牵一发动全身，其他相关的服务器也要变更相应的配置，影响巨大。 当前的一些解决方案：拓扑简化思想 为了打破这种跨三层网络限制，实现虚拟机的大范围甚至跨地域的动态迁移，就要求把VM迁移可能涉及的所有服务器都纳入到同一个二层网络中，这样才能实现VM大范围的无障碍迁移。 在汇聚核心层部署CSS，在接入层部署istack，可实现简化拓扑结构的目的。 设备无需使能STP等二层环路保护机制，更有效地提高了链路资源利用率。 但设备性能问题并没有得到根本解决。 该解决方案比较适于在一个数据中心内部进行VM迁移操作。 该解决方案存在的问题： MAC地址数量陡增，接入设备压力较大。 多租户隔离环境中设备VLAN资源紧张。 二层网络范围过大，影响网络通信效率。 传统解决方案适用于DC内部大二层互联应用。 STP或CSS+iStack传统二层技术不适合构建大规模二层网络。 通过VXLAN可以构建大二层网络，链路带宽利用率高。 多数据中心大二层互联-VXLAN： 早期的虚拟机管理及迁移依附于物理网络，因此数据中心内部东西向流量主要是二层流量。 为扩大二层物理网络的规模，提高链路利用率，出现了TRILL、SPB等大二层网络技术。 随着虚拟化数据中心规模的不断扩大，以及云化管理的不断深入，物理网络的种种限制越来越不能满足虚拟化的要求，由此提出了VXLAN、NVGRE等Overlay技术。 在Overlay方案中，物理网络的东西向流量类型逐渐由二层向三层转变，通过增加封装，将网络拓扑由物理二层变为逻辑二层，同时提供了逻辑二层的划分管理，更好地满足了多租户的需求。 VXLAN、NVGRE等Overlay技术都是通过将MAC封装在IP之上，实现对物理网络的屏蔽，解决了物理网络VLAN数量限制、接入交换机MAC表资源有限等问题，同时通过提供统一的逻辑网络管理工具，更方便地实现了虚拟机在进行迁移时网络策略跟随的问题，大大降低了虚拟化对网络的依赖，成为了目前网络虚拟化的主要发展方向。 网络和业务维护自动化需求：业务快速创新、自动发放需求. 图：传统DC与云DC的对比 云数据中心的网络解决方案： 图：云数据中心的网络解决方案 VXLAN技术主要解决多租户环境下的二层互联问题。 VXLAN通过隧道技术在不改变三层网络拓扑的前提下构建跨数据中心的逻辑二层网络拓扑。 VXLAN技术有效解决了vlan数量的限制问题。 VXLAN技术对二层网络做了优化不会造成广播风暴等问题。 SDN技术主要是简化网络的部署、运维、调整等。 VXLAN基本原理VXLAN部署的典型网络架构： 图：VXLAN部署的典型网络架构 VXLAN/NVGRE/STT是三种典型的NVO3技术。 是通过MAC In IP技术在IP网络之上构建逻辑二层网络。 同一租户的VM彼此可以二层通信、跨三层物理网络进行迁移。 相比传统L2 VPN等Overlay技术，NVO3的CE侧是虚拟或物理主机，而不是网络站点。 此外主机具有可移动性。 目前，一般是IT厂商主导，通过服务器的Hypervisor来构建Overlay网络。 VXLAN组网逻辑架构： 图：VXLAN组网逻辑架构 VXLAN（Virtual eXtensible Local Area Network，RFC7348）是IETF NVO3（Network Virtualization over Layer 3）定义的NVO3标准技术之一，采用MAC in UDP封装方式，将二层报文用三层协议进行封装，可对二层网络在三层范围进行扩展，同时支持24bits的VNI ID（16M租户能力），满足数据中心大二层VM迁移和多租户的需求。 在VXLAN NVO3网络模型中，部署在VXLAN网络边缘的设备称为VXLAN NVE（Network Virtualization Edge，网络虚拟边缘），主要负责VLAN网络与VXLAN网络间的封装和解封装。经过NVE封装转换后，NVE间就可基于L3基础网络建立Overlay二层虚拟化网络。 VXLAN技术特点： 位置无关性：业务可在任意位置灵活部署，缓解了服务器虚拟化后相关的网络扩展问题。 可扩展性：在传统网络架构上规划新的Overlay网络，部署方便，同时避免了大二层的广播风暴问题，可扩展性极强。 部署简单：由高可靠SDN Controller完成控制面的配置和管理，避免了大规模的分布式部署，同时集中部署模式可加速网络和安全基础架构的配置，提高可扩展性。 适合云业务：可实现千万级别的租户间隔离，有力地支持了云业务的大规模部署。 技术优势：VXLAN利用了现有通用的UDP进行传输，成熟性极高。 VXLAN网关： 图：VXLAN网关结构图 NVE:目前有软件NVE（一般安装在服务器上；例如OVS）和硬件NVE（一般集成在交换机上，例如CE6850）。由于软件NVE是在原设备中安装一个软件包，硬件NVE是在原设备中增加一个硬件模块，而原设备多数是VLAN的二层设备，所以，NVE又是VXLAN的二层网关，主要实现VXLAN与VLAN、MAC等的二层映射。 VXLAN网关： 与VXLAN NVE类似，是地位更高一些的另一个VXLAN角色，即VXLAN三层网关，简称VXLAN GW，主要实现VXLAN报文头与IP报文头的映射。 不管二层VXLAN网关还是三层VXLAN网关，都是主要实现了VXLAN网络和非VXLAN网络之间的连接。 NVE是服务器虚拟化层的一个功能模块，虚拟机通过虚拟化软件直接建立VTEP隧道。 NVE也可以是一台支持VXLAN的接入交换机集中为多租户提供VXLAN网关服务。 VXLAN网关可以实现不同VXLAN下租户间通信，也能实现VXLAN用户与非VXLAN用户间通信，这和VLANIF接口的功能是类似的。 NVO3标准术语： VN 虚拟网络 VNI 虚拟网络实例（Virtual Network Instance），可以为L2或L3网络，一个租户可以对应一个或多个VNI。 虚拟网络ID（Virtual Network Identifier），标识一个虚拟网络。 虚拟网络边缘（Virtual Network Edge），可以位于物理网络边缘设备，也可以位于Hypervisor，可以是二层转发或三层转发。 VN Context 该字段位于Overlay封装头部，用于Egress NVE设备确定VNI。 运行在物理服务器内的虚拟化软件，为服务的VN提供共享计算资源、内存、存储，而且Hypervisor内经常内嵌Virtual Switch。 Tenant End System 租户终端系统，可以是物理服务器也可以是VM。 业界其他技术实现-NVO3技术背景： VXLAN/NVGRE/STT是NVO3三种典型技术，总体是通过MAC In IP技术来构建Over在IP网络之上的二层网络，使同一个租户的VM彼此可以二层通信、跨三层物理网络进行迁移。相比传统L2 VPN等Overlay技术，NVO3的CE侧是虚拟或物理Host，而不是网络Site，另外Host具有移动性。目前，一般是IT厂商主导，通过服务器内Hypervisor来构建Overlay网络。 NVGRE主要支持者是Microsoft。与VXLAN不同的是，NVGRE没有采用标准传输协议（TCP/IP），而是借助通用路由封装协议（GRE）。NVGRE使用GRE头部的低24bit位作为租户网络标识符。 VXLAN（Virtual Extensible LAN）虚拟可扩展局域网，是一种Overlay的网络技术，使用MAC in UDP的方法进行封装。后文会详细介绍VXLAN技术。 STT（Stateless Transport Tunneling）是一种MAC Over Ip的协议，和VXLAN、NVGRE类似，都是把二层的帧封装在一个Ip报文的payload中，在Ip报文的payload中，除了虚拟网络的二层包以外，还要把构造的一个TCP头和一个STT头加在最前面。 VXLAN报文封装： VXLAN是IETF定义的NVO3（Network Virtualization over Layer3）标准技术之一。 采用Mac in UDP封装方式将二层报文用三层协议进行封装。 支持24bits的VNI iD，满足数据中心大二层VM迁移和多租户需求。 图：VXLAN报文格式 VXLAN header（VXLAN头封装）： VXLAN Flags：标记位，8比特，取值为00001000。 VNI：VXLAN网络标识，用于区分VXLAN段，由24比特组成，支持多达16M的租户。一个租户可以有一个或多个VNI，不同VNI的租户之间不能直接进行二层相互通信。 Reserved：保留未用，分别由24比特和8比特组成，设置为0。 Outer UDP header（外层UDP头封装）： DestPort：目的UDP端口号，设置为4789。 Source Port：源UDP端口号，根据内层以太报文头通过哈希算法计算后的值。 Outer IP header（外层IP头封装）： IP SA：源IP地址，VXLAN隧道源端VTEP的IP地址。 IP DA：目的IP地址，VXLAN隧道目的端VTEP的IP地址。 Outer Ethernet header（外层Ethernet头封装）： MAC DA：目的MAC地址，为到达目的VTEP的路径上，下一跳设备的MAC地址。 MAC SA：源MAC地址，发送报文的源端VTEP的MAC地址。 802.1Q Tag：可选字段，该字段为报文中携带的VLAN Tag。 Ethernet Type：以太报文类型，IP协议报文中该字段取值为0x0800。 VXLAN数据封装过程： 图：VXLAN数据封装过程 VXLAN通信流程： 图：VXLAN通信流程 vSwitch为虚拟机工具Hypervisor层中集成的虚拟交换机。 VTEP是在虚拟机所属服务器的Hypervisor中的vSwitch间进行建立的。 控制器为可选组件。 VTEP—Virtual Tunnel End Point 虚拟隧道端点，即VXLAN隧道的入口和出口。在这里VM流量经过vSwtich交换后会导入到VXLAN隧道里，入口是VTEP。 VNI— Virtual Network Instance 虚拟网络实例，一个VNI就是一个虚拟网络，一个VNI用一个VNI ID标识。例子里VM1和VM2在同一个虚拟网络里，VNI ID为1。 VM1地址为IP1，VM3地址为IP3，IP1与IP3为同一子网。 ARP协议交互过程： VM1先发送ARP报文，请求VM3的MAC地址。 ARP报文通过OpenFlow报文封装发给AC，AC上使能ARP代理。 AC通过IP3找到MAC3，响应ARP报文，SIP为IP3，SMAC为MAC3。 vSwtich将ARP响应报文发给VM1。 图:报文转发过程 报文转发过程： VM1发送数据报文，SIP为IP1，DIP为IP3，SMAC为MAC1，DMAC为MAC3。 VXLAN封装，内层SIP为IP1，DIP为IP3，外层SIP为VTEP1 IP，外层DIP为VTEP2 IP。 解封装VXLAN头部，发往VM3。 VXLAN基本配置基于SDN的VXLAN基本组网： 图：拓扑图 接口配置： 图：基于SDN的VLXAN基本组网-接口配置 协议配置： 图：基于SDN的VLXAN基本组网-协议配置 1.配置控制器和转发器建立OpenFlow通信通道: 123456789101112131415161718192021222324//SNC上配置：openflow listening-ip 5.5.5.5 //配置SDN控制器侦听地址 fp-id 1 //配置转发器ID type huawei-default //配置转发器的设备类，其中huawei-default表示转发器是华为设备； //ovs-default表示转发器是OVS（openvswitch）设备version default //配置转发器的版本是defaultrole default //配置转发器的角色是defaultopenflow controller //配置控制器与转发器之间的通信通道，采用OpenFlow连 //接并进入OpenFlow视图peer-address 1.1.1.1 //指定转发器FP1的Loopback1地址 //FP1配置controller-ip 5.5.5.5 //指定控制器的Loopback地址，并进入Controller视图openflow agent//配置转发器与控制器之间的通信通道采用OpenFlow连接//并进入OpenFlow Agent视图transport-address 1.1.1.1 //配置OpenFlow连接的本端地址 2.配置业务接入点实现区分业务流量: 123456789101112131415161718//在控制器上配置FP1switch fp 1 //进入fp1视图下，1是fp的ID，这里假设fp id是1。bridge-domain 10 //创建广播域BD，可以看成是一个虚拟交换机。interface vserviceif 1:1 //创建vServiceIf接口，并进入vServiceIf接口视图， //vServiceIF接口是一个逻辑的VXLAN接口。用于和bridge-domain关联，将流量引入到广播域。binding interface GE0/0/2 //为vService接口绑定物理接口。interface vserviceif 1:1.1 mode l2 //创建vServiceif接口子接口，并进入子接口视图。//子接口作用是为了匹配带VLAN的报文，进而报文进入桥域。encapsulation dot1q vid 10 //配置二层vServiceIf子接口的流封装类型，允许接//口接收携带一层VLAN Tag是10的报文。rewrite pop single//配置二层vServiceIf子接口的流动作是pop，对接收的报文进行剥除VLAN Tag操作。//这样可以实现不同VLAN的租户在相同VXLAN下可以互访。 3.配置VXLAN隧道转发业务流量: 12345678910111213//在控制器上配置FP1bridge-domain 10 //创建VXLAN网络标识VNI并关联广播域BD，将VNI以1:1方式映射到BD， //通过BD转发流量。此命令相当于将VXLAN隧道和bridgedomain（虚拟交换机）关联起来。VXLAN vni 10interface nve 1:1 //创建NVE接口，并进入NVE接口视图。source 1.1.1.1 //配置源端VTEP的IP地址。vni 10 head-end peer-list 3.3.3.3 //配置头端复制列表。通过头端复制列表，源端NVE接口将收到的 //BUM（Broadcast&amp;Unknown-unicast&amp;Multicast）报文，根据VTEP列表进行复制并发送给属于同一个VNI的所有VTEP。 VXLAN组网应用（UNICA、联通公有云、上海电影公有云）： 业务呈现层： 面向运营商、企业、租户、RSP的Portal。 提供业务灵活定制化界面。 协同层： 标准、开放的OpenStack架构，并兼容多厂商。 实现存储、计算和网络资源的协同。 网络控制层： 网络控制平台由NetMatrix和SNC组成，完成网络建模和网络实例化。 北向支持开放API接口，实现业务快速定制和自动发放。 南向支持OpenFlow/Netconf等接口，实现统一管理和控制物理和虚拟网络。 基础网络层： 物理网络和虚拟网络统一规划和设计的Overlay网络。 基于硬件的VXLAN网关提高业务性能。 支持对传统VLAN网络的兼容。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>VLAN</tag>
        <tag>交换基础</tag>
        <tag>VXLAN</tag>
        <tag>数据中心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vmware虚拟化概念原理]]></title>
    <url>%2F2018%2F04%2F13%2FVmware%E8%99%9A%E6%8B%9F%E5%8C%96%E6%A6%82%E5%BF%B5%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[虚拟化介绍什么是虚拟化：虚拟化是一种资源管理技术, 是将计算机的各种物理资源, 如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破物理设备结构间的不可切割的障碍，使用户可以比原本的架构更好的方式来应用这些资源。这些资源的虚拟部分是不受现有资源的架构方式、地域或物理设备所限制。 虚拟化创建了一层隔离层，把硬件和上层应用分离开来，允许在一个硬件资源上运行多个逻辑应用。 虚拟化有：服务器虚拟化、应用程序虚拟化、展现层虚拟化、桌面虚拟化。 常见的虚拟化： 内存虚拟化 磁盘虚拟化 网络虚拟化 VMware实现的是x86服务器的虚拟化，更确切地说，包含以下三个方面 计算能力：CPU/Memory的虚拟化 存储：VMFS文件系统 网络：虚拟交换机 服务器虚拟化的方式：服务器虚拟化有两种常见的类型 寄居架构（Hosted Architecture） 作为应用安装在OS之上 基于现有操作系统 兼容性好 性能较差 功能单一 裸金属架构（Bare Metal Architecture） 直接安装在硬件之上，本身就是OS 基于裸机（Bare Metal） 硬件兼容性要求高 性能好 有许多高级功能。 为什么要使用虚拟机：物理架构存在的问题： 难以复制和移动 受制于一定的硬件组件 生命周期短 物理服务器的资源利用率低 服务器虚拟化 将一台物理服务器虚拟成多台虚拟服务器。虚拟服务器由一系列的文件组成 虚拟机与物理机相比 最大化利用物理机的资源，节省能耗 更方便地获取计算资源 硬件无关。虚机都是文件，方便迁移、保护 生命周期更长，不会随着硬件变化而变化 根据需求的变化，非常容易更改资源的分配 更多高级功能 在线的数据、虚拟机迁移 高可用 自动资源调配 云计算 减少整体拥有成本，包括管理、维护等 vSphere基本架构： 图：vSphere 基本架构 虚拟化环境中的资源共享：物理机的资源被多个虚拟机共享：CPU、内存、网络、存储等。 CPU虚拟化： LCPU 逻辑运算单元 可供使用的物理资源 超线程对LCPU的影响 vCPU 虚拟化的CPU vmkernel 负责CPU资源调度 分时 内存虚拟化： 图：内存虚拟化示意图 由vmkernel控制 vmkernel控制物理内存 每个虚拟机拥有独立的连续可寻址的虚拟内存空间 采用多种技术优化内存的使用 物理内存不足时可以使用磁盘存储作为交换空间 网络虚拟化： 图：网络虚拟化示意图 通过虚拟网络交换机实现 连接虚拟机、vmkernel与外部物理网络，工作在第二层 虚拟网卡 虚拟机中运行的网卡 虚拟机对外进行网络通讯 vmkernel口-vmkernel对外进行网络通讯 物理网卡-上连物理网络，工作在第一次 存储虚拟化： 图：存储虚拟化 通过虚拟磁盘vmdk文件的封装实现 多个ESXi主机访问共享存储 虚机的虚拟磁盘以vmdk文件格式存放在存储中 每个虚拟机由一组文件组成 每个虚拟机有各自的目录 虚拟机的文件系统对ESXi主机不可见 vSphere与云计算： 虚拟化是云计算的基础 虚拟机在虚拟基础架构上运行 动态的计算资源池作为云计算的基础 支持各种云计算平台 VMware vRealize OpenStack 支持多种云环境 私有云 公有云 混合云 ESXi基本结构ESXi介绍：VMware ESXi是最核心的组件VMware ESXi是我们常说的ESXi主机，虚拟化层组件的作用：ESXi用于协调物理计算机的资源，同时通过ESXi管理其上的虚拟机，如部署、迁移等操作。同时还可以通过ESXi对物理计算机上的网络存储资源仅从管理，ESXi通过配置虚拟交换机上的vSwitch管理配置网络资源，通过VMfs和nfs管理虚拟存储资源。 核心Hypervisor - VMkernel 基于裸机的虚拟化 虚拟CPU/内存 VMFS存储支持 虚拟交换机支持 ESXi的安装方式 可以安装在本地硬盘，存储网络盘， USB/SD卡，或者内存中 VMware ESX的发展过程： 2006年，服务器有了第一款虚拟化产品—GSX，此时VMware的安装方式时现在物理机上安装操作系统，再将VMware作为应用程序安装在主机上，VMware通过宿主操作系统进行资源和操作系统的管理。这种将虚拟化程序安装在宿主机上的架构称为寄居式虚拟化。寄居式虚拟化最大的问题式过度的依赖于宿主操作系统。 2009年，VMware推出 ESX，VMware 直接将ESX安装在物理计算机上，这种安装方式称为裸机安装。但是ESX并不能完全的摒弃宿主操作系统，他的解决方法是将虚拟化程序和操作系统整合到一起。也就是说，他将虚拟化的程序写入到linux的操作系统中。此时，ESX通过linux系统的Servers Console来运行，而资源和虚拟机的管理工作则通过合作代理伙伴和编写脚本来执行。ESX有效的解决了对宿主操作系统过于依赖的问题。但是这种架构依然有他自己的缺陷，首先，由于虚拟化程序中包含linux的操作系统，linux的操作系统中非虚拟化部分的进程会占用主机上的部分资源，造成资源的浪费。其次，在进行资源和虚拟机的管理时，只能通过脚本和代理，非常的不方便。 2011年，VMware推出了ESXi,即为当前应用最广泛的虚拟化产品。同样，ESXi也是裸机安装在物理计算机上的，他做的改进是将虚拟化层中繁杂的linux层剔除，只保留了VMkernel虚拟化内核对资源进行管理。这样，便大大的额降低了虚拟化层的大小。同时，也减小了虚拟化层对物理化层的开销。ESXi做的第二大改进便是将控制台从虚拟化程序中移除，变成一个独立的组件，即Vsphere Client，使得管理工作更加的轻松便捷。 ESXi体系结构独立于通用的操作系统运行，从而简化了虚拟化管理程序管理并提高了安全性。 ESXi的优点： 精简的体系结构 更小的安全占用空间 简化的部署和配置 简化的修补和更新模式 ##ESXi基本架构： 图：ESXi基本架构 ESXi主机的管理方式： 独立的ESXi主机 直接访问ESXi主机 单独的管理界面，可管理项少 用户管理与授权由ESXi主机控制 常用于初始配置或者故障诊断 通过vCenter服务器管理多台ESXi主机 通过vCenter服务器访问ESXi主机 统一的管理界面，高级功能管理 可整合第三方管理插件 用户管理与授权由vCenter服务器控制 用于日常管理 图形界面 vSphere Client vSphere Web Client 通过API使用第三方软件 命令行 vCLI vMA PowerCLI *DCUI *SSH/ESXi Shell** API接口 图：ESXi主机的管理方式 vCenter服务器–数据中心的单一控制点vCenter介绍： vCenter Server： 定义：VMware vCenter Server是充当ESXi主机及其虚拟化中心管理点的服务。供管理员集中的统一的管理企业的虚拟化环境。 主要的作用是：提供集中的管理接口，供管理员可以管理整套的虚拟化环境。 也可以为虚拟化提供更高级的功能。如，虚拟机迁移，分布式的服务，快速部署虚拟机 vCenter的配置信息和清单信息主要保存在数据库中，这就是数据库服务器和数据库存储。 同时vCenter管理主机时，有部分服务需要在各个主机上，比如，分布式虚拟交换机需要一定的分布式服务，同时在管理虚拟化的环境时，需要有相应的权限管理以及ACL用户访问控制。同时，为了便于管理，需要统一的身份验证，vCenter提供了一些接口，供第三方程序进行连接。 虚拟化平台的管理服务器 提供配置、管理、访问控制、监控等基本数据中心服务 可管理最多1000台ESXi主机、10000台开机的虚拟机 vCenter服务器及逻辑组件架构： 图：vCenter逻辑组件架构 每个vCenter可以管理1千台ESXi服务器以及1万台开机的虚拟机 许多跨越ESXi主机的服务必须要vCenter支持 HA, FT, vMotion, DRS, Storage vMotion, Storage DRS, dVS 等等 vCenter服务器的主要逻辑组件包括： vCenter服务器 – 管理组件 数据库服务器 – 存放配置与性能数据 SSO组件 – 与LDAP或者AD服务器通讯，提供用户认证 清单服务 Inventory Service 用户管理界面 – vSphere Client或者使用浏览器+Flash连接Web Client vCenter其他组件： 管理接口vSphere API – 应用程序接口 vCenter Lookup Service包含关于 vSphere 基础架构的拓扑信息,使 vSphere 组件能够安全地互相连接 其它分布式服务 包括vMotion、DRS和vSphere HA,这些服务随vCenter Server一起安装 vCenter管理角色： 安装完vCente后，便带有的管理功能，包括资源管理，模板管理，虚拟机分布，虚拟机管理，安全任务事件，和日志主机管理等 可扩展的组件，比如云平台管理，站点恢复管理，APP接口和更新管理等。 在安装vCente时，可以自由选择是否安装可扩展的插件。注意，可扩展模块是包括一个服务器组件和一个客户端组件。 VMware虚拟机及虚拟机管理介绍什么是虚拟机：什么是虚拟机：虚拟机是一个逻辑的计算机，可以在其上运行受支持的客户端操作系统和应用程序的虚拟硬件集；从本质上来说，或者是从存储的角度来看，是一组离散的文件。虚拟机文件包括 .vmx – 虚拟机配置文件（文本） .nvram – 虚拟机BIOS文件（二进制） .vmdk – 虚拟磁盘描述文件（仅描述信息，非常小） -flat.vmdk – 虚拟磁盘数据文件（实际数据） -rdm.vmdk – 裸设备映射虚拟磁盘文件 .vswp/vmx-***.vswp – vmkernel swap文件，也称为虚拟机交换文件 .vmtx –模板的配置文件（文本） .vmsd/.vmsn/-delta.vmdk – 虚拟机快照文件及磁盘delta数据文件 .log – 虚拟机日志文件 .vmss – 挂起状态文件 虚拟机的模板： 通过虚拟机的模板快速的部署虚拟机 模板是虚拟机的主副本，用于创建和部署新的虚拟机。 模板通常包括一个客户操作系统，一组应用程序和一个特定的虚拟机配置的映像。 管理模板: 在制作模板时，我们可以选择将虚拟机转化为模板，也可以选择克隆为模板。 若是转换为模板，则是选择为该虚拟机添加模板标记，并转化为模板，效率很快，此时虚拟机必须处于关闭状态才可以进行。 若选择克隆为模板，则是先客隆虚拟机，再制作模板，所以，耗时很长，但是克隆为模板时，虚拟机的电源是可以开启的，也可以是关闭的。 在选择用模板部署虚拟机时，可以选择通过模板部署虚拟机，也可以选择转换为虚拟机，来修改模板。同时，在部署虚拟机的过程中，我们可以选择使用规范或者自定义的向导完成部署后的自定义工作。比如，刷新SID，加入域等，以减少部署虚拟机后的后序工作。 克隆虚拟机：克隆是虚拟机的一个精确副本，被克隆的虚拟机的电源是可以开启的，也可以是关闭的。 ##迁移类型： 迁移主机 迁移存储 同时迁移主机与存储 虚拟机迁移的方式： 图：迁移方式 冷迁移 虚拟机电源处于关闭或者挂起状态 可以迁移主机、存储、或者两者同时迁移 热迁移：虚拟机电源处于开机状态 迁移主机 – vMotion 迁移数据存储 – Storage vMotion 同时迁移主机和存储 – Cross-Host vMotion，或者称为无共享存储的vMotion vSpher vMotion：虚拟机开机时，将虚拟机从一个主机在线迁移到另一个主机 虚拟机数据应当位于可以被两台主机同时访问的共享存储上 两台主机的CPU必须兼容 主机与虚拟机需要满足vMotion的条件 用于 减少由于主机维护、升级等引起的虚拟机计划内宕机时间 可以用于控制主机资源的负载均衡 Storage vMotion：虚拟机开机时，将虚拟机从一个存储在线迁移到另一个存储 不可以跨越虚拟数据中心 不迁移主机、无宕机时间 应用场景 减少由于存储维护引起的计划内宕机时间 存储资源的负载均衡 在线地更改虚拟磁盘格式及文件名 迁移类型的对比： 虚拟机快照： 通过快照保留虚拟机的状态，以便可以反复的回到同一状态。 快照提供了一种临时的容错解决方案 快照的工作原理：当为虚拟机拍摄快照时，回生成快照的状态文件，保留拍摄快照时虚拟机运行的状态信息，同时，将元虚拟机的磁盘变为只读磁盘，并且新建一块新的增量虚拟磁盘，拍摄快照后的变更数据，写入增量虚拟磁盘中；恢复快照时，将增量虚拟磁盘删除，清除所有变更后的快照信息。并再次新建增量磁盘，如果想在删除快照，则上块增量虚拟磁盘中的数据写入到只读磁盘中，并删除增量虚拟磁盘，这样就保留了快照后的信息，删除了快照节点，可以在开启，关闭和挂起时拍摄快照。拍摄快照也可以选择是否捕获虚拟机内存状态，设置状态和虚拟的磁盘状态 但是，虚拟机快照只是一种临时的容错方案，不能替代备份方案，如果虚拟机的数据损坏，快照无法完成修复。所以，依然需要规划虚拟机的数据保护。同时，为了比避免增量磁盘过大，需要对虚拟机的快照做及时的删除。 虚拟机快照是虚拟机某一时间点的状态 虚拟机磁盘状态 虚拟机BIOS及配置状态 虚拟机内存状态 可以通过快照记录虚拟机状态 用于测试、备份数据源、快速恢复等用途 VMware可用性及可扩展性的介绍VMware各级容灾方案： 在站点级别：有set recovery manager,实现站点的数据备份。 在数据级别，有VMware Data Recovery以及其他第三方的备份解决方案 在存储级别：通过Storage vMotion可以保存储的可用性 在服务器级别：有VMware vSphere和vMotion 和DRS动态资源分布等保证主机级的可用性。 在组件级别：有网卡绑定、存储多路径等功能保障网络、存储的可用性。 VMware为我们提供了针对故障的保护，实现零停机的计划运维，同时，针对计划外的停机和灾难也提供了相应的保护机制 VMware在虚拟化级别为我们提供的解决方案—HA（High Availability） HA的作用：高可用性，停机时间最少，可用于支持的客户操作系统，可用于支持所有的EXSXI硬件，用于为需要这种保护级别的虚拟机提供高可用行 HA的适用故障 主机故障 客户OS故障 应用程序故障 HA如何实现高可用？当服务器发生故障时，HA自动的到其他的虚拟机上进行虚拟机的重启，保障其虚拟机的可用性以及业务的连续性 HA的优势：HA是一套经济有效的适用于所有应用的高可用的解决方案因为HA不需要独占stand-by硬件，也没有集群软件的成本和复杂性，只需要在集群中启用HA的功能即可。 HA的缺陷：HA可以为组织提供自信的运行其关键业务能力的应用程序的能力，但是是通过重启虚拟机来实现的，有些虚拟机的重新启动的速度很慢，这时业务的连续性就比较低，甚至有些虚拟机需要开机后，在手动的进行某些配置才可以提供服务。仅仅时自动重启，并不能满足高可用性。 Fault Tolerance（FT）FT容错系统的设计目标是：出现计划外的中断时，某个备份的虚拟机可以立即去完成任务，确保不出现服务的中断。FT体提供了比HA更高的业务连续性实现了应用程序的零停机和零数据丢失。 虚拟化的可扩展性—DRSDRS—Distributed Resource Scheduler,动态负载均衡DRS实现了动态负载均衡连续的智能优化保证了所有的应用需要的资源。DRS可以实现跨资源池的动态调整计算资源，可基于预定义的规则，智能的分配资源。注意：规划DRS时，是围绕着业务进行组织和规划的，而不是硬件 DRS如何实现动态的扩展？【当有新主机的加入时】当有新主机的加入时，DRS自动的将资源池扩展，经过计算后，自动的将虚拟机迁移到新的主机上，这样，变更利于添加更多的资源，避免业务繁忙时，出现过载的现象。]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>华为网络大赛</tag>
        <tag>Vmware</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云数据中心基础]]></title>
    <url>%2F2018%2F04%2F13%2F%E4%BA%91%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[数据中心概述： DC (Data Center) 企业IT系统的核心 海量数据运算、交换、存储的中心 关键信息业务应用的计算环境 集中管控各种数据、应用程序、物理或虚拟化设备的环境 数据中心四大焦点：可靠、灵活、绿色、资源利用率。 传统数据中心面临的问题： IT复杂： 30%传统数据中心资源分散，利用率低。 平均业务恢复时间长。100分钟。 80%工程师手工分配资源。 5+运维工具，传统数据中心IT设备需要。 商业迟缓： 大数据处理能力差，不能有效提升商业嗅觉。 资源需求无法弹性适配。 不能有效支持企业生命周期发展。 多DC分散管理协同性差，商业注意力难以集中。 解决传统问题的最佳途径—云计算： 虚拟化：大模块集群，资源全面虚拟化。 安全可靠：端到端安全设计，高可用性软硬件架构，跨域容灾。 自动化：自动资源分配，故障自愈，可运营自主服务。 绿色：能耗智能管理，模块化机房，智能测量评估。 数据中心趋势 — 数据中心迈向云时代：数据中心发展过程： 主机时代：分散化 局域网架构，大小型机构建，小型数据中心。 互联官网时代：集中化 WWW网架构，X86服务器参与共建，各种大型数据中心涌现。 云计算时代：模块化 云计算架构，X86服务器主流，模块化部署。 虚拟化、云计算技术牵引新一代数据中心系统架构的迁移。 下一代数据中心架构与场景下一代数据中心整体架构： 图：下一代数据中心整体架构 下一代数据中心场景一：运营商IDC公有云 图：IDC共有云场景方案 为IDC运营商提供端到端的IDC公有云解决方案： 提供多种云计算业务和传统业务组合。 提供一站式整体IDC运营管理方案。 提供云计算华为物理环境的同一IT运营管理方案。 提供高性价比的资源池化平台。 业务价值： 摆脱传统IDC业务类型同质化竞争。 特色的云业务和应用服务带来新的盈利和管道流量的创收。 实现传统业务和云计算业务统一运营，提升运营能力。 降低IT管理复杂度和OPEX，提升管理效率35%以上。 提升IDC资源使用率，节省CAPEX投资30%以上。 下一代数据中心场景二：园区IDC公有云 图：园区IDC公有云 场景方案： 网络租赁方案 业务开展服务器租赁方案 数据存储租赁方案 数据库租赁方案 桌面云方案 安全服务方案 业务价值： 零成本创业、低成本迁移 快速创建云主机 低成本桌面云 贴心服务、政企沟通 总包式服务 灵活多样的定制服务 资源配置智能 随需应变的弹性服务 支持企业全业务发展 支撑能力全面 移动服务的全园区覆盖 随时随地响应业务 下一代数据中心场景三：电子政务IT托管私有云 图：IDC IT外包–政府场景 IDC电信运营商为政府提供政务外网的应用外包方案建设和应用外包服务: 三数据中心容灾和远程数据备份方案 针对ITO设计典型的IT服务流程和IT管理方案 网络对接方案设计实现网络的可靠性和网络质量 提供访问安全、网络安全和数据安全保障 业务价值： 政务外网的托管带来管道业务流量的增长创收； 政府作为核心大客户带来长期稳定的盈利； 政府客户的特性确保稳健的现金流； 政务网外网的托管实现将多年运维经验转化为盈利能力； 政务外网新业务的开展实现业务创新，带来整体竞争力的提升。 下一代数据中心场景四：大企业IT托管私有云 图：IDC IT外包-大企业场景 IDC电信运营商为企业客户提供应用外包方案建设和应用外包服务: 提供高性价比的虚拟化计算平台 提供可扩展的整柜方案满足IT架构的动态扩展 提供三数据中心容灾和远程数据备份方案 提供访问安全、网络安全和数据安全保障 业务价值： 大企业IT的托管带来管道业务流量的增长创收； 大客户带来长期稳定的盈利； 大企业IT的托管实现将多年运维经验转化为盈利能力； 添加增值业务，承载高附加值服务，带来整体竞争力的提升。 下一代数据中心关键技术：数据中心热点技术：云计算、数据中心网络、容灾备份、安全技术、绿色机房、运营管理、整合迁移、虚拟化技术等。 云计算： 云计算是一种提供动态、弹性的虚拟化资源的服务模式 从服务层次的角度，可分为IAAS, PAAS, SAAS 云计算的特点： 高效 存储利用率: 40%内存利用率50%虚拟化性能损耗&lt;5% 开放性 兼容主流的服务器统一管理主流的虚拟化平台支持DTMF, Amazon API 自动化 智能资源调度自动化部署 虚拟化技术：虚拟化前：IT资源独立，操作系统必须与硬件紧耦合。 虚拟化后：资源抽象成共享资源池，上层操作系统与硬件解耦，操作系统从资源池中分配资源。 虚拟机四大特点： 分区：在单一物理机上同时运行多个虚拟机。 隔离：同一物理机上多个虚拟机相互隔离。 封装：整个虚拟机执行环境封装在独立的文件中。 独立：虚拟机无需修改可运行在任何物理机上。 端到端的安全防护：云数据中心面临的各种威胁，对安全解决方案提出更全面的要求。 防火墙安全 防火墙、 VPN接入、多因素身份认证、流量清洗、安全域划分、多因素身份认证。 虚拟化安全 云管理应用加固、恶意虚拟机防护、虚拟机模板安全加固 、HyperVisor加固 、虚拟机隔离。 数据安全 云管理应用加固、HyperVisor加固、数据加密密钥管理。 用户管理 身份识别访问管理、双因素强认证、特权用户访问管理审计。 数据中心灾备： 数据中心绿色机房： 数据中心网络，扁平化、模块化： 数据中心统一管理，简化管理、敏捷运营： 数据中心整合迁移技术： 云计算是下一代数据中心的核心技术，虚拟化技术是云计算的灵魂，而在云数据中心的环境里安全，容灾等技术是客户关注的重点技术。数据中心网络，管理，机房属于数据中心的基础技术，如何实现传统数据中心到云数据中心过渡和迁移是数据中心技术的又一个热点技术。]]></content>
      <categories>
        <category>数据中心</category>
      </categories>
      <tags>
        <tag>华为网络大赛</tag>
        <tag>云数据中心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[备份容灾技术基础]]></title>
    <url>%2F2018%2F04%2F12%2F%E5%A4%87%E4%BB%BD%E5%AE%B9%E7%81%BE%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[备份概念及结构备份的基本概念：备份：指将文件系统或数据库系统中的数据加以复制；一旦发生灾难或错误操作时，得以方便而及时地恢复系统的有效数据和正常运作。 备份系统的组成： 备份服务器 备份软件 存储设备 备份的结构：软件结构： 图：NBU软件备份架构 LAN Based： 图：LAN Based结构 优点： 备份系统和应用系统分开，备份时不占用应用服务器的硬件资源。 缺点： 备份的代理会影响应用服务器的性能。 备份数据基于LAN，影响网络性能。 对用户业务处理能力的要求较高。 LAN FREE: 图：LAN Free架构 优点： 备份数据流不占用LAN资源，大大提高备份性能，且不影响用户网络性能；备份速度比较快。 缺点： 备份的代理会影响应用服务器的性能。 对用户业务处理能力的要求较高。 常见的备份D2D：D2D：磁盘-磁盘的数据备份。 常见的备份D2T：D2T：磁盘-物理磁带库的数据备份。 常见的备份D2V：D2V：磁盘-虚拟磁带库的数据备份。 常见的备份D2D2T：D2D2T：磁盘-虚拟磁带库-物理磁带的数据备份 备份技术：数据重删技术和压缩技术：重删和压缩时完全不同的两种技术，解决不同的问题。 重删：就是说有很多分相同的数据，我只存储其中一份，其他的重复数据块我保留一个地址引用到这个唯一存储的块即可。 重删技术可以按照重删的位置、时刻、粒度、范围等多个维度进行分类。 压缩：将一个大字符串中的子串用一个很简短的数字来标记，然后检索该字符串出现的位置，用个简单的字符来替代。从而来减少数据表达所需要的空间，带来空间节省。 比如说用1代表“AB”，用2代表“CD”，然后用255 来表“hanfute”。1到255只需要8个bit，而“AB”“CD”或者“hanfute”则需要很多的空间，这样多次扫描替代之后，就可以快速的将数据缩减。 用通俗的话说：重删就是讲相同的东西只存储一次，而压缩则是改造数据排布用一种算法来统计数据的排布模式，从而达到减少数据存储的模式。 重复数据删除与压缩的区别： 备份策略制定备份策略的内容： 数据类型 文件、操作系统、数据库、裸设备备份、备份软件日志 备份介质 磁盘、磁带、备份服务器 备份类型 全量备份：每天全备份，易于管理。 增量备份：每周一天全备份，周其余每天备份和上次备份的差异部分。 差量备份：每周一全备份，本周其余每天备份和全备份的差异部分。 数据保留时间 一周、一个月、一年 备份数据保留周期：即在介质上存放的备份数据的有效期，在保留周期内的数据是不允许被覆盖，当数据存放时间超过保留周期后，该部分数据所使用的介质空间可以被覆盖，从而释放介质空间。 备份周期 每天备份、每周备份 备份窗口 备份时间范围 备份窗口（Backup window）：是指在不严重影响使用需要备份的数据的应用程序情况下，进行数据备份的时间间隔，也就是完成一次给定备份所需的时间。 容灾介绍容灾分类： 业务级容灾 应用级容灾 数据级容灾 容灾建设国际标准：根据国际组织提出的标准，可以将系统容灾的级别划分为如下7级。 图：容灾建设国际标准 容灾系统建设：总体设计：灾备系统建设三要素 流程：保障容灾系统正常运行工作流程，包括，切换流程、回切流程、测试流程和演习流程等。 技术：容灾系统建设涉及到的技术，包括数据复制技术、应用切换和网络切换技术等。 人员：在容灾系统建设分析、设计、实施和维护等过程中涉及的人员及组织。 容灾系统建设四步走： 需求分析 容灾系统实施前，对客户情况进行全面分析，包括业务影响分析和风险分析。 策略制定 制定适合客户情况的容灾方案和策略。 方案实施 按完善的实施方案建设容灾系统。 管理维护 容灾系统运行后的日常维护，包括演练管理和灾难恢复管理。 建设流程： 恢复流程： 衡量指标：RPO（Recovery Point Objective）恢复点目标： 灾难发生后，系统和数据必须恢复到的时间点要求； 值越小表明丢失的数据越少。 RTO（Recovery Time Objective）恢复时间目标： 灾难发生后，信息系统或业务功能从停顿到必须恢复的时间要求； 值越小表明业务中断时间越小。 典型容灾应用—两地三中心：]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>华为网络大赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SAN技术及应用]]></title>
    <url>%2F2018%2F04%2F12%2FSAN%E6%8A%80%E6%9C%AF%E5%8F%8A%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[传统存储的结构与缺点存储网络集中常见的类型： 图：存储网络常见的类型 DAS基础概念：DAS技术是最早被采用的存储技术，如同PC机的结构，是把外部的数据存储设备都直接挂在服务器内部的总线上，数据存储设备是服务器结构一部分，但由于这种存储技术是把设备直接挂在服务器上，随着需求的不断增大，越来越多的设备添加到网络环境中，导致服务器和存储独立数量较多，资源利用率低下，使得数据共享受到严重的限制。因此适用在一些小型网络应用中。 DAS存储更多的依赖服务器主机操作系统进行数据的IO读写和存储维护管理，数据备份和恢复要求占用服务器主机资源（包括CPU、系统IO等），数据流需要回流主机再到服务器连接着的磁带机（库），数据备份通常占用服务器主机资源20-30%，因此许多企业用户的日常数据备份常常在深夜或业务系统不繁忙时进行，以免影响正常业务系统的运行。直连式存储的数据量越大，备份和恢复的时间就越长，对服务器硬件的依赖性和影响就越大。 直连式存储与服务器主机之间的连接通道通常采用SCSI连接，随着服务器CPU的处理能力越来越强，存储硬盘空间越来越大，阵列的硬盘数量越来越多，SCSI通道将会成为IO瓶颈；服务器主机SCSI ID资源有限，能够建立的SCSI通道连接有限。 无论直连式存储还是服务器主机的扩展，从一台服务器扩展为多台服务器组成的群集(Cluster)，或存储阵列容量的扩展，都会造成业务系统的停机，从而给企业带来经济损失，对于银行、电信、传媒等行业7×24小时服务的关键业务系统，这是不可接受的。并且直连式存储或服务器主机的升级扩展，只能由原设备厂商提供，往往受原设备厂商限制。 DAS的结构与缺点： 图：DAS的结构 开放系统的直连式存储(Direct-Attached Storage，简称DAS) DAS的优点： 1、部署简单 2、成本低 3、适合本地数据存储 DAS存储缺点 扩展性差 资源浪费 管理分散 异构化问题 数据备份问题 DAS采用的连接协议： ATA（IDE）和SATA SCSI（又分为并行和串行，并行适合内部DAS，串行适合外部DAS） FC SAN存储基本结构SAN存储定义及组网：SAN：存储区域网络（Storage Area Networks）是通过专用高速网将一个或多个网络存储设备和服务器连接起来的专用存储系统。 图：SAN的三种组网方式 如上图，SAN有三种组网方式，分别为： 直连组网 单交换组网 双交换组网 SAN组件介绍： 存储阵列设备 光纤交换机 主机总线设配卡 光纤线缆 图：SAN组件 SAN存储特点： 业务高性能 集中、远程、灵活的管理 存储资源动态共享 不占用业务网络资源 高扩展性 兼容SCSI存储设备 SAN与DAS区别： 项目 DAS SAN 支持的协议 SCSI协议 FC协议、ISCSI协议 适合场景 对存储容量要求不高、服务器数量很少的中小型局域网 关键数据库、集中存储、海量存储、备份、容灾等中高端存储应用环境 特点 部署简单、投资少 高可用性、高性能、高扩展性、兼容性、集中管理 缺点 可扩展性差、资源浪费、不易管理、性能瓶颈 投资相对较高 FC-SAN存储：FC协议介绍：FC（Fibre Channel）协议简介：FC是由美国标准化委员会（ANSI）的X3T11小组于1988年提出的高速串行传输总线，解决了并行总线SCSI遇到的技术瓶颈，并在同一大的协议平台框架下可以映射更多FC-4上层协议，最早是用来提高硬盘协议的传输带宽，侧重于数据的快速、高效、可靠传输。FC协议其实并不能翻译成光纤协议，只是FC协议普遍采用光纤作为传输线缆而不是铜缆，因此很多人把FC称为光纤通道协议。在逻辑上，我们可以将FC看作是一种用于构造高性能信息传输的、双向的、点对点的串行数据通道。在物理上，FC是一到多对应的点对点的互连链路，每条链路终结于一个端口或转发器。FC的链路介质可以是光纤、双绞线或同轴电缆。 FC拓扑结构： 图：FC拓扑结构 各种拓扑的对比: 协议栈： 图：FC协议栈 FC光纤通道拥有自己的协议层，它们是： FC-0：连接物理介质的界面、电缆等；定义编码和解码的标准。l FC-1：传输协议层或数据链接层，编码或解码信号。l FC-2：网络层，光纤通道的核心, 定义了帧、流控制、和服务质量等。l FC-3：定义了常用服务，如数据加密和压缩。l FC-4：协议映射层，定义了光纤通道和上层应用之间的接口，上层应用比如：串行SCSI 协 议，HBA卡的驱动提供了FC-4 的接口函数。FC-4 支持多协议，如：FCP-SCSI，FC-IP，FC-VI。 光纤通道的主要部分实际上是FC-2。其中从FC-0到FC-2被称为FC-PH，也就是“物理层”。光纤通道主要通过FC-2来进行传输，因此，光纤通道也常被成为“二层协议”或者“类以太网协议”。 FC-SAN系统组成: 图：FC-SAN系统组成 存储设备：存储设备上的FC接口模块提供了应用服务器与存储系统的业务接口，用于接收应用服务器发出的数据交换命令。 光纤交换机：光纤通道交换机在逻辑上是SAN的核心，它连接着主机和存储设备。 光纤交换机的主要功能如下： 自配置端口、环路设备支持、交换机级联、自适应速度检测、可配置的缓冲、分区（基于物理端口和基于WWN的分区）、IP over Fiber Channel（IPFC）广播、远程登录、Web管理、简单网络管理协议（SNMP）以及SCSI接口独立设备服务（SES）等。 Zone概念： Zone是可进行互通的端口或设备的名称构成的集合 在一个zone里的设备只能与同一个zone中的其他设备通信 一个设备可以同时在多个zone里 图：光纤交换机–zone 光模块： 光通道交换机光模块由光电子器件、功能电路和光接口等组成。光电子器件包括发射和接收两部分。 按照速率分：以太网应用的100Base（百兆）、1000Base（千兆）、10GE SDH应用的155M、622M、2.5G、10G 按照封装分：1×9、SFF、SFP、GBIC、XENPAK、XFP 按照光纤的类型分：单模光纤连接器、多模光纤连接器 按照光纤连接器的连接头形式分：FC，SC，ST，LC，MU，MTRJ 等等 目前常用的有FC，SC，ST，LC。 图：光模块 FC HBA卡： HBA（Host Bus Adapter）： 主机总线适配器，就是连接主机I/O总线和计算机内存系统的I/O适配器。 分类： FC HBA、SCSI HBA、SAS HBA、iSCSI HBA等。 用途： 用于服务器、海量存储子网络、外设间通过集线器、交换机和点对点连接进行双向、串行数据通讯 WWNN（World Wide Node Name）全球唯一节点名字 WWPN（World Wide Port Name）全球惟一端口名字 IP-SAN存储IP-SAN基础： 什么是IP-SAN： 以TCP/IP协议为底层传输协议，采用以太网作为承载介质构建起来的存储区域网络架构。 实现IP-SAN的典型协议是iSCSI，它定义了SCSI指令集在IP中传输的封装方式。 图：IP-SAN架构 IP-SAN优点： 接入标准化 不需要专用的HBA卡和光纤交换机，普通的以太网卡和以太网交换机就可以存储和服务器的连接。 传输距离远 理论上IP网络可达的地方就可以使用IP SAN，而IP网络是目前地球上应用最为广泛的网络。 可维护性好 广大的具备IP网络技术的维护人员和强大的IP网络维护工具支撑。 带宽扩展方便 随着10Gb以太网的迅速发展，IP SAN单端口带宽扩展到10Gb已经是发展的必然。 IP-SAN面临的挑战： 数据安全性 数据在传输过程的安全性和在存储设备中的安全性是IP SAN存储面临的严峻问题。 TCP负载 TCP为了完成数据的排序工作需要占用较多的主机CPU资源导致用户业务处理延迟的增加 块数据传输。 IP协议比较适合传输大量的小块消息，对大块数据的传输的效率还有待提高。 FC-SAN与IP-SAN比较： IP-SAN的组件： 图：IP-SAN的组件 iSCSI连接方式：IP-SAN根据主机与存储的连接方式不同，可以分为三种： 以太网卡+Initiator软件实现方式 TOE网卡+Initiator软件实现方式 iSCSI HBA卡连接方式 iSCSI协议：iSCSI（Internet SCSI）把SCSI命令和块状数据封装在TCP中在IP网络中传输，基本出发点是利用成熟的IP网络技术来实现和延伸SAN。 图：iSCSI协议 iSCSI体系结构：iSCSI节点将SCSI指令和数据封装成iSCSI包，然后该数据封装被传送给TCP/IP层，再由TCP/IP协议将iSCSI包封装成IP协议数据以适合在网络中传输。 iSCSI的发起端与目标端： 发起端（Initiator） SCSI层负责生成CDB（命令描述符块），将CDB传给iSCSI iSCSI层负责生成iSCSI PDU（协议数据单元），并通过IP网络将PDU发给target 目标器（Target） iSCSI层收到PDU，将CDB传给SCSI层 SCSI层负责解释CDB的意义，必要时发送响应 图：iSCSI传输示意图 iSCSI数据包封装模型：所有的SCSI命令都被封装成iSCSI协议数据单元，iSCSI利用TCP/IP协议栈中传输层的TCP协议为连接提供可靠的传输机制。 图：iSCSI报文格式 FC-SAN与IP-SAN融合FC协议与TCP协议融合：目前FC与TCP/IP协议的真正融合主要有两种趋势： TCP/IP网络承载FC信道 FCIP iFCP FCOE 以FC信道承载TCP/IP数据 IPFC 从现有的情况来看，以太网技术和FC技术都在飞速发展IP-SAN和FC-SAN会在很长的一段时间内都将是并存且互为补充的。 FCoE协议： FCoE（Fibre Channel over Ethernet）以太网光纤通道：FCoE允许在一根通信线缆上传输LAN和FC SAN通信，融合网络可以支持LAN和SAN数据类型，减少数据中心设备和线缆数量，同时降低供电和制冷负载，收敛成一个统一的网络后，需要支持的点也跟着减少了，有助于降低管理负担。 FCoE把FC帧封装在以太网帧中，允许LAN和SAN的业务流量在同一个以太网中传送。 FCoE协议的封装：FCoE是把FC-2层以上的内容封装到以太网报文中进行承载。 图：FCoE协议的封装 FCoE–CEE:基于优先级的流量控制（PFC）+ 增强的传输选择（ETS） + 拥塞报告 FCoE采用增强型以太网作为物理网络传输架构，能够提供标准的光纤通道有效内容载荷。 融合增强型以太网（CEE）可以避免类似TCP/IP协议的开销和数据包损失。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>华为网络大赛</tag>
        <tag>SAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NAS技术及应用]]></title>
    <url>%2F2018%2F04%2F12%2FNAS%E6%8A%80%E6%9C%AF%E5%8F%8A%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[NAS的基本概念NAS的概念：NAS （Network Attached Storage）网络附加存储：是一种将分布、独立的数据进行整合，集中化管理，以便于对不同主机和应用服务器进行访问的技术。 图：NAS架构 存储系统的演进： DAS(Direct-Attached Storage）开放系统的直连式存储 磁盘和其它模块在一个服务器机箱中，也可置于服务器外部。 SAN(Storage Area Network)存储区域网络 服务器通过FC、IP网络连接磁盘阵列。 磁盘阵列走向网络化，成为包交换网络上的一个节点。磁盘阵列可同时被多个节点访问。 NAS（Network Attached Storage）网络附加存储 文件系统层次之下的模块转移到外部独立设备中。 主机只负责处理自身业务。 NAS网络拓扑： 图：NAS的网络拓扑结构 集群NAS：集群技术 定义： 集群是由一组相互独立的服务器组成，对外表现为单一服务器，提供高可靠性服务。 特点： 统一命名 高可靠性 性能扩展 共享数据空间 集群NAS优点： 可靠性 故障切换快速；双控模式采用Active-Active模式，集群单个节点故障不影响业务。 高性能 引擎架构可扩展；共享存储设备；文件系统位于存储侧，读取速度快。 可扩展性 多层面提供扩展优势：NAS机头，存储容量；支持在线扩展。 易用性 支持统一存储；通用操作系统易于管理。 NAS与FTP比较： FTP NAS 优势 服务多样化、功能强大、易用、操作简单 稳定性、可靠性高、数据安全性高、存储空间大、具有容灾、备份设计、支持NFS，CIFS，AFP协议 劣势 支持协议比较单一、无容灾设计、数据安全性差 提供的服务种类相比文件服务器有不足 NAS系统的组成NAS系统架构： 图：NAS系统架构 NAS系统组成： 图：NAS系统组成 NAS引擎 提供文件系统，以及承载文件系统、各种前端协议的操作系统 网络接口 提供用户交互的网络协议：NFS、CIFS 存储系统 主要技术是RAID、SCSI、SAS、FC等技术 NAS文件共享协议CIFS、NFSCIFS协议介绍： CIFS（Common Internet File System） 通用Internet文件系统 ，一个新提出的协议，它使程序可以访问远程Internet计算机上的文件并要求此计算机的服务。CIFS可以看做是应用程序协议如文件传输协议和超文本传输协议的一个实现。 架构 客户/服务器模式 应用 Windows系统共享文件的环境 传输协议 TCP/IP NFS协议介绍： NFS (Network File System ) 网络文件系是Unix系统间实现磁盘文件共享的一种方法，支持应用程序在客户端通过网络存取位于服务器磁盘中数据的一种文件系统协议。NFS允许一个系统在网络上与它人共享目录和文件。通过使用NFS，用户和程序可以象访问本地文件一样访问远端系统上的文件。 架构 客户端/服务器架构 应用 主要应用在UNIX、LINUX环境 传输协议 TCP或者UDP CIFS和NFS的对比： 如果文件系统已经设置为CIFS共享，则此文件系统只能设置为只读的NFS共享。 如果文件系统已经设置为NFS共享，则此文件系统只能设置为只读的CIFS共享。 NAS文件系统IO与性能NAS文件系统架构： 图：NAS文件系统架构 主机侧： 主机客户端本身配置较低 — 处理器性能低 主机上运行的业务程序过多 — 负荷过载 网络方面： 跳转次数 由于访问过程中经过的网络设备很多，大量的网络包跳转会增加延迟。 重传 链路错误、缓冲区溢出和流量控制机制都会导致重传，不恰当的配置会导致错误和重传，增加延迟。 目录服务认证 例如LDAP、活动目录或NIS：认证服务是网络上必须的服务，大量的认证请求发向服务器会增加延迟 路由交换机性能。 在网络中，一个过载的设备所需要的响应时间总是比优化状态下使用或低负载使用的设备所需要的响应时间要长。 设备侧： 设备过载 文件目录查找 阵列降级 阵列性能低下 SAN与NAS比较SAN与NAS对比： SAN是只能独享的数据存储池，NAS是共享与独享兼顾的数据存储池。 NAS是网络外挂式，而SAN是通道外挂式。 NAS适用CPU密集型。 应用程序内部逻辑复杂，占CPU资源多，对磁盘的实际IO操作较少。 SAN适用IO密集型。 应用程序内部逻辑简单，占CPU资源不多，但存储数据量比较大并且较频繁。 NAS产品应用—云备份场景： NAS产品应用—存储整合场景：]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>NAS</tag>
        <tag>华为网络大赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储阵列技术及应用]]></title>
    <url>%2F2018%2F04%2F11%2F%E5%AD%98%E5%82%A8%E9%98%B5%E5%88%97%E6%8A%80%E6%9C%AF%E5%8F%8A%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[存储阵列系统组成存储阵列系统： 图：存储阵列系统架构 存储阵列由存储硬件、存储软件和解决方案三层组成。 存储阵列硬件组成：存储阵列硬件系统又两部分组成： 控制框 控制框用于处理各种存储业务，并管理级联在控制框下面的硬盘框。 硬盘框 硬盘框主要用于容纳各种硬盘，为应用服务器提供充足的存储空间。 硬盘框组成部件：系统插框、电源模块、风扇模块、级联模块、硬盘模块。 存储阵列软件组成： 图：存储阵列软件组成 华为存储阵列技术华为存储阵列技术总览: 图：华为存储技术总览 高可靠性：器件冗余（对控）、硬盘坏道检测/修复、磁盘健康分析、多路径技术、BBU掉电保护、RAID重构、缓存镜像技术、磁盘保险箱技术、磁盘与拷贝技术、块照/克隆技术、LUN拷贝、远程复制等。 可扩展性：Sacle-out、iSCSI、FC技术、SAS技术、PCI-e、FcOE. 高性能：块虚拟化技术、cache回写、cache预取技术、12GbSAS、16Gb FC。 高可用性：SmartTier技术、SmartQoS技术、Smart Thin技术。 高可靠性存储阵列技术：器件冗余： 控制器模块冗余 接口模块冗余 管理模块冗余 电源模块冗余 风扇模块冗余 BBU模块冗余 多控技术：双控制器系统的工作模式: 主备模式（AP） 双活模式（AA）— 华为存储都采用AA模式 图：多控技术 硬盘坏道检测技术：读写失败自动分析： 根据失败有多重原因。 根据系统当前状态、硬盘状态、IO失败信息等进行综合分析。 硬盘截止自动扫描： 直接使用硬盘的内建介质扫描功能 避免了硬盘扫描后多后端带宽的占用 将对系统性能的影响降到最低 磁盘坏道修复技术： 图：RAID 5 坏道修复示意图（红色色表示坏道） 磁盘健康分析DHA：DHA（Disk Health Analyzer）系统包括: 硬盘信息采集模块 分析模块 Call Home模块 数据预处理 硬盘信息数据库 数据分析 图：DHA系统原理图 多路径技术： 通过多跳路径，增加实现了线路冗余。 图：多路径技术 镜像技术:两个控制器的写Cache数据通过相互镜像实现备份，确保数据的安全和完整，提高了系统的可靠性。 图：镜像技术 镜像通道：SAS、PCI-e、FC. 实现机制：读Cache、写Cache、镜像Cache。 读策略： 智能预取：对主机读请求进行连续性判断。如果是连续的请求，则将当前读请求后面的一段数据从硬盘预取到Cache中，提高读Cache命中率。如果是随机读，则不预取，只从硬盘读取需要的部分。 固定预取：Cache读取硬盘数据时，每次从硬盘中读取固定的长度（用户配置）。 可变预取：按照主机I/O请求中读取长度的倍数将数据预取到Cache中。 写策略： 透写：应用下发写数据请求时，既将数据写入Cache，同时也将数据写入硬盘。 回写/镜像：应用下发写数据请求时，将数据写入本地Cache，同时也将数据写入对端Cache。 强制回写/镜像：当存储系统发生故障（例如高温故障或BBU供电不足）时，强制将数据写入本地Cache，同时也将数据写到对端Cache。 强制回写/不镜像：当存储系统发生故障（例如高温故障或BBU供电不足）时，强制将数据写入本地Cache。 数据保险箱技术：数据保险箱技术：用于保存Cache数据，避免因系统意外断电时数据丢失。内置BBU电池可保证在系统意外断电时，对Cache和系统保险箱硬盘同时供电，让Cache中的数据写到数据保险箱中，实现Cache数据永久保存。 图：数据保险箱 磁盘预拷贝技术： 正常状态时，实时监控硬盘状态。 当某个硬盘出现故障时：将该硬盘上的迁移数据到热备判。 迁移完成后，用新盘替换掉故障盘，数据会Copy back到新更换的硬盘上。 图：预拷贝技术原理 预拷贝与重构:数据重构的影响 系统性能的大幅降低 大量数据读写易导致硬盘损坏 会导致业务中断 图：预拷贝与重构 快照技术：快照为一个数据对象产生完全可用的副本，它包含该数据对象在某一时间点的映像。 数据对象：对存储阵列来说就是可映射给主机的LUN。 完全可用：可以正常读写。 时间点：数据具有一致性。 图：快照技术 LUN拷贝技术： 定义：一种基于块的将源LUN的数据复制到目标LUN的技术。 应用：通过LUN拷贝，实现分级存储、系统升级、异地备份等应用需求。 图：LUN拷贝技术 远程复制技术:远程复制（HyperMirror）：提供不同区域间数据的同步/异步镜像。保护用户数据，避免灾难性事件带来的损失。 图：远端复制技术 远程复制技术与LUN拷贝技术对比： 对比项目 远程复制 LUN拷贝 兼容性 只能在同类型存储系统之间运行 不但支持同类型存储系统，而且支持经过认证的第三方的存储系统 数据下发 每个主LUN只能向1个（异步模式）或2个（同步模式，分别位于不同的存储系统上）从LUN复制数据。 每个源LUN可以向数十个或者更多目标LUN复制数据。 数据备份 用于持续的数据保护。从LUN可读，但始终不可写。 用于数据备份。数据拷贝完成后，主机即可访问目标LUN. 可扩展性技术： 扩展接口协议 优点 缺点 SCSI 成熟稳定 只适用于直连，扩展能力差 iSCSI 组网方便，管理简单，不受距离限制。 数据传输效率低，安全性差。 FC 吞吐量大，可靠性高，第时滞，安全性高，数据传输效率高。 需存储专网，成本高 SAS 性价比高，发展空间大，技术新 连接距离短，只适用于直连 高性能存储技术：块虚拟化技术：块级虚拟化技术：一种新型RAID技术，该技术将硬盘划分成若干固定大小的块（chunk），然后将其组合成若干个小RAID组。 图：块级虚拟化技术 高可用性存储技术：SmartTier技术：动态分级存储技术（SmartTier）：自动将不同活跃度的数据和不同特点的存储介质动态匹配，提高存储系统性能并降低用户成本。 图：SmartTier技术 SmartQoS技术：SmartQoS：是一种性能特性，通过动态地分配存储系统的资源来满足某些应用程序的特定性能目标。 图：SmartQoS技术 Smart Thin技术：SmartThin：能够实现按需分配存储空间。在存储空间配额范围内，应用服务器用到多少空间，存储系统才给它分配多少空间，从而节省了宝贵的存储资源。 图：Smart Thin技术 操作分级管理： 图：操作分级管理 Level 0：无影响，不进行处理 Level 1：提示 Level 2：警告 Level 3：危险]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>华为网络大赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RAID技术及应用]]></title>
    <url>%2F2018%2F04%2F10%2FRAID%E6%8A%80%E6%9C%AF%E5%8F%8A%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[RAID基本概念与技术原理RAID基本概念：RAID（Redundant Array of Independent Disks）：独立冗余磁盘阵列，简称磁盘阵列。 RAID的实现方式：RAID的主要实现方式分为硬件RAID方式和软件RAID方式。 硬件RAID：采用集成了处理器的RAID适配卡（简称RAiD卡）来说实现的。它有自己的控制处理器、I/O处理芯片和存储器，减少对上机CPU运算时间的占用，塔高数据传输速度。 软件RAID：安全依赖于主机的CPU，没有额外的处理器和I/O芯片，软件RAID需要占用CPU处理周期，并且依赖于操作系统。 RAID技术：基于RAID技术，有两个基本的概念： RAID采用分条带，并行的方式进行存储。更有效的数据组织。 RAID采用校验、镜像的方式对数据安全提供保护。 条带：磁盘中单个或者多个连续的扇区构成一个条带。它是组成分条的元素。 注：硬盘容量大小。硬盘接口类型，硬盘速率要求都要保持相同。 分条：同一磁盘阵列中的多个磁盘驱动器上的相同“位置”（或者说是相同编号）的条带。 图：条带和分条示意图 传统的RAID数据保护主要采用的镜像和校验。 XOR校验的算法—–相同为假，相异为真。 0⊕0=0；0⊕1=1；1⊕0=1；1⊕1=0； RAID组的四个状态： 图：RAID组的四个状态 RAID技术与应用RAID级别：RAID技术将多个单独的物理硬盘以不同的方式组合成一个逻辑硬盘，提高了硬盘的读写性能和数据安全性，根据不同的组合方式可以分为不同的RAID级别。 常用RAID级别有：RAID0、RAID1、RAID3、RAID5、RAID6、组和RAID：RAID10、RAID50。 RAID0：RAID0：数据条带化，无校验。它代表了所有RAID接班中最高的存储性能，RAID 0 至少使用两个磁盘驱动器。 优点：在读的过程中是多块硬盘同时进行工作。读写性能是最高的。磁盘利用率最高。 缺点：没有冗余。阵列中某一个驱动器发生故障，将导致其中的数据丢失。 RAID 1：RAID 1：数据镜像，无校验。RAID 1使用两组磁盘互补镜像，速度没有提高，但允许单个磁盘故障，数据可靠性最高。 优点：可以允许有一份数据可丢失。 缺点：读写性能不如RAID 0。但读性能与RAID 0相似。写的性能比RAID 0 有很大差距。 RAID 3：RAID 3：数据条带化读写，校验信息存放 + 专用硬盘。当N+1个硬盘中的其中一个硬盘出现故障时，可以通过硬盘恢复数据。 优点：冗余较好。 缺点：在校验过程汇中，容易出现校验盘负载过大，使整个校验盘失效。在数据写入时，是写入最慢的，每次写入都要与校验盘校验，校验盘也成为这个存储的瓶颈。数据读取相对较快，采用多块硬盘同时读取。 RAID 5：RAID 5：数据条带化，校验信息分布式存放。分布式奇偶校验码的独立磁盘结构。校验信息均匀的分部在阵列所属的硬盘上，没块硬盘上既有数据信息也有校验信息。 图：RAID5结构 优点：校验信息在每块盘上，相对出故障的概率更小。数据写入相对比较快，所有盘都参与进来做校验。数据读取相对以比较快，采用条带化存储。可靠性高。 缺点：当有两块磁盘出现故障时，磁盘失效。 RAID 6：RAID 6：带有两个校验的独立磁盘结构，采用两种奇偶校验方法。需要至少N+2（N&gt;2）个磁盘构成阵列。一般用在数据可靠性，可用性要求高的应用场合。 常用的RAID6技术：RAID6P＋Q、RAID6DP。 RAID 6P+Q： RAID6P＋Q需要计算出两个校验数据P和Q，当有两个数据丢失时，根据P和Q恢复出丢失的数据。相当于两次RAID5的过程。校验数据P和Q是由以下公式计算得来的：​ P=D0⊕D1⊕D2……​ Q=(α⊗D0)⊕(β⊗D1)⊕(γ⊗D2)…… 图：RAID6 P+Q结构 优点：可以允许有两块盘同时出现故障，而不影响整个数据的丢失。数据磁盘的可丢失率为2. 缺点：因为要做两次校验，所需写入性能相对一般。数据读取比较快。 RAID 6 DP： DP－DoubleParity，就是在RAID4所使用的一个行XOR校验磁盘的基础上又增加了一个磁盘用于存放斜向的XOR校验信息。 横向校验盘中P0—P3为各个数据盘中横向数据的校验信息 例：P0=D0 XOR D1 XOR D2 XO RD3 斜向校验盘中DP0—DP3为各个数据盘及横向校验盘的斜向数据校验信息 例：DP0=D0 XOR D5 XOR D10 XOR D15 图：RAID6 DP结构 优点：可以允许有两块盘同时出现故障，而不影响整个数据的丢失。数据磁盘的可丢失率为2. 缺点：数据写入过程比较慢。读取比较快。 RAID 10：RAID10：是将镜像和条带进行组合的RAID级别，先进行RAID1镜像然后再做RAID0。RAID10也是一种应用比较广泛的RAID级别。 图：RAID10结构 RAID50:RAID50：是将RAID5和RAID0进行两级组合的RAID级别，第一级是RAID5，第二级为RAID0。至少需要6块硬盘。 图：RAID50结构 RAID比较： RAID应用场景选择： RAID级别选择：从可靠性、性能和成本简单比较各RAID级别的优劣（相对而言），供在实际项目中选择时参考。 空间利用率: RAID5明显优于RAID10 可靠性: RAID5低于RAID10 性能: 业务是一些大文件的读写操作时，RAID5的性能会明显好于RAID10 业务以随机的小数据块读写为主的时候，RAID10是最优的选择 随机读写性能比较：RAID5和RAID10下分条深度变化随机写性能规律： RAID5规律：随着分条深度的增加，随机写IOPS先会不断的增加，到达一定程度之后，随机写IOPS会不断的递减; RAID10规律：随着分条深度的增加，随机写IOPS不断的增长，当分条深度增大到一定程度后，随机写IOPS保持一个较为稳定的状态; 写惩罚：假设由5块硬盘组成的RAID5，每块盘同一条带数据如下： 如果有一个数据要写入，假设在第1个磁盘上写入的数据为0111。那么整个RAID5需要完成写入的过程分为： 读取原数据，然后与新数据0111做XOR操作：1010XOR 0111= 1101 读取原有的校验位1111 用第一步算出的数值与原校验再做一次XOR操作：1101XOR 1111= 0010 然后将0111新数据写入到数据磁盘，将第三步计算出来的新的校验位写入校验盘。 由上述几个步骤可见，对于任何一次写入，在存储端，需要分别进行两次读+两次写，所以说RAID5的Write Penalty的值是4。 常见RAID级别的Write Penalty值： 在实际存储方案设计的过程中，计算实际可用IOPS的过程中必须纳入RAID的写惩罚计算。计算的公式如下：​ 物理磁盘总的IOPS= 物理磁盘的IOPS×磁盘数目 ​ 可用的IOPS= (物理磁盘总的IOPS×写百分比÷RAID写惩罚) + (物理磁盘总的IOPS×读百分比) 假设组成RAID5的物理磁盘总共可以提供500 IOPS，使用该存储的应用程序读写比例是50%/50%，那么对于前端主机而言，实际可用的IOPS是：(500 ×50% ÷4)+ ( 500 * 50%) = 312.5 IOPS RAID数据保护，RAID与LUN热备盘：热备（HotSpare）：当冗余的RAID阵列中某个磁盘失效时，在不干扰当前RAID系统正常使用的情况下，用RAID系统中另外一个正常的备用磁盘顶替失效磁盘。 全局热备盘 局部热备盘。 热备盘要求和RAID组成员盘的容量，接口类型，速率一致，最好是采用同一厂家的同型号硬盘。 预拷贝：预拷贝：系统通过监控发现RAID组中某成员盘即将故障时，将即将故障成员盘中的数据提前拷贝到热备盘中，有效降低数据丢失风险。 重构：重构：RAID阵列中发生故障的磁盘上的所有用户数据和校验数据的重新生成，并将这些数据写到热备盘上的过程。 RAID与LUN：RAID由几个硬盘组成，从整体上看相当于由多个硬盘组成的一个大的物理卷。在物理卷的基础上可以按照指定容量创建一个或多个逻辑单元，这些逻辑单元称作LUN，可以做为映射给主机的基本块设备。 RAID 2.0RAID 2.0原理： RAID 2.0：为增强型RAID技术，有效解决了机械硬盘容量越来越大，重构一块机械硬盘所需时间越来越长，传统RAID组重构窗口越来越大而导致重构期间又故障一块硬盘而彻底丢失数据风险的问题。 RAID2.0+：在RAID 2.0的基础上提供了更细粒度（可以达几十KB粒度）的资源颗粒，形成存储资源的标准分配及回收单位，类似计算虚拟化中的虚拟机，我们称之为虚拟块技术。 华为RAID2.0+：是华为针对传统RAID 的缺点，设计的一种满足存储技术虚拟化架构发展趋势的全新的RAID 技术，其变传统固定管理模式为两层虚拟化管理模式，在底层块级虚拟化（Virtual for Disk）硬盘管理的基础之上，通过一系列Smart 效率提升软件，实现了上层虚拟化（Virtual for Pool）的高效资源管理。 图：RAID2.0结构 将硬盘划分成若干个连续的固定大小的存储空间，称为存储块（chunk）简称CK。 Ck按RAID策略组合成RAID组，称为存储块组（chunkgroup）简称CKG。 在CKG中划分若干小数据块（extent），LUN就是由来自不同CKG的extent组成。 用作热备空间的CK也是分散在各个盘上的。 RAID2.0+原理： 软件逻辑对象： 图：软件逻辑对象 Volume即卷，是存储系统内部管理对象。 LUN是可以直接映射给主机读写的存储单元，是Volume对象的对外体现。 RAID2.0+优势：自动负载均衡RAID 2.0+使得各硬盘均衡分担负载，不再有热点硬盘，提升了系统的性能和硬盘可靠性。 系统可靠性高： 快速精简重构： 提升单LUN性能： SmartTier:LUN上的数据可以根据数据的活跃度，自动调整，迁移到存储池中的不同存储层。 I/O监控：统计每个数据块的活跃度计数 数据分布分析：对每个数据的活跃度计数进行排序 数据迁移：根据排名结果和数据迁移策略实施数据迁移]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>华为网络大赛</tag>
        <tag>RAID</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储基础知识]]></title>
    <url>%2F2018%2F04%2F10%2F%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[存储的发展历程什么是存储：存储：就是根据不同的应用环境通过采取合理、安全、有效的方式将数据保存到某些截止上并能保证有效的访问。 当前存储的主要体系结构有三种：DAS、NAS、SAN。 存储发展历程的两个推动力： 业务上的需求 技术上的不断提升 早期的存储：服务器与存储一体： CPU主频较低 内存比较小 硬盘容量也不大 业务要求也没那么多 存储发展趋势： 重复数据删除 SSD固态硬盘 云存储 虚拟化环境的保护 一体化应用存储设备 非结构化数据存储与管理 备份容灾 存储与应用环境主机内部存储环境：主机内部I/O流程各个环境共同构成了数据储存的内部应环境。 图：内部存储环境流程 主机内部存储环境的瓶颈： 传统内置存储，有接口，CPU，内存，硬盘等。 硬盘成为整个系统的瓶颈 有限的硬盘槽数 单个硬盘存放数据，安全性得不到保证 存储空间利用率等 本地存储，数据分散，难以共享 可扩展性不够 总线结构，而非网络结构 可连接的设备受到限制增加容量时，需停机 网络存储应用环境：网络存储系统各层构成了网络存储系统的应用环境，决定了数据存储的可靠性、性能和安全性。 图：网络存储结构 存储介质机械硬盘： 图：机械硬盘结构 机械硬盘由盘片、磁头驱动机构、接口、控制电路、磁头组件、主轴等构成。还有高速缓存芯片、主控芯片、数据传输信息。 机械硬盘的主要参数： 硬盘容量（Volume） 缓存（Rotatinoal speed）：磁盘转动圈数/分钟 缓存 平均访问时间 平均访问时间由平均寻道时间和平均等待时间构成。 数据传输率(Data Transfer Rate) 内部传输率(Internal Transfer Rate) 外部传输率(External Transfer Rate) IOPS(Input/Output per Second)每秒的输入输出量（或读写次数），是衡量磁盘性能的主要指标之一。 Throughput吞吐量：值单位时间内可以成功传输的数据数量。对于大量数据读写的应用，如电视台的视频编辑，视频点播VOD（Video On Demand），则更关注吞吐量指标。 SSD硬盘： 图：SSD架构框图 无高速旋转部件，性能高，功耗低 多通道并发，通道内Flash颗粒复用时序 支持TCQ/NCQ，一次响应多个IO请求。 典型响应时间低于0.1ms。 SSD优势： 响应时间段 机械硬盘的机械特性导致大部分时间浪费在寻道和机械延迟上，数据传输效率受到严重制约。 读写效率高 机械硬盘在进行随机读写操作时，磁头不听地移动，导致读写效率底下，而SSD通过内部控制器计算出数据的存放位置，直接进行存取操作，过效率高。 设备温度低，功耗比机械硬盘低。 SSD不含高速的机械结构部件，可经得住严苛的环境考验，以华为SSD硬盘为例： HSSD可承受整栋加速度16.4G,机械硬盘一般为0.5G以下。 HSSD可抗冲击1500G，机械硬盘一般为70G左右。 SSD硬盘–存储中的应用： 图：存储中的应用 硬盘接口类型： ATA（Advanced Technology Attachment）高级技术附加装置 ATA硬盘以经常成为IDE Integrated Drive Electronics硬盘。 ATA接口为并行ATA技术。 SCSI接口（Small Computer System Interface）小型计算机系统接口 SATA：Serial ATA，串型ATA。 SATA采用串型方式进行数据传输，接口速率比IDE接口高，最低为150Mps，并且第二代（SATA II），300Mbps接口硬盘已经形成商用，规划内的最高速率可达600Mbps。 SATA硬盘采用点对点连接方式，支持热插拔，即插即用。 适合大数据块，业务压力不大的用户使用。如；企业备份数据，归档数据，视频图片存储。 SAS接口：（Serial Attached SCSI）串行连接SCSI SAS是一种点对点、全双工、双端口的接口。 SAS专为满足高性能企业需求而设计，实现与SATA的互操作，为企业用户带来前所未有的灵活性和低成本。 速率每路600M SAS具有高性能、高可靠性、强大的扩展性能。 适合业务量大， 范围评率较高，以小数据块居多，数据较为离散的中/高端用户。如：企业数据库，CRM、ERP等应用。 FC接口：FC硬盘采用FC-AL（Fiber Channel Arbitrated Loop）光纤通道仲裁环。 FC-AL是一种双端口的串型存储接口 FC-AL支持全双工工作方式 FC-AL利用类似SATA/SAS所用的4芯连接，提供一种单环拓步结构，一个控制器能够访问126个硬盘。 NL SAS采用SAS接口，SATA盘体，也叫近线SAS。 原生支持SCSI，支持双端口访问，高级容错技术，大容量低功耗。 更适合大数据块业务，压力不大的用户使用。如：；邮件服务器，文件服务器。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>华为网络大赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础]]></title>
    <url>%2F2018%2F04%2F09%2FLinux%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Linux概述Unxi的发展： 1946年：世界上第一台计算机ENIAC诞生于美国 1960年：麻省理工学院研发出兼容分时操作系统 1965年：Multiscs计划 1970年：Ken Thompson研发出Unix原型 1973年：Ritchie用C语言编写了Unix内核，Unix正式诞生 1974年：Unix对外公布，开始广泛流行 Linux的发展： 1986年：Tanenbaum研发出Minix，并与次年发布 1991年：Linus Torvalds研发出Linux内核雏形 1994年：Linux1.0内核发布 1995年：各种不同Linux发行版本相继出现 Linux发行版本： Redhat， SUSE Entprise ， CentOS 侧重于网络服务，企业管理 Debian， Slackware 侧重于服务器及其稳定性 Ubuntu，Fedora， OpenSUSE 侧重于用户体验 Unix和Linux的区别： Unix Linux 商业付费软件 免费，公开源代码 多数是与硬件配套的 可运行在多种硬件平台上 对硬件要求更为苛刻 对硬件要求没Unix高 安装复杂 安装相对简易 使用比较复杂 使用相比Unix简易 最稳定 稳定性次之 Linux的结构： 图：Linux的结构 Linux的结构由四部分构成： 硬件 内核（kernel）：是Linux操作系统的核心，指挥调度Linux机器的运行。直接控制计算机的资源。保护用户程序不受错综复杂的硬件实现细节的影响。 外壳（Shell）：是Linux的一个特殊程序，是用户和内核之间的命令解释器。在命令提示符下，用户输入相应的命令，发出后会被执行。使用者可以通过shell与计算机通信。 shell与内核是分开的。可以使用其他的shell来代替本机的shell。 Linux中的shell： Boune shell（sh）：Linux最初使用的shell，并且在所有的Linux系统上都可以使用。在编程方面相当优秀，在处理与用户的交互方面比较差。 C shell（csh）：C shell 使用的是“类C”语法,csh是具有C语言风格的一种shell，其内部命令有52个，较为庞大。目前使用的并不多，已经被/bin/tcsh所取代。 Korn shell（ksh）：Korn shell 的语法与 Bourne shell 相同，同时具备了 C shell 的易用特点。许多安装脚本都使用 ksh ，ksh有42条内部命令，与bash相比有一定的限制性。 应用程序 Linux的特点： 多用户，多任务 多任务：CPU时间分片，分给不同的进程。 多用户：允许多个用户同时登陆使用。 管道，功能强大的shell 管道:前一个程序的输出作为后一个程序的输入。 功能强大的Shell：shell是一种解释型的高级语言。 安全保护机制，稳定性好 安全保护机制：防止系统及数据库未经许可而被非法访问。 稳定性好：Unix浩宇Linux，Linux好于Windows。 用户界面，强大的网络支持 用户界面：常用命令行界面，同时提供图形界面。 强大的网络支持：TCP/IP协议就是Linux的缺省网络协议。 移植性好 移植性好:Linux的源代码是用C语言写成的，非常方便移植到其他计算机上。 Linux用户和用户组管理Linux用户和用户组： 图：用户与用户组的关系 Linux用户会归属于用户组。归属于同一用户组的用户，对一些公共的文件具有相同的访问权限。 UID-用户ID： UserID 每个用户的唯一识别ID SuperUser：UID = 0 SystemUser： UID = 1 - 499 一般用户：UID = 500 - 60000 GID-组ID： Group ID 每个组的唯一识别ID 没有SuperGroup SystemGroup ： GID = 0-499 一般组：GID = 500 - 60000 用户与用户组主要文件内容：/etc/passwd 图：/etc/passwd文件 开放给全部用户可以存取的权限 一个用户一行 字段说明： 第一个字段root：用户名 第二个字段x：密码 第三个字段0：UID 第四个字段0：PrimaryGroup‘s GID 第五个字段root：说明 第六个字段/root: 家目录 第七个字段：/bin/bash: Login shell /etc/shadow 图：/etc/shadow文件 /etc/passwd不安全 /etc/shadow支持SHA-256及SHA-512密码哈希 密码哈希中存储三种信息 哈希算法 用于加密哈希的salt 以加密的哈希 /etc/shadow字段 /etc/group 图：/etc/group文件 开放给全部用户可以存取的权限 一个组一行 字段说明： 第一个字段root：组名称 第二个字段x: 组密码 第三个字段0： GID 第四个字段root：加如该组的用户 用户管理的常用命令：用户查询命令： id：查询当前登录用户的GID，UID。 finger：查询当前用户属性信息。 新增用户：useradd 默认情况下，不设密码，用户无法登录。 例如：增加用户ipcc。 1useradd -d/home/ipcc -m -u 2000 -g mms -s/bin/csh ipcc useradd [参数] 用户名 -d：设置用户的家目录 -m：设置的家目录不存在时自动创建 -u：设置用户的UID -g：设置初始的GID或组名 -s：指定用户的shell，如/bin/csh 如果在新增用户式，直接输入useradd ipcc ，系统过自动读取/etc/default/useradd 配置文件。里面规定了默认的初始用户组，sehll等。可通过useradd -D 读取默认配置文件。 删除用户：userdel userdel [参数] 用户名 -r：连用户家目录一起删除。 设置用户密码：passwd passwd [用户名] ：设置和修改用户密码。 修改用户属性：usermod usermod [用户名]： -d：修改用户目录 -g：修改初始用户组 用户组管理的常用命令：新增用户组：groupadd groupadd [参数] 用户组名 -g：指定组ID。 删除用户组：groupdel 修改用户组：groupmod groupmod [参数] 用户组名 -g：修改组ID -n：修改组名 Linux文件和目录管理绝对路径与相对路径：绝对路径： 对路径的描述，一律从”/“开始 例如：/home/student/file.txt 绝对路径的特征是，路径的描述，第一个字符一定是”/“。 “/“根目录是文件阶层系统的最长层 相对路径： 描述路径时，第一个字符不是”/“ 例如：绝对路径的/home/student/file.txt /temp : ../home/student/file.txt /home : student/file.txt 描述路径的相对关系 “..” 表示上一层文件夹 Linux的目录结构： 图：Linux的目录结构 目录 内容 /bin 构建最小系统所需要的命令，引导是会使用一般命令或可执行文件 /sbin 和系统操作有关的命令，引导是会使用系统命令或可执行文件 /boot 内核与启动文件 /dev 各种设备文件 /etc 系统软件的启动和配置文件，大部分是 *.conf ,/etc/passwd、/etc/group、/etc/shadow例外 /home 用户的主目录 /root 超级用户root的家目录 /usr 非系统的程序和命令 /var 系统专用的数据和配置文件 /opt 可选的应用软件包 /temp：临时文件存放点 /media:本机硬盘以外的存储设备 /mnt：本机硬盘以外的存储设备 文件管理常用命令： 显示当前工作目录：pwd 变更工作目录：cd 列出文件夹的内容清单：ls 复制文件夹或文件：cp 移动文件或文件夹：mv 创建文件夹：mkdir 删除文件夹：rmdir，必须是空文件夹才能删除 删除整个文件夹：rm linux文件系统管理文件系统的概念：文件系统是操作系统用于明确存储和组织计算机数据的方法。 存储在介质中的数据的三个因素： 文件名：定位存储的位置 数据：文件的具体内容 源数据（meta-date）: 文件有关的信息 Linux支持的文件系统类型，可以查看/etc/filesystems 。 文件系统的分类：是否有日志： 传统型文件系统 写入文件内容的时候，先写入数据，在写入元数据。如果在写入元数据之前突然断电，可能会造成文件系统处于不一致的状态。因此，不如日志型文件系统安全。 典型的传统型文件系统是ext2文件系统。也是Linux默认的文件系统。 日志型文件系统 写入文件内容的时候，首先写入日志记录文件。若整个写的操作，由于某种原因导致系统掉电，中断，那么则会在下次系统启动时，会读日志记录文件的内容来恢复没有完成的写操作，一般能在几分钟之内将文件系统恢复到一致的状态。比传统的文件系统更加安全。 典型的日志型文件系统有ext3、ReiserFS文件系统。 ext3是对ext2的扩展，在ext2基础上加入了日志功能。 ReiserFS使用基于平衡树的文件系统结构，搜索快。另一个特点是节约空间。对于小文件，比如小于4k的文件可以直接存储进树，小文件的读取和写入树会更加快。 如何查找数据： 索引式文件系统 将文件属性数据和实际内容存放在不同的区块。通过属性数据，可以很快找到实际数据所存储的位置。 如ext2文件系统，文件属性存放的地方成为inode，记录了文件的所有者，权限和修改时间等属性。实际数据存储在Block中。 非索引式文件系统 只有block，数据需要一个block接一个block读取，效率相对来说比较低。 典型的非索引文件系统如windows下的FAT。 磁盘碎片整理，就是通过系统软件或者专业的磁盘碎片整理软件对电脑磁盘在长期使用过程中产生的碎片和凌乱文件重新整理，可提高电脑的整体性能和运行速度。 磁盘碎片应该称为文件碎片，是因为文件被分散保存到整个磁盘的不同地方，而不是连续地保存在磁盘连续的簇中形成的。硬盘在使用一段时间后，由于反复写入和删除文件，磁盘中的空闲扇区会分散到整个磁盘中不连续的物理位置上，从而使文件不能存在连续的扇区里。这样，再读写文件时就需要到不同的地方去读取，增加了磁头的来回移动，降低了磁盘的访问速度。 ext2文件系统的结构： 图：ext2文件系统的结构 文件系统中存储的最小单元是块(block)，一个块的大小是在格式化时确定的。启动块(Boot Block)的大小为1KB，由PC标准规定，用来存储磁盘分区信息和启动信息，任何文件系统都不能使用启动块。启动块之后才是ext2文件系统的开始，ext2文件系统将整个分区划分成若干个同样大小的块组(Block Group)。 每个块组的组成： 超级块(Super Block)描述整个分区的文件系统信息，如inode/block的大小、总量、使用量、剩余量，以及文件系统的格式与相关信息。超级块在每个块组的开头都有一份拷贝。 块组描述符表(GDT,Group Descriptor Table)由很多块组描述符组成，整个分区分成多个块组就对应有多少个块组描述符。 每个块组描述符存储一个块组的描述信息，如在这个块组中从哪里开始是inode Table，从哪里开始是Data Blocks，空闲的inode和数据块还有多少个等等。块组描述符在每个块组的开头都有一份拷贝。 块位图(Block Bitmap)用来描述整个块组中哪些块已用哪些块空闲。块位图本身占一个块，其中的每个bit代表本块组的一个block，这个bit为1代表该块已用，为0表示空闲可用。假设格式化时block大小为1KB，这样大小的一个块位图就可以表示1024 8个块的占用情况，因此一个块组最多可以有1024 8个块。 inode位图(inode Bitmap)和块位图类似，本身占一个块，其中每个bit表示一个inode是否空闲可用。 inode表(inode Table)由一个块组中的所有inode组成。一个文件除了数据需要存储之外，一些描述信息也需要存储，如文件类型，权限，文件大小，创建、修改、访问时间等，这些信息存在inode中而不是数据块中。inode表占多少个块在格式化时就要写入块组描述符中。 配置文件系统分区：创建分区：fdisk语法：fdisk 设备名 通过m参数，可以查看按键操作说明 通过p参数，可以得到本地磁盘的相关信息 通过n命令，可以新建一个分区 新建分区的步骤： 选择分区的类型 选择分区开始的磁柱 决定分区大小 保存新建分区 重启服务器或使用partprobe命令通知内核。 创建文件系统：mkfs语法：mkfs[参数] 设备名称 -t：指定文件系统类型，图ext3 -b：指定block大小，单位bytes，ext2/ext3只支持1024,2048,4096三种。 挂载文件系统：mount语法：mount 设备名 挂载点 -t:指定文件系统类型，如ext3 -b:指定block大小，单位bytes 管理Linux文件系统：查看分区使用情况： 图：查看示例 df：查看文件系统的磁盘空间占用情况 -h：以容易理解的格式打印出文件系统大小 -i：显示inode信息而非块使用信息 du：查询文件或目录的磁盘使用空间： -a：显示目录下每个文件所占用的磁盘空间 -s：只显示大小的总和（summarize） -h：以容易理解的格式输出文件大小 查看系统打开的文件：lsof：显示系统打开的文件 lsof filename：显示打开指定文件的所有进程 lsof -c string ：显示以指定字符开头的进程所有打开的文件 lsof -u username：显示所属user相关进程打开的文件 修复文件系统：fsck：检查文件系统并尝试修复错误 执行fsck时，必须将要修复的设备进行umount后，再指定fsck命令。 e2fsck：检查和修复ext2和ext3文件系统 Linux LVM配置LVM的原理：什么是LVM？LVM是Logical Volume Manager的简写，即逻辑卷管理。 是一种将一个或多个硬盘的分区在逻辑上集合，相当于一个大硬盘来使用，当硬盘的空间不够使用的时候，可以继续将其它的硬盘的 分区加入其中，这样可以事项一种磁盘空间的动态管理，相对于普通的磁盘分区有很大的灵活性，使用普通的磁盘分区，当一个磁盘的分区空间不够使用的时候，可 能就会带来很大的麻烦。使用LVM在一定程度上就可以解决普通磁盘分区带来的问题。 LVM是建立在硬盘和分区之间的一个逻辑层，用来提高磁盘分区管理的灵活性。在传统的文件管理中，文件系统是直接构建在物理分区之上的，物理分区的大小就决定了其上文件系统的存储容量，因此对文件系统的存储容量调整就比较繁琐。LVM的设计目的就是为了实现文件系统存储容量的课扩展性，使对容量的调整更为简易，而非读写性能和数据的安全性。 LVM架构： 图：LVM架构图 PV(physical volume)：物理卷在逻辑卷管理系统最底层，可为整个物理硬盘或实际物理硬盘上的分区。VG(volume group)：卷组建立在物理卷上，一卷组中至少要包括一物理卷，卷组建立后可动态的添加卷到卷组中，一个逻辑卷管理系统工程中可有多个卷组。LV(logical volume)：逻辑卷建立在卷组基础上，卷组中未分配空间可用于建立新的逻辑卷，逻辑卷建立后可以动态扩展和缩小空间。PE(physical extent)：物理区域是物理卷中可用于分配的最小存储单元，物理区域大小在建立卷组时指定，一旦确定不能更改，同一卷组所有物理卷的物理区域大小需一致，新的pv加入到vg后，pe的大小自动更改为vg中定义的pe大小。LE(logical extent)：逻辑区域是逻辑卷中可用于分配的最小存储单元，逻辑区域的大小取决于逻辑卷所在卷组中的物理区域的大小。卷组描述区域：卷组描述区域存在于每个物理卷中，用于描述物理卷本身、物理卷所属卷组、卷组中逻辑卷、逻辑卷中物理区域的分配等所有信息，它是在使用pvcreate建立物理卷时建立的。 LVM的优点：通过使用LVM： 文件系统可以跨域多个磁盘 动态地扩展文件系统的大小 增加新磁盘到LVM的存储池中 LVM的要点： 按需分配文件系统的大小 把不同的数据放在不同的卷中 物理卷管理命令： pvcreate：创建物理卷 将普通的分区加上pv属性。 例如：将分区/dev/sha6创建文物理卷： pvcreae /dev/sha6 pvscan：查看物理卷信息 pvdisplay：查看各个物理卷的详细参数 pvremove：删除物理卷 删除物理卷的pv属性。 卷组管理： vgcreate：创建卷组 vgsacn：查看卷组信息 vgdisplay：查看卷组的详细信息 vgreduce：缩小卷组，把物理卷从卷组中删除 vgextend：扩展卷组，把某个物理卷添加到卷组中 vgremove：删除卷组 逻辑卷管理命令： lvcreate：创建逻辑卷 lvscan：查看逻辑卷的信息 lvdisplay：：查看逻辑卷的具体参数 lvextend：增大逻辑卷的大小 lvreduce：减小逻辑卷大小 lvremove：删除逻辑卷 管理文件系统空间：增大文件系统空间： 先卸载逻辑卷 然后通过vgextend，lvextend等命令增大lv的空间 再使用resize2fs将逻辑卷容量增加 最后将逻辑卷挂载到目录树下 缩小文件系统空间： 先卸载逻辑卷 然后使用resize2fs将逻辑容量减小 再通过lvreduce等命令减小lv空间 最后将逻辑卷挂载到目录树下 Linux网络管理有管网络配置的具体命令参数可参考：Linux学习笔记命令篇 查询和配置网口：查看网口的配置：ifconfig ，可查看IP地址，广播地址和掩码等。 修改网口的配置：ifconfig eth3 192.168.100.128 broadcast 192.168.100.255 netmask 255.255.255.0。修改网络配置文件够，重启后配置才会一直都在，使用ifup命令，启动网口。 查询和配置路由：查询本机路由表：route。 新增路由：route add ，新增路由数据保存在内存中，系统重启失效。 /etc/sysconfig/network/routes 用来保存静态路由数据，需要重启网络服务才能生效。 侦测网络：ping：检测对端网络是否可达。 traceroute：探测从源到目的所经过的路由。 配置常用网络服务： 图：配置ftp服务 图：配置telnet服务 Linux进程和任务管理进程管理： 程序：文件中保存的一系列可执行命令 进程：加载到内存中的程序，由CPU运行 守护进程：常驻内存，与终端无关的系统进程 用户进程：用户通过终端加载的进程 进程中常用命令：ps ：静态查看某一时间点进程信息： a：显示现行终端机下的所有程序 x：显示所有程序，不以终端机来区分 u：以用户维注的格式来显示程序状态 f：用ASCII字符显示树状结构 top：连续观察进程的动态，默认每3秒刷新一次，并按CPU使用率由高到低排序。 pstree：用ASCII字符显示树状结构： -p：显示进程ID -u：显示用户名称 kill：结束进程和进程PID，系统可能响应忽视。 kill -9 PID,强制终止进程。 Killall：终止同一进程组内得所有进程。例如：killall httpd 任务管理： 任务：登录系统取得shell之后，在单一终端接口下启动的进程。 前台：在终端接口上，可以出现提示符让哟用户操作的环境。 后台：不显示在终端接口的环境。 任务管理的相关命令：&amp;：直接将程序放入后台处理，如：find /-name smcapp &amp; jobs:查看当前shell的后台任务。 ctrl+z：将正在运行的任务放入后台暂停。 fg %[job ID]:将任务放入前台执行。不加job id表示对当前的任务进程操作。 bg %[job ID]:将任务放入后台执行。 crontab：管理周期计划任务. 语法：crontab [-u user ] -e | -l | -r -u：指定用户 -e：边界crontab任务内容 -l：查阅crontab任务内容 -r：移除所有的crontab的任务内容 crontab相关配置文件： 使用crontab -e编辑时，程序会直接调用vi接口，程序路径是/usr/sbin/cron 系统记挂任务保存在/etc/crontab文件中 /var/spool/cron/tabs下面有对应的用户名crontab，对应用户级别的任务配置。 /var、cron对应系统级别的任务配置。 at ：管理定时任务，安排一个任务在未来执行，必须先启用atd进程。 at -l：相当于atq，列出当前at任务。 at -d [job ID]:相当于atrm，删除一个at任务 at -c[job ID]:查看任务的具体内容。 at的使用方法： at HH：MM ：今日的HH：MM执行，若是时间已经超过，则明天的HH：MM执行。 at HH:MM YYYY-MM-DD ：指定具体的执行日期和时间。 at now + number [minutes | hours | days weeks ]:当前时间往后多长时间执行。 at HH:MM + number [minutes | hours | days ] ：某个时间点+多长时间执行。 Linux系统监控监控系统启动日志： dmesg | less /var/log/boot.msg 监控硬件信息：cat/proc/... 系统硬件信息保存在/pron下的文件中： /pron/cpuinfo:CPU的信息 /pron/devies:已经加载过的设备信息 /pron/bus:系统总线信息 /pron/scsi scsi:设备信息 /pron/net:网卡设备信息 hwinfo：显示所有硬件相关信息： –disk：显示磁盘信息 –cpu：显示CPU信息 –memory：显示内存信息 –network：显示网卡信息 –short：显示硬件的摘要信息 fdisk：查看硬盘信息。-l：查看服务器所挂载判个数及分区情况。 iostat：查询cpu和磁盘 I/O的统计信息： -c：仅显示CPU统计信息 -d：仅显示磁盘统计信息 -k：以k为单位显示每秒的磁盘请求数 lspci：列出所有的PCI设备。 -v：显示PCI接口装置的详细信息 -w比-v更详细的信息。 监控系统和进程： PS：用来显示当前进程状态，和top不同的是，查看的是今天信息。 top：即时显示进程的动态，可以用来查看进程使用的cpu，内存等。 uptime：查看系统已经开机的时间以及系统平均负载。 uname：查看系统版本相关的信息，如内核号。 netstat：显示与IP、TCP/UDP协议相关的统计数据、用于检测本机各个端口的网络连接情况。 监控登录信息：who：查看当前登录系统的用户 -H：显示各栏位的标题信息列 -m：效果同who am i，显示出自己在系统中的用户名，登录终端，登录时间。 w:查看当前登录的用户机用户当前的工作 -u：后面接user，查看具体用户信息 finger：查看用户详细信息 -s：短格式显示用户信息 -l：长格式显示用户信息 last：查看曾今登录后系统的用户 -n num:设置列出名单的显示列数 -F：显示登录和登出的详细信息 lastlog：查看用户前一次的登录的信息。 -t days:查看距今n天内登录了系统的用户的最近一个词登录信息。 -u：显示的登录和登出的详细信息。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
        <tag>华为网络大赛</tag>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器基础]]></title>
    <url>%2F2018%2F04%2F08%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[服务器定义及发展史服务器概念: 图：服务器概念 服务器也是一种计算机。 服务器，也称伺服器，是提供计算服务的设备。由于服务器需要响应服务请求，并进行处理，因此一般来说服务器应具备承担服务并且保障服务的能力。 服务器的构成包括处理器、硬盘、内存，系统，总线等，和通用的计算机架构类似，但是由于需要提供高可靠的服务，因此在处理能力、稳定性、可靠性、安全性、可扩展性、可管理性等方面要求较高。 服务器与客户机：服务器在网络中为其他客户机提供计算或应用服务。客户机可以是PC机，智能手机，ATM等终端设备，也可以是其他的服务器。甚至是火车，飞机等大型系统设备。 服务器的特性： 高速度的CPU运算能力 长时间的可靠运行 强大的I/O外部数据吞吐能力 服务器通常具有更高的性能，效率，高可靠，高可用性，以及更好的扩展性。 工业革命4.0：计算机，IT信息技术等科学技术的快速发展，推动了从上世纪40年代至今的第三次科技革命。在第三次科技革命的基础之上，信息技术，大数据与物联网相结合而形成的智能工厂，智能生产等成为工业4.0的关键。 服务器技术的快速发展，对工业3.0和4.0产生了直接的推动作用。 服务器的发展史： 图：服务器演进 第一台电子计算机诞生在1946年。揭开了人类科学计算与信息技术的新纪元。 1964年，IBM开发出的第一台大型机System 360，成为真正意义上的服务器。它采用创新的集成电路设计，计算性能达到每秒100万次。System 360价格非常昂贵，每台价格高达200到300万美元约合现在的2000多万美元。 第一台服务器商业应用： 这台服务器赏识之后全球订单蜂拥而至，创造了许多技术和商业的第一。例如：它协助美国太空总署建立阿波罗11号的数据库，完成了航天员登录月球计划。 1965年，DEC公司开发了一块PDP-8小型机，掀起了一场小型机的革命。这台小型机服务器体积变小了。更加易用，价格也更便宜了。深受用户的喜爱，也推动了服务器技术的进步，使之面向更广的应用领域发展。 90年代，Unix服务器， RISC CPU 和Unix操作系统。今天的小型机概念是指计算机技术发展到90年代，又原来的大型机衍生出来的一种，针对中小型企业低成本的Unix服务器，这类服务器通常采用RISC CPU和Unix操作系统，因此国外将其分类为Unix Server，国内俗称为小型机。 1989年，第一台X86服务器，Intel 486微处理器。 Intel成功将当时的Intel 486 CPU推广到服务器领域。由康柏公司生产了业界第一台X86服务器。Intel这一创举致使服务器变的低廉，变的平民化，普及化。Intel在X86架构领域的持续创新，也慢慢确立了X86服务器的市场地位，并逐步走到了领先地位。今天的X86服务器已经是市场上的绝对主流。成功占据着行业的领先地位，出货量占比高代98%以上。销售量占比80%以上。 服务器核心部件CPU发展至今，一直在遵循摩尔定律进行快速的演进与创新。现在全球的处理器，绝大多数都采用了性能较强的Intel处理器。 服务器类型服务器按外形分类： 图：服务器按外形分类 服务器按外形分类可以分为： 塔式服务器 机架服务器 刀片式服务器 高密度服务器 服务器按CPU数量分类： 图：服务器按CPU数量分类 服务器按CPU数量进行分类，可以分为： 单路服务器（一路服务器） 双路服务器（两路服务器） 四路服务器 多路服务器 这种分类方式，也最常体现到不同厂家服务器类型的分类上。如华为的RH2288为两路服务器，RH5885为四路服务器，RH8100为八路服务器。 服务器按指令集分类： 图：服务器按指令集分类 有的Unix服务器不采用CPU数量分类，而是采用CPU内核数量进行分类。早期的CPU只有一个内核，后来的新技术可以将多个内核封装在一个CPU芯片中，性能得到数倍的提升。 现在我们经常谈到的如小型机，X86服务器，小机迁移等，这是以CPU类型，也就是CPU指令集进行分类。 按CPU指令集进行分类有： RISC精简指令集CPU 采用RISC CPU的服务器通常运行Unix操作系统，国外称为Unix服务器，国内俗称为小型机。 CISC复杂指令集CPU X86 CPU则采用的是CISC指令集，采用X86 CPU的服务器称为X86服务器。 服务器按应用分类： 图：服务器按应用分类 我们最关心的是服务器上面运行的业务种类和负载类型，不同的业务应用和负载需要不同类型的服务器来承载。从这个角度上通常可分为： 数据库服务器 应用服务器 Web服务器 接入服务器 文件服务器等 服务器发展变化：随着服务器不断发展，服务器的外形也不断发生着变化，体积不断缩小，更加节能省电。从塔式服务器后来发展为更薄更小的机架式服务器。后来又退出了高度，节能，管理优化的刀片式服务器。 服务器硬件组成构成： 图：服务器硬盘组成 服务器的主要硬件主要包含CPU、内存、硬盘三大组件。另外还配置有主板、机箱、电源、风扇灯基础硬件。以及RAID卡、网卡等可选部件。CPU、内存、硬盘三大件占服务器成本的2/3以上。 主流服务器厂商：除了IBM，Oracle等厂商的大小型机外，各厂商的X86服务器都是跟着Intel的产品开发节奏走，三大件也通用化了，这导致各厂商的服务器从原理上看大体相差不多。当然也各有差异，主要体现在产品的工业化，模块化设计，RAS特性，可扩展，可管理型差异，以及品牌服务能力等。 服务器技术架构服务器技术架构的三大发展趋势： 图：服务器发展三大趋势 客户需求决定了服务器的发展方向。从服务器的技术架构来看，目前整个服务器的技术架构的发展有三个大趋势： Scale-up纵向扩展架构 Scale-out横向扩展架构 Hyper-converged超融合架构 Scale-up纵向扩展架构特性： 图：Scale-up架构特性 主要是提升单体服务器的计算性能。包括高可靠，高可用以及可扩展性。主要适用于高性能交易类业务。如：企业核心交易数据库；关键应用系统以及HPC高性能计算机等业务。 Scale-up架构被广泛应用于金融交易，电信计费，科学研究，气象分析等领域。 Scale-up服务器可以比作一艘庞大而战斗力超强的大型战列舰，具有强大的武器装备和作战性能，是大规模海战的核心作战系统。 Scale-out横向扩展架构特性: 简单说就是以数量取胜。Scale-out架构通常对单台服务器的性能要求不高，主要通过更多的服务器来协同完成任务。 Scale-out通常具有高并发性能、低成本、高密度、节能低碳、统一管理等特点。 这种架构通常使用与超大规模数据中心、大数据分析、共有云、Web应用集群等业务场景。 Scale-out系统可以比作是一个轻型的快艇集群，通过群狼战术，实现整体的作战效能。 Hyper-converged超融合架构： 图：超融合架构特性 这种架构的理念是将计算、存储、网络和统一管理放在一个盒子里，可以做到开箱即用，提供一个整体的计算解决方案。这样的架构设计，可达到整体系统的一体化融合集成，性能优化，建议管理的目的。通过一体化的设计、集成与优化，消除系统瓶颈，实现更好的整体系统效能。 超融合架构主要应用于高性能数据分析，数据库整合，云计算资源池平台，一体化数据中心等应用场景。 Hyper-converged的超融合架构可以比作一艘航空母舰，通过系统平台的整体集成与优化设计。既拥有超强的核动力驱动，又有强大的舰载机集群，远程防控，巡航导弹等综合火力打击系统，以及C4SIR综合情报，管理与指挥控制系统，形成一个超强的整体优势作战平台。 业务应用和服务器部署： 单机系统： 早期的服务器系统都是单机应用，在一台服务器上部署了所有的应用软件。为一个或几个用户提供计算或业务服务，这种单机系统通常也被称为工作站。 C/S应用部署架构： 图：C/S架构 在C/S共享系统中，通常会有一个集中共享的应用数据库，而每个员工会有自己的PC机，在每台PC机上要安装相同或不同的应用程序，这些应用程序能够操作使用或者共享应用数据库。这样能够实现业务数据的协同操作，应用共享和统一保存。 在C/S架构中，由一个共享数据库对应多个应用客户端，构成两次的应用部署架构。这些应用程序的部署，配置和维护都比较复杂。软件升级也需要每天客户端逐一的升级，不利于应用的灵活部署，也不利于大规模的客户应用和推广。 B/S架构模式： 图：B/S架构模式 为了解决C/S架构所面临的问题，在C/S架构的基础上，又提出了一种优化的B/S架构。也就是Browse/Server三层模式的应用系统架构。B/S架构伴随着因特网的兴起而发展起来，是对C/S架构的一种改进。 在B/S架构中，PC机客户端只需要有一个标准的Web浏览器，不需要安装其他的应用程序。而类似于C/S架构中的数据库，应用服务器软件都被安装在后台的服务器上，使用用户通过Web浏览器连接登录到服务器即可获得相应的服务。当需要使用不同的应用服务时，客户只需要用Web浏览器连接到不同的应用服务器即可。 B/S架构的Web客户端使用简单，免维护。而业务应用软件，数据库系统，则可以集中，统一部署，统一维护。非常适用于大规模应用系统的部署与服务。 互联网业务是典型的B/S架构。 由于互联网业务的并发点击负载高，海量大数据等特点。因此互联网业务的后台服务系统的架构模式，一直是朝着开放，分布式的架构模式发展，并不断产生新的变化与技术创新。今天如百度，腾讯数据中心的互联网架构，普遍采用大规模分布式的数据库，Hadoop大数据集群，高密Scale-out水平扩展的应用，搜索，Web集群接入的部署架构模式。 服务器上层软件架构服务器的系统安装与业务部署： 图：常见OS 主流的Unix服务器操作系统有AIX Solaris和HP-un11。 X86服务器的操作系统通常是Linux系统和Windows操作系统。 对于云计算平台通常要安装VMware，FusionSphere或KVM等虚拟化系统。虚拟化系统可以将一个物理服务器模拟成多台小的虚拟化服务器来使用，通过服务器虚拟化化能够提供更好的资源使用效率，自动部署和简化管理。 主要服务器数据库： 图：主流数控软件 主流的数据库有，Oracle，IBM DB2数据库，开源的My SQL数据库，以及国产的人大金仓，达梦数据库等。 主要服务器中间件： 图：主要服务器中间件 目前市场上以Java中间件为主，比如商用的中间件有Weblogic，Webspher，Tuxedo，东方通等。开源的中间件有，Tomcat JBoss中间件等。中间件可以为上层应用软件提供运行和开发环境。提供预制可复用的业务功能模块，API接口等，帮助用户灵活、高效地开发和基础复杂的应用系统。 主要服务器业务应用： 图：主要服务器业务应用 业务应用软件是面向客户的应用逻辑层软件。比如ERP，CRM，HR等应用软件。业务应用软件通常是基于数据库、中间件等基础架构平台之上，根据客户的需求进行定制开发，最终满足客户业务要求的软件系统。 与云计算服务架构对应关系： 图：与云计算服务架构对应关系 通常来讲包括服务器，存储，网络等硬件基础设施，以及操作系统，虚拟化层。对应的是IaaS云服务层。 数据库、中间件通常会对应PaaS云服务层。 业务应用层软件则会面向SaaS层服务。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>华为网络大赛</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop基础技术概述]]></title>
    <url>%2F2018%2F04%2F07%2FHadoop%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[大数据处理技术发展趋势传统数据处理系统面临的问题： 图：传统数据处理系统面临的问题 如上图：传统数据处理系统面临的问题主要有： 海量数据的存储成本。 有限的扩展能力。 数据资产对外增值。 大数据处理能力的不足。 单一数据源。 流式数据处理缺失。 数据处理技术演进趋势： 图：数据处理演进趋势 数据处理技术演进的趋势： 完全共享模式 存储方式：磁盘。 特点：单机、Scale up。 缺点：性能存在瓶颈、扩展性能差。 数据库服务器 存储方式：高性能网络存储。 特点：集群、Share Everything、结构化、关系型。Flash Cache+分布式块存储+IB。 完全不共享模式 存储方式：磁盘阵列。 特点：集群、Share Nothing、结构化、关系型。通用的硬件。 NameNode模式 存储方式：DateNode。 特点：集群、Share Nothing。开放、全球生态。结构化、半结构化、非结构化。高性能、实时。 大数据的特征： 数据量大：100T-PB级，几TB/天。 格式复杂：结构化，非结构化。 响应速度要求高：毫秒级。 数据价值密度低：零点零几USD/KB。 Hadoop概述Hadoop简介： Hadoop是Apache软件基金会旗下的一个开源分布式计算平台，为用户提供了系统底层细节透明的分布式基础架构 Hadoop是基于Java语言开发的，具有很好的跨平台特性，并且可以部署在廉价的计算机集群中 Hadoop的核心是分布式文件系统HDFS（Hadoop Distributed File System）和MapReduce Hadoop被公认为行业大数据标准开源软件，在分布式环境下提供了海量数据的处理能力 几乎所有主流厂商都围绕Hadoop提供开发工具、开源软件、商业化工具和技术服务，如谷歌、雅虎、微软、思科、淘宝等，都支持Hadoop Hadoop发展简史： 图：Hadoop的标志 Hadoop最初是由Apache Lucene项目的创始人Doug Cutting开发的文本搜索库。Hadoop源自始于2002年的Apache Nutch项目——一个开源的网络搜索引擎并且也是Lucene项目的一部分。 在2004年，Nutch项目也模仿GFS开发了自己的分布式文件系统NDFS（Nutch Distributed File System），也就是HDFS的前身。 2004年，谷歌公司又发表了另一篇具有深远影响的论文，阐述了MapReduce分布式编程思想。 2005年，Nutch开源实现了谷歌的MapReduce。 到了2006年2月，Nutch中的NDFS和MapReduce开始独立出来，成为Lucene项目的一个子项目，称为Hadoop，同时，Doug Cutting加盟雅虎。 2008年1月，Hadoop正式成为Apache顶级项目，Hadoop也逐渐开始被雅虎之外的其他公司使用。 2008年4月，Hadoop打破世界纪录，成为最快排序1TB数据的系统，它采用一个由910个节点构成的集群进行运算，排序时间只用了209秒。 在2009年5月，Hadoop更是把1TB数据排序时间缩短到62秒。Hadoop从此名声大震，迅速发展成为大数据时代最具影响力的开源分布式开发平台，并成为事实上的大数据处理标准。 Hadoop的特性：Hadoop是一个能够对大量数据进行分布式处理的软件框架，并且是以一种可靠、高效、可伸缩的方式进行处理的，它具有以下几个方面的特性： 高可靠性 高效性 高可扩展性 高容错性 成本低 运行在Linux平台上 支持多种编程语言 Hadoop的应用现状： Hadoop凭借其突出的优势，已经在各个领域得到了广泛的应用，而互联网领域是其应用的主阵地 2007年，雅虎在Sunnyvale总部建立了M45——一个包含了4000个处理器和1.5PB容量的Hadoop集群系统 Facebook作为全球知名的社交网站，Hadoop是非常理想的选择，Facebook主要将Hadoop平台用于日志处理、推荐系统和数据仓库等方面 国内采用Hadoop的公司主要有百度、淘宝、网易、华为、中国移动等，其中，淘宝的Hadoop集群比较大 Hadoop在企业中的应用架构： 图：Hadoop在企业中的应用架构 Hadoop版本演变： Apache Hadoop版本分为两代，我们将第一代Hadoop称为Hadoop 1.0，第二代Hadoop称为Hadoop 2.0。 第一代Hadoop包含三个大版本，分别是0.20.x，0.21.x和0.22.x，其中，0.20.x最后演化成1.0.x，变成了稳定版，而0.21.x和0.22.x则增加了NameNode HA等新的重大特性。 第二代Hadoop包含两个版本，分别是0.23.x和2.x，它们完全不同于Hadoop 1.0，是一套全新的架构，均包含HDFS Federation和YARN两个系统，相比于0.23.x，2.x增加了NameNode HA和Wire-compatibility两个重大特性。 选择 Hadoop版本的考虑因素： 是否开源（即是否免费） 是否有稳定版 是否经实践检验 是否有强大的社区支持 Hadoop项目结构： 图：Hadoop项目结构 组件 功能 HDFS 分布式文件系统 MapReduce 分布式并行编程模型 YARN 资源管理和调度器 Tez 运行在YARN之上的下一代Hadoop查询处理框架 Hive Hadoop上的数据仓库 HBase Hadoop上的非关系型的不是数据库 Pig 一个基于Hadoop的大规模数据分析平台，提供类似SQL的查询语言Pig Latin Sqoop 用于在Hadoop与传统数据库之间进行数据传递 Hadoop上的工作流管理系统 Zookeeper 提供分布式协调一致性服务 流计算框架 Flume 一个高可用，高可靠，分布式的海量日志采集、聚合和传输的系统 Ambari Hadoop快速部署工具，支持Apache Hadoop集群的供应、管理和监控 Kafka 一种高吞吐量的根不是发布订阅消息系统，可以处理消费者规模的网络的所有动作流数据 Spark 类似于Hadoop MapReduce的通用并行框架 大数据主要存储技术介绍HDFS简介：HDFS（Hadoop Distributed File System）基于谷歌发布的GFS(Google File System)论文设计开发，其除具备其他分布式文件系统相同的特性外，还有自己特有的特性： 高容错：认为硬件总是不可靠的。 高吞吐量：为有大量数据访问的应用提供高吞吐量的支持。 大文件存储：支持存储TB-PB级别的数据。 HDFS适合用于：大文件存储，流失数据访问。 HDFS不适合用于：大量小文件处理，随机写入，低延迟读写。 YARN简介：Yarn是Hadoop2.0中的资源管理系统，它是一个通用的资源管理模块，可为各类应用程序进行资源管理和调度。可支持MapReduce，Spark，Storm等多种框架。 Yarn的优势有： 资源利用率高 运维成本低 数据共享方便 MapReduce简介：MapReduce是基于Google发布的分布式计算框架MapReduce论文设计开发，用于大规模数据集（大于1TB）的并行计算。 MapReduce的特点： 易于编程：开发者仅需编写简单的程序，系统的执行框架会处理细节。 良好的扩展性：可以通过添加主机以达到扩展集群能力的目的。 高容错性：通过开算迁移或者数据迁移提高集群的可用性与容错性。 MapReduce适合用于：大规模数据离线批处理，子任务相对独立。 MapReduce不适合用于：实时交互计算，流失计算、实时分析，子任务相互依赖。 Hive简介：Hive提供数据提取、转换、加载功能，并可用类似于SQL的语法，对HDFS好了数据库中的数据进行查询统计等操作。 Hive可用于： 数据汇总：每天/每周用户点击数，点击排行。 非实时分析：日子分析，统计分析。 数据挖掘：用户行为分析，兴趣分析、区域展示。 HBase简介： HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。 HBase–Hadoop Datebase，是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可以在廉价的PC Server上搭建起大规模结构化存储集群。 HBase的用途： 海量的数据存储 准实时查询 HBase的特点： 容量大 HBase单表可以有上百亿行、百万列，数据矩阵横向和纵向两个维度所支持的数据量级都非常具有弹性。 面向列 HBase是面向列的存储和权限控制，并支持独立检索。列式存储，其数据在表中是按照某列存储的，这样在查询只需要少数几个字段的时候，能大大减少读取的数据量。 多版本 HBase每一个列的数据存储有多个Version（version）。 稀疏性 为空的列并不占用存储空间，表可以设计的非常稀疏。 扩展性 底层依赖于HDFS 高可靠性 WAL机制保证了数据写入时不会因集群异常而导致写入数据丢失：Replication机制保证了在集群出现严重的问题时，数据不会发生丢失或损坏。而且HBase底层使用HDFS，HDFS本身也有备份。 高性能 底层的LSM数据结构和Rowkey有序排列等架构上的独特设计，使得HBase具有非常高的写入性能。region切分、主键索引和缓存机制使得HBase在海量数据下具备一定的随机读取性能，该性能针对Rowkey的查询能够达到毫秒级别。 Spark简介：Spark是基于内存计算的大数据分布式计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。 Spark系统是分布式批处理系统和分析挖掘引擎。Spark可以用来快速处理数据，并支持迭代计算，有效应对多步的数据处理逻辑。 图：Spark Spark特点： 提供分布式计算功能，将分布式存储的数据读入，同时将任务分发到各个节点进行计算； 基于内存计算，将磁盘数据读入内存，将计算的中间结果保存在内存，这样可以很好的进行迭代运算； 支持高容错； 提供多计算范式 Flume简介：Flume是由Cloudera公司开源的，分布式可靠，高可用的海量日志聚和的系统，支持在系统中定制各类数据发送方，用于收集数据。同时，Flume提供对数据进行简单处理，并写到各种数据接收方（可定制）的能力。 Kafka简介：Kafka是Linkedin开源的分布式的，基于发布/订阅的日志系统。Kafka可以在消息队列中保存大量的开销很想的数据，且支持大量的消费者订阅。 Hadoop电仪应用场景离线统计分析：将海量的原始数据存储到HDFS中，定期离线做汇总统计，按分钟、手机号、地域、业务类型等维度导出到OLAP系统用于分析或报表。 图：离线数据分析示例 详单查询：将海量的原始XDR，加载如库并转换位半结构化的格式，用于低延时查询。 图：详单查询示例 云化ETL：移动数据业务和流量的爆炸式增长，带来了网络建设和维护费用的成倍增加。要求将海量数据存储在分布式存储且能够进行汇总等计算。 图：云化ETL示例]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
        <tag>华为网络大赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据概述]]></title>
    <url>%2F2018%2F04%2F03%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[大数据概述大数据产生的背景：基于海量的存储与处理面临挑战： 数据量大，数据种类多。 海量数据的高存储成本，大数据两下数据处理性能不足，流式数据处理缺失。 优先的扩展能力，单一数据源。 数据资产对外增值。 行业技术标准的日益形成： 数据处理技术分布式演进趋势：Hadoop成为开放的事实标准。 各种技术特点： SMP：单机、Scale UP。性能存在瓶颈，扩展性差。 SMP+MPP混合：集群、Share Everything。结构化、关系型。Flash cache+分布式块存储+IB。 MPP：集群、Share Nothing，结构化，关系型，通用的硬件。 Hadoop：集群，Share Nothing，开放、全球生态、结构化、半结构化、非结构化，高性能，实施。 大数据的前世今生： 大数据的提出： 1996年，SGI首次提出大数据。 描述大数据： 2001年，Gartner在评论中首先定义大数据的三个维度：数据容量、速度和种类。 大数据的实现： 业界把3V扩展到了11V，但主要包括Volume、Velocity、Variety、Value等。 大数据定义：大数据：指无法在可承受的时间内用软硬件进行捕捉、管理和处理的数据集合，需要新处理模式才能使数据集合称为具有更强的决策力、洞察力和流程优化等能力的海量、多样化的信息资产。 数据类型： 结构化数据： 是指可以存储在数据库里，可以用二维表结果来逻辑表达实现的数据。 非结构化数据： 不方便用二维表结果来逻辑表来表现的数据。包括所有格式的办公文档、文本、图片、XML、HTML、各类报表、图像、音频、视频信息等等。 半结构化数据： 介于结构化数据和非结构化数据之间的数据。HTML文档就属于半结构数据。 分析当代的数据集合，由25%的结构化数据和75%的非结构化和半结构数据构成。 大数据的价值： 在卫星测绘领域： 大数据具备海量数据存储服务能力，每天能存储1TB的数据，整个系统可以存储PB级别的数据。 在金融领域： 大数据可以帮助金融机构盘活客户少量数据资产，深挖存量数据价值。 在能源勘测领域： 大数据工具能有效降低能源公司的勘测成本，通过大数据分析，每口油井的勘探成本从800万美金降到300万美金。 在媒体娱乐领域：也有很多重要应用。 对应企业：在竞争能力、决策及时、成本控制有广泛的应用前景。 对于事业组织：在科学探索、知识服务、社会安全领域有强烈需求。 大数据的特征（4V）： 量大（Volume）：存储大，计算量大； 样多（Variety）：来源多，格式多； 快速（Velocity）: 生成速度快，处理速度要求快。 价值（Value）：价值密度低，和数据总量的大小成反比。 大数据带来的挑战： 传统网络架构不适用大数据时代。 从垂直访问到水平访问。 传统网络架构对南北向的网络流量需求支持良好，但不适应大数据映月宫对东西流量的需求。为了满足对东西流量的传输需求，要对传统网络架构进行重构。 数据中心将面临巨大挑战。 同时访问子系统压力大。 传统数据中心，计算、存储等各个子系统相对独立。用于大数据处理的数据中心，需要更高的资源利用率、自动化，需要使用虚拟化、云计算等技术对这些子系统进行整合和拉通。在重构过程中，增加了技术上的复杂性，给规划、建设、运维带来的压力和新的挑战。 数据仓库架构不适用高速反应的要求。 非结构化数据无法处理。 传统数据仓库对各类结构化关系型数据库支持良好，但不适应非结构化数据和半结构数据在数据处理上的需求。无法高效、迅速处理非结构化和半结构化的数据。同时，在存储非结构和半结构化数据的原始数据上，数据仓库也面临挑战。 大数据与云计算之间的关系： 大数据是需求，云计算是解决之道。 云计算是平台，大数据是应用。 云计算之于大数据，云计算是底层平台，大数据是应用。云计算作为底层平台整合计算、存储和网络等资源，同时提供基础脚骨资源弹性伸缩的能力。大数据在云计算平台的支撑下，调度下层资源，进行数据源加载，计算和最终结果输出等动作。 如何面对大数据：从传统的被动应对业务，到主动挖掘价值。 新的需求：管理方法，技术工具，基础架构，思维方式等。 电信大数据应用大数据带给电信行业的机会与挑战： 挑战一： 电信行业生态圈的信息产业遇到了革命性的变化，运营商相关业务的发展更加依赖数据，如传统的语音、窄带、宽带数据以及超宽带，数据经济等相关业务的数据量越来越大。 挑战二： 是OTT、虚拟运行商的介入，使得运行商竞争环境更加的复杂和激烈。 挑战三： 是客户消费模式的改变，需要大数据分析深入洞察用户的需求，进行定制化的服务，改善客户体验。 挑战四： 是提升精细化的管理水平，以数据为中心的运营支撑一体化，精细化成为必然趋势，而数据将成为企业的核心资产。 电信行业大数据典型商业需求：大数据的总体目标是构建同一的数据采集与整合能力，大数据分析处理能力，计算及数据服务能力，大数据应用能力，和互联网化的数据开放能力，支撑业务创新与商业成功。 延长用户生命周期 大数据建模支撑用户生命周期的营销和维系。 提升业务网使用量 基于大数的营销体系有效运作，支撑多批次，小群体，高成功率，多用户触点的营销。 对外价值变现 时间对外合作，MR数据轨迹形成商业价值，用户行为轨迹形成商业价值。 电信大数据三大场景应用场景： 场景一：潜在离网用户维挽场景。 通过大数据的应用管理，对潜在的离网用户进行数据分析。通过大数据实现用户管理，营销策划，营销实施和闭环反馈的拉通。当海量的大数来临后，用大数平台对所有用户进行分类、识别和管理，如常见的后付费、预付费。用户识别之后，根据用户的大数据分析结构触发营销策略。比如，用户的余额不足，签约到期，体验不好投诉或者用户流量溢出时，对其进行分析。对用户在内部进行聚到选择，匹配响应的资源套餐。通过用户的选择进行效果的反馈， 场景二：综合网管分析平台-基站关联分析场景。 根据离网用户的位置轨迹，用户的业务行为，基站地图以及基站网络质量KPI获得数据源。然后进行大数据的建模分析，判断离网用户是否与其常出没的基站存在管联，进而输出质差的基站列表，基站供需平衡度。经常出没已识别质差以及基站的未离网用户列表，最后，确定客服务的商用场景。如预付费，后付费维挽场景，网络优化以4G基站选址等。 场景三：数据变现场景：户外数字媒体/非数字媒体价值评估场景。 例如：先阶段户外媒体行业缺乏受众测量的方法。行业交易混乱，如何去进行户外广告的价值评估？ 可以通过大数据平台去分析人流量，车流量、覆盖率等相关信息，根据所得的信息来进行统一的管理，获得相应的需求描述。得到目标人群的属性，MR，工参，用户行为，RNC信令，地图等相关数据，同时结合户外的LED广告屏，公交站的广告牌，进而整合所有的数据，得出最终的广告资源价值评估，广告投放效果监测。广告投放时段和内容规划以及精准的营销策划。 中国电信兴业大数据应用方向:数字与数字化服务业务。 支撑自由业务提升，支撑非通信价值变现。进而实运行时的业务数字化。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>华为网络大赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker基础原理]]></title>
    <url>%2F2018%2F04%2F02%2FDocker%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Docker发展历程容器技术的演进： 1979年：Unix V7 chroot技术的引进开启了进程隔离的大门。 2000年：FreeBSD Jails将计算机分为多个独立的小型计算机系统。 2006年：Process Containers 进程的资源使用限制。 2008年：LXC 第一个完整的容器管理工具。 2013年：LMCTFY Libcontainer的重要组成。 2013年：Docker。 容器迅猛发展的背景： 应用架构正在发生变革—–微服务化。 基础架构系统也在发生变革—虚拟化、混合云。 容器技术：面临越多的应用数据和种类，各种底层环境， 容器技术可以完美的将各种组件封装起来，应用开发完成以后，一次开发，多次部署，随时迁移。完全不需要关注底层结构，从而更好的支持微服务架构的实现。 定义标准+服务应用： 基础设施标准化—Docker Engine。 当前所有的Linux系统均已支持Docker Engine，有了Docker Engine就可以使Docker容器运行起来。 应用交付标准化—Docker Image。 提供了一套可以快速打包为轻量级Docker Image的方法。开发人员在代码完成以后，竟可以将其打包为镜像。运维人员也不在需要准备应用、准备系统、运行环境、组件和基础软件包。 运维管理标准化—Docker Container。 运维将关注在这些标准的容器中，而不再是关注底层的复杂系统环境。 分发部署标准化—Docker Registry。 指的是容器化以后，不同版本的应用镜像都存储在镜像仓库中，运维人员可以将镜像仓库中特定版本的镜像一键部署到开发环境，测试环境或者是生产环境中。也可以实现快速的版本升级，或者回退。 史无前例的发展速度： 2016年6月，已经有46万的应用部署在容器中。容器化应用在两年内增长了3000%。 截止2016年1月为止，容器镜像下载数次达16亿次。2016年6月，次数飙升到41亿次。 容器技术精髓剖析namespace：Namespace的6项隔离： namespace 隔离的内容 UTS 主机名与域名 IPC 信号量、消息队列和共享内容 PID 进程编号 Network 网络设备、网络栈、端口 Mount 文件系统 User 用户和用户组 利用Namespace可以构建一个相对隔离的容器。 cgroups：通过Cgroups可以实现为容器设置系统资源的险恶 包括CPU，内存，I/O等等。 其他相关的Linux Kernel技术： 图：Linux Kernel selinux和apparmor可以增强对容器的访问控制。 capabilitise的主要实现在于将超级用户root的主要权限分割成各种不同的capabilities。从而更严格的控制容器的权限。 netlink技术可以完成Docker容器的网络环境配置和创建。 这些Linux Kernel技术从安全、隔离、防火墙、访问等方面为容器的成熟和落地打下了坚实的基础。 容器管理： 图：Lxc和Libcontainer Lxc是第一个完整意义上的容器管理技术，通过Lxc可以方便的创建、启动和停止一个容器。还可以通过它来操作容器中的应用，也可以查看容器的运行状态。 Libcontainer用于容器管理的包，管理namespaces、cgroups、capabilities以及文件系统来对容器控制。可用Libcontainer创建容器，并对容器进行管理。pivot_root 用于改变进程的根目录，可以将进程控制在rootfs中。如果rootfs是基于ramfs的（不支持pivot_root），那会在mount时使用MS_MOVE标志位加上chroot来顶替。 Libcontainer通过接口的方式定义了一系列容器管理的操作，包括处理容器的创建（Factory）、容器生命周期管理（Container）、进程生命周期管理（Process）等一系列接口。 Docker： 图：Docker构造架构 Docker是一个传统的Client-Server架构，装好了Docker工具后，同时也就装好了Docker Cilent端和Server端。Client是Docker命令行工具，也可以是GitHub上开源的图形化工具。通过Client工具可以发起创建、管理容器的指令至Server端进行处理。 Docker技术原理： 图：Docker技术原理 Docker是依赖Linux中一些核心技术来实现的。 Docker Daemon(守护进程)通过libcontainer、lxc等容器管理工具来接收Client端的指令完成容器管理操作。 Docker三个重要的组件： execdriver： 存储了容器定义的配置信息了，libcontainer拿到这些配置信息后，将会调用底层的namespace和cgroups等技术来完成容器的创建和管理。 networkdirver： 主要作用是完成Docker容器的网络环境配置，包括容器的IP地址，端口，防火墙策略，以及与主机的端口映射等。 graphdriver： 主要负责对容器镜像的管理。 Docker核心技术VM vs Docker： 图：VM 和 容器的对比 通过对比，容器的运行时不需要安装虚拟机的操作系统，是比虚拟机更加轻量型的虚拟化技术。 Docker的优势： 对比项 VM Docker 隔离性 强 较弱 计算资源开销 大 小 镜像大小 几百MB至几GB 可小至几MB 启动速度 数秒至数分钟 毫秒级 快速扩展能力 一般 强 跨平台迁移能力 一般 强 对微服务架构的支持 一般 强 对Devops的支持 一般 强 容器、镜像、仓库： Docker Container，容器与虚拟机一样，都是承载相关应用的载体。 Docker Image，镜像可以与虚拟机模板进行类比，将安装好的应用打包成一个镜像，需要的时候可以直接快速安装。 Docker Registry，仓库是存储镜像的地方。 Docker容器：Docker容器的三种状态： 图：Docker容器的状态 通过docker 命令可以将容器重启、停止，挂起或恢复启动。 Docker镜像： 图：Docker 镜像构建 将镜像下载到本地可通过docker run 命令就可以启动基于镜像的容器。当对镜像做一些修改以后，可以将容器commit 回去，这时会生成一个新版本的镜像。 镜像的生成除了使用commit置位，还有一种更为标准，更常用的方式。使用dockerfile 来build镜像。这种方式build出来的镜像，更新干净，透明。 图：Docker层级文件系统 Docker镜像是一种层级结构的文件系统，镜像的最上层往往是可写的，存储着已经运行容器的修改信息，当我们对容器进行kill 时，这些信息就会被删掉。当将容器commit 称为新的镜像后，这些修改信息也会保存成新的层级。 Docker仓库： 图：Docker仓库结构 Dockerhub是官方的镜像仓库，仓库中存放了各种标准化的镜像。可以使用pull 命令直接从Docker仓库中下载镜像到本地进行使用。 还可以构建企业自己的私有仓库，用于存放常用的镜像，以及企业自定义的镜像。可以通过pull 下载镜像，也可以通过push 上传镜像到私有仓库中。 Docker的核心技术Build，Ship，Run： 图；Docker的Build，ship，run流程 实现Docker一次构建，在任何地方能够运行的构想。 Docker数据卷：数据卷存在的意义： 容器运行时可使用数据卷中的文件。 数据卷可在多个容器间共享。 存储容器运行过程中产生的数据。 方便主机对容器数据的访问。 Docker网络： 图：Docker网络架构 Docker网络的四种网络模式： Bridged:表示容器可以与主机上的容器，主机，外部进行通信。 Host：表示容器只能与主机镜像通信。 Container：表示容器只能与容器之间进行通信，而无法与主机进行通信。 None：表示没有网络连接。 比较常用的是Bridged模式，安装完Docker之后，主机会生成一个Docker网桥，每个容器拥有自己的虚拟网卡，容器网卡通过网桥连接到主机的物理网卡与外部进行通信。 Docker平台架构Orchestration： 图：容器的广义编排 集群管理：容器平台是由一系列的主机来提供计算资源，通过集群，管理技术，将这些主机管理起来，获取这些主机的配置信息。实时的资源使用情况，并可以快速增加主机节点，并且需要保证整个集群的高可用性。 容器调度：集群管理能够让我们知道每一个主机的资源使用情况，我们可以将容器平均的部署到每个主机上，并且可以在某个主机资源紧张的情况下，可以让容器在其他主机上跑起来。还可以设定调度策略，实现将某几个通信紧密的容器在同样一个主机上运行，或者某些资源消耗大的容器，总是运行在不同的主机上。这就是所谓的互斥。 故障恢复：容器平台需要具备对主机和容器的健康性检查。当主机出现问题的时候，需要在其他主机上将入容器启动起来，并做好相关的服务注册。当容器出现问题是，需要将容器进行重启，或者重新部署来保证应用的健康运行。 应用编排：容器时代，应用是由一个个细微的容器来组成。每一个容器之间，具有一定的逻辑关系，我们需要使用简单明了的编排语句将这些容器管理起来。比如，容器之间的端口访问，容器的启动顺序等等，从而实现整个应用的逻辑架构。 三大Orchestration工具： 编排工具 厂商 发布时间 说明 Swarm Docker 2014年 内置于Docker，和Compose一起使用 Mesos Apache 2007年 一般会结合marathon、Zookeeper一起使用 Kubernets Google 2014年 结合Etcd一起使用 负载均衡与服务发现： 图：负载均衡与服务发现 负载均衡：指的是请求到达负载均衡器以后，负载均衡器将请求平均分配到后面的每个容器上。 常用的负载均衡技术有：haproxy、LVS、F5、Nginx。 服务发现：服务发现会自动将容器的配置信息发送给配置中心，包括IP、端口、对外的域名等。负载均衡器会周期性的从配置中心获取相关配置信息。并且将容器加入到相关的负载均衡器访问架构中。 常用的服务发现技术有：Etcd、Zookeeper、Consul。 日志管理：容器时代，对日志处理平台的要求是，集中化、海量存储、灵活过滤、快速查询、伸缩性架构、高可用、强大的UI。 图：日志管理平台EOK架构 日志管理平台EOK包含的三个组件： LogStash Shipper：主要用于收集各种各样的日志。 ElasticSearch：主要用于存储和搜索日志。 Kibana：是一个用于界面展示的管理工具。 Docker监控： 图：Docker监控架构 从主机，应用，镜像，容器的维度进行监控。并构建监控相关的告警，跟踪相关的监控，这样的一个流程体系。即WANT原则。 当前常用的监控工具有：Zabbix、Nagios、cAdvisor、Datedog、Scout。 Docker平台架构： 图：Docker平台架构 基础平台有：集群管理，网络存储，镜像管理，容器调度，应用编排。 集成功能有：弹性架构，负载均衡，性能监控，日志管理，用户中心，租户管理，持续交付，版本控制。 同时需要提供强大的Web UI和开放的API服务。 Docker平台技术体系： 图：Docker平台技术体系 Docker平台的对比三大编排工具之—Mesos：Mesos Slave安装在集群节点上的，Mesos Master作为集群的管理节点。Slave会将资源的使用情况周期性的报告给Master节点。Mesos需要配合计算架构的Framework进行资源的调度。 Mesos配合Framework的工作流程如下： 图：Mesos配合Framework的工作流程 Master会定期将所有主机的计算机资源使用情况报告给Framework Scheduler。 Scheduler进行调配后，下发部署的任务给集群节点。 节点上的Framework Executor获取任务，进行容器的部署，在容器架构中，Executor就是容器的引擎。 节点会将部署情况反馈给Master。 Master会更新最新的主机资源状态给Scheduler。 Mesos+Marathon+Zookeeper来构架Docker平台。 图：Mesos+Marathon+Zookeeper Marathon是一个可调用Docker引擎的Framework。Marathon可以将容器按照一定的调度策略部署到合适的主机上。 Zookeeper主要是用来保证Mesos和Marathon来管理节点的高可用性。即当Master节点宕机以后，可以快速的选举中新的Master节点，从而不影响整个逻辑架构。Zookeeper本身也是一个高可用性的分布式架构。 三大编排工具之—Kubernetes：Kubernetes是Google开源的容器集群管理系统，其提供应用部署、维护、 扩展机制等功能，利用Kubernetes能方便地管理跨机器运行容器化的应用，其主要功能如下： 使用Docker对应用程序包装(package)、实例化(instantiate)、运行(run)。 以集群的方式运行、管理跨机器的容器。 解决Docker跨机器容器之间的通讯问题。 Kubernetes的自我修复机制使得容器集群总是运行在用户期望的状态。 Kubernetes中的pod： 图：Kubernetes中的pod Mesos构造的平台中容器是最小的单元。 Kubernetes构建的平台中Pod是最小的单元。容器是被封装在Pod中的。一个Pod可以拥有一个或多个Docker容器。 Kubernetes设计Pod的目的主要是为了将需要紧密联系的容器放置到一个独立的空间内，即Pod。 同个pod中的容器可以方便的共享存储。 同个pod中的容器可直接访问另一个容器。 Kubernetes的整体架构： 图：Kubernetes的整体架构 三大编排工具之—Swarm：Swarm特点： 对外以Docker API接口呈现，这样带来的好处是，如果现有系统使用Docker Engine，则可以平滑将Docker Engine切到Swarm上，无需改动现有系统。 Swarm对用户来说，之前使用Docker的经验可以继承过来。非常容易上手，学习成本和二次开发成本都比较低。同时Swarm本身专注于Docker集群管理，非常轻量，占用资源也非常少。 *“Batteries included but swappable”，简单说，就是插件化机制，Swarm中的各个模块都抽象出了API，可以根据自己一些特点进行定制实现。 Swarm自身对Docker命令参数支持的比较完善，Swarm目前与Docker是同步发布的。Docker的新功能，都会第一时间在Swarm中体现。 Docker开源容器管理项目Swarm. 图：Swarm架构 Docker平台的对比： Mesos Swarm Kubernetes 应用定义 应用组定义的容器集合 Compose中定义的容器逻辑集合 Pods的集合 应用扩展 可以以容器或应用组为单位进行扩展 以容器为单位进行扩展 以pod为单位进行扩展 高可用 一般依赖于Zookeeper 依赖依赖于自己的etcd等工具 依赖于Etcd 负载均衡 可依赖于Marathon-lib 自身继承lvs 可依赖于haproxy 日志和监控 使用外部工具 使用外部工具 可使用自带工具，也可使用外部工具 Docker生态圈及企业应用案例应用场景：快速交付与CICD： 图：Docker应用，快速交付 应用场景：弹性扩展： 图：弹性扩展 Docker自测题 （判断题）Docker容器本质上是宿主机上的进程，宿主机只能是硬件服务器。 答案：错。 下列哪个不是Docker引擎的组件？ A.Docker daemon B.Rest API接口 C.Docker CLI D.Docker registries 下列关于Docker的namespace特征特性描述中哪一项是不正确的？ A.不同用户的进程通过pid namespace隔离开 B.mnt namespace允许不同namespace的进程看到的文件结构不同 C.通过net namespace实现网络隔离 D.namespace不允许每个container拥有独立的hostname和domain name 在Docker中，关于容器的描述中不正确的哪项？ A.Docker 利用容器来运行应用 B.容器看做是一个简易版的 Linux 环境 C.每个容器都是相互隔离的 D.Docker容器比较适合运行多个进程 （多选）Docker 作为成功的容器解决方案，具有下列哪些特性？ A.可移植 B.简单易用 C.跨平台 D.无需维护]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>华为网络大赛</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓝桥杯第七届省赛Java-B组]]></title>
    <url>%2F2018%2F03%2F30%2F%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%AC%AC%E4%B8%83%E5%B1%8A%E7%9C%81%E8%B5%9BJava-B%E7%BB%84%2F</url>
    <content type="text"><![CDATA[1.煤球数目： 有一堆煤球，堆成三角棱锥形。具体：第一层放1个，第二层3个（排列成三角形），第三层6个（排列成三角形），第四层10个（排列成三角形），….如果一共有100层，共有多少个煤球？ 请填表示煤球总数目的数字。注意：你提交的应该是一个整数，不要填写任何多余的内容或说明性文字。 源代码： 12345678910public class 煤球数 &#123; public static void main(String[] args) &#123; int sum = 0; for(int i = 1; i &lt;= 100; i++) for(int j = 1; j &lt;= i; j++) sum += j; System.out.println(sum); &#125;&#125; 答案： 1171700 2.生日蜡烛： 某君从某年开始每年都举办一次生日party，并且每次都要吹熄与年龄相同根数的蜡烛。 现在算起来，他一共吹熄了236根蜡烛。 请问，他从多少岁开始过生日party的？ 请填写他开始过生日party的年龄数。注意：你提交的应该是一个整数，不要填写任何多余的内容或说明性文字。 源代码： 12345678910111213141516public class 生日蜡烛 &#123; public static void main(String[] args) &#123; for(int i = 1; i &lt; 120; i++) &#123; int sum = 0; for(int j = i; j &lt;= 120; j++) &#123; sum += j; if(sum == 236) System.out.println(i); if(sum &gt; 236) break; &#125; &#125; &#125; &#125; 答案： 126 凑算式：1234&gt; B DEF&gt; A + --- + ------- = 10&gt; C GHI&gt; 这个算式中A ~ I 代表 1~9的数字，不同的字母代表不同的数字。 比如：6+8/3+952/714 就是一种解法，5+3/1+972/486 是另一种解法。 这个算式一共有多少种解法？ 注意：你提交应该是个整数，不要填写任何多余的内容或说明性文字。 源代码： 12]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回溯算法]]></title>
    <url>%2F2018%2F03%2F30%2F%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念： 回溯算法（back tracking）实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。 回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。 ​ 许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 基本思想：在包含问题的所有解的解空间树中，按照深度优先搜索的策略，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯。（其实回溯法就是对隐式图的深度优先搜索算法）。 ​ 若用回溯法求问题的所有解时，要回溯到根，且根结点的所有可行的子树都要已被搜索遍才结束。 ​ 而若使用回溯法求任一个解时，只要搜索到问题的一个解就可以结束。 用回溯法解题的一般步骤： 针对所给问题，确定问题的解空间： 首先应明确定义问题的解空间，问题的解空间应至少包含问题的一个（最优）解。 确定结点的扩展搜索规则 以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。 回溯法的一般实现：回溯法一般有两种代码实现方案，递归方法和非递归方法。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法]]></title>
    <url>%2F2018%2F03%2F30%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念：所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。 ​ 贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。 ​ 所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。 贪心算法的基本思路： 建立数学模型来描述问题。 把求解的问题分成若干个子问题。 对每一子问题求解，得到子问题的局部最优解。 把子问题的解局部最优解合成原来解问题的一个解。 贪心算法使用的问题:贪心策略适用的前提是：局部最优策略能导致产生全局最优解。 实际上，贪心算法适用的情况很少。一般，对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析，就可做出判断。 贪心算法的实现框架：123456从问题的某一初始解出发；while （能朝给定总目标前进一步）&#123; 利用可行的决策，求出可行解的一个解元素；&#125;由所有解元素组合成问题的一个可行解； 贪心策略的选择： 因为用贪心算法只能通过解局部最优解的策略来达到全局最优解，因此，一定要注意判断问题是否适合采用贪心算法策略，找到的解是否一定是问题的最优解。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>贪心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划算法]]></title>
    <url>%2F2018%2F03%2F30%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[基本概念：动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。 基本思想与策略：基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。 ​ 由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。 ​ 与分治法最大的差别是：适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 适用的情况：能采用动态规划求解的问题的一般要具有3个性质： 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。 有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势） 求解的基本步骤：动态规划所处理的问题是一个多阶段决策问题，一般由初始状态开始，通过对中间阶段决策的选择，达到结束状态。这些决策形成了一个决策序列，同时确定了完成整个过程的一条活动路线(通常是求最优的活动路线)。如图所示。动态规划的设计都有着一定的模式，一般要经历以下几个步骤。 ​ 初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态 ​ 图1 动态规划决策过程示意图 划分阶段：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解。 确定状态和状态变量：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足无后效性。 确定决策并写出状态转移方程：因为决策和状态转移有着天然的联系，状态转移就是根据上一阶段的状态和决策来导出本阶段的状态。所以如果确定了决策，状态转移方程也就可写出。但事实上常常是反过来做，根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程。 寻找边界条件：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。 ​ 一般，只要解决问题的阶段、状态和状态转移决策确定了，就可以写出状态转移方程（包括边界条件）。 实际应用中可以按以下几个简化的步骤进行设计： 分析最优解的性质，并刻画其结构特征。 递归的定义最优解。 以自底向上或自顶向下的记忆化方式（备忘录法）计算出最优值 根据计算最优值时得到的信息，构造问题的最优解 算法实现说明：动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。 ​ 使用动态规划求解问题，最重要的就是确定动态规划三要素： 问题的阶段 每个阶段的状态 从前一个阶段转化到后一个阶段之间的递推关系。 ​ 递推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现，不过因为递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，有递归不可比拟的优势，这也是动态规划算法的核心之处。 ​ 确定了动态规划的这三要素，整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态，**表格需要填写的数据一般对应此问题的在某个阶段某个状态下的最优值**（如最短路径，最长公共子序列，最大价值等），填表的过程就是根据递推关系，从1行1列开始，以行或者列优先的顺序，依次填写表格，最后根据整个表格的数据通过简单的取舍或者运算求得问题的最优解。 ​ f(n,m)=max{f(n-1,m), f(n-1,m-w[n])+P(n,m)}]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分治法]]></title>
    <url>%2F2018%2F03%2F30%2F%E5%88%86%E6%B2%BB%E6%B3%95%2F</url>
    <content type="text"><![CDATA[分治法的基本概念： 在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。这个技巧是很多高效算法的基础，如排序算法(快速排序，归并排序)，傅立叶变换(快速傅立叶变换)…… ​ 任何一个可以用计算机求解的问题所需的计算时间都与其规模有关。问题的规模越小，越容易直接求解，解题所需的计算时间也越少。例如，对于n个元素的排序问题，当n=1时，不需任何计算。n=2时，只要作一次比较即可排好序。n=3时只要作3次比较即可，…。而当n较大时，问题就不那么容易处理了。要想直接解决一个规模较大的问题，有时是相当困难的。 基本思想及策略：分治法的设计思想是：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。 分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种算法设计策略叫做分治法。 如果原问题可分割成k个子问题，1&lt;k≤n，且这些子问题都可解并可利用这些子问题的解求出原问题的解，那么这种分治法就是可行的。由分治法产生的子问题往往是原问题的较小模式，这就为使用递归技术提供了方便。在这种情况下，反复应用分治手段，可以使子问题与原问题类型一致而其规模却不断缩小，最终使子问题缩小到很容易直接求出其解。这自然导致递归过程的产生。分治与递归像一对孪生兄弟，经常同时应用在算法设计之中，并由此产生许多高效算法。 分治法适用的情况： 分治法所能解决的问题一般具有以下几个特征： 该问题的规模缩小到一定的程度就可以容易地解决 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质。 利用该问题分解出的子问题的解可以合并为该问题的解； 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。 第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加； 第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用；、 第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法。 第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好。 分治法的基本步骤：分治法在每一层递归上都有三个步骤： 分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题； 解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题 合并：将各个子问题的解合并为原问题的解。 它的一般的算法设计模式如下： ​ Divide-and-Conquer(P) if |P|≤n0 then return(ADHOC(P)) 将P分解为较小的子问题 P1 ,P2 ,…,Pk for i←1 to k do yi ← Divide-and-Conquer(Pi) △ 递归解决Pi T ← MERGE(y1,y2,…,yk) △ 合并子问题 return(T) ​ 其中|P|表示问题P的规模；n0为一阈值，表示当问题P的规模不超过n0时，问题已容易直接解出，不必再继续分解。ADHOC(P)是该分治法中的基本子算法，用于直接解小规模的问题P。因此，当P的规模不超过n0时直接用算法ADHOC(P)求解。算法MERGE(y1,y2,…,yk)是该分治法中的合并子算法，用于将P的子问题P1 ,P2 ,…,Pk的相应的解y1,y2,…,yk合并为P的解。 分治法的复杂性分析：一个分治法将规模为n的问题分成k个规模为n／m的子问题去解。设分解阀值n0=1，且adhoc解规模为1的问题耗费1个单位时间。再设将原问题分解为k个子问题以及用merge将k个子问题的解合并为原问题的解需用f(n)个单位时间。用T(n)表示该分治法解规模为|P|=n的问题所需的计算时间，则有： T（n）= k T(n/m)+f(n) ​ 通过迭代法求得方程的解： ​ 递归方程及其解只给出n等于m的方幂时T(n)的值，但是如果认为T(n)足够平滑，那么由n等于m的方幂时T(n)的值可以估计T(n)的增长速度。通常假定T(n)是单调上升的，从而当 mi≤n&lt;mi+1时，T(mi)≤T(n)&lt;T(mi+1)。 可使用分治法求解的一些经典问题： 二分搜索 大整数乘法 Strassen矩阵乘法 棋盘覆盖 合并排序 快速排序 线性时间选择 最接近点对问题 循环赛日程表 汉诺塔 依据分治法设计程序时的思维过程：实际上就是类似于数学归纳法，找到解决本问题的求解方程公式，然后根据方程公式设计递归程序。 一定是先找到最小问题规模时的求解方法 然后考虑随着问题规模增大时的求解方法 找到求解的递归函数式后（各种规模或因子），设计递归程序即可。 分治法的程序示例：旋转数组的最小数字（改造二分法）： 把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个递增排序的数组的一个旋转，输出旋转数组的最小元素。例如数组{3， 4， 5， 1， 2}为{1，2， 3， 4, 5}的一个旋转，该数组的最小值为1. 1234567891011121314151617181920212223242526public class 旋转数组的最小数字 &#123; public static void main(String[] args) &#123; int[] arr = &#123; 4, 5, 6, 1, 2, 3&#125;; System.out.println(minNum(arr)); int[] arr1 = &#123;35, 42, 52, 80, 10, 23&#125;; System.out.println(minNum(arr1)); &#125; public static int minNum(int[] arr) &#123; int begin = 0; int end = arr.length - 1; if(arr[begin] &lt; arr[end]) return arr[begin]; while (begin + 1 &lt; end) &#123; int mid = begin + ((end - begin) &gt;&gt; 1); if(arr[mid] &gt;= arr[begin]) &#123; begin = mid; &#125;else &#123; end = mid; &#125; &#125; return arr[end]; &#125;&#125; 程序运行结果： 12110 在有空字符串的有序字符串数组中查找： 有个排序后的字符串数组，其中散步这一些空字符串，编写一个方法，找出给定字符创（肯定不是空字符串）的索引。 1234567891011121314151617181920212223242526272829303132public class 字符串查找 &#123; public static void main(String[] args) &#123; String[] arr = &#123;"a", "", "ac", "", "", "ad", "", "b", "", "ba"&#125;; int res = indexOf(arr, "b"); System.out.println(res); res = indexOf(arr, "ac"); System.out.println(res); &#125; public static int indexOf(String[] arr, String s) &#123; int begin = 0; int end = arr.length - 1; while(begin &lt;= end) &#123; int indexOfMid = begin + ((end - begin) &gt;&gt; 1); while (arr[indexOfMid].equals("")) &#123; indexOfMid++; if(indexOfMid&gt;end) return -1; &#125; if(arr[indexOfMid].compareTo(s) &gt; 0) &#123; end = indexOfMid - 1; &#125;else if(arr[indexOfMid].compareTo(s) &lt; 0) &#123; begin = indexOfMid + 1; &#125;else &#123; return indexOfMid; &#125; &#125; return -1; &#125;&#125; 程序运行结果： 1272]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>分治法</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[枚举算法]]></title>
    <url>%2F2018%2F03%2F29%2F%E6%9E%9A%E4%B8%BE%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[枚举算法的基本思想 枚举算法是我们在日常中使用到的最多的一个算法，它的核心思想就是:枚举所有的可能。 枚举法的本质就是从所有候选答案中去搜索正确的解,使用该算法需要满足两个条件：(1)可预先确定候选答案的数量；(2)候选答案的范围在求解之前必须有一个确定的集合。 枚举结构：循环+判断语句。 枚举法的优缺点枚举算法的优点： 由于枚举算法一般是现实生活中问题的“直译”，因此比较直观，易于理解； 由于枚举算法建立在考察大量状态、甚至是穷举所有状态的基础上，所以算法的正确性比较容易证明 枚举算法的缺点：枚举算法的效率取决于枚举状态的数量以及单个状态枚举的代价，因此效率比较低。 使用枚举法解题的基本思路： 确定枚举对象、范围和判定条件。 逐一枚举可能的解并验证每个解是否是问题的解。 枚举算法实例：砝码称重：题目： 【问题描述】设有1g、2g、3g、5g、10g、20g的砝码各若干枚（其总重&lt;=1000），求用这些砝码能称出不同的重量个数。 【文件输入】输入1g、2g、3g、5g、10g、20g的砝码个数。 【文件输出】输出能称出不同重量的个数。 【样例输入】1 1 0 0 0 0 【样例输出】3 源代码：12345678910111213141516171819202122232425262728293031import java.util.Scanner;public class 砝码称重 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int[] a = new int [1001]; int[] b = new int [7]; //用来存放各个砝码的个数 int[] c = &#123;0, 1, 2, 3, 5, 10, 20&#125;; int[] arr = new int [7]; for(int i=1; i&lt;b.length; i++) b[i] = sc.nextInt(); for(arr[1]=0; arr[1]&lt;=b[1]; arr[1]++) for(arr[2]=0; arr[2]&lt;=b[2]; arr[2]++) for(arr[3]=0; arr[3]&lt;=b[3]; arr[3]++) for(arr[4]=0; arr[4]&lt;=b[4]; arr[4]++) for(arr[5]=0; arr[5]&lt;=b[5]; arr[5]++) for(arr[6]=0; arr[6]&lt;=b[6]; arr[6]++) &#123; int sum=0; for(int i=1; i&lt;=6; i++) &#123; sum+=arr[i]*c[i]; a[sum]=1; &#125; &#125; int num = 0; for(int i=1; i&lt;=1000; i++) &#123; if(a[i] == 1) num++; &#125; System.out.println(num); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>枚举</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法]]></title>
    <url>%2F2018%2F03%2F27%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[冒泡排序冒泡排序（英语：Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 冒泡排序算法的运作如下： 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 动图演示: 图：冒泡排序过程示意图 Java代码实现：12345678910111213141516171819202122public class Bubble_Sort &#123; public static void main(String[] args) &#123; int a[] = &#123;10, 3,19, 32, 4, 23, 323, 34, 2, 35&#125;; Bubble_Sort(a); for(int i=0; i&lt;a.length; i++) System.out.println(a[i]); &#125; //冒泡排序 private static void Bubble_Sort(int[] a) &#123; int i, j, temp; for(i = 0; i &lt; a.length-1; i++) for(j = 0; j &lt; a.length-i-1; j++) &#123; if(a[j] &gt; a[j+1]) &#123; temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; &#125; &#125; &#125;&#125; 算法分析：最佳情况：T(n) = O(n) 最差情况：T(n) = O(n2) 平均情况：T(n) = O(n2) 插入排序插入排序（英语：Insertion Sort）是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 算法描述：一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下： 从第一个元素开始，该元素可以认为已经被排序 取出下一个元素，在已经排序的元素序列中从后向前扫描 如果该元素（已排序）大于新元素，将该元素移到下一位置 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 将新元素插入到该位置后 重复步骤2~5 动图演示： 图：插入排序过程示意图 Java代码实现：12345678910111213141516171819202122232425public class Insertion_sort &#123; public static void main(String[] args) &#123; int a[] = &#123;10, 3,19, 32, 4, 23, 323, 34, 2, 35&#125;; Insertion_sort(a); for(int i=0; i&lt;a.length; i++) System.out.print(a[i] + " "); &#125; //插入排序 private static void Insertion_sort(int[] a) &#123; for(int i=0; i&lt;a.length-1; i++) &#123; for(int j=i+1; j&gt;0; j--) &#123; if(a[j-1] &lt;= a[j]) break; int temp = a[j]; a[j] = a[j-1]; a[j-1] = temp; &#125; &#125; &#125;&#125; 算法分析：最佳情况：T(n) = O(n) 最坏情况：T(n) = O(n2) 平均情况：T(n) = O(n2)。 选择排序选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 选择排序的主要优点与数据移动有关。如果某个元素位于正确的最终位置上，则它不会被移动。选择排序每次交换一对元素，它们当中至少有一个将被移到其最终位置上，因此对个元素的表进行排序总共进行至多次交换。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。 算法描述：n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下： 初始状态：无序区为R[1..n]，有序区为空； 第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区； n-1趟结束，数组有序化了。 动图演示： 图：选择排序过程示意图 Java代码实现：12345678910111213141516171819202122232425public class Select_Sort &#123; public static void main(String[] args) &#123; int a[] = &#123;10, 3,19, 32, 4, 23, 323, 34, 2, 35&#125;; select_Sort(a);select_Sort(a); for(int i=0; i&lt;a.length; i++) System.out.print(a[i]+" "); System.out.println(); &#125; //选择排序s private static void select_Sort(int[] a) &#123; for(int i = 0; i &lt; a.length-1; i++) &#123; int min = i; //未排序序列中最小数据数组下标 //在未排序元素中继续寻找最小元素，并保存其下标 for(int j = i+1; j &lt; a.length; j++) if(a[min] &gt; a[j]) min = j; //将最小元素放到已排序序列的末尾 int temp = a[min]; a[min] = a[i]; a[i] = temp; &#125; &#125;&#125; 算法分析：最佳情况：T(n) = O(n2) 最差情况：T(n) = O(n2) 平均情况：T(n) = O(n2)。 快速排序快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 算法描述：快速排序使用分治法（Divide and conquer）策略来把一个序列（list）分为两个子序列（sub-lists）。 步骤为： 从数列中挑出一个元素，称为”基准”（pivot）， 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。 动图演示： 图：快速排序过程示意图 Java代码实现：1234567891011121314151617181920212223242526272829303132public class Quick_Sort &#123; public static void main(String[] args) &#123; int a[] = &#123;10, 3,19, 32, 4, 23, 323, 34, 2, 35&#125;; quick_Sort(a, 0, a.length-1); for(int i=0; i&lt;a.length; i++) System.out.print(a[i]+" "); System.out.println(); &#125; public static void quick_Sort(int[] a, int low, int high) &#123; if(low &lt; high) &#123; int i = low, j = high, pivot = a[(low+high)/2]; while(i &lt;= j) &#123; while (a[i] &lt; pivot) i++; while (a[j] &gt; pivot) j--; if(i &lt; j) &#123; int temp = a[i]; a[i] = a[j]; a[j] = temp; i++; j--; &#125;else if(i == j) i++; &#125; quick_Sort(a, low, j); quick_Sort(a, i, high); &#125; &#125; &#125; 算法分析：最佳情况：T(n) = O(nlogn) 最差情况：T(n) = O(n2) 平均情况：T(n) = O(nlogn) 希尔排序希尔排序(Shell’s Sort)，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序是非稳定排序算法。 希尔排序是基于插入排序的以下两点性质而提出改进方法的： 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位 算法描述：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 动图演示： 图：希尔排序过程示意图,以23, 10, 4, 1的步长序列进行希尔排序 Java代码实现：123456789101112131415161718192021222324public class Shell_sort &#123; public static void main(String[] args) &#123; int a[] = &#123;10, 3,19, 32, 4, 23, 323, 34, 2, 35&#125;; shell_Sort(a); for(int i=0; i&lt;a.length; i++) System.out.print(a[i]+" "); System.out.println(); &#125; public static void shell_Sort(int[] a) &#123; int gap = 1,j, len = a.length; while(gap &lt; len/3) gap = gap * 3 + 1;//动态定义间隔序列。1, 4, 13... for(; gap&gt;0; gap /= 3) &#123; for(int i = gap; i &lt; len; i++) &#123; int temp = a[i]; for(j = i-gap; j&gt;=0 &amp;&amp; a[j]&gt;temp; j-=gap) a[j+gap] = a[j]; a[j+gap] = temp; &#125; &#125; &#125;&#125; 算法分析：最佳情况：T(n) = O(nlog2 n) 最坏情况：T(n) = O(nlog2 n) 平均情况：T(n) =O(nlog n)。 归并排序归并排序（merge-sort）是建立在归并操作上的一种有效的排序算法,该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。 算法描述：递归法： 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 重复步骤3直到某一指针超出序列尾。 将另一序列剩下的所有元素直接复制到合并序列尾 动图演示： 图：归并排序过程示意图 Java代码实现：1234567891011121314151617181920212223242526272829303132333435public class Merge_sort &#123; public static void main(String[] args) &#123; int a[] = &#123;10, 3,19, 32, 4, 23, 323, 34, 2, 35&#125;; merge_Sort(a); for(int i=0; i&lt;a.length; i++) System.out.print(a[i]+" "); System.out.println(); &#125; public static void merge_Sort(int[] a) &#123; int len = a.length; int [] result = new int[len]; merge_sort_recusiver(a, result, 0, len-1); &#125; public static void merge_sort_recusiver(int[] a, int[] result, int start, int end) &#123; if(start &gt;= end) return; int len = end - start, mid = (len/2) + start; int start1 = start, end1 = mid; int start2 = mid + 1, end2 = end; merge_sort_recusiver(a, result, start1, end1); merge_sort_recusiver(a, result, start2, end2); int k = start; while(start1 &lt;= end1 &amp;&amp; start2 &lt;= end2) result[k++] = a[start1] &lt; a[start2] ? a[start1++] : a[start2++]; while(start1 &lt;= end1) result[k++] = a[start1++]; while(start2 &lt;= end2) result[k++] = a[start2 ++]; for(k = start; k &lt;= end; k++) a[k] = result[k]; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package chapter3_排序;/** * 思路：将数组分为左右两个子数组，递归调用归并进行排序&lt;br /&gt; * 分别排序完成后，使用辅助的合并函数将两个有序的子数组合并成一个整体有序的数组&lt;br /&gt; * 时间复杂度：均：O(nlgn)，好：O(nlgn)，坏：O(nlgn)&lt;br /&gt; * 空间复杂度：需要开辟辅助空间，该辅助空间可以重用，大小为N&lt;br /&gt; * 非原址排序&lt;br /&gt; * 稳定性：所有排序都是归并，在左的永远在左，在右的永远在右，稳定&lt;br /&gt; */public class MegerSort &#123; private static int[] helper;//辅助空间，和arr的长度一样 public static void main(String[] args) &#123; int[] arr = util.ArrayUtil.arr(10); helper = new int[arr.length]; util.ArrayUtil.printArr(arr); megerSort(arr, 0, arr.length-1); util.ArrayUtil.printArr(arr); &#125; public static void megerSort(int[] arr, int p, int r) &#123; if(p &lt; r) &#123; int mid = p + ((r - p) &gt;&gt; 1); megerSort(arr, p, mid); megerSort(arr, mid + 1, r); meger(arr, p, mid, r); &#125; &#125; private static void meger(int[] arr, int p, int mid, int r) &#123; System.arraycopy(arr, p, helper, p, r - p + 1); int left = p; // 左侧队伍的头部指针，指向待比较的元素 int right = mid + 1; //右侧队伍的头部指针，指向待比较的元素 int current = p; //原数组的指针，指向待填入数据的位置 while(left &lt;= mid &amp;&amp; right &lt;= r) &#123; if(helper[left] &lt;= helper[right]) &#123; arr[current++] = helper[left++]; &#125;else &#123; arr[current++] = helper[right++]; &#125; &#125; //如果左侧队伍没比较完，需要将左侧的数依次添加到原队列后面 while(left &lt;= mid) &#123; arr[current++] = helper[left++]; &#125; &#125;&#125; 算法分析：最佳情况：T(n) = O(n) 最差情况：T(n) = O(nlogn) 平均情况：T(n) = O(nlogn)。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RIP基础知识]]></title>
    <url>%2F2018%2F03%2F23%2FRIP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[RIP简介RIP是Routing Information Protocol（路由信息协议）的简称，它是一种较为简单的内部网关协议（Interior Gateway Protocol）。RIP是一种基于距离矢量（Distance-Vector）算法的协议，它使用跳数（Hop Count）作为度量来衡量到达目的网络的距离。RIP通过UDP报文进行路由信息的交换，使用的端口号为520。 RIP包括RIP-1和RIP-2两个版本，RIP-2对RIP-1进行了扩充，使其更具有优势。 RIP原理描述RIP基本原理：RIP是一种基于距离矢量（Distance-Vector）算法的协议，它使用跳数（Hop Count）作为度量值来衡量到达目的地址的距离。在RIP网络中，缺省情况下，设备到与它直接相连网络的跳数为0，通过一个设备可达的网络的跳数为1，其余依此类推。也就是说，度量值等于从本网络到达目的网络间的设备数量。为限制收敛时间，RIP规定度量值取0～15之间的整数，大于或等于16的跳数被定义为无穷大，即目的网络或主机不可达。由于这个限制，使得RIP不可能在大型网络中得到应用。 RIPv1报文：RIP-1报文由头部（Header）和多个路由表项（Route Entries）部分组成。在一个RIP报文中，最多可以有25个路由表项。RIP是一个基于UDP协议的，并且RIP-1的数据包不能超过512字节。 图：RIPv1报文格式 字段解释： 字段名 长度 含义 Command 8比特 标识报文的类型：1：Request报文，向邻居请求全部或部分路由信息；2：Reponse报文，发送自己全部或部分路由信息，一个Response报文中最多包含25个路由表项。 Version 8比特 RIP的版本号：1：RIP-12：RIP-2 Must be zero 16/32比特 必须为零字段。 AFI（Address family identifier） 16比特 地址族标识，其值为2时表示IP协议。对于Request报文，此字段值为0。 IP Address 32比特 该路由的目的IP地址，可以是自然网段的地址，也可以是子网地址或主机地址。 Metric 32比特 路由的开销值。对于Request报文，此字段值为16。 RIPv1报文抓包示例： 图：RIPv1报文抓包示例 RIPv1的特点： 有类别路由协议。 广播更新。 基于UDP，端口号520. RIP是一个基于UDP的路由协议，并且RIPv1的数据包不能超过512字节（RIP报文头部占用4个字节,而每个路由条目占用20个八位组字节。因此,RIP消息最大为4+(25*20)=504个字节,再加上8个字节的UDP头部,所以RIP数据报的大小(不含IP包的头部)最大可达512个字节。）。RIPv1的协议报文中没有携带掩码信息，所以RIPv1在发送和接收路由更新时会根据主类网段掩码和接口地址掩码来处理路由条目。因此RIPv1无法支持路由聚合，也不支持不连续子网。RIPv1的协议报文中没有验证字段，所以RIPv1也不支持验证。 RIP工作过程分析： 图：RIP工作过程分析 初始状态:路由器开启RIP进程，宣告相应接口，则设备就会从相关接口发送和接收RIP报文。 构建路由表：路由器依据收到的RIP报文构建自己的路由表项 维护路由表：路由器每隔30秒发送更新报文，同时接收相邻路由器发送的更新报文以维护路由表项。 老化路由表项：路由器为将自己构建的路由表项启动180秒的定时器。180秒内，如果路由器收到更新报文，则重置自己的更新定时器和老化定时器。 垃圾收集表项：如果180秒过后，路由器没有收到相应路由表项的更新，则启动时长为120秒的垃圾收集定时器，同时将该路由表项的度量置为16。 删除路由表项：如果120秒之后，路由器仍然没有收到相应路由表项的更新，则路由器将该表项删除。 RIP路由表的形成：RIP启动时的初始路由表仅包含本设备的一些直连接口路由。通过相邻设备互相学习路由表项，才能实现各网段路由互通。 图：RIP路由表形成过程 RIP路由表形成过程如上图所示: RIP协议启动之后，RouterA会向相邻的路由器广播一个Request报文。 当RouterB从接口接收到RouterA发送的Request报文后，把自己的RIP路由表封装在Response报文内，然后向该接口对应的网络广播。 RouterA根据RouterB发送的Response报文，形成自己的路由表。 RIPv1的发送和接收规则：RIPv1的发送规则：注意发送时没有子网掩码。 将要发送的前缀路由和出接口网段匹配： 如果不在同一主网，此为主网边界，将前缀自动汇总为有类网段发送前缀到出接口。 如果在同一主网，检查发送的前缀是否为32位： 如果是，发送32位前缀到出接口。 如果不是，检查前缀和出口掩码是否相同： 如果不同，抑制发送或者汇聚为主网络号。 如果相同，没有边界，发送正确的前缀到出接口。 RIPv1接收规则：收到一个前缀后，如果发现是主网络号，直接放入路由表，掩码是8/16/24. 如果不是主网络号，检查是否在同一主网： 如果不在，生成有类路由，掩码按有类路由计算。 如果在同一主网，用接口掩码去掩，然后检查该前缀是网络地址还是主机地址： 如果是网络地址，生成路由，掩码等于自己的接口掩码，放入路由表。 如果不是网络地址，就默认是主机地址，生成32位路由，放入路由表。 RIP的更新与维护：RIP协议在更新和维护路由信息时主要使用四个定时器： 更新定时器（Update timer）：当此定时器超时时，立即发送更新报文。 老化定时器（Age timer）：RIP设备如果在老化时间内没有收到邻居发来的路由更新报文，则认为该路由不可达。 垃圾收集定时器（Garbage-collect timer）：如果在垃圾收集时间内不可达路由没有收到来自同一邻居的更新，则该路由将被从RIP路由表中彻底删除。 抑制定时器（Suppress timer）：当RIP设备收到对端的路由更新，其cost为16，对应路由进入抑制状态，并启动抑制定时器。为了防止路由震荡，在抑制定时器超时之前，即使再收到对端路由cost小于16的更新，也不接受。当抑制定时器超时后，就重新允许接受对端发送的路由更新报文。 RIP路由与定时器之间的关系： RIP的更新信息发布是由更新定时器控制的，默认为每30秒发送一次。 每一条路由表项对应两个定时器：老化定时器和垃圾收集定时器。当学到一条路由并添加到RIP路由表中时，老化定时器启动。如果老化定时器超时，设备仍没有收到邻居发来的更新报文，则把该路由的度量值置为16（表示路由不可达），并启动垃圾收集定时器。如果垃圾收集定时器超时，设备仍然没有收到更新报文，则在RIP路由表中删除该路由。 注意事项： 如果设备不具有触发更新功能，一个路由表项最多需要300秒才能被删除（老化时间+垃圾收集时间）。 如果存在触发更新，那么一个路由条目最多需要120秒才能被删除（即为垃圾收集时间）。 触发更新：触发更新可以缩短网络收敛时间。在路由表项变化时立即向其他设备广播该信息，而不必等待定时更新。如果没有触发更新，缺省情况下，失效的路由条目会在路由表停留最多300秒（老化定时器+垃圾收集定时器）。 RIPv2的增强特性：RIPv2特点： 无类别路由协议。 组播更新，组播地址224.0.0.9 基于UDP，端口号520. 支持外部Tag。 支持路由聚合和CIDR 支持指定下一跳。 支持认证。 RIPv2的报文： 图：RIPv2报文格式 字段解释： 字段名 长度 含义 Command 8比特 标识报文的类型：1：Request报文，向邻居请求全部或部分路由信息；2：Reponse报文，发送自己全部或部分路由信息，一个Response报文中最多包含25个路由表项。 Version 8比特 RIP的版本号：1：RIP-12：RIP-2 Must be zero 16比特 必须为零字段。 AFI（Address Family Identifier） 16比特 地址族标识，其值为2时表示IP协议。对于Request报文，此字段值为0。 Route Tag 16比特 外部路由标记。 IP Address 32比特 该路由的目的IP地址，可以是自然网段的地址，也可以是子网地址或主机地址。 Subnet Mask 32比特 目的地址的掩码。 Next Hop 32比特 提供一个更好的下一跳地址。如果为0.0.0.0，则表示发布此路由的路由器地址就是最优下一跳地址。 Metric 32比特 路由的开销值。对于Request报文，此字段为16。 RIPv2报文抓包示例： 图：RIPv1报文抓包示例 RIPv1与RIPv2的比较： RIPv1是有类路由协议，RIPv2是无类路由协议 RIPv1不能支持VLSM，RIPv2可以支持VLSM RIPv1没有认证的功能，RIPv2可以支持认证，并且有明文和MD5两种认证 RIPv1没有手工汇总的功能，RIPv2可以在关闭自动汇总的前提下，进行手工汇总 RIPv1是广播更新，RIPv2是组播更新， RIPv1对路由没有标记的功能，RIPv2可以对路由打标记（tag），用于过滤和做策略 RIPv1发送的updata最多可以携带25条路由条目，RIPv2在有认证的情况下最多只能携带24条路由 RIPv1发送的updata包里面没有next-hop属性，RIPv2有next-hop属性，可以用与路由更新的重定 RIPv2路由聚合：路由聚合的原理是，同一个自然网段内的不同子网的路由在向外（其它网段）发送时聚合成一个网段的路由发送。 RIPv2支持路由聚合，因为RIPv2报文携带掩码位，所以支持子网划分。在RIPv2中进行路由聚合可提高大型网络的可扩展性和效率，缩减路由表。 基于RIPv2进程的有类聚合即实现自动聚合。 基于接口的聚合即实现手动聚合。 如果被聚合路由携带了Tag，那么路由聚合发生之后，Tag信息将被清除。 路由聚合有两种方式： 基于RIP进程的有类聚合： 聚合后的路由使用自然掩码的路由形式发布。比如，对于10.1.1.0/24（metric=2）和10.1.2.0/24（metric=3）这两条路由，会聚合成自然网段路由10.0.0.0/8（metric=2）。RIP–2聚合是按类聚合的，聚合得到最优的metric值。 基于接口的聚合： 用户可以指定聚合地址。比如，对于10.1.1.0/24（metric=2）和10.1.2.0/24（metric=3）这两条路由，可以在指定接口上配置聚合路由10.1.0.0/16（metric=2）来代替原始路由。 RIP的特性：水平分割：水平分割（Split Horizon）的原理是，RIP从某个接口学到的路由，不会从该接口再发回给邻居路由器。这样不但减少了带宽消耗，还可以防止路由环路。 水平分割在不同网络中实现有所区别，分为按照接口和按照邻居进行水平分割。广播网、P2P和P2MP网络中是按照接口进行水平分割的，如下图所示： 图：按照接口进行水平分割原理图 RouterA会向RouterB发送到网络10.0.0.0/8的路由信息，如果没有配置水平分割，RouterB会将从RouterA学习到的这条路由再发送回给RouterA。这样，RouterA可以学习到两条到达10.0.0.0/8网络的路由：跳数为0的直连路由；下一跳指向RouterB，且跳数为2的路由。 但是在RouterA的RIP路由表中只有直连路由才是活跃的。当RouterA到网络10.0.0.0的路由变成不可达，并且RouterB还没有收到路由不可达的信息时，RouterB会继续向RouterA发送10.0.0.0/8可达的路由信息。即，RouterA会接受到错误的路由信息，认为可以通过RouterB到达10.0.0.0/8网络；而RouterB仍旧认为可以通过RouterA到达10.0.0.0/8网络，从而形成路由环路。配置水平分割后，RouterB将不会再把到网络10.0.0.0/8的路由发回给RouterA，由此避免了路由环路的产生。 对于NBMA（Non-Broadcast Multiple Access）网络，由于一个接口上连接多个邻居，所以是按照邻居进行水平分割的。路由就会按照单播方式发送，同一接口上收到的路由可以按邻居进行区分。从某一接口的对端邻居处学习到路由，不会再通过该接口发送回去。 图：按照邻居进行水平分割原理图 在NBMA网络配置了水平分割之后，RouterA会将从RouterB学习到的172.16.0.0/16路由发送给RouterC，但是不会再发送回给RouterB。 毒性反转：毒性反转（Poison Reverse）的原理是，RIP从某个接口学到路由后，从原接口发回邻居路由器，并将该路由的开销设置为16（即指明该路由不可达）。利用这种方式，可以清除对方路由表中的无用路由。 配置毒性反转后，RouterB在接收到从RouterA发来的路由后，向RouterA发送一个这条路由不可达的消息（将该路由的开销设置为16），这样RouterA就不会再从RouterB学到这条可达路由，因此就可以避免路由环路的产生。 水平分割和毒性逆转的区别：水平分割和毒性逆转都是为了防止RIP中的路由环路而设计的，但是水平分割是不将收到路由条目再按“原路返回”来避免环路，而毒性逆转遵循“坏消息比没消息好”的原则，即将路由条目按“原路返回”，但是该路由条目被标记为不可达（度量值为16）。 缺省情况下不使能毒性逆转。一般情况下，在华为设备中均使能水平分割（除NBMA网络外）而禁用毒性逆转。 多进程和多实例：RIP多进程允许为指定的RIP进程关联一组接口，从而保证该进程进行的所有协议操作都仅限于这一组接口。这样，就可以实现一台设备有多个RIP进程，不同RIP进程之间互不影响，它们之间的路由交互相当于不同路由协议之间的路由交互。 RIP多实例是为每个VPN实例绑定一个RIP进程，从而实现VPN实例与指定进程下的所有接口相关联。 RIP与BFD联动：网络上的链路故障会导致路由器重新计算路由，因此缩短路由协议的收敛时间对于提高网络性能是非常重要的。加快故障感知速度并快速通告给路由协议是一种可行的方案。 双向转发检测BFD（Bidirectional Forwarding Detection）是一种用于检测邻居路由器之间链路故障的检测机制，它通常与路由协议联动，通过快速感知链路故障并通告使得路由协议能够快速地重新收敛，从而减少由于拓扑变化导致的流量丢失。在RIP与BFD联动中，BFD可以快速检测到链路故障并通知RIP协议，从而加快RIP协议对于网络拓扑变化的响应。 RIP故障排除流程: 检查接口是否在RIP中使能：使用display rip process-id interface 可以查看运行rip的接口； 检查对方发送版本号和本地接口接收的版本号是否匹配：缺省情况下，接口只发送RIPv1报文，但可以接收RIPv1和RIPv2报文。当入接口与收到的RIP报文使用不同的版本号时，有可能造成RIP路由不能被正确的接收； 检查在RIP中是否配置了策略，过滤掉收到的RIP路由：如果被路由策略过滤掉，则需修改路由策略； RIP使用的端口520是否被禁用； 检查接口是否配置了undo rip input/output或者rip metricin设置度量值过大； 检查接口是否配置了抑制接口； 检查路由度量值是否大于16； 检查链路两端是否配置了认证，认证的配置是否正确。 RIPv1和RIPv2的兼容性问题 RIPv1和RIPv2默认互相不兼容。 运行RIPv2的路由器默认只发送和接收v2的报文，不接收v1的报文。 运行RIPv1的路由器可以接收v2的报文。 RIPv1和RIPv2兼容性实验验证： 图：RIPv1与RIPv2版本兼容性实验 配置如下： AR1： 12345678910111213 sysname AR1#interface GigabitEthernet0/0/0 ip address 10.1.1.1 255.255.255.252 #interface LoopBack0 ip address 1.1.1.1 255.255.255.255 #rip 1 version 2 network 10.0.0.0 network 1.0.0.0# AR2： 1234567891011121314&lt;AR2&gt;dis current-configuration # sysname AR2#interface GigabitEthernet0/0/0 ip address 10.1.1.2 255.255.255.252 #interface LoopBack0 ip address 2.2.2.2 255.255.255.255 #rip 1 network 10.0.0.0 network 2.0.0.0# 实验现象： 图：AR1的路由表 在AR1上开启的位RIPv2版本，路由表中并未收到从AR2中RIPv1发来的路由更新。 图：在AR2上配置为RIPv1，收到了从AR1中发送的路由，1.1.1.1/32路由条目。 图：抓包情况 实验结果： v2版RIP，将只发送v2，接收v2。 v1版本的RIP可以接收v2的报文。 当两边都是RIPv2时： 图：当都是RIPv2时Ar1的路由表 当两边都是v2时，AR1可以收到AR2发送的2.2.2.2/32这条路由条目，AR2也可以收到1.1.1.1/32. 当两边都是RIPv1时： 图：当两边都是v1版本时，AR1的路由表 图：当两边都是v1版本时，AR2的路由表 两边都是v1时，收到对方的路由条目都是有类路由，1.0.0.0/8和2.0.0.0/8。而v2版本中，收到的都是无类路由，1.1.1.1/32和2.2.2.2/32. RIP配置命令123456789101112131415161718192021222324252627282930313233343536373839404142434445checkzero//使能对RIP-1报文中的零域进行检查。//RIP-1报文中的有些字段必须为零，称之为零域。RIP-1在接收报//文时将对零域进行检查，零域的值不为零的RIP-1报文将不被处理。//checkzero只对RIP-1报文有效。host-route//允许32位主机路由加到路由表里。network network-address//对指定网段接口使能RIP路由。peer ip-address//指定RIP邻居的IP地址。配置此命令后，更新报文以单播形式发//送到对端，而不采用正常的组播或广播的形式。preference 100//配置RIP路由的优先级rip authentication-mode//配置RIP-2的认证方式及认证参数。rip bfd//指定接口上配置动态BFD会话的参数值。rip input//控制允许指定接口接收RIP报文。rip output//允许接口发送RIP报文。rip metricin//配置接口接收RIP报文时给路由增加的度量值。rip metricout//配置接口发送RIP报文给路由增加的度量值。//缺省情况下，接口发送RIP报文时给路由增加度量值为1。rip pkt-transmit//指定接口上设置RIP发送更新报文的时间间隔和每次发送报文的数量。//缺省情况下，RIP接口发送更新报文的时间间隔为200毫秒，每次发送的报文数量为50。 rip poison-reverse//使能RIP的毒性反转功能。rip split-horizon//使能RIP的水平分割功能。//如果毒性反转和水平分割都配置了，简单的水平分割行为（从某//接口学到的路由再从这个接口发布时将被抑制）会被毒性反转行为代替。rip summary-address//配置RIP路由器发布一个聚合的本地IP地址。silent-interface //来抑制接口，使其只接收报文，用来更新自己的路由表，而不发送RIP报文。summary [ always ]//使能RIP有类聚合,指定有类聚合被使能，不论水平分割功能是否配置。timers rip 30//调整定时器。//缺省情况下，路由更新报文的发送间隔为30秒，路由老化时间为180秒，路由被从路由表中删除的时间为120秒。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>RIP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓝桥杯第八届省赛Java-B组]]></title>
    <url>%2F2018%2F03%2F15%2F%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%AC%AC%E5%85%AB%E5%B1%8A%E7%9C%81%E8%B5%9BJava-B%E7%BB%84%2F</url>
    <content type="text"><![CDATA[1.购物单：题目： 小明刚刚找到工作，老板人很好，只是老板夫人很爱购物。老板忙的时候经常让小明帮忙到商场代为购物。小明很厌烦，但又不好推辞。 这不，XX大促销又来了！老板夫人开出了长长的购物单，都是有打折优惠的。 ​ 小明也有个怪癖，不到万不得已，从不刷卡，直接现金搞定。 ​ 现在小明很心烦，请你帮他计算一下，需要从取款机上取多少现金，才能搞定这次购物。 ​ 取款机只能提供100元面额的纸币。小明想尽可能少取些现金，够用就行了。 ​ 你的任务是计算出，小明最少需要取多少现金。 以下是让人头疼的购物单，为了保护隐私，物品名称被隐藏了。 -—————- ** 180.90 88折 ** 10.25 65折 ** 56.14 9折 ** 104.65 9折 ** 100.30 88折 ** 297.15 半价 ** 26.75 65折 ** 130.62 半价 ** 240.28 58折 ** 270.62 8折 ** 115.87 88折 ** 247.34 95折 ** 73.21 9折 ** 101.00 半价 ** 79.54 半价 ** 278.44 7折 ** 199.26 半价 ** 12.97 9折 ** 166.30 78折 ** 125.50 58折 ** 84.98 9折 ** 113.35 68折 ** 166.57 半价 ** 42.56 9折 ** 81.90 95折 ** 131.78 8折 ** 255.89 78折 ** 109.17 9折 ** 146.69 68折 ** 139.33 65折 ** 141.16 78折 ** 154.74 8折 ** 59.42 8折 ** 85.44 68折 ** 293.70 88折 ** 261.79 65折 ** 11.30 88折 ** 268.27 58折 ** 128.29 88折 ** 251.03 8折 ** 208.39 75折 ** 128.88 75折 ** 62.06 9折 ** 225.87 75折 ** 12.89 75折 ** 34.28 75折 ** 62.16 58折 ** 129.12 半价 ** 218.37 半价 ** 289.69 8折 -——————- 需要说明的是，88折指的是按标价的88%计算，而8折是按80%计算，余者类推。 特别地，半价是按50%计算。 请提交小明要从取款机上提取的金额，单位是元。 答案是一个整数，类似4300的样子，结尾必然是00，不要填写任何多余的内容。 源代码： 123456789101112131415161718import java.util.Scanner;public class 购物单 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); float [][] a = new float[50][2]; float sum = 0; for(int i=0; i&lt;50; i++) &#123; a[i][0] = sc.nextFloat(); a[i][1] = sc.nextFloat(); &#125; for(int i=0; i&lt;50; i++) sum += (a[i][0] * a[i][1] / 100); System.out.println(sum); &#125;&#125; 运行结果： 15136.8594 所以答案为： 5200 2.纸牌三角形：题目： A,2,3,4,5,6,7,8,9 共9张纸牌排成一个正三角形（A按1计算）。要求每个边的和相等。​ 下图就是一种排法（如有对齐问题，参看p1.png）。 ​ A​ 9 6​ 4 8​ 3 7 5 2 ​ 这样的排法可能会有很多。 ​ 如果考虑旋转、镜像后相同的算同一种，一共有多少种不同的排法呢？ ​ 请你计算并提交该数字。 ​ 注意：需要提交的是一个整数，不要提交任何多余内容。 暴力破解. 源代码： 1234567891011121314151617181920212223242526272829303132public class 纸牌三角形 &#123; public static void main(String[] args) &#123; int sum = 0; for (int a = 1; a &lt;= 9; a++) for (int b = 1; b &lt;= 9; b++) for (int c = 1; c &lt;= 9; c++) for (int d = 1; d &lt;= 9; d++) for (int e = 1; e &lt;= 9; e++) for (int f = 1; f &lt;= 9; f++) for (int g = 1; g &lt;= 9; g++) for (int h = 1; h &lt;= 9; h++) for (int i = 1; i &lt;= 9; i++) if (a + b + c + d == a + e + f + g &amp;&amp; a + b + c + d == d + h + i + g) &#123; if (a != b &amp;&amp; a != c &amp;&amp; a != d &amp;&amp; a != e &amp;&amp; a != f &amp;&amp; a != g &amp;&amp; a != h &amp;&amp; a != i) if (b != c &amp;&amp; b != d &amp;&amp; b != e &amp;&amp; b != f &amp;&amp; b != g &amp;&amp; b != h &amp;&amp; b != i) if (c != d &amp;&amp; c != e &amp;&amp; c != f &amp;&amp; c != g &amp;&amp; c != h &amp;&amp; c != i) if (d != e &amp;&amp; d != f &amp;&amp; d != g &amp;&amp; d != h &amp;&amp; d != i) if (e != f &amp;&amp; e != g &amp;&amp; e != h &amp;&amp; e != i) if (f != g &amp;&amp; f != h &amp;&amp; f != i) if (g != h &amp;&amp; g != i) if (h != i) &#123; sum++; &#125; &#125; System.out.println(sum / 2 / 3); &#125; &#125; 运行结果： 1144 所以答案为：144 3.承压计算：题目： X星球的高科技实验室中整齐地堆放着某批珍贵金属原料。 每块金属原料的外形、尺寸完全一致，但重量不同。金属材料被严格地堆放成金字塔形。 ​ 7​ 5 8​ 7 8 8​ 9 2 7 2​ 8 1 4 9 1​ 8 1 8 8 4 1​ 7 9 6 1 4 5 4​ 5 6 5 5 6 9 5 6​ 5 5 4 7 9 3 5 5 1​ 7 5 7 9 7 4 7 3 3 1​ 4 6 4 5 5 8 8 3 2 4 3​ 1 1 3 3 1 6 6 5 5 4 4 2​ 9 9 9 2 1 9 1 9 2 9 5 7 9​ 4 3 3 7 7 9 3 6 1 3 8 8 3 7​ 3 6 8 1 5 3 9 5 8 3 8 1 8 3 3​ 8 3 2 3 3 5 5 8 5 4 2 8 6 7 6 9​ 8 1 8 1 8 4 6 2 2 1 7 9 4 2 3 3 4​ 2 8 4 2 2 9 9 2 8 3 4 9 6 3 9 4 6 9​ 7 9 7 4 9 7 6 6 2 8 9 4 1 8 1 7 2 1 6​ 9 2 8 6 4 2 7 9 5 4 1 2 5 1 7 3 9 8 3 3​ 5 2 1 6 7 9 3 2 8 9 5 5 6 6 6 2 1 8 7 9 9​ 6 7 1 8 8 7 5 3 6 5 4 7 3 4 6 7 8 1 3 2 7 4​ 2 2 6 3 5 3 4 9 2 4 5 7 6 6 3 2 7 2 4 8 5 5 4​ 7 4 4 5 8 3 3 8 1 8 6 3 2 1 6 2 6 4 6 3 8 2 9 6​ 1 2 4 1 3 3 5 3 4 9 6 3 8 6 5 9 1 5 3 2 6 8 8 5 3​ 2 2 7 9 3 3 2 8 6 9 8 4 4 9 5 8 2 6 3 4 8 4 9 3 8 8 7 7 7 9 7 5 2 7 9 2 5 1 9 2 6 5 3 9 3 5 7 3 5 4 2 8 9 7 7 6 6 8 7 5 5 8 2 4 7 7 4 7 2 6 9 2 1 8 2 9 8 5 7 3 6 5 9 4 5 5 7 5 5 6 3 5 3 9 5 8 9 5 4 1 2 6 1 4 3 5 3 2 4 1X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X 其中的数字代表金属块的重量（计量单位较大）。最下一层的X代表30台极高精度的电子秤。 假设每块原料的重量都十分精确地平均落在下方的两个金属块上，最后，所有的金属块的重量都严格精确地平分落在最底层的电子秤上。电子秤的计量单位很小，所以显示的数字很大。 工作人员发现，其中读数最小的电子秤的示数为：2086458231 请你推算出：读数最大的电子秤的示数为多少？ 注意：需要提交的是一个整数，不要填写任何多余的内容。 处理过的数据，将最后一行X换成0。 7 5 8 7 8 89 2 7 28 1 4 9 18 1 8 8 4 17 9 6 1 4 5 45 6 5 5 6 9 5 65 5 4 7 9 3 5 5 17 5 7 9 7 4 7 3 3 14 6 4 5 5 8 8 3 2 4 31 1 3 3 1 6 6 5 5 4 4 29 9 9 2 1 9 1 9 2 9 5 7 94 3 3 7 7 9 3 6 1 3 8 8 3 73 6 8 1 5 3 9 5 8 3 8 1 8 3 38 3 2 3 3 5 5 8 5 4 2 8 6 7 6 98 1 8 1 8 4 6 2 2 1 7 9 4 2 3 3 42 8 4 2 2 9 9 2 8 3 4 9 6 3 9 4 6 97 9 7 4 9 7 6 6 2 8 9 4 1 8 1 7 2 1 69 2 8 6 4 2 7 9 5 4 1 2 5 1 7 3 9 8 3 35 2 1 6 7 9 3 2 8 9 5 5 6 6 6 2 1 8 7 9 96 7 1 8 8 7 5 3 6 5 4 7 3 4 6 7 8 1 3 2 7 42 2 6 3 5 3 4 9 2 4 5 7 6 6 3 2 7 2 4 8 5 5 47 4 4 5 8 3 3 8 1 8 6 3 2 1 6 2 6 4 6 3 8 2 9 61 2 4 1 3 3 5 3 4 9 6 3 8 6 5 9 1 5 3 2 6 8 8 5 32 2 7 9 3 3 2 8 6 9 8 4 4 9 5 8 2 6 3 4 8 4 9 3 8 87 7 7 9 7 5 2 7 9 2 5 1 9 2 6 5 3 9 3 5 7 3 5 4 2 8 97 7 6 6 8 7 5 5 8 2 4 7 7 4 7 2 6 9 2 1 8 2 9 8 5 7 3 65 9 4 5 5 7 5 5 6 3 5 3 9 5 8 9 5 4 1 2 6 1 4 3 5 3 2 4 10 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 解题思路：从第一层开始平均累加，将第i排的所有金属块放在第i排的第1~i位置。最后累加到最后一层，找出最大数与最小数，按照题目所给的最小数，从而根据比例求出最大读数。 源代码： 123456789101112131415161718192021222324252627282930313233package 第八届蓝桥杯;import java.util.Scanner;public class 承压计算 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); double [][] a = new double[30][30]; for(int i=0; i&lt;30; i++) for(int j=0; j&lt;=i; j++) &#123; a[i][j] = sc.nextDouble(); &#125; for(int i=1; i&lt;30; i++) &#123; for(int j=0; j&lt;=i; j++) &#123; if(j == 0) a[i][j] = a[i-1][j]/2.0 + a[i][j]; else a[i][j] = a[i-1][j-1]/2.0 + a[i-1][j]/2.0 + a[i][j]; &#125; &#125; double min = 1000000; double max = 0; for(int i=0; i&lt;30; i++) &#123; max = Math.max(max, a[29][i]); min = Math.min(min, a[29][i]); &#125; System.out.println(max + "\n" + min); System.out.println(max*2086458231/min); &#125;&#125; 程序运行结果： 123135.349468633532523.88633130304515367.2665192664E10 所以最后答案：72665192664 5.取数位：题目： 求1个整数的第k位数字有很多种方法。以下的方法就是一种。 对于题目中的测试数据，应该打印5。 请仔细分析源码，并补充划线部分所缺少的代码。 注意：只提交缺失的代码，不要填写任何已有内容或说明性的文字。。 解题思路：直接递归，很简单。 源代码： 123456789101112131415161718192021public class 取数位 &#123; static int len(int x)&#123; if(x&lt;10) return 1; return len(x/10)+1; &#125; // 取x的第k位数字 static int f(int x, int k)&#123; if(len(x)-k==0) return x%10; return f(x/10, k); //填空 &#125; public static void main(String[] args) &#123; int x = 23513; //System.out.println(len(x)); System.out.println(f(x,3)); &#125;&#125; 答案：f(x/10, k) 6.最大公共子串：题目： 最大公共子串长度问题就是： 求两个串的所有子串中能够匹配上的最大长度是多少。比如：”abcdkkk” 和 “baabcdadabc”，可以找到的最长的公共子串是”abcd”,所以最大公共子串长度为4。下面的程序是采用矩阵法进行求解的，这对串的规模不大的情况还是比较有效的解法。请分析该解法的思路，并补全划线部分缺失的代码。 解题思路：动态规划思想。 源代码： 12345678910111213141516171819202122232425262728public class 最大公共子串 &#123; static int f(String s1, String s2) &#123; char[] c1 = s1.toCharArray(); char[] c2 = s2.toCharArray(); int[][] a = new int[c1.length+1][c2.length+1]; int max = 0; for(int i=1; i&lt;a.length; i++)&#123; for(int j=1; j&lt;a[i].length; j++)&#123; if(c1[i-1]==c2[j-1]) &#123; a[i][j] = a[i-1][j-1] + 1; //填空 if(a[i][j] &gt; max) max = a[i][j]; &#125; &#125; &#125; return max; &#125; public static void main(String[] args)&#123; int n = f("abcdkkk", "baabcdadabc"); System.out.println(n); &#125; &#125; 8.包子凑数： 题目： 小明几乎每天早晨都会在一家包子铺吃早餐。他发现这家包子铺有N种蒸笼，其中第i种蒸笼恰好能放Ai个包子。每种蒸笼都有非常多笼，可以认为是无限笼。 每当有顾客想买X个包子，卖包子的大叔就会迅速选出若干笼包子来，使得这若干笼中恰好一共有X个包子。比如一共有3种蒸笼，分别能放3、4和5个包子。当顾客想买11个包子时，大叔就会选2笼3个的再加1笼5个的（也可能选出1笼3个的再加2笼4个的）。 当然有时包子大叔无论如何也凑不出顾客想买的数量。比如一共有3种蒸笼，分别能放4、5和6个包子。而顾客想买7个包子时，大叔就凑不出来了。 小明想知道一共有多少种数目是包子大叔凑不出来的。 输入第一行包含一个整数N。(1 &lt;= N &lt;= 100)以下N行每行包含一个整数Ai。(1 &lt;= Ai &lt;= 100) 输出一个整数代表答案。如果凑不出的数目有无限多个，输出INF。 例如，输入：245 程序应该输出：6 再例如，输入：246 程序应该输出：INF 源代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package 第八届蓝桥杯;import java.util.Arrays;import java.util.Scanner;public class 包子凑数 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int N = sc.nextInt(); int a[] = new int[N+1]; int b[] = new int[101]; //一种蒸笼能凑出的数集 int vis[] = new int[101];//标记能否凑出 //初始化 for(int i=0;i&lt;101;i++)&#123; vis[i]=0; &#125; for(int i=0;i&lt;N;i++)&#123; a[i]=sc.nextInt(); &#125; //只拿一种蒸笼 int k=0; for(int i=0;i&lt;N;i++)&#123; for(int j=1;j*a[i]&lt;101;j++)&#123; vis[j*a[i]]=1; b[k]=j*a[i]; k++; &#125; &#125; //多个蒸笼 for(int i=0;i&lt;k;i++)&#123; int temp1=0; int temp2=0; for(int j=i+1;j&lt;k;j++)&#123; temp1= b[i]+b[j]; temp2+=b[j]; if(temp1&lt;101) vis[temp1]=1; if(temp2&lt;101) vis[temp2]=1; &#125; &#125; //小于最小蒸笼的数不能凑出 Arrays.sort(a); for(int i=1;i&lt;a[0];i++)&#123; vis[i]=1; &#125; int sum = 0; for(int i=1;i&lt;101;i++)&#123; if(vis[i]==0) &#123; sum++; &#125; &#125; if((sum+a[0]-1)&gt;=50) System.out.println("INF"); else System.out.println(sum); &#125; &#125; 9.分巧克力：题目： 儿童节那天有K位小朋友到小明家做客。小明拿出了珍藏的巧克力招待小朋友们。 ​ 小明一共有N块巧克力，其中第i块是Hi x Wi的方格组成的长方形。 ​ 为了公平起见，小明需要从这 N 块巧克力中切出K块巧克力分给小朋友们。切出的巧克力需要满足： ​ 1. 形状是正方形，边长是整数 ​ 2. 大小相同 例如一块6x5的巧克力可以切出6块2x2的巧克力或者2块3x3的巧克力。 当然小朋友们都希望得到的巧克力尽可能大，你能帮小Hi计算出最大的边长是多少么？ 输入 第一行包含两个整数N和K。(1 &lt;= N, K &lt;= 100000) 以下N行每行包含两个整数Hi和Wi。(1 &lt;= Hi, Wi &lt;= 100000) 输入保证每位小朋友至少能获得一块1x1的巧克力。 输出 输出切出的正方形巧克力最大可能的边长。 样例输入： 2 10 6 5 5 6 样例输出： 2 资源约定： 峰值内存消耗（含虚拟机） &lt; 256M CPU消耗 &lt; 1000ms 解题思路：使用二分法。 源代码： 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.Scanner;public class 分巧克力 &#123; static int k; static int n; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); k = sc.nextInt(); int [][] a = new int[100010][2]; for(int i=0; i&lt;n; i++) &#123; a[i][0] = sc.nextInt(); a[i][1] = sc.nextInt(); &#125; int low = 1; int high = 10000; while(low &lt; high-1) &#123; int mid = (high+low)/2; if(slove(a, mid)) low = mid; else high = mid; &#125; System.out.println(low); &#125; private static boolean slove(int [][] a, int mid) &#123; int sum = 0; for(int i=0; i&lt;n; i++) &#123; int h = a[i][0]/mid; int w = a[i][1]/mid; sum += h*w; &#125; if(sum &gt;= k) return true; return false; &#125; &#125; 10.K倍区间：题目： 给定一个长度为N的数列，A1, A2, … AN，如果其中一段连续的子序列Ai, Ai+1, … Aj(i &lt;= j)之和是K的倍数，我们就称这个区间[i, j]是K倍区间。 你能求出数列中总共有多少个K倍区间吗？ 输入 -—- 第一行包含两个整数N和K。(1 &lt;= N, K &lt;= 100000) 以下N行每行包含一个整数Ai。(1 &lt;= Ai &lt;= 100000) 输出 -—- 输出一个整数，代表K倍区间的数目。 例如， 输入： 5 2 1 2 3 4 5 程序应该输出： 6 资源约定： 峰值内存消耗（含虚拟机） &lt; 256M CPU消耗 &lt; 2000ms 123456789101112131415161718192021222324252627import java.util.Scanner;public class K倍区间 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int k = sc.nextInt(); int [] a = new int[n]; for(int i=0; i&lt;n; i++) &#123; a[i] = sc.nextInt(); &#125; int s = 0; for(int i=0; i&lt;n; i++) &#123; long sum = 0; for(int j=i; j&lt;n; j++) &#123; sum += a[j]; if(sum % k == 0) &#123; s++; &#125; &#125; &#125; System.out.println(s); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>Java编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务基础概念]]></title>
    <url>%2F2018%2F03%2F14%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[从单体架构到微服务架构的演进Monolithic单体式架构简介：Monolithic单体式架构指的是尽管是模块化逻辑，但是最终还是会打包并且部署为一个单一应用，具体的格式依赖于具体的语言和框架，例如，部分java应用会被大包围WAR格式，部署在Tomcat上或者JIT上，而另外一些java应用会被打包为自包含的jar格式，同样，Reals和node.js会被打包为层级目录。 Monolithic单体式架构的优缺点： 优点：开发工具IDE和其他工具都擅长开发一个简单应用，这类应用也很易于调试和部署。只需要把打包应用拷贝到服务器端，通过在负载均衡器后端运行多个拷贝，就可以轻松是实现多个扩展 缺点：单体式架构一旦随着时间的推移，逐渐的变大，敏捷开发和部署举步维艰。任何单个开发者都很难搞懂它。修正bug和正确的添加新功能变得非常困难且很耗时。 Monolithic单体式架构面临的挑战：随着市场变化快用户需求变化快、用户访问量增加的同时，单块架构应用的维护成本、人员的培养成本、缺陷修复成本、技术架构演进的成本、系统扩展成本等都在增加。单块架构的曾经的优势已逐渐不在适应互联网时代的快速变化。 微服务架构模式提倡的做法：Microservice微服务架构是一种架构模式，提倡将Monolithic单体式架构应用划分为一系列小的服务，服务之间相互协调，相互配合，为用户提供服务。每个服务运行于其独立的进程中，服务之间采用轻量级的协议进行通信，每个服务都围绕着具体业务进行构建，并能够独立部署。 微服务架构的优点：每个服务能够内聚，代码容易理解，开发效率高，服务之间可以独立部署，使得持续部署成为可能，容易正对每个服务组件开发团队，容错性也大大提高。 包括每个服务足够内聚，代码容易理解，开发效率高。 复杂度可控：在将应用分解的同时，规避了原本复杂度无止境的积累。每一个微服务专注于单一功能，并通过定义良好的接口清晰表述服务边界。由于体积小、复杂度低，每个微服务可由一个小规模开发团队完全掌控，易于保持高可维护性和开发效率。 独立部署：由于微服务具备独立的运行进程，所以每个微服务也可以独立部署。当某个微服务发生变更时无需编译、部署整个应用。由微服务组成的应用相当于具备一系列可并行的发布流程，使得发布更加高效，同时降低对生产环境所造成的风险，最终缩短应用交付周期。 技术选型灵活：微服务架构下，技术选型是去中心化的。每个团队可以根据自身服务的需求和行业发展的现状，自由选择最适合的技术栈。由于每个微服务相对简单，故需要对技术栈进行升级时所面临的风险就较低，甚至完全重构一个微服务也是可行的。 容错：当某一组建发生故障时，在单一进程的传统架构下，故障很有可能在进程内扩散，形成应用全局性的不可用。在微服务架构下，故障会被隔离在单个服务中。若设计良好，其他服务可通过重试、平稳退化等机制实现应用层面的容错。 扩展：单块架构应用也可以实现横向扩展，就是将整个应用完整的复制到不同的节点。当应用的不同组件在扩展需求上存在差异时，微服务架构便体现出其灵活性，因为每个服务可以根据实际需求独立进行扩展。 向微服务架构演进的推荐顺序：先规划，然后是中间件和数据库，最后是服务和应用。 基于Docker的微服务应用架构设计微服务架构设计需要遵循的模式：比较知名的“12-Factor” 提供了相应的方法论。 将差异化降到最低。 基准代码： 基准代码和应用之间总是保持一一对应的关系：一但有多个基准代码，就不能称为一个应用，而是一个分布式系统. 多个应用共享一份基准代码是有悖与12-Factor原则。 依赖关系： 应用程序不会隐式依赖系统级的类库。它一定通过依赖清单，确切地声明所有的依赖项。 在运行过程中通过依赖隔离工具来确保程序不会调用系统中存在但清单中为申声明的依赖项。 高层服务可以依赖低层服务，同层服务间不互相依赖。 配置： 环境变量可以非常方便的在不同的部署间做修改，却不动一行代码。 与配置文件不同，不小心把他们嵌入代码库的该类微乎其微。 与一些传统的解决配置问题的机制（比如Java的属性配置文件）相比，环境变量与语言和系统无关。 后端服务： 12-Factor应用不会区别对待第三方服务。对应用程序而言，两种都是附加资源。 12-Factor应用的支持任意部署。如，可以在不进行任何代码改动的情况下，将本地MySQL数据库换成第三方服务。 基于容器的微服务架构剖析 Docker比VM虚拟机更加轻量。 每个Docker里面装一个服务或应用，一个服务器上可以运行多个Docker。 每个Docker中运行一个微服务。 Docker是一种崭新的PaaS平台。 Docker利用容器将资源进行有效隔离。 微服务架构设计模式 实践微服务需要面临的问题。 客户端如何访问这些服务。 服务之间的通信。 微服务云架构管理微服务简化：基于容器技术的云服务将极大的简化容器化微服务创建、集成、部署、运维的整个流程，从而推动微服务在云端的大规模实践。 微服务创建：假设用户的微服务程序，存储与GitHub等代码托管服务中，用户可以将这个代码仓库构建成容器镜像，并保存在镜像仓库中，用户可以将这个微服务一键部署到容器云平台。 云平台提供了持续集成的功能，用户可以选择是否使用。 微服务集成：用户可以自由组合、复用数以万计的容器化微服务，像搭积木一样轻松集成应用。 比如，用户需要一个通用的MySQL数据库服务，他无需构建镜像，可以直接在镜像仓库中选择合适的数据库服务镜像，并与其微服务连接起来。 微服务部署：微服务由于组件数量众多，云端部署成为实践上的一个难点。 容器云平台容器为应用发布的载体，用户不必指定传统部署方式助攻繁琐的步骤，只需提供容器镜像和简单的容器配置，平台会将真个部署流程自动化。 微服务运维：微服务由于独立进程众多，部署后的运维管理成为实践上的另一个难点。 容器云平台完全屏蔽底层云主机和基础架构运维，让用户专注于应用。 通过容器编排、自动修复、自动扩展、监控日志等高级应用生命周期服务，实现容器化微服务的智能托管。]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>华为网络大赛</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[递归与循环]]></title>
    <url>%2F2018%2F03%2F08%2F%E9%80%92%E5%BD%92%E4%B8%8E%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[递归与循环：理论上，任何循环都可以重写为递归形式。 有时候，为栈限制，需要“尾递归”。 java不支持尾递归。 有些语言没有循环语句，只能使用递归。 循环改递归：改为递归的关键是发现逻辑的“相似性”。 不要忘记递归的“出口”。 构造相似性： 如果没有明显的相似性，需要主动构造。 不能相似的原因很可能是缺少参数。 递归与数学上的递推公式类似。 递归调用： 递归调用紧紧是被函数恰为的函数。 注意每次调用的层次不同。 注意每次分配形参并非同一个变量。 注意返回的次序。 示例1，求和：1234567891011121314151617181920212223public class ArraySum &#123; public static void main(String[] args) &#123; int [] a = &#123;5, 2, 4, 3, 20&#125;; sum(a); System.out.println(f(a, 0)); &#125; //递归求和 private static int f(int[] a, int begin) &#123; if(begin == a.length) return 0; int x = f(a, begin+1); return x + a[begin]; &#125; //循环求和 private static void sum(int[] a) &#123; int sum = 0; for(int i = 0; i &lt; a.length; i++) sum+=a[i]; System.out.println(sum); &#125;&#125; 示例2，字符串比较：123456789101112131415161718192021222324public class IsSameString &#123; public static void main(String[] args) &#123; String s1 = "abce"; String s2 = "abcd"; System.out.println(isSameString(s1, s2)); System.out.println(f(s1, s2)); &#125; private static boolean f(String s1, String s2) &#123; if(s1.length() != s2.length()) return false; if(s1.length() == 0) return true; if(s1.charAt(0) != s2.charAt(0)) return false; return f(s1.substring(1), s2.substring(1)); &#125; private static boolean isSameString(String s1, String s2) &#123; return s1.equals(s2); &#125;&#125; 经典的递归问题组和问题：题目：在n个球助中，任意取出m个（不放回），求有多少中不同的取法。 12345678910111213public class 组和问题 &#123; public static void main(String[] args) &#123; int k = f(10, 3); System.out.println(k); &#125; private static int f(int n, int m) &#123; if(n &lt; m) return 0; if(n == m) return 1; if(m == 0) return 1; return f(n-1, m-1) + f(n-1, m); &#125;&#125; 全排列问题：题目：求n个元素的全排列。 12345678910111213141516171819202122232425262728public class 全排列 &#123; public static void main(String[] args) &#123; char [] date= "ABCDE".toCharArray(); f(date, 0); &#125; private static void f(char[] date, int k) &#123; if(k == date.length) &#123; for(int i =0; i &lt; date.length; i++) System.out.print(date[i] + " "); System.out.println(); &#125; for(int i = k; i &lt; date.length; i++) &#123; //试探 char t = date[k]; date[k] = date[i]; date[i] = t; f(date, k+1); //回溯 t = date[k]; date[k] = date[i]; date[i] = t; &#125; &#125;&#125; 最大公共序列：题目：求两个串的最大公共子序列的长度。 1234567891011121314151617public class 最大公共子序列 &#123; public static void main(String[] args) &#123; int k = f("abc", "xbacd"); System.out.println(k); &#125; public static int f(String s1, String s2)&#123; if(s1.length() == 0 || s2.length() == 0) return 0; if(s1.charAt(0) == s2.charAt(0)) return f(s1.substring(1), s2.substring(1)) + 1; else return Math.max(f(s1.substring(1), s2), f(s1, s2.substring(1))); &#125;&#125; 求反串：题目：求串的反转，如：abcd转换后为dcba。 123456789101112public class 求反串 &#123; public static void main(String[] args) &#123; System.out.println(f("abcd")); &#125; private static String f(String s) &#123; if(s == null || s.length() &lt; 2) return s; return f(s.substring(1)) + s.charAt(0); &#125;&#125; 杨辉三角：123456789101112131415161718public class 杨辉三角 &#123; public static void main(String[] args) &#123; int n = 15; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt;= i; j++) System.out.print(f(i, j) + " "); System.out.println(); &#125; &#125; //杨辉三角m层的第n个元素 private static int f(int m, int n) &#123; if(n == 0) return 1; if(m == n) return 1; return f(m-1, n) + f(m-1, n-1); &#125;&#125; 排列：题目：3个A，2个B有多少种排列方法？ 123456789101112public class 排列组合 &#123; public static void main(String [] args) &#123; //3个A，2个B，有多少种排列方法 System.out.println(f(3, 2)); &#125; private static int f(int m, int n) &#123; if(m == 0 || n == 0) return 1; return f(m-1, n) + f(m, n-1); &#125;&#125;//程序运行结果：10 整数的划分问题：题目：如对正整数n=6；可以划分为： 6 5+1 4+2,4+1+1 3+3, 3+2+1， 3+1+1 2+2+2， 2+2+2+1， 2+1+1+1+1 1+1+1+1+1+1 123456789101112131415161718192021222324252627282930public class 整数的划分 &#123; public static void main(String[] args) &#123; int [] a = new int[6]; f(6, a, 0); &#125; //对n进行划分 //a[]: 缓冲 //k:当前的位置 private static void f(int n, int[] a, int k) &#123; if(n&lt;=0) &#123; for(int i=0; i&lt;k; i++) &#123; if(i == k-1) &#123; System.out.print(a[i]); &#125;else System.out.print(a[i] + "+"); &#125; System.out.println(); return; &#125; for(int i=n; i&gt;0; i--) &#123; if(k&gt;0 &amp;&amp; i &gt; a[k-1]) continue; a[k] = i; f(n-i, a, k+1); &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenStack简介]]></title>
    <url>%2F2018%2F03%2F08%2FOpenStack%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[OpenStack简介OpenStack是什么？目前最流行的开源操作系统内核。 资源抽象 OpenStack将各类硬件资源，通过虚拟化与软件定义的方式，抽象成资源池。 资源分配与负载调度 OpenStack根据管理员/用户的需求，将资源池中的资源分配给不同的用户，承载不同的应用。 应用声明周期管理 OpenStack已经可以提供初步的应用部署/撤除、自动规模调整能力。 系统运维 OpenStack已经可以提供一定的系统监控能力。 人机交互 OpenStack提供人机接口，外界可以通过API、命令行或图形界面的方式参与OpenStack进行交互。 OpenStack不是什么？OpenStack不是虚拟化： OpenStack的架构定位与技术范畴 OpenStack只是系统的控制面。 OpenStack不包括系统的数据面组件，如hypervisor、存储和网络设备等。 云和虚拟化有着关键的区别 云计算：IT能力服务化； 按需使用，按量计费； 多租户隔离； 虚拟化：环境隔离，资源复用； 降低隔离损耗，提升运行效率； 提供高级虚拟化特性。 虚拟化是实现云计算的技术支撑手段之一，但并非云计算的核心关注点。 OpenStack不是云： OpenStack只是构建云的关键组件。 内核、骨干、框架、总线。 为了构建一个云，还需要许多东西： 图：云的架构 OpenStack的设计与开发：基本设计思想： 开放 开源,并尽最大可能重用已有的开源项目。 不要“重复发明轮子”，而要“站在巨人的肩膀上”。 灵活 不使用任何不可太低的私有/商有组件。 大量使用插件化方式进行架构设计与实现。 可扩展 由多个相互独立的项目组成。 每个项目包含多个独立的组件 无中心架构。 无状态架构。 OpenStack服务简介： 服务 项目名称 描述 Dashboard Horizon 提供了一个基于web的自主服务门户，与OpenStack底层服务交互，诸如启动一个实例，分配IP地址以及配置访问控制。 Computer Nova 在OpenStack环境中计算实例的生命周期管理。按需响应包括生成、调度、回收虚拟机等操作。 Network Neutron 确保为其它OpenStack服务提供网络连接即服务，比如OpenStack计算。为用户提供API定义网络和使用。基于插件的架构其支持众多的网络提供商和技术。 Objecet Storage Swift 通过一个 RESTful,基于HTTP的应用程序接口存储和任意检索的非结构化数据对象。它拥有高容错机制，基于数据复制和可扩展架构。它的实现并像是一个文件服务器需要挂载目录。在此种方式下，它写入对象和文件到多个硬盘中，以确保数据是在集群内跨服务器的多份复制。 Block Storage Cinder 为运行实例而提供的持久性块存储。它的可插拔驱动架构的功能有助于创建和管理块存储设备。 Identity Service Keystone 为其他OpenStack服务提供认证和授权服务，为所有的OpenStack服务提供一个端点目录。 Image Service Glance 存储和检索虚拟机磁盘镜像，OpenStack计算会在实例部署时使用此服务。 Telemetry Service Ceilmeter 为OpenStack云的计费、基准、扩展性以及统计等目的提供监测和计量。 Orchestration Service Heat 既可以使用本地模板格式，亦可使用AWS CloudFormation模板格式，来编排多个综合的云应用，通过OpenStack本地REST API或者是CloudFormation相兼容的队列API。 OpenStack的项目分层： 图：OpenStack的项目分层 OpenStack项目涵盖了IaaS层常用的服务类型、部分系统管理及自动化相关服务，和一些重要的IaaS+服务。 OpenStack各组件详细介绍OpenStack新建云主机流程： 图：各组件逻辑关系图 图：OpenStack新建云主机流程图 虚拟机启动过程如下： 界面或命令行通过RESTful API向keystone获取认证信息。 keystone通过用户请求认证信息，并生成auth-token返回给对应的认证请求。 界面或命令行通过RESTful API向nova-api发送一个boot instance的请求（携带auth-token）。 nova-api接受请求后向keystone发送认证请求，查看token是否为有效用户和token。 keystone验证token是否有效，如有效则返回有效的认证和对应的角色（注：有些操作需要有角色权限才能操作）。 通过认证后nova-api和数据库通讯。 初始化新建虚拟机的数据库记录。 nova-api通过rpc.call向nova-scheduler请求是否有创建虚拟机的资源(Host ID)。 nova-scheduler进程侦听消息队列，获取nova-api的请求。 nova-scheduler通过查询nova数据库中计算资源的情况，并通过调度算法计算符合虚拟机创建需要的主机。 对于有符合虚拟机创建的主机，nova-scheduler更新数据库中虚拟机对应的物理主机信息。 nova-scheduler通过rpc.cast向nova-compute发送对应的创建虚拟机请求的消息。 nova-compute会从对应的消息队列中获取创建虚拟机请求的消息。 nova-compute通过rpc.call向nova-conductor请求获取虚拟机消息。（Flavor） nova-conductor从消息队队列中拿到nova-compute请求消息。 nova-conductor根据消息查询虚拟机对应的信息。 nova-conductor从数据库中获得虚拟机对应信息。 nova-conductor把虚拟机信息通过消息的方式发送到消息队列中。 nova-compute从对应的消息队列中获取虚拟机信息消息。 nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求glance-api获取创建虚拟机所需要镜像。 glance-api向keystone认证token是否有效，并返回验证结果。 token验证通过，nova-compute获得虚拟机镜像信息(URL)。 nova-compute通过keystone的RESTfull API拿到认证k的token，并通过HTTP请求neutron-server获取创建虚拟机所需要的网络信息。 neutron-server向keystone认证token是否有效，并返回验证结果。 token验证通过，nova-compute获得虚拟机网络信息。 nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求cinder-api获取创建虚拟机所需要的持久化存储信息。 cinder-api向keystone认证token是否有效，并返回验证结果。 token验证通过，nova-compute获得虚拟机持久化存储信息。 nova-compute根据instance的信息调用配置的虚拟化驱动来创建虚拟机。 Keystone:Keystone简介： 提供身份验证、服务规则和服务令牌功能。 任何服务之间相互调用，都需要经过Keystone的身份验证。 Keystone基本概念介绍： 图：常用术语之间的逻辑关系 User OpenStack最基本的用户。 User即用户，他们代表可以通过keystone进行访问的人或程序。Users通过认证信息（credentials，如密码、APIKeys等）进行验证。 Project（Tenant） 指分配给使用者的资源的集合。 Tenant即租户，它是各个服务中的一些可以访问的资源集合。例如，在Nova中一个tenant可以是一些机器，在Swift和Glance中一个tenant可以是一些镜像存储，在Neutron中一个tenant可以是一些网络资源。Users默认的总是绑定到某些tenant上。 Role Role即角色，Roles代表一组用户可以访问的资源权限，例如Nova中的虚拟机、Glance中的镜像。Users可以被添加到任意一个全局的或租户的角色中。在全局的role中，用户的role权限作用于所有的租户，即可以对所有的租户执行role规定的权限；在租户内的role中，用户仅能在当前租户内执行role规定的权限。 Service Service即服务，如Nova、Glance、Swift。根据前三个概念（User，Tenant和Role）一个服务可以确认当前用户是否具有访问其资源的权限。但是当一个user尝试着访问其租户内的service时，他必须知道这个service是否存在以及如何访问这个service，这里通常使用一些不同的名称表示不同的服务。 Endpoint 服务的URL路径，暴露出来的访问点。 Endpoint，翻译为“端点”，我们可以理解它是一个服务暴露出来的访问点，如果需要访问一个服务，则必须知道他的endpoint。因此，在keystone中包含一个endpoint模板，这个模板提供了所有存在的服务endpoints信息。一个endpoint template包含一个URLs列表，列表中的每个URL都对应一个服务实例的访问地址，并且具有public、private和admin这三种权限。public url可以被全局访问，private url只能被局域网访问，admin url被从常规的访问中分离。 Domain 定义管理边界，可以包含多个project,user,role. Token Token是访问资源的钥匙。它是通过Keystone验证后的返回值，在之后的与其他服务交互中只需要携带Token值即可。每个Token都有一个有效期，Token只在有效期内是有效的。 Policy OpenStack对User的验证除了OpenStack的身份验证以外，还需要鉴别User对某个Service是否有访问权限。Policy机制就是用来控制User对Tenant中资源(包括Services)的操作权限。对于Keystone service来说，Policy就是一个JSON文件，默认是/etc/keystone/policy.json。通过配置这个文件，Keystone Service实现了对User基于Role的权限管理。 Credentials 用于确认用户身份的凭证。 Authentication： 确定用户身份的过程。 各种概念之间的关系解释： 图：各种概念之间的关系解释 租户下，管理着一堆用户（人，或程序）。 每个用户都有自己的credentials（凭证）用户名+密码或者用户名+APIkey，或其他凭证。 用户在访问其他资源（计算、存储）之前，需要用自己的credential去请求keystone服务，获得验证信息（主要是Token信息）和服务信息（服务目录和它们的endpoint）。 用户拿着Token信息，就可以去访问特点的资源了。 Keystone在OpenStack中的访问流程范例： 图：Keystone在OpenStack中的访问流程范例 Nova: OpenStack云中的计算组织控制器。 管理OpenStack云中示例的生命周期。 管理计算资源资源、网络、认证所需的可扩展平台。 计算管理(codenamed “Nova”)基于用户需求为VM提供计算资源管理. 基于Python语言编写。 计算服务：计算节点–运行虚拟机的Hypervisor。 分布式控制器：负责处理器调度策略及API调用等。 Nova常用术语： KVM 内核虚拟化，OpenStack中默认的Hypersvisor。 Qemu KVM的替补角色，没有KVM执行效率高，不支持虚拟化。 Flavor 新建虚拟机的配置列表，虚拟机模板。 安全组 用来控制实例访问策略的容器。 安全组规则 用来控制实例访问的具体策略。 Nova中的一些基本概念： Nova-API 对外统一提供标准化接口，接受和响应最终用户ComputeAPI的请求,同时还实现与Openstack其他各逻辑模块的通讯与服务提供。 Nova-Scheduler 从队列上得到一个虚拟机实例请求并且决定它应该在哪里运行(使用多种过滤器或算法调度)。即负责调度将实例分配到具体的计算节点。 Queue 提供了一个守护进程之间传递消息的中央枢纽。消息队列系统作用还可以实现与Openstack其他各逻辑模块之间的通信建立连接枢纽。 Nova-Datebase 存储云基础设施的编译时和运行时的状态,从理论上讲，OpenStack Nova可以支持任何SQL-Alchemy支持的数据库，但是目前被广泛使用的数据库有sqlite3（只适用于测试和开发工作），MySQL和PostgreSQL。 Nova-Compute 主要是一个人工守护进程，它可以通过虚拟机管理程序的API（XenAPIfor XenServer/XCP,libvirtfor KVM or QEMU, VMwareAPIfor VMware等）来创建和终止虚拟机实例。支持多种虚拟化平台。 Nova-conductor 主要负责与Nova数据库进行交互。 Nova还提供控制台的服务 让最终用户通过代理服务器访问他们的虚拟实例的控制台。这涉及到多个守护进程(nova-console，nova-novncproxy、nova-xvpnvncproxy和nova-consoleauth) Nova功能特性： 实例的生命周期管理。 管理平台的计算资源。 统一风格的RestAPI。 支持透明的hypervisor。 各个模块通过消息队列实现交互。 Cinder：Cinder简介： 为虚拟机示例提供volume卷的块存储服务。 一个volume可以同时挂载到多个实例上。 共享的卷同时只能被一个示例进行写操作。 Cinder主要核心是对卷的管理，允许对卷、卷的类型、卷的快照进行处理。它并没有实现对块设备的管理和实际服务，而是为后端不同的存储结构提供了统一的接口，不同的块设备服务厂商在Cinder中实现其驱动支持以与OpenStack进行整合。 块存储管理模块(codenamed “Cinder”)提供到虚拟机的永久性块存储卷.类似AWS的EBS块存储服务。 多个卷可以被挂载到单一虚拟机实例，同时卷可以在虚拟机实例间移动，单个卷在同一时刻只能被挂载到一个虚拟机实例。 块存储系统管理块设备到虚拟机的创建，挂载以及卸载。 块设备卷完全与OpenstackCompute集成,并支持云用户在Dashboard中管理数据自己的存储。 除了支持简单的Linux服务器本地存储之外，还支持众多的存储平台,包括Ceph,NetApp, Nexenta,SolidFire,Zadara。 快照管理提供了强大的在块存储上实现数据备份的功能可以用来作为引导卷使用。 块存储适合性能敏感性业务场景,例如数据库存储大规模可扩展的文件系统或服务器需要访问到块级裸设备存储。 常用术语： Volume备份：volume卷的备份。 Volume快照：卷在某个时间点的状态。 Cinder API：为Cinder请求提供的统一风格的Rest API服务。 Cinder Schedule：负责为新建卷指定块存储设备。 Cinder Volume：负责与存储的块设备交互，实现卷的创建、删除、修改等操作。 Cinder Backup：备份服务负责通过驱动和后端的备份设备打交道。 Cinder的架构： 图：Cinder的架构 API Service：负责接受和处理 Rest请求，并将请求放入 RabbitMQ对列。 Scheduler Service:处理任务队列的任务，并根据预定策略选择合适的 Volume Service 节点来执行任务。目前版本的Cinder仅仅提供了一个 Simple Scheduler, 该调度器选择卷数量最少的一个活跃节点来创建卷。 Volume Service: 该服务运行在存储节点上，管理存储空间。每个存储节点都有一个 Volume Service，若干个这样的存储节点联合起来可以构成一个存储资源池。为了支持不同类型和型号的存储，均通过Drivers的形式为Cinder的 Volume Service 提供相应的Cinder-Volume。 Volume-Resize：在可用情况下调整卷大小。 Volume-Backup-To-Ceph：现在卷可以备份到Ceph集群中。 Volume-Migration：现在不同用户间可以透明地转移和交换卷。 QoS：增加限速相关的元信息供Nova和其 Hypervisor使用。 More-Drivers：更多的存储厂商加入和完善了自己的Cinder驱动。 Cinder目前支持的存储类型： 本地存储：LVM,Sheepdog 网络存储：NFS,RBD(Ceph) HP:3PAR (iSCSI/FC),LeftHand (iSCSI) IBM: Storwize family/SVC (iSCSI/FC)，XIV(iSCSI)， GPFS，zVM Netapp: NetApp(iSCSI/NFS) EMC: VMAX/VNX (iSCSI)，Isilon(iSCSI) Solidfire:Solidfire cluster(iSCSI) Swift：Swift简介： 高可用分布式式对象存储。 为nova组件提供虚拟化的镜像存储。 使用与互联网应用场景下非结构化的数据存储。 分布式对象存储系统，类似于AWS的S3。 通过采用基于标准化服务器的集群架构提供冗余,可扩展的对象存储。 具有良好的扩展性,可以实现PB级别数据的存储。 支持存储对象写入的多份拷贝,并且支持当拷贝丢失后的自我修复功能.确保数据的一致性。 提供每GB高性价比的极佳的可用性和数据耐久性。 支持原生的 OpenStack™ API 以及S3 compatible API。 Swift常用术语： Account： 用户定义的管理存储区域。 Container： 存储间隔，类似于文件夹或目录。 Object： 包含了基本的存储实体和它自身的元数据。 Ring： 记录了磁盘存储的实体名称和物理位置的映射关系。 Account包含Container，Container包含Object。 Region： 地域，从地理位置上划分的一个概念。 Zone： 可用区，按照独立的供网、供电基础设置划分。 Node： 节点，存储服务器。 Disk： 磁盘，物理服务器上的存储设备。 Cluster： 群集，为冗余考虑的部署架构。 Cluster包含Region，Region包含Zone；Zone包含Node。 Swift功能：Swift在物理结构上往往会存储对象的多个副本，通常按照物理位置的特点，将对象拷贝到不同的物理位置上，来保证数据的可靠性。 Swift数据模型：Swift采用层次数据模型，共设三层逻辑结构：Account/Container/Object（即账户/容器/对象)，每层节点数均没有限制，可以任意扩展。数据存储基于NWR理论。 Account对应租户,用于隔离。 Container对应某个租户数据的存储区域。 Object对应存储区域中具体的block。 Swift系统架构： Swift 采用完全对称、面向资源的分布式系统架构设计。 所有组件都可扩展，避免因单点失效而扩散并影响整个系统运转。 通信方式采用非阻塞式I/O 模式，提高了系统吞吐和响应能力。 图：Swift系统架构 Swift系统组件： 代理服务（Proxy Server）：对外提供对象服务API，会根据环的信息来查找服务地址并转发用户请求至相应的账户、容器或者对象服务；由于采用无状态的REST请求协议，可以进行横向扩展来均衡负载。 认证服务（Authentication Server）：验证访问用户的身份信息，并获得一个对象访问令牌（Token），在一定的时间内会一直有效；验证访问令牌的有效性并缓存下来直至过期时间。 缓存服务（Cache Server）：缓存的内容包括对象服务令牌，账户和容器的存在信息，但不会缓存对象本身的数据；缓存服务可采用Memcached集群，Swift会使用一致性散列算法来分配缓存地址。 账户服务（Account Server）：提供账户元数据和统计信息，并维护所含容器列表的服务，每个账户的信息被存储在一个SQLite数据库中。 容器服务（Container Server）：提供容器元数据和统计信息，并维护所含对象列表的服务，每个容器的信息也存储在一个SQLite数据库中。 对象服务（Object Server）：提供对象元数据和内容服务，每个对象的内容会以文件的形式存储在文件系统中，元数据会作为文件属性来存储，建议采用支持扩展属性的XFS文件系统。 复制服务（Replicator）：会检测本地分区副本和远程副本是否一致，具体是通过对比散列文件和高级水印来完成，发现不一致时会采用推式（Push）更新远程副本，例如对象复制服务会使用远程文件拷贝工具rsync来同步；另外一个任务是确保被标记删除的对象从文件系统中移除。 更新服务（Updater）：当对象由于高负载的原因而无法立即更新时，任务将会被序列化到在本地文件系统中进行排队，以便服务恢复后进行异步更新；例如成功创建对象后容器服务器没有及时更新对象列表，这个时候容器的更新操作就会进入排队中，更新服务会在系统恢复正常后扫描队列并进行相应的更新处理。 审计服务（Auditor）：检查对象，容器和账户的完整性，如果发现比特级的错误，文件将被隔离，并复制其他的副本以覆盖本地损坏的副本；其他类型的错误会被记录到日志中。 账户清理服务（Account Reaper）：移除被标记为删除的账户，删除其所包含的所有容器和对象。 对Swift的补充-SINA的经验：主要组件 Proxy Server ProxyServer是提供SwiftAPI的服务器进程，负责Swift其余组件间的相互通信。对于每个客户端的请求，它将在Ring中查询Account、Container或Object的位置，并且相应地转发请求。Proxy提供了Rest-fullAPI，并且符合标准的HTTP协议规范，这使得开发者可以快捷构建定制的Client与Swift交互。 Storage Server StorageServer提供了磁盘设备上的存储服务。在Swift中有三类存储服务器：Account、Container和Object。其中Container服务器负责处理Object的列表，Container服务器并不知道对象存放位置，只知道指定Container里存的哪些Object。这些Object信息以sqlite数据库文件的形式存储。Container服务器也做一些跟踪统计，例如Object的总数、Container的使用情况。 Consistency Servers 在磁盘上存储数据并向外提供Rest-fulAPI并不是难以解决的问题，最主要的问题在于故障处理。Swift的Consistency Servers的目的是查找并解决由数据损坏和硬件故障引起的错误。主要存在三个Server：Auditor、Updater和Replicator。 Auditor运行在每个Swift服务器的后台持续地扫描磁盘来检测对象、Container和账号的完整性。如果发现数据损坏，Auditor就会将该文件移动到隔离区域，然后由Replicator负责用一个完好的拷贝来替代该数据。图2给出了隔离对象的处理流图。在系统高负荷或者发生故障的情况下，Container或账号中的数据不会被立即更新。如果更新失败，该次更新在本地文件系统上会被加入队列，然后Updaters会继续处理这些失败了的更新工作，其中由AccountUpdater和ContainerUpdater分别负责Account和Object列表的更新。Replicator的功能是处理数据的存放位置是否正确并且保持数据的合理拷贝数，它的设计目的是Swift服务器在面临如网络中断或者驱动器故障等临时性故障情况时可以保持系统的一致性。 Ring Ring是Swift最重要的组件，用于记录存储对象与物理位置间的映射关系。在涉及查询Account、Container、Object信息时，就需要查询集群的Ring信息。 Ring使用Zone、Device、Partition和Replica来维护这些映射信息。Ring中每个Partition在集群中都（默认）有3个Replica。每个Partition的位置由Ring来维护，并存储在映射中。Ring文件在系统初始化时创建，之后每次增减存储节点时，需要重新平衡一下Ring文件中的项目，以保证增减节点时，系统因此而发生迁移的文件数量最少。 Replica 如果集群中的数据在本地节点上只有一份，一旦发生故障就可能会造成数据的永久性丢失。因此，需要有冗余的副本来保证数据安全。Swift中引入了Replica的概念，其默认值为3，理论依据主要来源于NWR策略（也叫Quorum协议）。 NWR是一种在分布式存储系统中用于控制一致性级别的策略。在Amazon的Dynamo云存储系统中，使用了NWR来控制一致性。其中，N代表同一份数据的Replica的份数，W是更新一个数据对象时需要确保成功更新的份数；R代表读取一个数据需要读取的Replica的份数。公式W+R&gt;N，保证某个数据不被两个不同的事务同时读和写；公式W&gt;N/2保证两个事务不能并发写某一个数据。在分布式系统中，数据的单点是不允许存在的。即线上正常存在的Replica数量为1的情况是非常危险的，因为一旦这个Replica再次出错，就可能发生数据的永久性错误。假如我们把N设置成为2，那么只要有一个存储节点发生损坏，就会有单点的存在，所以N必须大于2。N越高，系统的维护成本和整体成本就越高。工业界通常把N设置为3。例如，对于MySQL主从结构，其NWR数值分别是N=2, W = 1, R = 1，没有满足NWR策略。而Swift的N=3,W=2, R=2，完全符合NWR策略，因此Swift系统是可靠的，没有单点故 Zone 如果所有的Node都在一个机架或一个机房中，那么一旦发生断电、网络故障等，都将造成用户无法访问。因此需要一种机制对机器的物理位置进行隔离，以满足分区容忍性（CAP理论中的P）。因此，Ring中引入了Zone的概念，把集群的Node分配到每个Zone中。其中同一个Partition的Replica不能同时放在同一个Node上或同一个Zone内。注意，Zone的大小可以根据业务需求和硬件条件自定义，可以是一块磁盘、一台存储服务器，也可以是一个机架甚至一个IDC。 Weight Ring引入Weight的目的是解决未来添加存储能力更大的Node时，分配到更多的Partition。例如，2TB容量的Node的Partition数为1TB的两倍，那么就可以设置2TB的Weight为200，而1TB的为100。 Glance：Glance简介： 为Nova提供镜像服务。 通常不负责镜像的本地存储。 实现对镜像的管理。 Glance是OpenStack镜像服务,用来注册、登陆和检索虚拟机镜像。Glance服务提供了一个REST API，使你能够查询虚拟机镜像元数据和检索的实际镜像。通过镜像服务提供的虚拟机镜像可以存储在不同的位置，从简单的文件系统对象存储到类似OpeenStack对象存储系统。 镜像服务组件: Glance-API ： 负责提供镜像服务的rest api。 接收最终用户或Noav对镜像的请求,检索和存储镜像的相关API调用。 Glance-registry： 存储,处理和检索有关镜像的元数据,元数据大小、类型等等。 Database ：存储镜像元数据,可以支持多种数据库,现在使用比较广泛的是mysql和sqlite. Glance与其他模块的关系: 图： Glance与其他模块的关系 Glance支持的镜像格式： raw –非结构化的镜像格式 vhd– 一种通用的虚拟机磁盘格式，可用于Vmware、Xen、Microsoft Virtual PC/VirtualServer/Hyper-V、VirtualBox等 vmdk– Vmware的虚拟机磁盘格式，同样也支持多种Hypervisor vdi– VirtualBox、QEMU等支持的虚拟机磁盘格式 qcow2 –一种支持QEMU并且可以动态扩展的磁盘格式 aki– Amazon Kernel 镜像 ari– Amazon Ramdisk 镜像 ami– Amazon 虚拟机镜像 Neutron: 提供网络服务的核心组件。 基于软件定义网络的的思想。 网络服务(codenamed “Quantum/Neutron”)提供在被管理设备之间的网络连接服务. 允许用户自己创建自己的网络并attach端口使用. 通过开发的Plugins支持SDN和OpenFlow 用户自定义子网地址,私有网络/公有网络以及FloatingIP分配规则 基于插件的模型。 常用术语： Bridge-int 实现内部网络功能的网桥。 Br-ex： 跟外部网络通信的网桥。 Neutron-server： 提供API接口。 Neutron-L2-agent： 实现二层网络通信的代理。 Neutron-DHCP-agent： 为子网自动分发IP地址。 Neutron-L3-agent： 租户网络和floating IP间地址的转换。 Neutron-metadate-agent： 响应Nova的metadate请求。 LBaas agent： 为多台实例和Open vswitch agent提供负载均衡服务。 服务组件： Neutron API l提供Openstack其他服务或管理员及用户访问的接口. 抽相层 网络资源抽象化,包括网络，子网，端口及路由。将底层各种各样的网络资源按照openstack定义的网络描述规则化。 Plug-in 通过Plug-in方式可以整合更多的高级的功能以及与底层网络厂商的设备实现更好的集成。 网络Agent： Plug-in agent:本地虚拟交换配置。 Dhcp agent:为tenant网络提供DHCP服务。 L3agent:提供l3/NAT转发功能，为tenant网络中的vm提供外网访问。 Meteringagent:提供l3流量监控和计量。 网络描述： 管理网络：用于OpenStack各组件之间的内部通信。 数据网络：用于云部署中虚拟数据之间的通信。 外部网络：公共网络，外部或internet可以访问的网络。 API网络：暴露所有的OpenStackAPIs,包括OpenStack网络 API给租户 Neutron服务网络管理的三种模式，两种IP：两种IP： 固定IP(Fixed-IP)：分配给虚拟机实例使用 浮动IP(FloatingIP)：分配给虚拟机实例的外网地址,通过NAT方式实现。 三种模式： Flat模式 Flat 模式是最简单的一种联网模式。每个实例接收一个来自池的固定IP。所有实例均默认附加到相同的桥(br100)。桥必须进行手动配置。联网配置在实例引导前插入到实例中。在这种模式中，没有浮动IP特性。 Flat DHCP模式 用于测试环境。 这种模式下与Flat模式不同的地方在于有一个DHCP进程，每一个运行nova-network进程的节点（网络控制节点/nove-network主机）就是一个单独的网络。Nova会在 nova-network主机建立网桥（默认名称br100，配置项 flat_network_bridge=br100），并给该网桥指定该网络的网关IP，同时 Nova在网桥处起一个DHCP进程，最后，会建立iptables规则（SNAT/DNAT）使虚拟机能够与外界通信，同时与一个metadata服务器通信以取得cloud内的信息。 计算节点负责创建对应节点的网桥，此时的计算节点网卡可以不需要IP地址，因为网桥把虚拟机与nove-network主机连接在一个逻辑网络内。虚拟机启动时会发送dhcpdiscover以获取 IP地址。虚拟机通往外界的数据都要通过nova-network主机，DHCP在网桥处监听，分配fixed_range指定的 IP段。 这种部署方式的缺点—-单节点故障、无二层隔离（即所有的虚拟机都在一个广播域）。 VLAN模式 用于生产环境。 VLAN模式的目的是为每个项目提供受保护的网段，具有以下特点： NAT实现public ip。 除了public NAT外没有其它途径进入每个lan。 受限的流出网络，project-admin可以控制。 受限的项目之间的访问，同样project-admin控制。 所以实例和api的连接通过vpn。 Ceilometer： OpenStack中的数据监控器。 为流量计费提供数据支持。 核心概念： Ceilometer-agent-computer： 收集计算节点上的信息的代理。 Ceilometer-agent-central： 运行在控制节点上，轮询服务的非持续化数据。 Ceilometer-collector： 运行在控制节点上，监听Message Bus，将收到的消息写入到数据库中。 Storage： 数据存储，支持MySQL等，用于存储收到的样本数据。 API server: 运行在控制节点上，提供对数据节点的访问。 Message Bus： 计量数据的消息总线，收集数据提供给collector。 Heat： OpenStack的核心项目之一。 提供基于模板的编排服务。 常用术语： Stack：指的是Heat要用到的所有设施和资源的集合。 Heat template：是以 .yaml结尾的文件，用于创建Stack。 heat-api：提供rest-api服务，将api请求发送给heat engine去执行。 haet-api-cfn：支持亚马逊格式访问的Rest-api。 Heat-engine：Heat的核心模块，接收请求API请求在OpenStack中创建资源。 Heat-cfntools、Heat-init：在镜像中安装完成虚拟化实例操作任务的工具。 Heat-api-cloudwatch：监控编排服务。 Resource：底层各种服务抽象的集合。 Heat-Client：调用访问其他各个组件的Client工具。]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>华为网络大赛</tag>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FusionSphere整体介绍]]></title>
    <url>%2F2018%2F03%2F04%2FFusionSphere%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[FusionSphere-概念认识FusionSpherer： 华为公司面向多行业客户推出的云操作系统产品。 专门为云设计和优化。 提供强大的虚拟化功能和资源池管理。 丰富的云基础服务组件和工具。 开放的API接口等。 水平整合数据中心物理和虚拟资源，垂直优化业务平台，让企业云计算更加简捷。 FusionSpherer 虚拟基础架构层 FusionComputer CNA 虚拟资源管理层 FusionComputer VRM 云资源管理层 FusionManager/FusionSpherer Openstack FusionSpherer-组成构建及分述FusionSpherer构成部件： 图：FusionSpherer构成部件 FusionComputer计算设备虚拟化：FusionComputer是建立虚拟化环境用到的必选功能模块。 FusionComputer包含模块及模块间的示意图： 图：FusionComputer模块关系 FusionStorage: 华为FusionStorage是一款软件定义分布式块存储软件。 FusionStorage可以为FusionSphere,VMware和物理数据库环境提供高扩展，高性能，高可靠的块存储服务。可以独立购买和使用，对于构建FusionSphere环境，其是可选功能模块 。 FusionStorage包含模块及模块间关系示意 图：FusionStorage模块关系 FusionNetwork: 华为软件定义网络功能模块。 FusionNetwork是建立/使用高级网络功能， 灵活配置管理网络功能的组件。对于构建FusionSphere环境， 其是可选功能模块 Fusion Network包含模块及模块间关系示意: 图：FusionNetwork模块关系 OpenStack模型： OpenStack模块是实现虚拟化环境的统一模型。 OpenStack被引入FusionSphere，实现异构虚拟化环境的同一资源抽象，管理和分配。 OpenStack插件化扩展示意图： 图:OpenStack插件化示意图 FusionSphere-兼容性，规格参数硬件兼容性包括： 服务器 存储设备 网络设备 I/O设备，如网卡，RAID卡，HBA卡，GPU等。 Guest OS，Linux，Windows。 软件兼容性主要包括： FusionSphere应用兼容性列表： 如数据库软件，中间件，Web服务器软件，Email，HA，备份容灾，安全类软件，企业应用软件等。 FusionSpherer OpenStack应用兼容性类别： 如数据库软件，Web服务器软件，文件服务软件，DNS软件，ICT应用软件等。 FusionSpherer规格参数： FusionSpherer-三个主要场景及典型部署形式服务器虚拟化场景： 图：服务器虚拟化场景 ：图：服务器虚拟化典型部署 图：FusionSpherer服务器虚拟化场景典型部署 Local FusionManager定位于本地数据中心虚拟化环境接入管理等配置。 FusionManager ServiceCenter定位千全局资源管理分配，租户portal和自服务等功能。 ManageOne数据中心统一管理软件包含ManageOne ServiceCenter运营中心和ManageOne OperationCenter运维中心。 ManageOne ServiceCenter负责企业资源统一运营管理。 ManageOne OperationCenter负责企业资源统一运维管理。 云数据中心场景： 图：云数据中心场景 图：云数据中心典型部署场景 图：云数据中心典型部署场景 NFV场景： 图：FusionSphere NFV场景 FusionSphere-灾备方案华为数据保护—-eBackup产品： 图：华为数据保护 华为业务连续性容灾容BCManager产品: 图：华为业务连续性容灾容BCManager产品]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>FusionSphere</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓝桥杯程序练习]]></title>
    <url>%2F2018%2F03%2F04%2F%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%A8%8B%E5%BA%8F%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[数列排序 问题描述 给定一个长度为n的数列，将这个数列按从小到大的顺序排列。1&lt;=n&lt;=200 输入格式 第一行为一个整数n。 第二行包含n个整数，为待排序的数，每个整数的绝对值小于10000。 输出格式 输出一行，按从小到大的顺序输出排序后的数列。 样例输入 58 3 6 4 9 样例输出 3 4 6 8 9 源代码： 12345678910111213141516import java.util.Arrays;import java.util.Scanner;public class Main&#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); int [] a = new int[n]; for(int i = 0; i &lt; n; i++) &#123; a[i] = scanner.nextInt(); &#125; Arrays.sort(a); for(int i = 0; i &lt; a.length; i++) System.out.print(a[i] + " "); &#125;&#125; Fibonacci数列 问题描述 ​ Fibonacci数列的递推公式为：Fn=Fn-1+Fn-2，其中 F1=F2=1。 ​ 当n比较大时，Fn也非常大，现在我们想知道，Fn除以10007的余数是多少。 输入格式 ​ 输入包含一个整数n。 输出格式 ​ n ​ 说明：在本题中，答案是要求Fn除以10007的余数，因此我们只要能算出这个余数即可，而不需要先计算出Fn的准确值，再将计算的结果除以10007取余数，直接计算余数往往比先算出原数再取余简单。 样例输入 10 样例输出 55 样例输入 22 样例输出 7704 数据规模与约定 1 &lt;= n &lt;= 1,000,000。 源代码： 123456789101112131415import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int[] a = new int[1000000]; a[1] = 1; a[2] = 1; for(int i=3; i&lt;=n; i++) a[i] = (a[i-1]+a[i-2])%10007; System.out.println(a[n]); &#125; &#125; 十六进制转八进制 问题描述** 给定n个十六进制正整数，输出它们对应的八进制数。 输入格式** 输入的第一行为一个正整数n （1&lt;=n&lt;=10）。 接下来n行，每行一个由0~9、大写字母A~F组成的字符串，表示要转换的十六进制正整数，每个十六进制数长度不超过100000。 输出格式** 输出n行，每行为输入对应的八进制正整数。 【注意**】 输入的十六进制数不会有前导0，比如012A。 输出的八进制数也不能有前导0。 样例输入** 2 39 123ABC 样例输出** 71 4435274 【提示**】 先将十六进制数转换成某进制数，再由某进制数转换成八进制。 源代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import java.util.Scanner;public class Main&#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); String [] h = new String[n]; for(int i = 0; i &lt; n; i++) &#123; h[i] = sc.next(); &#125; sc.close(); String [] b = new String[n]; String [] o = new String[n]; for(int i=0; i&lt;n; i++) &#123; b[i] = toBinary(h[i]); if(b[i].length()%3 == 1) b[i] = "00" + b[i]; if(b[i].length()%3 == 2) b[i] = "0" + b[i]; o[i] = toOctal(b[i]); System.out.println(o[i]); &#125; &#125; private static String toOctal(String strBinary) &#123; int len = strBinary.length(); int k; StringBuffer stb =new StringBuffer(); if(strBinary.substring(0,3).equals("000")) k=3; else k=0; for(int i=k;i&lt;len; i+=3)&#123; String string = strBinary.substring(i,i+3); if(string.equals("000")) stb.append("0"); else if(string.equals("001")) stb.append("1"); else if(string.equals("010")) stb.append("2"); else if(string.equals("011")) stb.append("3"); else if(string.equals("100")) stb.append("4"); else if(string.equals("101")) stb.append("5"); else if(string.equals("110")) stb.append("6"); else if(string.equals("111")) stb.append("7"); &#125; return stb.toString(); &#125; private static String toBinary(String strHex) &#123; StringBuffer stb =new StringBuffer(); for(int i=0;i &lt; strHex.length(); i++) &#123; switch(strHex.charAt(i)) &#123; case '0': stb.append("0000");break; case '1': stb.append("0001");break; case '2': stb.append("0010");break; case '3': stb.append("0011");break; case '4': stb.append("0100");break; case '5': stb.append("0101");break; case '6': stb.append("0110");break; case '7': stb.append("0111");break; case '8': stb.append("1000");break; case '9': stb.append("1001");break; case 'A': stb.append("1010");break; case 'B': stb.append("1011");break; case 'C': stb.append("1100");break; case 'D': stb.append("1101");break; case 'E': stb.append("1110");break; case 'F': stb.append("1111");break; default:break; &#125; &#125; return stb.toString(); &#125;&#125; 十六进制转十进制 问题描述 从键盘输入一个不超过8位的正的十六进制数字符串，将它转换为正的十进制数后输出。 注：十六进制数中的10~15分别用大写的英文字母A、B、C、D、E、F表示。 样例输入 FFFF 样例输出 65535 源代码： 123456789101112131415161718192021222324252627282930313233343536373839import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); String string = scanner.next(); int a = 0; long sum = 0; for(int i = 0; i &lt; string.length(); i++) &#123; switch (string.charAt(i)) &#123; case '0': a = 0;break; case '1': a = 1;break; case '2': a = 2;break; case '3': a = 3;break; case '4': a = 4;break; case '5': a = 5;break; case '6': a = 6;break; case '7': a = 7;break; case '8': a = 8;break; case '9': a = 9;break; case 'A': a = 10;break; case 'B': a = 11;break; case 'C': a = 12;break; case 'D': a = 13;break; case 'E': a = 14;break; case 'F': a = 15;break; default: break; &#125; sum += a* Math.pow(16, string.length()-i-1); &#125; System.out.println(sum); &#125;&#125; 十进制转十六进制 问题描述 十六进制数是在程序设计时经常要使用到的一种整数的表示方式。它有0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F共16个符号，分别表示十进制数的0至15。十六进制的计数方法是满16进1，所以十进制数16在十六进制中是10，而十进制的17在十六进制中是11，以此类推，十进制的30在十六进制中是1E。 给出一个非负整数，将它表示成十六进制的形式。 输入格式 输入包含一个非负整数a，表示要转换的数。0&lt;=a&lt;=2147483647 输出格式 输出这个整数的16进制表示 样例输入 30 样例输出 1E 源代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int a = scanner.nextInt(); int[] b = new int[10]; int len = 0; if(a==0) &#123; System.out.println(0); return ; &#125; while(a != 0) &#123; b[len] = a%16; len++; a /= 16; &#125; StringBuffer stb = new StringBuffer(); for( int i = len-1; i &gt;= 0; i--) &#123; String s = null; switch(b[i]) &#123; case 0: s = "0";break; case 1: s = "1";break; case 2: s = "2";break; case 3: s = "3";break; case 4: s = "4";break; case 5: s = "5";break; case 6: s = "6";break; case 7: s = "7";break; case 8: s = "8";break; case 9: s = "9";break; case 10: s = "A";break; case 11: s = "B";break; case 12: s = "C";break; case 13: s = "D";break; case 14: s = "E";break; case 15: s = "F";break; default: break; &#125; stb.append(s); &#125; System.out.println(stb.toString()); &#125;&#125; 特殊回文数： 问题描述 123321是一个非常特殊的数，它从左边读和从右边读是一样的。 输入一个正整数n， 编程求所有这样的五位和六位十进制数，满足各位数字之和等于n 。 输入格式 输入一行，包含一个正整数n。 输出格式 按从小到大的顺序输出满足条件的整数，每个整数占一行。 样例输入 52 样例输出 899998989989998899 数据规模和约定 1&lt;=n&lt;=54。 源代码： 1234567891011121314151617181920212223242526import java.util.ArrayList;import java.util.Collections;import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); ArrayList&lt;Integer&gt; rs = new ArrayList&lt;Integer&gt;(); for(int i=1; i&lt;10; i++) &#123; for(int j=0; j&lt;10; j++) &#123; for(int k=0; k&lt;10; k++) &#123; if(2*i+2*j+k == n) rs.add(i*10000 + j*1000 + k*100 + j*10 + i); if(2*i+2*j+2*k == n) rs.add(i*100000 + j*10000 + k*1000 + k*100 + j*10 + i); &#125; &#125; &#125; Collections.sort(rs); for(int i=0; i&lt;rs.size(); i++) System.out.println(rs.get(i)); &#125;&#125; 回文数： 问题描述 1221是一个非常特殊的数，它从左边读和从右边读是一样的，编程求所有这样的四位十进制数。 输出格式 按从小到大的顺序输出满足条件的四位十进制数。 源代码： 1234567891011121314public class Main &#123; public static void main(String [] arg) &#123; for(int i = 1000; i &lt; 10000; i++) &#123; int a = i/1000; int b = i%1000/100; int c = i%100/10; int d = i%10; if( a == d &amp;&amp; b ==c) System.out.println(i); &#125; &#125;&#125; 特殊的数字： 问题描述 153是一个非常特殊的数，它等于它的每位数字的立方和，即153=111+555+333。编程求所有满足这种条件的三位十进制数。 输出格式 按从小到大的顺序输出满足条件的三位十进制数，每个数占一行。 源代码： 123456789101112public class Main &#123; public static void main(String[] args) &#123; for(int i = 100; i &lt; 1000; i++) &#123; int a = i/100; int b = i%100/10; int c = i%10; if(i == a*a*a + b*b*b + c*c*c) System.out.println(i); &#125; &#125;&#125; 杨辉三角 问题描述 ​ 杨辉三角形又称Pascal三角形，它的第i+1行是(a+b)i的展开式的系数。 ​ 它的一个重要性质是：三角形中的每个数字等于它两肩上的数字相加。 ​ 下面给出了杨辉三角形的前4行： 1 1 1 ​ 1 2 1 ​ 1 3 3 1 ​ 给出n，输出它的前n行。 输入格式 ​ 输入包含一个数n。 输出格式 ​ 输出杨辉三角形的前n行。每一行从这一行的第一个数开始依次输出，中间使用一个空格分隔。请不要在前面输出多余的空格。 样例输入 4 样例输出 11 11 2 11 3 3 1 数据规模与约定 1 &lt;= n &lt;= 34。 源代码： 123456789101112131415161718192021222324import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int [][] array = new int[n][n]; for(int i = 0; i &lt; n; i++) &#123; for(int j = 0; j &lt;= i; j++) &#123; if( j == 0 || j == i) array[i][j] = 1; else array[i][j] = array[i-1][j] + array[i-1][j-1]; System.out.print(array[i][j] + " "); &#125; System.out.println(); &#125; &#125;&#125; 查找整数： 问题描述 ​ 给出一个包含n个整数的数列，问整数a在数列中的第一次出现是第几个。 输入格式 ​ 第一行包含一个整数n。 ​ 第二行包含n个非负整数，为给定的数列，数列中的每个数都不大于10000。 ​ 第三行包含一个整数a，为待查找的数。 输出格式 ​ 如果a在数列中出现了，输出它第一次出现的位置(位置从1开始编号)，否则输出-1。 样例输入 61 9 4 8 3 99 样例输出 2 数据规模与约定 1 &lt;= n &lt;= 1000。 源代码： 1234567891011121314151617181920212223242526import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int [] a = new int[n]; for(int i = 0; i &lt; n; i++) &#123; a[i] = sc.nextInt(); &#125; int s = sc.nextInt(); int b = 0; for(int i = 0; i &lt; n; i++) &#123; if(a[i] == s) &#123; System.out.println(i+1); b = 1; break; &#125; &#125; if(b == 0) System.out.println(-1); &#125;&#125; 数列特征： 问题描述 ​ 给出n个数，找出这n个数的最大值，最小值，和。 输入格式 ​ 第一行为整数n，表示数的个数。 ​ 第二行有n个数，为给定的n个数，每个数的绝对值都小于10000。 输出格式 ​ 输出三行，每行一个整数。第一行表示这些数中的最大值，第二行表示这些数中的最小值，第三行表示这些数的和。 样例输入 51 3 -2 4 5 样例输出 5-211 数据规模与约定 1 &lt;= n &lt;= 10000。 源代码： 1234567891011121314151617181920import java.util.Arrays;import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); int [] a = new int[n]; int b = 0; for(int i = 0; i &lt; n; i++) &#123; a[i] = sc.nextInt(); b += a[i]; &#125; Arrays.sort(a); System.out.println(a[n-1]); System.out.println(a[0]); System.out.println(b); &#125; &#125; 闰年判断： 问题描述 给定一个年份，判断这一年是不是闰年。 当以下情况之一满足时，这一年是闰年： 年份是4的倍数而不是100的倍数； 年份是400的倍数。 其他的年份都不是闰年。 输入格式 输入包含一个整数y，表示当前的年份。 输出格式 输出一行，如果给定的年份是闰年，则输出yes，否则输出no。 样例输入 2013 样例输出 no 样例输入 2016 样例输出 yes 数据规模与约定 1990 &lt;= y &lt;= 2050。 源代码： 12345678910111213import java.util.Scanner;public class Main &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int y = sc.nextInt(); if((y%4 == 0 &amp;&amp; y%100 != 0) || y%400 == 0) System.out.println("yes"); else System.out.println("no"); &#125;&#125; 01字符： 问题描述 对于长度为5位的一个01串，每一位都可能是0或1，一共有32种可能。它们的前几个是： 00000 00001 00010 00011 00100 请按从小到大的顺序输出这32种01串。 输入格式 本试题没有输入。 输出格式 输出32行，按从小到大的顺序每行一个长度为5的01串。 样例输出 00000000010001000011&lt;以下部分省略&gt; 源代码： 1234567891011public class Main&#123; public static void main(String[] args) &#123; for(int i=0; i&lt;2; i++) for(int j=0; j&lt;2; j++) for(int k=0; k&lt;2; k++) for(int l=0; l&lt;2; l++) for(int m=0; m&lt;2; m++) &#123; System.out.println(i+""+j+""+k+""+l+""+m); &#125; &#125;&#125; 阶乘计算： 问题描述 输入一个正整数n，输出n!的值。 其中n!=123…n。 算法描述 n!可能很大，而计算机能表示的整数范围有限，需要使用高精度计算的方法。使用一个数组A来表示一个大整数a，A[0]表示a的个位，A[1]表示a的十位，依次类推。 将a乘以一个整数k变为将数组A的每一个元素都乘以k，请注意处理相应的进位。 首先将a设为1，然后乘2，乘3，当乘到n时，即得到了n!的值。 输入格式 输入包含一个正整数n，n&lt;=1000。 输出格式 输出n!的准确值。 样例输入 10 样例输出 3628800 源代码： 1234567891011121314151617181920212223242526272829303132333435import java.math.BigInteger;import java.util.ArrayList;import java.util.Scanner;public class 阶乘计算 &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); System.out.println(f(n)); &#125; //初始化数组 protected static ArrayList&lt;BigInteger&gt; table = new ArrayList&lt;BigInteger&gt;(); static &#123; //BigInterger.valueof(long val); //返回其值等于指定 long 的值的 BigInteger。 table.add(BigInteger.valueOf(1));//给数组添加初始值1 &#125; public static BigInteger f(int x) &#123; for(int size = table.size(); size &lt;= x; size++) &#123; //获取当前数组的最后一个数 BigInteger lastfact = (BigInteger)table.get(size-1); /* *multiply(BigInterger val) *返回其值为（this * val）的BigInterger。 */ //当前数组的最后一个数和size相乘，并存入数组 BigInteger nextfact = lastfact.multiply(BigInteger.valueOf(size)); table.add(nextfact); &#125; return (BigInteger)table.get(x);//返回数组的最后一个数 &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>Java编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MPLS VPN]]></title>
    <url>%2F2018%2F03%2F03%2FMPLS-VPN%2F</url>
    <content type="text"><![CDATA[BGP/MPLS IP VPN简介BGP/MPLS IP VPN是一种L3VPN（Layer 3 Virtual Private Network）。它使用BGP（Border Gateway Protocol）在服务提供商骨干网上发布VPN路由，使用MPLS（Multiprotocol Label Switch）在服务提供商骨干网上转发VPN报文。这里的IP是指VPN承载的是IP（Internet Protocol）报文。 图：BGP/MPLS IP VPN模型 BGP/MPLS IP VPN的基本模型由三部分组成：CE、PE和P。 CE（Customer Edge）：用户网络边缘设备，有接口直接与服务提供商网络相连。CE可以是路由器或交换机，也可以是一台主机。通常情况下，CE“感知”不到VPN的存在，也不需要支持MPLS。 PE（Provider Edge）：是服务提供商网络的边缘设备，与CE直接相连。在MPLS网络中，对VPN的所有处理都发生在PE上，对PE性能要求较高。 P（Provider）：服务提供商网络中的骨干设备，不与CE直接相连。P设备只需要具备基本MPLS转发能力，不维护VPN信息。 PE和P设备仅由服务提供商管理；CE设备仅由用户管理，除非用户把管理权委托给服务提供商。 一台PE设备可以接入多台CE设备。一台CE设备也可以连接属于相同或不同服务提供商的多台PE设备。 目的：传统的VPN通过在所有站点间建立全连接隧道或者永久虚链路PVC（Permanent Virtual Circuit）的方式实现，不易维护和扩展，尤其是向已有的VPN加入新的站点时，需要同时修改所有接入此VPN站点的边缘节点的配置。 BGP/MPLS IP VPN基于对等体模型，这种模型使得服务提供商和用户可以交换路由，服务提供商转发用户站点间的数据而不需要用户的参与。相比较传统的VPN，BGP/MPLS IP VPN更容易扩展和管理。新增一个站点时，只需要修改提供该站点业务的边缘节点的配置。 BGP/MPLS IP VPN支持地址空间重叠、支持重叠VPN、组网方式灵活、可扩展性好，并能够方便地支持MPLS TE，成为在IP网络运营商提供增值业务的重要手段，因此得到越来越多的应用。 MPLS VPN的原理描述基本概念:Site: Site是指相互之间具备IP连通性的一组IP系统，并且，这组IP系统的IP连通性不需通过运营商网络实现。 Site的划分是根据设备的拓扑关系，而不是地理位置，尽管在大多数情况下一个Site中的设备地理位置相邻。地理位置隔离的两组IP系统，如果它们使用专线互联，不需要通过运营商网络就可以互通，这两组IP系统也组成一个Site。 一个Site中的设备可以属于多个VPN，换言之，一个Site可以属于多个VPN。 Site通过CE连接到运营商网络，一个Site可以包含多个CE，但一个CE只属于一个Site。 根据Site的情况，建议CE设备选择方案如下： 如果Site只是一台主机，则这台主机就作为CE设备； 如果Site是单个子网，则使用交换机作为CE设备； 如果Site是多个子网，则使用路由器作为CE设备。 对于多个连接到同一运营商网络的Site，通过制定策略，可以将它们划分为不同的集合（set），只有属于相同集合的Site之间才能通过运营商网络互访，这种集合就是VPN。 地址空间重叠：VPN是一种私有网络，不同的VPN独立管理自己的地址范围，也称为地址空间（address space）。不同VPN的地址空间可能会在一定范围内重合，例如，VPN1和VPN2都使用10.110.10.0/24网段地址，这就发生了地址空间的重叠（address spaces overlapping）。 以下两种情况允许VPN使用重叠的地址空间： 两个VPN没有共同的Site 两个VPN有共同的Site，但此Site中的设备不与两个VPN中使用重叠地址空间的设备互访 VPN示例：在BGP/MPLS IP VPN中，不同VPN之间的路由隔离通过VPN实例（VPN-instance）实现。 PE为每个直接相连的Site建立并维护专门的VPN实例，VPN实例中包含对应Site的VPN成员关系和路由规则。具体来说，VPN实例中的信息包括：IP路由表、标签转发表、与VPN实例绑定的接口以及VPN实例的管理信息。VPN实例的管理信息包括RD（Route Distinguisher，路由标识符）、路由过滤策略、成员接口列表等。 VPN、Site、VPN实例之间的关系如下： VPN是多个Site的组合。一个Site可以属于多个VPN。 每一个Site在PE上都关联一个VPN实例。VPN实例综合了它所关联的Site的VPN成员关系和路由规则。多个Site根据VPN实例的规则组合成一个VPN。 VPN实例与VPN不是一一对应的关系，VPN实例与Site之间存在一一对应的关系。 VPN实例也称为VPN路由转发表VRF（VPN Routing and Forwarding table）。PE上存在多个路由转发表，包括一个公网路由转发表，以及一个或多个VPN路由转发表。 公网路由转发表与VPN实例存在以下不同： 公网路由表包括所有PE和P设备的IPv4路由，由骨干网的路由协议或静态路由产生。 VPN路由表包括属于该VPN实例的所有Site的路由，通过CE与PE之间或者两个PE之间的VPN路由信息交互获得。 公网转发表是根据路由管理策略从公网路由表提取出来的转发信息；而VPN转发表是根据路由管理策略从对应的VPN路由表提取出来的转发信息。 可以看出，PE上的各VPN实例之间相互独立，并与公网路由转发表相互独立。 可以将每个VPN实例看作一台虚拟的设备，维护独立的地址空间并有连接到私网的接口。 RD和VPN-IPv4地址：传统BGP无法正确处理地址空间重叠的VPN的路由。假设VPN1和VPN2都使用了10.110.10.0/24网段的地址，并各自发布了一条去往此网段的路由。虽然本端PE通过不同的VPN实例可以区分地址空间重叠的VPN的路由，但是这些路由发往对端PE后，由于不同VPN的路由之间不进行负载分担，因此对端PE将根据BGP选路规则只选择其中一条VPN路由，从而导致去往另一个VPN的路由丢失。 PE之间使用MP-BGP（Multiprotocol Extensions for BGP-4，BGP-4的多协议扩展）来发布VPN路由，并使用VPN-IPv4地址来解决上述问题。 VPN-IPv4地址共有12个字节，包括8字节的路由标识符RD（Route Distinguisher）和4字节的IPv4地址前缀，地址格式如下： 图：VPN-IPv4地址结构 RD用于区分使用相同地址空间的IPv4前缀，增加了RD的IPv4地址称为VPN-IPv4地址（即VPNv4地址）。PE从CE接收到IPv4路由后，转换为全局唯一的VPN-IPv4路由，并在公网上发布。 RD的结构使得每个服务供应商可以独立地分配RD，但为了在CE双归属的情况下保证路由正常，必须保证PE上的RD全局唯一。 VPN Target：BGP/MPLS IP VPN使用BGP扩展团体属性－VPN Target（也称为Route Target）来控制VPN路由信息的发布。 每个VPN实例关联一个或多个VPN Target属性。有两类VPN Target属性： Export Target：本地PE从直接相连Site学到IPv4路由后，转换为VPN-IPv4路由，并为这些路由设置Export Target属性。Export Target属性作为BGP的扩展团体属性随路由发布。 Import Target：PE收到其它PE发布的VPN-IPv4路由时，检查其Export Target属性。当此属性与PE上某个VPN实例的Import Target匹配时，PE就把路由加入到该VPN实例中。 在BGP/MPLS IP VPN网络中，通过VPN Target属性来控制VPN路由信息在各Site之间的发布和接收。VPN Export Target和Import Target的设置相互独立，并且都可以设置多个值，能够实现灵活的VPN访问控制，从而实现多种VPN组网方案。 基本原理：私网标签分配：在BGP/MPLS IP VPN中，PE通过MP-BGP发布私网路由给骨干网的其他相关的PE前，需要为私网路由分配MPLS标签（私网标签）。当数据包在骨干网传输时，携带私网标签。 PE上分配私网标签的方法有如下两种： 基于路由的MPLS标签分配：为VPN路由表的每一条路由分配一个标签（one label per route）。这种方式的缺点是：当路由数量比较多时，设备入标签映射表ILM（Incoming Label Map）需要维护的表项也会增多，从而提高了对设备容量的要求。 基于VPN实例的MPLS标签分配：为整个VPN实例分配一个标签，该VPN实例里的所有路由都共享一个标签。使用这种分配方法的好处是节约了标签。 MP-BGP为私网路由分配标签的前提是PE上使能MPLS功能。 私网路由交叉：两台PE之间通过MP-BGP传播的路由是VPNv4路由。当接收到VPNv4路由，PE先进行如下处理： 检查其下一跳是否可达。如果下一跳不可达，该路由被丢弃。 对于RR发送过来的VPNv4路由，如果收到的路由中cluster_list包含自己的cluster_id，则丢弃这条路由。 进行BGP的路由策略过滤，如果不通过，则丢弃该路由。 之后，PE把没有丢弃的路由与本地的各个VPN实例的Import Target属性匹配。VPNv4路由与本地VPN实例的Import VPN-Target进行匹配的过程称为私网路由交叉。 PE上有种特殊的路由，即来自本地CE的属于不同VPN的路由。对于这种路由，如果其下一跳直接可达或可迭代成功，PE也将其与本地的其他VPN实例的Import Target属性匹配，该过程称为本地交叉。例如：CE1所在的Site属于VPN1，CE2所在的Site属于VPN2，且CE1和CE2同时接入PE1。当PE1收到来自CE1的VPN1的路由时，也会与VPN2对应的VPN实例的Import Target属性匹配。 公网隧道迭代：为了将私网流量通过公网传递到另一端，需要有一条公网隧道承载这个私网流量。因此私网路由交叉完成后，需要根据目的IPv4前缀进行路由迭代，查找合适的隧道（本地交叉的路由除外）；只有隧道迭代成功，该路由才被放入对应的VPN实例路由表。将路由迭代到相应的隧道的过程叫做隧道迭代。 隧道迭代成功后，保留该隧道的标识符（Tunnel ID），供后续转发报文时使用。Tunnel ID用于唯一标识一条隧道。VPN报文转发时根据Tunnel ID查找对应的隧道，然后从隧道上发送出去。 私网路由的选择规则：经过路由交叉和隧道迭代的路由并不是全部被放入VPN实例路由表。从本地CE收到的路由和本地交叉路由也不是全部被放入VPN实例路由表。 对于到同一目的地址的多条路由，如果不进行路由的负载分担，按如下规则选择其中的一条： 同时存在直接从CE收到的路由和交叉成功后的同一目的地址路由，则优选从CE收到的路由。 同时存在本地交叉路由和从其他PE接收并交叉成功后的同一目的地址路由，则优选本地交叉路由。 对于到同一目的地址的多条路由，如果进行路由的负载分担，则： 优先选择从本地CE收到的路由。只有一条从本地CE收到的路由而有多条交叉路由的情况下，也只选择从本地CE收到的路由。 只在从本地CE收到的路由之间分担或只在交叉路由之间分担，不会在本地CE收到的路由和交叉路由之间分担。 负载分担的AS_PATH属性必须完全相同。 BGP/MPLS IP VPN的路由发布：基本BGP/MPLS IP VPN组网中，VPN路由信息的发布涉及CE和PE，P设备只维护骨干网的路由，不需要了解任何VPN路由信息。PE设备一般维护所有VPN路由。 VPN路由信息的发布过程包括三部分：本地CE到入口PE、入口PE到出口PE、出口PE到远端CE。完成这三部分后，本地CE与远端CE之间建立可达路由，VPN路由信息能够在骨干网上发布。 下面分别对这三部分进行介绍。 本地CE到入口PE的路由信息交换 CE与直接相连的PE建立邻居或对等体关系后，把本站点的IPv4路由发布给PE。CE与PE之间可以使用静态路由、RIP（Routing Information Protocol）、OSPF（Open Shortest Path First）、IS-IS（Intermediate System to Intermediate System）或BGP（Border Gateway Protocol）。无论使用哪种路由协议，CE发布给PE的都是标准的IPv4路由。 入口PE到出口PE的路由信息交换 PE从CE学到VPN路由信息后，存放到VPN实例中。同时，为这些标准IPv4路由增加RD，形成VPN-IPv4路由。 入口PE通过MP-BGP的Update报文把VPN-IPv4路由发布给出口PE。Update报文中携带Export VPN Target属性及MPLS标签。 出口PE收到VPN-IPv4路由后，在下一跳可达的情况下进行路由交叉、隧道迭代和路由优选，决定是否将该路由加入到VPN实例的路由表。被加入到VPN路由表的路由，本地PE为其保留如下信息以供后续转发报文时使用： MP-BGP Update消息中携带的MPLS标签值 Tunnel ID 出口PE到远端CE的路由信息交换 远端CE有多种方式可以从出口PE学习VPN路由，包括静态路由、RIP、OSPF、IS-IS和BGP，与本地CE到入口PE的路由信息交换相同。此处不再赘述。值得注意的是，出口PE发布给远端CE的路由是普通IPv4路由。 以下图为（PE-CE之间使用BGP，公网隧道为LSP）为例，说明将CE2的一条路由发送到CE1的过程。 图：CE2-&gt;CE1的路由发布过程 在CE2的BGP IPv4单播地址族下引入IGP（Interior Gateway Protocol）路由。 CE2将该路由随EBGP的Update消息一起发布给Egress PE。Egress PE从连接CE2的接口收到Update消息，把该路由转化为VPN IPv4路由，加入对应的VPN实例路由表。 Egress PE为该路由分配MPLS标签，并将标签和VPN IPv4路由信息加入MP-IBGP的Update消息中的NLRI字段中，Export-RT属性加入MP-BGP Update消息的扩展团体属性字段中，将Update消息发送给Ingress PE。 Ingress PE对该路由进行路由交叉。交叉成功则根据路由目的IPv4地址进行隧道迭代，查找合适的隧道。如果迭代成功，则保留该隧道的Tunnel ID和标签，并将路由加入该VPN实例路由表。 Ingress PE把该路由通过BGP Update消息发布给CE1。此时路由是普通IPv4路由。 CE1收到该路由后，把该路由加入BGP路由表。通过在IGP中引入BGP路由的方法可使CE1把该路由加入IGP路由表。 上面过程只是将CE2的路由发布给CE1。要实现CE1与CE2的互通，还需要将CE1的路由发布给CE2，其过程与上面的步骤类似，此处不再赘述。 BGP/MPLS IP VPN的报文转发：在基本BGP/MPLS IP VPN应用中（不包括跨域的情况），VPN报文转发采用两层标签方式： 第一层（公网）标签在骨干网内部进行交换，指示从PE到对端PE的一条LSP。VPN报文利用这层标签，可以沿LSP到达对端PE； 第二层（私网）标签在从对端PE到达CE时使用，指示报文应被送到哪个Site，或者更具体一些，到达哪一个CE。这样，对端PE根据内层标签可以找到转发报文的接口。 特殊情况下，属于同一个VPN的两个Site连接到同一个PE，这种情况下只需要知道如何到达对端CE。 以下图为例说明BGP/MPLS IP VPN报文的转发过程。下图是CE1发送报文给CE2的过程。其中，I-L表示内层标签，O-L表示外层标签。 图：VPN报文转发过程 CE1发送一个VPN报文。 Ingress PE从绑定了VPN实例的接口上接收VPN数据包后进行如下操作： 先根据绑定的VPN实例的RD查找对应VPN的转发表。 匹配目的IPv4前缀，查找对应的Tunnel ID。 将报文打上对应的标签（I-L），根据Tunnel-ID找到隧道。 将报文从隧道发送出去。此例的隧道是LSP，则打上公网（外层）MPLS标签头（O-L1）。 接着，该报文携带两层MPLS标签穿越骨干网。骨干网的每台P设备都对该报文进行外层标签交换。 Egress PE收到该携带两层标签的报文，交给MPLS协议处理。MPLS协议将去掉外层标签（此例最后的外层标签是O-L2，但如果应用了倒数第二跳弹出，则此标签会在到达Egress PE之前的一跳弹出，Egress PE只能收到带有内层标签的报文）。 此时Egress PE就可以看见内层标签，发现该标签处于栈底，将内层标签剥离。 Egress PE将报文从对应出接口发送给CE2。此时报文是个纯IP报文。 这样，报文就成功地从CE1传到CE2了。CE2按照普通的IP转发过程将报文传送到目的地。 MPLS VPN学习笔记PE与CE之间为通过OSPF多实例接入时防环机制：在MP-BGP中传递路由信息时，会在扩展团体属性中携带IGP的路由信息。在OSPF中： OSPF DOMAIN ID &lt; 0.0.0.0 : 0 &gt;: 0..0.0.0 : 代表domain ID，默认值为0.0.0.0，可以修改。 0：代表vlaue 值，默认为0，可以修改。 OSPF RT &lt; 0.0.0.0 : 1 : 0 &gt;: 0.0.0.0 :代表区域ID。 1 ：代表LSA的类型（1：域内路由、3：域间路由、5：外部路由、7：外部路由（NSSA）） 0：代表外部路由的类型（0=类型1,1=类型2） OSPF ROUTER ID &lt; 37.1.1.3 : 0 &gt;: 37.1.1.1:代表通告OSPF路由设备的router-id。 将BGP路由重发布进OSPF以哪种类型的路由通告，需要看OSPF的扩展参数。判断原则如下： 如果扩展参数中的domain-id和设备本地的somain-id不一致，直接通告成外部路由（5类LSA）。 如果domain-id一致，需要看OSPF RT中的LSA类型，如果LSA的类型为1或者3，则通告类型为域间路由（3类LSA），如果LSA的类型为5则通告为外部路由，并标识外部路由类型。如果LSA的类型为7则通告为NSSA外部路由，并标识外部路由类型。 注：在修改domain id时，domain id和value两端必须一致，type可以不一致。如果domain id两端不一致，OSPF路由会直接以外部路由方式（5类LSA）通告。 OSPF在VPN中有两种防环机制：TAG和Downbit位（DN位）。 DN位主要用于3类LSA防环，而TAG主要用于5类、7类LSA防环。（在华为中5/7类同时也会将DN为置位）。 注：TAG长度是32个bit，其中最后16个bit用于标识AS number。PE设备收到OSPF外部 LSA后需要查看外部路由的TAG中是否包含本地的AS number，如果包含不计算该路由。 Sham-Link：建立Sham-link的条件： 建立sham-link的路由必须是32位路由。 建立sham-link的路由必须通过MPBGP通告。 注：sham-link在华为中的实现并不是按需电路，会定期通告hello和lsa维护邻居状态和LSA的状态。 sham-link需要在两端PE的OSPF私有进程下配置。 防环机制： ISIS中通过UP/DOWN位实现防环，PE设备不会讲DOWN位置位的路由重分发进BGP. RIP中通过在单点双向重分发时做过标记，过滤进行防环。 在MPLS VPN中访问Internet有三种方式： 通过在CE和PE之间拉单独的专线实现上网。 路由泄露。 路由泄露配置（主要在PE上配置） ip router-static 14.1.1.1.0 255.255.255.0 vpn-instance HCIE 14.1.1.4 ip router-static vpn-instance HCIE 0.0.0.0 0 12,1,1,2 public 利用Tunnel实现CE访问Internet。 CE端配置： interface Tunnel0/0/0 ip address 100.1.1.1 24 tunnel-protocol gre source 14.1.1.4 destination 14.1.1.1 nat outbound 20000 PE端配置： interface Tunnel 0/0/0 ip address 100.1.1.2 24 tunnrl-protocol gre source 14.1.1.1 destination vpn-instance HCIE 14.1.1.4//在PE端配置目的地址需要指定VPN实例 ospf enable 1 area 0 //需要将tunnel夹克宣告进公网路由。 MPLS IP VPN配置命令行12345678910111213141516171819202122232425262728293031323334apply-label per-instance//配置当前VPN实例地址族下所有发往对端PE的路由都使用同一个标签值。apply-label per-nexthop//使能ASBR按下一跳为VPNv4路由分标签。apply-label per-route//使能每路由每标签的标签分配方式，即配置当前VPN实例地址//族下的所有发往对端PE的每条路由使用单独的标签值。//缺省情况下，同一VPN实例IPv4地址族下所有发往对端PE的路由都使用同一个标签值。display ip vpn-instance//查看VPN实例的配置信息。display ip vpn-instance import-vt//显示所有具备指定入口vpn-target属性的VPN实例。display interface tunnel//查看Tunnel接口的所有信息。display tunnel-info//查看隧道信息。ingress-lsp trigger//配置基于路由策略为BGP标签路由创建Ingress LSP的功能。ip binding vpn-instance//将PE上的接口与VPN实例绑定。//配置接口与VPN实例绑定后，或取消接口与VPN实例的绑定，//都会清除该接口的IP地址、三层特性和IP相关的路由协议，如果需要应重新配置。ip vpn-instance//创建VPN实例，并进入VPN实例视图。peer soo//为BGP VPN实例下的EBGP对等体配置Site-of-Origin（SoO）。peer substitute-as//使能AS号替换功能，即用本地AS号替换AS_Path属性中指定对等体的AS号。route-distinguisher//为VPN实例地址族配置路由标识RD（Route Distinguisher）。traffic-statistics enable//使能基于VPN实例的流量统计功能。vpn-target//配置VPN实例地址族入方向或出方向的VPN-Target扩展团体属性。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>MPLS VPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MPLS LDP基础]]></title>
    <url>%2F2018%2F02%2F23%2FMPLS-LDP%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[MPLS LDP简介标签分发协议LDP（Label Distribution Protocol）是多协议标签交换MPLS的一种控制协议，相当于传统网络中的信令协议，负责转发等价类FEC（Forwarding Equivalence Class）的分类、标签的分配以及标签交换路径LSP（Label Switched Path）的建立和维护等操作。LDP规定了标签分发过程中的各种消息以及相关处理过程。 目的：MPLS支持多层标签，并且转发平面面向连接，故具有良好的扩展性，使在统一的MPLS/IP基础网络架构上为客户提供各类服务成为可能。通过LDP协议，标签交换路由器LSR（Label Switched Router）可以把网络层的路由信息直接映射到数据链路层的交换路径上，动态建立起网络层的LSP。 目前，LDP广泛地应用在VPN服务上，具有组网、配置简单、支持基于路由动态建立LSP、支持大容量LSP等优点。 LDP基本概念：LDP对等体： LDP对等体是指相互之间存在LDP会话、使用LDP来交换标签消息的两个LSR。LDP对等体通过它们之间的LDP会话获得对方的标签。 LDP邻居体： 当一台LSR接收到对端发送过来的Hello消息后LDP邻接体建立。LDP邻接体存在两种类型： 本地邻接体（Local Adjacency）：以组播形式发送Hello消息（即链路Hello消息）发现的邻接体叫做本地邻接体。 远端邻接体（Remote Adjacency）：以单播形式发送Hello消息（即目标Hello消息）发现的邻接体叫做远端邻接体。 LDP通过邻接体来维护对等体的存在，对等体的类型取决于维护它的邻接体的类型。一个对等体可以由多个邻接体来维护，如果由本地邻接体和远端邻接体两者来维护，则对等体类型为本远共存对等体。 LDP会话： LDP会话用于LSR之间交换标签映射、释放等消息。只有存在对等体才能建立LDP会话，LDP会话分为两种类型： 本地LDP会话（Local LDP Session）：建立会话的两个LSR之间是直连的。 远端LDP会话（Remote LDP Session）：建立会话的两个LSR之间可以是直连的，也可以是非直连的。 本地LDP会话和远端LDP会话可以共存。 LDP工作机制LDP协议规定了标签分发过程中的各种消息以及相关的处理过程。通过LDP，LSR可以把网络层的路由信息映射到数据链路层的交换路径上，进而建立起LSP。 LDP消息类型：LDP协议主要使用四类消息： 发现（Discovery）消息：用于通告和维护网络中LSR的存在，如Hello消息。 会话（Session）消息：用于建立、维护和终止LDP对等体之间的会话，如Initialization消息、Keepalive消息。 通告（Advertisement）消息：用于创建、改变和删除FEC的标签映射。 通知（Notification）消息：用于提供建议性的消息和差错通知。 为保证LDP消息的可靠发送，除了Discovery消息使用UDP（User Datagram Protocol）传输外，LDP的Session消息、Advertisement消息和Notification消息都使用TCP（Transmission Control Protocol）传输。 LDP消息作用： 图：LDP消息作用 图：Label mapping消息报文 LDP报文消息抓包示例: 图：LDP的hello报文抓包示例 图：LDP的init报文抓包示例 图：KeepAlive消息和Address消息抓包示例 LDP工作过程：LDP工作过程主要分为两个阶段： LDP会话的建立 通过Hello消息发现邻居后，LSR之间开始建立LDP会话。会话建立后，LDP对等体之间通过不断地发送Hello消息和Keepalive消息来维护这个会话。 LDP对等体之间，通过周期性发送Hello消息表明自己希望继续维持这种邻接关系。如果Hello保持定时器超时仍没有收到新的Hello消息，则删除Hello邻接关系。邻接关系被删除后，本端LSR将发送Notification消息，结束该LDP会话。 LDP对等体之间通过LDP会话连接上传送的Keepalive消息来维持LDP会话。如果会话保持定时器(Keepalive保持定时器)超时仍没有收到任何Keepalive消息，则关闭TCP连接，本端LSR将发送Notification消息，结束LDP会话。 LDP LSP的建立 会话建立后，LDP通过发送标签请求和标签映射消息，在LDP对等体之间通告FEC和标签的绑定关系，从而建立LSP。 LDP会话的建立：通过LDP发现机制发现LDP对等体用来建立LDP会话。只有建立了LDP会话后，才能建立LDP LSP来承载业务。 LDP发现机制：LDP发现机制用于LSR发现潜在的LDP对等体。LDP有两种发现机制： 基本发现机制：用于发现链路上直连的LSR。 LSR通过周期性地发送LDP链路Hello消息（LDP Link Hello），实现LDP基本发现机制，建立本地LDP会话。 LDP链路Hello消息使用UDP报文，目的地址是组播地址224.0.0.2。如果LSR在特定接口接收到LDP链路Hello消息，表明该接口存在LDP对等体。 扩展发现机制：用于发现链路上非直连LSR。 LSR周期性地发送LDP目标Hello消息（LDP Targeted Hello）到指定IP地址，实现LDP扩展发现机制，建立远端LDP会话。 LDP目标Hello消息使用UDP报文，目的地址是指定IP地址。如果LSR接收到LDP目标Hello消息，表明该LSR存在LDP对等体。 LDP会话的建立过程：两台LSR之间交换Hello消息触发LDP会话的建立。 LDP会话的建立过程如下图所示： 图：LDP会话的建立过程 两个LSR之间互相发送Hello消息。 Hello消息中携带传输地址（即设备的IP地址），双方使用传输地址建立LDP会话。 传输地址较大的一方作为主动方，发起建立TCP连接。 如上图所示，LSR_1作为主动方发起建立TCP连接，LSR_2作为被动方等待对方发起连接。 TCP连接建立成功后，由主动方LSR_1发送初始化消息，协商建立LDP会话的相关参数。 LDP会话的相关参数包括LDP协议版本、标签分发方式、Keepalive保持定时器的值、最大PDU长度和标签空间等。 被动方LSR_2收到初始化消息后，LSR_2接受相关参数，则发送初始化消息，同时发送Keepalive消息给主动方LSR_1。 如果被动方LSR_2不能接受相关参数，则发送Notification消息终止LDP会话的建立。 初始化消息中包括LDP协议版本、标签分发方式、Keepalive保持定时器的值、最大PDU长度和标签空间等。 主动方LSR_1收到初始化消息后，接受相关参数，则发送Keepalive消息给被动方LSR_2。 如果主动方LSR_1不能接受相关参数，则发送Notification消息给被动方LSR_2终止LDP会话的建立。 当双方都收到对端的Keepalive消息后，LDP会话建立成功。 LDP LSP的建立：LDP通过发送标签请求和标签映射消息，在LDP对等体之间通告FEC和标签的绑定关系来建立LSP，而标签的发布和管理由标签发布方式、标签分配控制方式和标签保持方式来决定。 标签的发布和管理：标签发布方式（Label Advertisement Mode） 在MPLS体系中，由下游LSR决定将标签分配给特定FEC，再通知上游LSR，即标签由下游指定，标签的分配按从下游到上游的方向分发。 标签发布方式有两种方式。具有标签分发邻接关系的上游LSR和下游LSR必须对使用的标签发布方式达成一致。 图：标签发布方式 标签发布方式 含义 描述 下游自主方式DU（Downstream Unsolicited） 对于一个特定的FEC，LSR无需从上游获得标签请求消息即进行标签分配与分发。 如上图所示，对于目的地址为192.168.1.1/32的FEC，下游（Egress）通过标签映射消息主动向上游（Transit）通告自己的主机路由192.168.1.1/32的标签。 下游按需方式DoD（Downstream on Demand） 对于一个特定的FEC，LSR获得标签请求消息之后才进行标签分配与分发。 如上图所示，对于目的地址为192.168.1.1/32的FEC，上游（Ingress）向下游发送标签请求消息，下游（Egress）收到标签请求消息后，才会向上游发送标签映射消息。 标签分配控制方式（Label Distribution Control Mode） 标签分配控制方式是指在LSP的建立过程中，LSR分配标签时采用的处理方式。 独立标签分配控制方式（Independent）：本地LSR可以自主地分配一个标签绑定到某个FEC，并通告给上游LSR，而无需等待下游的标签。 有序标签分配控制方式（Ordered）：对于LSR上某个FEC的标签映射，只有当该LSR已经具有此FEC下一跳的标签映射消息、或者该LSR就是此FEC的出节点时，该LSR才可以向上游发送此FEC的标签映射。 标签分配控制方式和标签发布方式的组合： 标签分配控制方式 下游自主方式DU（Downstream Unsolicited） 下游按需方式DoD（Downstream on Demand） 独立标签分配控制方式（Independent） DU ＋ Independent：LSR（Transit）无需等待下游（Egress）的标签，就会直接向上游（Ingress）分发标签。 DoD ＋ Independent：发送标签请求的LSR（Ingress）的直连下游（Transit）会直接回应标签，而不必等待来自最终下游（Egress）的标签。 有序标签分配控制方式（Ordered） DU ＋ Ordered：LSR（Transit）只有收到下游（Egress）的标签映射消息，才会向上游（Ingress）分发标签。 DoD ＋ Ordered：发送标签请求的LSR（Ingress）的直连下游（Transit）只有收到最终下游（Egress）的标签映射消息，才会向上游（Ingress）分发标签。 标签保持方式（Label Retention Mode） 标签保持方式是指LSR对收到的、但目前暂时不需要的标签映射的处理方式。 LSR收到的标签映射可能来自下一跳，也可能来自非下一跳。 标签保持方式： 自由标签保持方式（Liberal） 对于从邻居LSR收到的标签映射，无论邻居LSR是不是自己的下一跳都保留。 保守标签保持方式（Conservative） 对于从邻居LSR收到的标签映射，只有当邻居LSR是自己的下一跳时才保留。 目前设备支持如下组合方式： 下游自主方式（DU）＋ 有序标签分配控制方式（Ordered）＋ 自由标签保持方式（Liberal），该方式为缺省方式。 下游按需方式（DoD）＋ 有序标签分配控制方式（Ordered）＋ 保守标签保持方式（Conservative）。 下游自主方式（DU）＋ 独立标签分配控制方式（Independent）＋ 自由标签保持方式（Liberal）。 下游按需方式（DoD）＋ 独立标签分配控制方式（Independent）＋ 保守标签保持方式（Conservative）。 LDP LSP的建立过程：LSP的建立过程实际就是将FEC和标签进行绑定，并将这种绑定通告LSP上相邻LSR的过程。如下图所示，下面结合下游自主标签发布方式和有序标签控制方式来说明其主要步骤。 图：LDP LSP的建立过程 缺省情况下，网络的路由改变时，如果有一个边缘节点（Egress）发现自己的路由表中出现了新的主机路由，并且这一路由不属于任何现有的FEC，则该边缘节点需要为这一路由建立一个新的FEC。 如果MPLS网络的Egress有可供分配的标签，则为FEC分配标签，并主动向上游发出标签映射消息，标签映射消息中包含分配的标签和绑定的FEC等信息。 Transit收到标签映射消息后，判断标签映射的发送者（Egress）是否为该FEC的下一跳。若是，则在其标签转发表中增加相应的条目，然后主动向上游LSR发送对于指定FEC的标签映射消息。 Ingress收到标签映射消息后，判断标签映射的发送者（Transit）是否为该FEC的下一跳。若是，则在标签转发表中增加相应的条目。这时，就完成了LSP的建立，接下来就可以对该FEC对应的数据报文进行标签转发。 上面介绍的是普通LDP LSP的建立，还有一种代理Egress LSP。代理Egress（Proxy Egress）是能够针对非本地路由触发建立LSP的Egress节点，当路由器使能倒数第二跳弹出时，倒数第二跳节点实际上就是一种特殊的代理Egress。一般情况下，代理Egress由配置产生。代理Egress可以应用于网络中有不支持MPLS特性的路由器场景，也可用于解决BGP路由负载分担问题。 LDP的安全机制：为了提高LDP报文的安全性，MPLS提供了三种保护机制：LDP MD5认证、LDP Keychain认证和LDP GTSM。 LDP Keychain认证是比LDP MD5认证更安全的加密认证，对于同一邻居，只能选择其中一个加密认证；而LDP GTSM用来防止设备受到非法LDP报文的攻击，其可以与前面两个配合使用。 LDP MD5认证：MD5（Message-Digest Algorithm 5）是RFC1321定义的国际标准摘要密码算法。MD5的典型应用是针对一段信息计算出对应的信息摘要，从而防止信息被篡改。MD5信息摘要是通过不可逆的字符串变换算法产生的，结果唯一。因此，不管信息内容在传输过程中发生任何形式的改变，只要重新计算就会产生不同的信息摘要，接收端就可以由此判定收到的是一个不正确的报文。 LDP MD5应用其对同一信息段产生唯一摘要信息的特点来实现LDP报文防篡改校验，比一般意义上TCP校验和更为严格。其实现过程如下： LDP会话消息在经TCP发出前，会在TCP头后面填充一个唯一的信息摘要再发出。而这个信息摘要就是把TCP头、LDP会话消息以及用户设置的密码一起作为原始信息，通过MD5算法计算出的。 当接收端收到这个TCP报文时，首先会取得报文的TCP头、信息摘要、LDP会话消息，并结合TCP头、LDP会话消息以及本地保存的密码，利用MD5计算出信息摘要，然后与报文携带的信息摘要进行比较，从而检验报文是否被篡改过。 LDP Keychain认证：Keychain是一种增强型加密算法，类似于MD5，Keychain也是针对同一段信息计算出对应的信息摘要，实现LDP报文防篡改校验。 Keychain允许用户定义一组密码，形成一个密码串，并且分别为每个密码指定加解密算法（包括MD5，SHA-1等）及密码使用的有效时间。在收发报文时，系统会按照用户的配置选出一个当前有效的密码，并按照与此密码相匹配的加密解密算法以及密码的有效时间，进行发送时加密和接收时解密报文。此外，系统可以依据密码使用的有效时间，自动完成有效密码的切换，避免了长时间不更改密码导致的密码易破解问题。 Keychain的密码、所使用的加解密算法以及密码使用的有效时间可以单独配置，形成一个Keychain配置节点，每个Keychain配置节点至少需要配置一个密码，并指定加解密算法。 LDP GTSM：通用TTL安全保护机制GTSM（Generalized TTL Security Mechanism）是一种通过检查IP报文头中的TTL值是否在一个预先定义好的范围内来实现对IP业务进行保护的机制。使用GTSM的两个前提： 设备之间正常报文的TTL值确定 报文的TTL值很难被修改 LDP GTSM是GTSM在LDP方面的具体应用。 GTSM通过判定报文的TTL值，确定报文是否有效，从而保护设备免受攻击。LDP GTSM是对相邻或相近（基于只要跳数确定的原则）设备间的LDP消息报文应用此种机制。用户预先在各设备上设定好针对其他设备报文的有效范围，使能GTSM，这样当相应设备之间应用LDP时，如果LDP消息报文的TTL不符合之前设置的范围要求，设备就认为此报文为非法攻击报文予以丢弃，进而实现对上层协议的保护。 LDP扩展LDP跨域扩展：LDP跨域扩展通过使能LDP按最长匹配原则查找路由，使LDP能够依据聚合后的路由建立起跨越多个IGP区域的LDP LSP。 产生原因：当网络规模比较大时，通常需要部署多个IGP区域来达到灵活部署和快速收敛的目的。在这种情况下，IGP区域间进行路由通告时，为了避免路由数量多而引起的对资源的过多占用，区域边界路由器（ABR）需要将区域内路由聚合，再通告给相邻的IGP区域。然而，LDP在建立LSP的时候，会在路由表中查找与收到的标签映射消息中携带的FEC精确匹配的路由，对于聚合路由，LDP只能建立Liberal LSP，无法建立跨越IGP区域的LDP LSP。因此，引入LDP跨域扩展来解决这个问题。 注：已经被分配标签，但是没有建立成功的LSP叫做Liberal LSP。 实现过程：如下图所示,存在Area10和Area20两个IGP区域。在Area10区域边缘的LSR_2的路由表中，存在到LSR_3和LSR_4的两条主机路由，为了避免路由数量多而引起的对资源的过多占用，在LSR_2上通过ISIS路由协议将这两条路由聚合为1.3.0.0/24发送到Area20区域。 图：LDP跨域扩展组网拓扑 LDP在建立LSP的时候，会在路由表中查找与收到的标签映射消息中携带的FEC精确匹配的路由，对于上图中的情况，LSR_1的路由表中只有这条聚合后的路由，而没有32位的主机路由。 对于聚合路由，LDP只能建立Liberal LSP，无法建立跨越IGP区域的LDP LSP，以至于无法提供必要的骨干网隧道。 因此，在LSR_1上需要按照最长匹配方式查找路由建立LSP。在LSR_1的路由表中，已经存在聚合路由1.3.0.0/24。当LSR_1收到Area10区域的标签映射消息时（例如携带的FEC为1.3.0.1/32），按照最长匹配的查找方式，LSR_1能够找到聚合路由1.3.0.0/24的信息，把该路由的出接口和下一跳作为到FEC 1.3.0.1/32的出接口和下一跳。这样，LDP就可以建立跨越IGP区域的LDP LSP。 LDP学习笔记LDP是用来在LSR之间建立LDP Session并交换Label/FEC映射信息的协议。 LDP用UDP（协议ID=17）发现邻居，用TCP（协议ID=6）建立邻接（LDP协议的目的端口号：646） LDP协议将hello报文发往224.0.0.2（所有开启组播功能的路由器）的组播组，用于发现直连链路上的LDP邻居。 LDP的hello报文发送间隔是5s，hold time是3倍的hello时间15s。 LDP的keepalive报文的发送间隔是15s，old timer是3倍的keepalive时间45s。 ##LDP的环路检测机制： LDP路由向量法和最大跳数法分别通过两类TLV实现：Path Vector TLV和Hop Count TLV。如果配置使用者两类方法检测环路，那么在标签请求消息（Label Requset Message）和标签映射消息（Label Mapping MEssage）中都会携带者两种TLv。 距离向量法：每个LSR在发送标签请求消息（标签映射消息）中，包含一个Path Vector TLV，并且入口（出口）LSR产生的路由长度值为1，并且把自己的LSR ID加入到TLV的列表中，标签请求消息（标签映射消息）每经过一跳长度值加1，接收端LSR如果收到标签请求消息（标签映射消息），发现长度值达到预先设定的最大值或者发现LSR ID列表中有自己的LSR ID，认为发生环路，发出通告消息，拒绝LSP的建立。 LDP可以为以下协议分配标签： LDP：可以为直连、静态和IGP路由分配标签。 RSVR-TE：为TE预留资源和分配标签。 MPBGP：可以为私网路由分配标签。 BGP：可以为BGP路由分配标签。 FEC简介：转发等价类FEC（Forwarding Equivalence Class）是一组具有某些共性的数据流的集合。这些数据流在转发过程中被LSR以相同的方式出。 FEC可以根据地质、业务类型、QoS等要素进行划分。例如，在传统的采用最常匹配算法的IP转发中，到同一条路由的所有报文就是一个转发等价类。 Cisco定义： LFIB：标签转发表。 LIB：标签信息数据库。 FIB：转发信息数据库。 华为定义： FTN（FEC to NHLFE）：FIB。 NHLFE（Next hop lable forward entry） ILM（Incoming lable map）：LFIB+LIB。 LDP配置命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485fec-list//来创建动态BFD检测LDP LSP的FEC列表。fec-node//增加BFD会话的FEC节点。gtsm peer valid-ttl-hops//在指定的LDP对等体上配置GTSM功能。label advertise &#123; explicit-null | implicit-null | non-null &#125;//配置出节点向倒数第二跳分配的标签。//explicit-null:不支持PHP特性，出节点向倒数第二跳分配显式空标签。显式空标签的值为0。//implicit-null:支持PHP特性，出节点向倒数第二跳分配隐式空标签。隐式空标签的值为3。//non-null:不支持PHP特性，出节点向倒数第二跳正常分配标签。分配的标签值不小于16。label distribution control-mode &#123; independent | ordered &#125;//配置LDP标签分配控制方式。//缺省情况下，LDP标签分配控制方式为有序标签分配控制（Ordered）。label-withdraw-delay//使能Label Withdraw消息延迟发送功能。//执行此命令后,Label Withdraw消息延迟发送的时间默认为5秒，label-withdraw-delay timer 5//设置Label Withdraw消息延迟发送的时间。ldp-sync enable//使能IS-IS进程下所有接口的LDP和IS-IS联动功能。longest-match//配置LDP跨域扩展功能，使能LDP按照最长匹配方式查找路由建立LSP。//缺省情况下，LDP按照精确匹配方式查找路由建立LSP。lsp-trigger bgp-label-route//配置LDP为带标签的公网BGP路由分标签的能力。lsp-trigger//设置触发建立LSP的策略。lsr-id//配置LDP实例的LSR ID。md5-password//配置在建立LDP会话时，TCP连接所使用的密码。md5-password all//对所有对等体批量配置LDP MD5认证。mpls//使能本节点的全局MPLS能力mpls bfd enable//在LDP LSP的源端设备上使能动态创建BFD会话的功能。mpls bfd//设置BFD会话的相关参数mpls ldp advertisement &#123; dod | du &#125;//配置标签发布模式。//缺省情况下，标签发布模式为下游自主标签分发（Downstream Unsolicited）。mpls ldp//来使能本节点的LDP能力mpls ldp remote-peer//创建远端对等体并进入远端对等体视图。mpls ldp timer hello-hold 45//设置Hello保持定时器的值。mpls ldp timer hello-send 15//配置Hello发送定时器的值。mpls ldp timer igp-sync-delay 10//配置LDP会话建立后等待LSP建立的时间间隔。mpls ldp timer keepalive-hold 45//配置Keepalive保持定时器的值。mpls ldp timer keepalive-send 15//配置Keepalive发送定时器的值。mpls ldp transport-address//配置LDP传输地址。mpls-passive//在LSP的目的端设备上使能被动动态创建BFD会话功能。remote-ip//配置LDP远端对等体的IP地址。remote-ip auto-dod-request//配置在采用DoD的标签发布方式下，自动向下游指定的远端对等体请求标签映射消息。remote-peer pwe3//配置禁止向所有远端邻居分发公网标签。route recursive-lookup tunnel//使能迭代隧道功能。static-lsp egress//在出口节点配置静态LSP。static-lsp ingress//为入口节点配置静态LSP。static-lsp transit//为中间转发节点配置静态LSP。ttl expiration pop//配置MPLS TTL超时后ICMP响应报文沿本地IP路由转发。undo ttl expireation pop//ICMP超时应答报文会沿着LSP继续往下传，由边界设备回送给发送源ttl propagate//配置MPLS报文中TTL传播模式为uniform。//缺省情况下，ttl propagate命令使能，MPLS报文中TTL传播模式是uniform。 ttl propagate public//使能MPLS公网报文的IP TTL复制功能。//缺省情况下，对公网报文使能TTL复制功能。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>MPLS VPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MPLS基础]]></title>
    <url>%2F2018%2F02%2F22%2FMPLS%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[MPLS简介多协议标签交换MPLS（Multiprotocol Label Switching）是一种IP（Internet Protocol）骨干网技术。MPLS在无连接的IP网络上引入面向连接的标签交换概念，将第三层路由技术和第二层交换技术相结合，充分发挥了IP路由的灵活性和二层交换的简捷性。 MPLS起源于IPv4（Internet Protocol version 4），其核心技术可扩展到多种网络协议，包括IPv6（Internet Protocol version 6）、IPX（Internet Packet Exchange）和CLNP（Connectionless Network Protocol）等。MPLS中的“Multiprotocol”指的就是支持多种网络协议。 由此可见，MPLS并不是一种业务或者应用，它实际上是一种隧道技术。这种技术不仅支持多种高层协议与业务，而且在一定程度上可以保证信息传输的安全性。 MPLS基本结构网络结构MPLS网络的典型结构如下图所示。MPLS基于标签进行转发，下图中进行MPLS标签交换和报文转发的网络设备称为标签交换路由器LSR（Label Switching Router）；由LSR构成的网络区域称为MPLS域（MPLS Domain）。位于MPLS域边缘、连接其他网络的LSR称为边缘路由器LER（Label Edge Router），区域内部的LSR称为核心LSR（Core LSR）。 图：MPLS网络结构图 IP报文进入MPLS网络时，MPLS入口的LER分析IP报文的内容并且为这些IP报文添加合适的标签，所有MPLS网络中的LSR根据标签转发数据。当该IP报文离开MPLS网络时，标签由出口LER弹出。 IP报文在MPLS网络中经过的路径称为标签交换路径LSP（Label Switched Path）。LSP是一个单向路径，与数据流的方向一致。 如上图，LSP的入口LER称为入节点（Ingress）；位于LSP中间的LSR称为中间节点（Transit）；LSP的出口LER称为出节点（Egress）。一条LSP可以有0个、1个或多个中间节点，但有且只有一个入节点和一个出节点。 根据LSP的方向，MPLS报文由Ingress发往Egress，则Ingress是Transit的上游节点，Transit是Ingress的下游节点。同理，Transit是Egress上游节点，Egress是Transit的下游节点。 体系结构：MPLS的体系结构如下图所示，它由控制平面（Control Plane）和转发平面（Forwarding Plane）组成。 图：MPLS体系结构图 控制平面：负责产生和维护路由信息以及标签信息。 路由信息表RIB（Routing Information Base）：由IP路由协议（IP Routing Protocol）生成，用于选择路由。 标签分发协议LDP（Label Distribution Protocol）：负责标签的分配、标签转发信息表的建立、标签交换路径的建立、拆除等工作。 标签信息表LIB（Label Information Base）：由标签分发协议生成，用于管理标签信息。 转发平面：即数据平面（Data Plane），负责普通IP报文的转发以及带MPLS标签报文的转发。 转发信息表FIB（Forwarding Information Base）：从RIB提取必要的路由信息生成，负责普通IP报文的转发。 标签转发信息表LFIB（Label Forwarding Information Base）：简称标签转发表，由标签分发协议在LSR上建立LFIB，负责带MPLS标签报文的转发。 MPLS标签转发等价类：MPLS将具有相同特征的报文归为一类，称为转发等价类FEC（Forwarding Equivalence Class）。属于相同FEC的报文在转发过程中被LSR以相同方式处理。 FEC可以根据源地址、目的地址、源端口、目的端口、VPN等要素进行划分。例如，在传统的采用最长匹配算法的IP转发中，到同一条路由的所有报文就是一个转发等价类。 标签：标签（Label）是一个短而定长的、只具有本地意义的标识符，用于唯一标识一个分组所属的FEC。在某些情况下，例如要进行负载分担，对应一个FEC可能会有多个入标签，但是一台设备上，一个标签只能代表一个FEC。 MPLS报文与普通的IP报文相比增加了MPLS标签信息，MPLS标签的长度为4个字节。MPLS标签封装在链路层和网络层之间，可以支持任意的链路层协议。MPLS标签的封装结构如下图所示： 图：MPLS标签封装结构 标签共有4个字段： Label：20bit，标签值域。 Exp：3bit，用于扩展。现在通常用做CoS（Class of Service），当设备阻塞时，优先发送优先级高的报文。 S：1bit，栈底标识。MPLS支持多层标签，即标签嵌套。S值为1时表明为最底层标签。 TTL：8bit，和IP报文中的TTL（Time To Live）意义相同。 TTL：8bit，和IP报文中的TTL（Time To Live）意义相同。 标签栈（Label Stack）是指标签的排序集合。靠近二层首部的标签称为栈顶MPLS标签或外层MPLS标签（Outer MPLS label）；靠近IP首部的标签称为栈底MPLS标签或内层MPLS标签（Inner MPLS label）。理论上，MPLS标签可以无限嵌套。目前MPLS标签嵌套主要应用在MPLS VPN、TE FRR（Traffic Engineering Fast ReRoute）中。 标签栈按后进先出方式组织标签，从栈顶开始处理标签。 MPLS报文抓包示例： 图：MPLS报文抓包示例 标签空间：标签空间就是指标签的取值范围。标签空间划分如下： 0～15：特殊标签。 16～1023：静态LSP和静态CR-LSP（Constraint-based Routed Label Switched Path）共享的标签空间。 1024及以上：LDP、RSVP-TE（Resource Reservation Protocol-Traffic Engineering）、MP-BGP（MultiProtocol Border Gateway Protocol）等动态信令协议的标签空间。 特殊标签表： 标签值 含义 描述 0 IPv4 Explicit NULL Label 表示该标签必须被弹出（即标签被剥掉），且报文的转发必须基于IPv4。如果出节点分配给倒数第二跳节点的标签值为0，则倒数第二跳LSR需要将值为0的标签正常压入报文标签值顶部，转发给最后一跳。最后一跳发现报文携带的标签值为0，则将标签弹出。 1 Router Alert Label 只有出现在非栈底时才有效。类似于IP报文的“Router Alert Option”字段，节点收到Router Alert Label时，需要将其送往本地软件模块进一步处理。实际报文转发由下一层标签决定。如果报文需要继续转发，则节点需要将Router Alert Label压回标签栈顶。 2 IPv6 Explicit NULL Label 表示该标签必须被弹出，且报文的转发必须基于IPv6。如果出节点分配给倒数第二跳节点的标签值为2，则倒数第二跳节点需要将值为2的标签正常压入报文标签值顶部，转发给最后一跳。最后一跳发现报文携带的标签值为2，则直接将标签弹出。 3 Implicit NULL Label 倒数第二跳LSR进行标签交换时，如果发现交换后的标签值为3，则将标签弹出，并将报文发给最后一跳。最后一跳收到该报文直接进行IP转发或下一层标签转发。 4～13 保留 - 14 OAM Router Alert Label MPLS OAM（Operation Administration &amp; Maintenance）通过发送OAM报文检测和通告LSP故障。OAM报文使用MPLS承载。OAM报文对于Transit LSR和倒数第二跳LSR（penultimate LSR）是透明的。 15 保留 - LSP的建立MPLS需要为报文事先分配好标签，建立一条LSP，才能进行报文转发。LSP分为静态LSP和动态LSP两种。 静态LSP的建立：静态LSP是用户通过手工为各个转发等价类分配标签而建立的。由于静态LSP各节点上不能相互感知到整个LSP的情况，因此静态LSP是一个本地的概念。 静态LSP不使用标签发布协议，不需要交互控制报文，因此消耗资源比较小，适用于拓扑结构简单并且稳定的小型网络。但通过静态方式分配标签建立的LSP不能根据网络拓扑变化动态调整，需要管理员干预。 配置静态LSP时，管理员需要为各LSR手工分配标签，需要遵循的原则是：前一节点出标签的值等于下一个节点入标签的值。 动态LSP的建立：动态LSP的标签发布协议 动态LSP通过标签发布协议动态建立。标签发布协议是MPLS的控制协议（也可称为信令协议），负责FEC的分类、标签的分发以及LSP的建立和维护等一系列操作。 动态LSP的基本建立过程 标签由下游LSR分配，按从下游到上游的方向分发。如下图，由下游LSR在IP路由表的基础上进行FEC的划分，并根据FEC分配标签，通告给上游的LSR，以便建立标签转发表和LSP。 图：动态LSP的基本建立过程 MPLS转发MPLS基本转发过程：基本概念在MPLS基本转发过程中涉及的相关概念如下： 标签操作类型包括标签压入（Push）、标签交换（Swap）和标签弹出（Pop），它们是标签转发的基本动作。 Push：当IP报文进入MPLS域时，MPLS边界设备在报文二层首部和IP首部之间插入一个新标签；或者MPLS中间设备根据需要，在标签栈顶增加一个新的标签（即标签嵌套封装）。 Swap：当报文在MPLS域内转发时，根据标签转发表，用下一跳分配的标签，替换MPLS报文的栈顶标签。 Pop：当报文离开MPLS域时，将MPLS报文的标签剥掉。 在最后一跳节点，标签已经没有使用价值。这种情况下，可以利用倒数第二跳弹出特性PHP（Penultimate Hop Popping），在倒数第二跳节点处将标签弹出，减少最后一跳的负担。最后一跳节点直接进行IP转发或者下一层标签转发。 默认情况下，设备支持PHP特性，支持PHP的Egress节点分配给倒数第二跳节点的标签值为3。 基本转发过程：以支持PHP的LSP为例，说明MPLS基本转发过程。 图：MPLS基本转发过程 如上图所示，MPLS标签已分发完成，建立了一条LSP，其目的地址为4.4.4.2/32。则MPLS基本转发过程如下： Ingress节点收到目的地址为4.4.4.2的IP报文，压入标签Z并转发。 Transit节点收到该标签报文，进行标签交换，将标签Z换成标签Y。 倒数第二跳Transit节点收到带标签Y的报文。因为Egress分给它的标签值为3，所以进行PHP操作，弹出标签Y并转发报文。从倒数第二跳转发给Egress的报文以IP报文形式传输。 Egress节点收到该IP报文，将其转发给目的地4.4.4.2/32。 MPLS详细转发过程：基本概念：在MPLS详细转发过程中涉及的相关概念如下： Tunnel ID 为了给使用隧道的上层应用（如VPN、路由管理）提供统一的接口，系统自动为隧道分配了一个ID，也称为Tunnel ID。该Tunnel ID的长度为32比特，只是本地有效。 NHLFE 下一跳标签转发表项NHLFE（Next Hop Label Forwarding Entry）用于指导MPLS报文的转发。 NHLFE包括：Tunnel ID、出接口、下一跳、出标签、标签操作类型等信息。 FEC到一组NHLFE的映射称为FTN（FEC-to-NHLFE）。通过查看FIB表中Tunnel ID值不为0x0的表项，能够获得FTN的详细信息。FTN只在Ingress存在。 ILM 入标签到一组下一跳标签转发表项的映射称为入标签映射ILM（Incoming Label Map）。 ILM包括：Tunnel ID、入标签、入接口、标签操作类型等信息。 ILM在Transit节点的作用是将标签和NHLFE绑定。通过标签索引ILM表，就相当于使用目的IP地址查询FIB，能够得到所有的标签转发信息。 详细转发过程： 图：MPLS详细转发过程 MPLS的详细转发过程如上图所示： 当IP报文进入MPLS域时，首先查看FIB表，检查目的IP地址对应的Tunnel ID值是否为0x0。 如果Tunnel ID值为0x0，则进入正常的IP转发流程。 如果Tunnel ID值不为0x0，则进入MPLS转发流程。 在MPLS转发过程中，FIB、ILM和NHLFE表项是通过Tunnel ID关联的。 Ingress的处理：通过查询FIB表和NHLFE表指导报文的转发。 查看FIB表，根据目的IP地址找到对应的Tunnel ID。 根据FIB表的Tunnel ID找到对应的NHLFE表项，将FIB表项和NHLFE表项关联起来。 查看NHLFE表项，可以得到出接口、下一跳、出标签和标签操作类型。 在IP报文中压入出标签，同时处理TTL，然后将封装好的MPLS报文发送给下一跳。 Transit的处理：通过查询ILM表和NHLFE表指导MPLS报文的转发。 根据MPLS的标签值查看对应的ILM表，可以得到Tunnel ID。 根据ILM表的Tunnel ID找到对应的NHLFE表项。 查看NHLFE表项，可以得到出接口、下一跳、出标签和标签操作类型。 MPLS报文的处理方式根据不同的标签值而不同。 如果标签值&gt;＝16，则用新标签替换MPLS报文中的旧标签，同时处理TTL，然后将替换完标签的MPLS报文发送给下一跳。 如果标签值为3，则直接弹出标签，同时处理TTL，然后进行IP转发或下一层标签转发。 Egress的处理：通过查询ILM表指导MPLS报文的转发或查询路由表指导IP报文转发。 如果Egress收到IP报文，则查看路由表，进行IP转发。 如果Egress收到MPLS报文，则查看ILM表获得标签操作类型，同时处理TTL。 如果标签中的栈底标识S=1，表明该标签是栈底标签，直接进行IP转发。 如果标签中的栈底标识S=0，表明还有下一层标签，继续进行下一层标签转发。 MPLS对TTL的处理：MPLS对TTL的处理包括MPLS对TTL的处理模式和ICMP响应报文这两个方面。 MPLS对TTL的处理模式：MPLS标签中包含一个8比特的TTL字段，其含义与IP头中的TTL域相同。MPLS对TTL的处理除了用于防止产生路由环路外，也用于实现Traceroute功能。 RFC3443中定义了两种MPLS对TTL的处理模式：Uniform和Pipe。缺省情况下，MPLS对TTL的处理模式为Uniform。 Uniform模式 IP报文经过MPLS网络时，在入节点，IP TTL减1映射到MPLS TTL字段，此后报文在MPLS网络中按照标准的TTL处理方式处理。在出节点将MPLS TTL减1后映射到IP TTL字段。如下图所示： 图：Uniform模式下入方向TTL的处理 Pipe模式 在入节点，IP TTL值减1，MPLS TTL字段为固定值，此后报文在MPLS网络中按照标准的TTL处理方式处理。在出节点会将IP TTL字段的值减1。即IP分组经过MPLS网络时，无论经过多少跳，IP TTL只在入节点和出节点分别减1。如下图所示： 图：Pipe模式下入方向TTL的处理 在MPLS VPN应用中，出于网络安全的考虑，需要隐藏MPLS骨干网络的结构，这种情况下，对于私网报文，Ingress上使用Pipe模式。 ICMP响应报文：在MPLS网络中，当LSR收到TTL为1的含有标签的MPLS报文时，LSR生成ICMP的TTL超时消息。 如果LSR上存在到达报文发送者的路由，则可以通过IP路由，直接向发送者回应TTL超时消息。 如果LSR上不存在到达报文发送者的路由，则ICMP响应报文将按照LSP继续传送，到达LSP出节点后，由Egress节点将该消息返回给发送者。 通常情况下，收到的MPLS报文只带一层标签时，LSR可以采用第一种方式回应TTL超时消息；收到的MPLS报文包含多层标签时，LSR采用第二种方式回应TTL超时消息。 但是，在MPLS VPN中，ASBR（Autonomous System Boundary Router，自治系统边界路由器）和HoVPN组网应用中的SPE（Superstratum PE or Sevice Provider-end PE，上层PE或运营商侧PE），接收到的承载VPN报文的MPLS报文可能只有一层标签，此时，这些设备上并不存在到达报文发送者的路由，则采用第二种方法回应TTL超时消息。 LSP连通性检测在MPLS网络中，如果通过LSP转发数据失败，负责建立LSP的MPLS控制平面将无法检测到这种错误，加大了网络维护的难度。MPLS Ping/MPLS Tracert为用户提供了发现LSP错误、并及时定位失效节点的机制。 MPLS Ping主要用于检查LSP的连通性。MPLS Tracert在检查LSP的连通性的同时，还可以分析网络什么地方发生了故障。类似于普通IP的Ping/Tracert，MPLS Ping/MPLS Tracert使用MPLS回显请求（Echo Request）报文和MPLS回显应答（Echo Reply）报文检测LSP的可用性。这两种消息都以UDP报文格式发送，其中Echo Request的UDP端口号为3503，该端口号只有使能MPLS功能的设备才能识别。 MPLS Echo Request中携带需要检测的FEC信息，和其他属于此FEC的报文一样沿LSP发送，从而实现对LSP的检测。MPLS Echo Request报文通过MPLS转发给目的端，而MPLS Echo Reply报文则通过IP转发给源端。另外为了防止LSP断路时Echo Request进行IP转发，从而保证LSP的连通性测试，将Echo Request消息的IP头中目的地址设置为127.0.0.1/8（本机环回地址），IP头中的TTL值为1。 MPLS Ping： 图：MPLS网络 如上图，LSR_1上建立了一条目的地为LSR_4的LSP。从LSR_1对该LSP进行MPLS Ping时的处理如下： LSR_1查找该LSP是否存在（对于TE隧道，查找Tunnel接口是否存在且CR-LSP是否建立成功）。如果不存在，返回错误信息，停止Ping。如果存在，则继续进行以下操作。 LSR_1构造MPLS Echo Request报文，IP头中的目的地址为127.0.0.1/8，IP头中的TTL值为1，同时将4.4.4.4填入Echo Request报文中的目的FEC中。然后查找相应的LSP，压入LSP的标签，将报文发送给LSR_2。 中间节点LSR_2和LSR_3对MPLS Echo Request报文进行普通MPLS转发。如果中间节点MPLS转发失败，则中间节点返回带有错误码的MPLS Echo Reply报文。 当MPLS转发路径无故障，则MPLS Echo Request报文到达LSP的出节点LSR_4。然后检查目的FEC中包含的目的地址4.4.4.4是否为自己的Loopback接口地址，以此来确认LSR_4是该FEC的真正出口后，返回正确的MPLS Echo Reply报文。至此整个MPLS Ping过程结束。 MPLS Tracert:从LSR_1对4.4.4.4/32进行MPLS Tracert时的处理如下： LSR_1检查LSP是否存在（对于TE隧道，查找Tunnel接口是否存在且CR-LSP是否建立成功）。如果不存在，返回错误信息，停止Tracert，否则继续进行如下处理。 LSR_1构造MPLS Echo Request报文，IP头中的目的地址为127.0.0.1/8，同时将4.4.4.4填入MPLS Echo Request报文中的目的FEC中，然后查找相应的LSP，压入LSP的标签并且将MPLS TTL设置为1，将报文发送给LSR_2。此MPLS Echo Request报文中包含Downstream Mapping TLV（用来携带LSP在当前节点的下游信息，主要包括下一跳地址、出标签等）。 LSR_2收到LSR_1发送来的报文后，将MPLS Echo Request中MPLS TTL减1为0后发现TTL超时，然后LSR_2需要检查是否存在该LSP，同时检查报文中Downstream Mapping TLV的下一跳地址、出标签是否正确，如果两项检查都正确，返回正确的MPLS Echo Reply报文，并且报文中必须携带LSR_2本身的包含下一跳和出标签的Downstream Mapping TLV给LSR_1。如果检查有不正确，则返回错误的MPLS Echo Reply报文。 LSR_1收到正确的MPLS Echo Reply报文后再次发送MPLS Echo Request报文，报文的封装方式跟步骤2类似，只是将LSP标签的MPLS TTL设置为2，此时的MPLS Echo Request报文中的Downstream Mapping TLV是从MPLS Echo Reply报文中复制过来的。然后LSR_2收到该报文后进行普通MPLS转发。LSR_3收到此报文，标签的TTL超时，跟步骤3同样的处理方式后返回MPLS Echo Reply报文。 LSR_1收到正确的MPLS Echo Reply报文后重复步骤4把LSP标签的MPLS TTL设置为3，复制Downstream Mapping TLV后发送MPLS Echo Request报文。LSR_2和LSR_3对该报文进行普通MPLS转发。LSR_4收到此报文，重复步骤3处理方式对报文进行处理，同时检查目的FEC中包含的目的IP 4.4.4.4为自己的Loopback接口地址，以此来发现已经是该LSP的出节点，因此返回不带下游信息的MPLS Echo Reply报文，至此整个MPLS Tracert过程结束。 通过上述步骤中返回携带下游信息的MPLS Echo Reply报文，在LSR_1上就获取了该LSP沿途每一个节点信息。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>MPLS VPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IGMP Snooping]]></title>
    <url>%2F2018%2F02%2F18%2FIGMP-Snooping%2F</url>
    <content type="text"><![CDATA[IGMP Snooping简介IGMP Snooping (Internet Group Management ProtocolSnooping)是一种IPv4二层组播协议，通过侦听三层组播设备和用户主机之间发送的组播协议报文来维护组播报文的出接口信息，从而管理和控制组播数据报文在数据链路层的转发。 目的：在很多情况下，组播报文要不可避免地经过一些二层交换设备，尤其是在局域网环境里。 由于组播报文的目的地址为组播组地址，在二层设备上是学习不到这一类MAC表项的，因此组播报文就会在所有接口进行广播，和它在同一广播域内的组播成员和非组播成员都能收到组播报文。这样不但浪费了网络带宽，而且影响了网络信息安全。 IGMP Snooping有效地解决了这个问题。配置IGMP Snooping后，二层组播设备可以侦听和分析组播用户和上游路由器之间的IGMP报文，根据这些信息建立二层组播转发表项，控制组播数据报文转发。这样就防止了组播数据在二层网络中的广播。 IGMP Snooping原理描述基本原理：IGMP Snooping是二层组播的基本功能，可以实现组播数据在数据链路层的转发和控制。当主机和上游三层设备之间传递的IGMP协议报文通过二层组播设备时，IGMP Snooping分析报文携带的信息，根据这些信息建立和维护二层组播转发表，从而指导组播数据在数据链路层按需转发。 当组播数据从三层组播设备Router转发下来以后，处于接入边缘的二层组播设备Switch负责将组播数据转发给用户主机，使用户收看所点播的节目。当Switch没有运行IGMP Snooping时，组播数据在二层被广播；当Switch运行了IGMP Snooping后，组播数据不会在二层广播，而是会被Switch发送给指定的接收者。 使能IGMP Snooping功能后，Switch会侦听主机和上游三层设备之间交互的IGMP报文，通过分析报文中携带的信息（报文类型、组播组地址、接收报文的接口等），建立和维护二层组播转发表，从而指导组播数据在数据链路层按需转发。 基本概念：如下图所示，三层设备Router从组播源接收数据并向下游转发，在二层组播设备SwitchA和SwitchB上分别运行IGMP Snooping，HostA、HostB和HostC为接收者主机（即组播组成员）。 图：IGMP Snooping相关端口 IGMP Snooping中的端口角色: 端口角色 作用 如何生成 路由器端口（Router Port）如SwitchA和SwitchB上蓝色圆圈表示的接口。 说明： 路由器端口都是指二层组播设备上朝向组播路由器的接口，而不是指路由器上的接口。 二层组播设备上朝向三层组播设备（DR或IGMP查询器）一侧的接口，二层组播设备从此接口接收组播数据报文。 由协议生成的路由器端口叫做动态路由器端口。收到源地址不为0.0.0.0的IGMP普遍组查询报文或PIM Hello报文（三层组播设备的PIM接口向外发送的用于发现并维持邻居关系的报文）的接口都将被视为动态路由器端口。手工配置的路由器端口叫做静态路由器端口。 成员端口（Member Port）如SwitchA和SwitchB上黄色方框表示的接口。 又称组播组成员端口，表示二层组播设备上朝向组播组成员一侧的端口，二层组播设备往此接口发送组播数据报文。 由协议生成的成员端口叫做动态成员端口。收到IGMP Report报文的接口，二层组播设备会将其标识为动态成员端口。手工配置的成员端口叫做静态成员端口。 路由器端口和成员端口，是二层组播转发表项中的一个重要信息：出接口。其中路由器端口相当于上游接口，成员端口相当于下游接口。通过协议报文学习到的端口，对应的为动态表项；而手工配置的端口，对应的为静态表项。 除了出接口外，每条表项还包括组播组地址和VLAN编号。 工作机制：二层组播设备运行了IGMP Snooping后，收到不同的IGMP协议报文会进行不同的处理，并在此过程中建立起二层组播转发表项。 当收到IGMP普遍组查询报文时：IGMP工作阶段： 普遍组查询IGMP查询器定期向本地网段内的所有主机与路由器（目的地址为224.0.0.1）发送IGMP普遍组查询报文，以查询该网段有哪些组播组的成员。 处理方式： 向VLAN内除接收接口外的其他所有接口转发，并对接收接口做如下处理： 如果路由器端口列表中尚未包含该接口，则将其添加进去，并启动老化定时器。 如果路由器端口列表中已包含该动态路由器端口，则重置老化定时器。 收到IGMP普遍组查询报文时，动态路由器端口的老化定时器缺省为180秒，可以通过命令行配置。 当收到IGMP报告报文时：IGMP工作阶段： 成员报告有两种情况： 成员收到IGMP普遍组查询报文后，回应IGMP报告报文。 成员主动向IGMP查询器发送IGMP报告报文以声明加入该组播组。 处理方式： 向VLAN内所有路由器端口转发。从报文中解析出主机要加入的组播组地址，并对接收接口做如下处理： 如果不存在该组对应的转发表项，则创建转发表项，将该接口作为动态成员端口添加到出接口列表中，并启动老化定时器。如果已存在该组对应的转发表项，但出接口列表中未包含该接口，则将该接口作为动态成员端口添加到出接口列表，并启动老化定时器。如果已存在该组所对应的转发表项，且出接口列表中已包含该动态成员端口，则重置其老化定时器。 收到IGMP报告报文后，动态成员端口的老化定时器 = 健壮系数 x 普遍组查询间隔 + 最大响应时间。 当收到IGMP离开报文时：IGMP工作阶段： 成员离开组播组有两个阶段： 运行IGMPv2或IGMPv3的成员发送IGMP离开报文，以通知IGMP查询器自己离开了某个组播组。IGMP查询器收到IGMP离开报文后，从中解析出组播组地址，并通过接收接口向该组播组发送IGMP特定组查询报文/IGMP特定源组查询报文。 处理方式： 判断离开的组是否存在对应的转发表项，以及转发表项出接口列表是否包含报文的接收接口： 如果不存在该组对应的转发表项，或者该组对应转发表项的出接口列表中不包含接收接口，二层组播设备不转发该报文，将其直接丢弃。如果存在该组对应的转发表项，且转发表项的出接口列表中包含该接口，二层组播设备会将报文向VLAN内所有路由器端口转发。对于IGMP离开报文的接收接口（假定为动态成员端口），二层组播设备在其老化时间内： 如果从该接口收到了主机响应IGMP特定组/源组查询的报告报文，表示接口下还有该组的成员，于是重置其老化定时器。如果没有从该接口收到主机响应IGMP特定组/源组查询的报告报文，则表示接口下已没有该组成员，则在老化时间超时后，将接口从该组的转发表项出接口列表中删除。 此外，当二层组播设备收到PIM Hello报文时，向VLAN内除接收接口外的其他所有接口转发，并对接收接口做如下处理： 如果路由器端口列表中已包含该动态路由器端口，则重置老化定时器。 如果路由器端口列表中尚未包含该接口，则将其添加进去，并启动老化定时器。 如果配置了静态路由器端口，二层组播设备收到IGMP报告和离开报文也会向静态路由器端口转发。如果配置了静态成员端口，则转发表项中会添加该接口为出接口。 当二层组播设备上建立了二层组播转发表项以后，二层组播设备接收到组播数据报文时，依据报文所属VLAN和报文的目的地址（即组播组地址）查找转发表项是否存在对应的“出接口信息”。如果存在，则将报文发送到相应的组播组成员端口和路由器端口；如果不存在，则丢弃该报文或将报文在VLAN内广播。 IGMP Snooping配置命令123456789101112131415161718192021222324252627282930313233343536373839404142434445igmp-snooping enable//使能全局的IGMP Snooping功能。//在VLAN内，也需要使能Igmp Snooping功能。igmp-snooping group-limit//指定接口能够学习的组播表项最大数目。igmp-snooping lastmember-queryinterval 1//配置VLAN内的最后成员查询时间间隔，即IGMP特定组查询报文发送时间间隔。igmp-snooping learning//使能动态成员端口学习功能。//缺省情况下，动态成员端口学习功能处于使能状态。igmp-snooping max-response-time 10//在VLAN内配置IGMP普遍组查询的最大响应时间。igmp-snooping prompt-leave//配置允许VLAN内的成员端口快速离开组播组。//成员端口快速离开是指当路由器收到主机发送的离开某个组//播组的IGMP Leave报文后，不等待成员端口老化，将接口//对应该组播组的转发表项直接删除，这样可以节约带宽和资源。igmp-snooping querier enable//使能VLAN的IGMP Snooping查询器功能。igmp-snooping query-interval 60//配置VLAN内的IGMP Snooping普遍组查询报文发送时间间隔。igmp-snooping report-suppress//配置在VLAN内对Report和Leave报文的抑制功能。igmp-snooping router-aging-time 180//配置VLAN内的动态路由器端口老化时间。igmp-snooping router-learning//使能VLAN的路由器端口动态学习功能。igmp-snooping send-query enable//配置设备响应二层拓扑变化向非路由器端口发送IGMP普遍组查询报文。igmp-snooping send-query source-address//配置IGMP普遍组查询报文的源IP地址。//缺省情况下，IGMP普遍组查询报文的源IP地址为192.168.0.1。igmp-snooping ssm-mapping enable//使能VLAN内的SSM Mapping功能。igmp-snooping static-router-port//配置接口作为指定VLAN内的静态路由器端口。igmp-snooping suppress-time 10//配置VLAN内的IGMP报文抑制时间。//缺省情况下，VLAN内IGMP报文抑制时间为10秒。 igmp-snooping version//来配置IGMP Snooping在VLAN内可以处理的IGMP报文的版本。//缺省情况下，IGMP Snooping可以处理IGMPv1、IGMPv2版本的报文。multicast drop-unknown//配置将VLAN内收到的未知组播流丢弃。//缺省情况下，收到未知组播流会在VLAN内广播。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>组播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[组播源发现协议-MSDP]]></title>
    <url>%2F2018%2F02%2F17%2F%E7%BB%84%E6%92%AD%E6%BA%90%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AE-MSDP%2F</url>
    <content type="text"><![CDATA[MSDP简介MSDP是Multicast Source Discovery Protocol（组播源发现协议）的简称，是为了解决多个PIM-SM（Protocol Independent Multicast Sparse Mode，协议无关组播—稀疏模式）域之间的互连而开发的一种域间组播解决方案，用来发现其他PIM-SM域内的组播源信息。 MSDP目前只支持在IPv4网络部署，域内组播路由协议必须是PIM-SM。MSDP仅对ASM（Any-Source Multicast）模型有意义。 目的：PIM-SM模式下，源端DR（Designated Router）向RP注册，成员端DR也会向RP发起加入报文，因此RP可以获取到所有组播源和组播组成员的信息。随着网络规模的增大以及便于控制组播资源，管理员可能会将一个PIM网络划分为多个PIM-SM域，此时各个域中的RP无法了解其他域中的组播源信息。MSDP可以解决这一问题。 MSDP通过在不同PIM-SM域的路由器（通常在RP上）之间建立MSDP对等体，MSDP对等体之间交互SA（Source-Active）消息，共享组播源信息，最终可以使一个域内的组播用户接收到其他域的组播源发送的组播数据。 MSDP用于在ISP（Internet Service Provider）之间建立对等体。通常，ISP并不希望借助其他ISP的RP来向自己的用户提供服务。这一方面是出于安全性考虑，另一方面如果其他ISP的RP发生故障导致业务中断，用户投诉的却是自己的服务。借助MSDP，每个ISP可以实现依靠自己的RP来向Internet转发和接收组播数据。 尽管MSDP是为域间组播产生的，但它在PIM-SM域内还有着一项特殊的应用——Anycast RP（任播RP）。Anycast RP是指在同一PIM-SM域内通过设置两个或多个具有相同地址的RP，并在这些RP之间建立MSDP对等体关系，以实现域内各RP之间的负载分担和冗余备份。 优点：MSDP可以实现域间组播，同时对ISP而言还有以下优点： PIM-SM域可以依靠本域的RP提供服务，降低了对其他域RP的依赖。还可以控制本域的源信息是否传递到其他域中，提高了网络安全性。 如果某个域中只有接收者，他不必去整个网络上汇报组成员关系，只在本PIM-SM域内汇报，就可以接收到组播数据。 单个PIM-SM域内的设备不需要专门维护整网的组播源信息和组播路由表项，节省系统资源。 原理描述MSDP对等体：使用MSDP实现跨域组播的首要任务是：建立MSDP对等体。 通常，在各个PIM-SM域的RP之间配置MSDP对等体关系，MSDP对等体之间交互SA（Source Active）消息，SA消息中携带组播源DR在RP上注册时的（S，G）信息。通过这些MSDP对等体之间的信息传递，任意一个RP发出的SA消息能够被其他所有的RP收到。 MSDP对等体并不是只能配置在RP上，如下图所示，MSDP对等体可以创建在任意的PIM路由器上，在不同角色的PIM路由器上所创建的MSDP对等体的功能有所不同。 图：MSDP对等体位置 在RP上创建的MSDP对等体: MSDP对等体分类 位置 功能 源端MSDP对等体 离组播源（Source）最近的MSDP对等体（通常也就是源端RP，如RP1） 源端RP创建SA消息并发送给远端MSDP对等体，通告在本RP上注册的组播源信息。源端MSDP对等体必须配置在RP上，否则将无法向外发布组播源信息。 接收者端MSDP对等体 离接收者（Receiver）最近的MSDP对等体（如RP3） 接收者端MSDP对等体在收到SA消息后，根据该消息中所包含的组播源信息，跨域加入以该组播源为根的SPT；当来自该组播源的组播数据到达后，再沿RPT向本地接收者转发。接收者端MSDP对等体必须配置在RP上，否则无法接收到其他域的组播源信息。 中间MSDP对等体 拥有多个远端MSDP对等体的MSDP对等体（如RP2） 中间MSDP对等体把从一个远端MSDP对等体收到的SA消息转发给其他远端MSDP对等体，其作用相当于传输组播源信息的中转站。 在普通的PIM路由器（非RP）上创建的MSDP对等体 如RouterA和RouterB，其作用仅限于将收到的SA消息转发出去。 MSDP协议报文：MSDP的协议报文封装在TCP数据报中，协议报文的格式都符合标准的TLV（Type-Length-Value）消息格式，如下图所示： 图：MSDP协议报文格式 MSDP协议报文类型：Source-Active（SA）： Type 1。 功能：1、携带多组（S，G）信息，在多个RP之间传递。 ​ 包含的主要信息： ​ 源RP的IP地址。 ​ 消息中包含的（S,G）项数量。 ​ 域中活跃的（S，G）列表 ​ 2、封装PIM-SM组播数据。 ​ 包含的主要信息： ​ 源RP的IP地址。 ​ PIM-SM组播数据。 Source-Active-Response（SA-Req）: Type 2。 功能：主动请求指定组G的（S，G）列表，减少源加入的延迟。 报文中包含：被请求的组地址G。 Source-Active Response（SA-Resp）： Type 3. 功能：对Source-Active Request消息的响应。 报文中包含：源RP的IP地址​ 消息中包含的（S，G）项数量​ 域中活动（S，G）列表 KeepAlive： Type 4。 功能：保持MSDP对等体的连接关系。只在对等体之间无其他协议报文交互时才发送。 Reserved： Type 5。 功能：保留类型，当前是用作Notification消息。 Traceroute in Progress： Type 6。 Traceroute Reply： Type 7。 和类型6的功能：用于MSDP的Traceroute功能，对SA消息的RPF传递路径进行检测。 SA消息中可以携带（S，G）信息，也可以封装组播数据报文。MSDP对等体之间通过交互SA消息共享（S，G）信息。为了避免SA消息中的（S，G）表项超时导致远端用户无法收到组播源的数据，可以在SA消息中封装组播数据报文。 由于SA消息是周期性发送的，当域内出现新的组用户时，要等待一个周期内的SA消息以获取有效的（S，G）信息。为了减少新组用户加入源SPT的时延，MSDP提供了Type2和Type3的SA-Req消息与SA-Resp消息，提高活动源信息更新的效率。 对等体建立的过程：MSDP对等体建立：MSDP对等体通过TCP连接建立，使用端口639。 两台设备使能MSDP并互相指定对方为MSDP对等体后，两端先比较IP地址，IP地址较小的一端会启动连接重试定时器（ConnectRetry timer），并主动发起TCP连接。IP地址较大的一端负责确认是否有TCP连接在端口639建立。TCP连接建立后，MSDP对等体关系就建立了，对等体之间通过KeepAlive消息维持连接关系。 图：MSDP对等体建立过程 如上图所示，RouterA和RouterB之间建立MSDP对等体的过程如下： 起始状态下，两台路由器的MSDP会话状态都是Down。 在两端使能MSDP并互相指定对方为MSDP对等体后，两端比较建立连接使用的地址： RouterA的地址较小，进入Connect状态，向RouterB发起连接，并启动ConnectRetry定时器。该定时器用于定义连接重试的周期。 RouterB的地址较大，进入Listen状态，等待对端进行连接。 TCP连接建立成功后，两端的MSDP会话进入Up状态。 MSDP对等体两端发送KeepAlive消息，通知对方保持MSDP连接状态。 MSDP认证：在TCP连接建立时进行加密认证，可以保证安全性。配置了认证功能后，MSDP对等体两端必须都使用相同的加密算法和密码，才能正常建立TCP连接，否则不建立连接。MSDP支持MD5和Keychain两种加密方式，二者在使用时互斥，MSDP对等体之间只能选择一种方式加密。 组播源信息在域间的传递：如下图所示，PIM-SM网络被划分为4个PIM-SM域。PIM-SM1域内存在激活的组播源（Source），RP1通过组播源注册过程了解到了该组播源的存在。如果PIM-SM2和PIM-SM3域也希望知道该组播源的具体位置，进而能够从该组播源获取组播数据，则需要在RP1与RP2、RP2与RP3之间分别建立MSDP对等体关系。 图：组播源信息在域间的传递 组播源信息在域间传递的过程如下： 当PIM-SM1域内的组播源Source向组播组G发送第一个组播数据包时，DR1（Designated Router）将该组播数据封装在注册报文（Register Message）中，并发给RP1。RP1因此获知了该组播源的相关信息。 RP1作为源端RP，创建SA消息，并周期性地向它的对等体RP2发送。SA消息中包含组播源的地址S、组播组的地址G以及创建该SA消息的源端RP（即RP1）的地址。 RP2接收到该SA消息后，执行RPF（Reverse Path Forwarding）检查。检查通过，向RP3转发，同时检查本域内是否存在组G成员。由于PIM-SM2域内没有组G的接收者，故RP2不做其他动作。 RP3接收到该SA消息后，执行RPF检查，检查通过。由于PIM-SM3域内存在组G成员，会通过IGMP协议在RP3上生成（*，G）表项，表示本域内存在组G成员。 RP3创建（S，G）表项，向组播源Source逐跳发送（S，G）加入报文，创建一条从Source到RP3的组播路径（SPT）。组播数据沿SPT到达RP3后，再沿RPT向接收者转发。 当接收者侧DR3收到Source发出的组播数据后，可以自行决定是否发起SPT切换。 控制SA消息的转发：SA消息在MSDP对等体之间转发，除了RPF检查，还可以配置各种转发策略的过滤，从而只接收和转发来自正确路径并通过过滤的SA消息，以避免SA消息传递环路；另外，可以在MSDP对等体之间配置MSDP全连接组（Mesh Group），以避免SA消息在MSDP对等体之间的泛滥。 SA消息的RPF检测规则：为了防止SA消息在MSDP对等体之间被循环转发，MSDP对接收到的SA消息执行RPF检查，在消息传递的入方向上进行严格的控制。不符合RPF规则的SA消息，将被丢弃。 RPF检查的主要规则为：MSDP设备收到SA消息后，根据MRIB（Multicast RPF Routing Information Base）确定到源RP（即创建该SA消息的RP）最佳路径的下一跳是哪个对等体，这个对等体也称为“RPF对等体”。如果发现SA消息是从RPF对等体发出的，则接收该SA消息并向其他对等体转发。MRIB包括：MBGP、组播静态路由、单播路由（包括BGP、IGP）。 此外，还有如下的一些RPF检查规则，SA消息在转发时遵守： 规则1：发出SA消息的对等体就是源RP，则接收该SA消息并向其他对等体转发。 规则2：接收从静态RPF对等体到来的SA消息。一台路由器可以同时与多个路由器建立MSDP对等体关系。用户可以从这些远端对等体中选取一个或多个，配置为静态RPF对等体。 规则3：如果一台路由器只拥有一个远端MSDP对等体，则该远端对等体自动成为RPF对等体，路由器接收从该远端对等体发来的SA消息。 规则4：发出SA消息的对等体与本地路由器属于同一Mesh Group，则接收该SA消息。来自Mesh Group的SA消息不再向属于该Mesh Group的成员转发，但向该Mesh Group之外的所有对等体转发。 规则5：到达源RP的路由需要跨越多个AS时，接收从下一跳AS（以AS为单位）中的对等体发出的SA消息，如果该AS中存在多个远端MSDP对等体，则接收从IP地址最高的对等体发来的SA消息。 MSDP全连接组（Mesh Group）：当网络中存在多个MSDP对等体时，很容易导致SA消息在对等体之间泛滥。同时，MSDP对等体对每一个到来的SA报文进行RPF检查，给系统造成很大的负担。将多个MSDP对等体加入同一个Mesh Group，就可以大幅度减少在这些MSDP对等体之间传递的SA消息。 Mesh Group成员可以都属于同一个PIM-SM域，也可以分布在多个PIM-SM域中；可以都位于同一个AS，也可以位于多个AS中。 属于同一个Mesh Group的所有成员之间必须两两建立MSDP对等体连接，并承认对方为该Mesh Group的成员。如下图中的RouterA、RouterB、RouterC和RouterD，加入同一个Mesh Group，则必须在每台路由器上配置与其他三台路由器建立MSDP对等体关系。 图：Mesh Group内部成员之间的MSDP对等体连接 当Mesh Group内部成员接收到SA消息后，首先检查该SA消息的来源： 如果该SA消息来自Mesh Group外部的某个MSDP对等体，则对该SA消息进行RPF检查。如果检查通过，向Mesh Group内其他所有成员转发。 如果该SA消息来自Mesh Group内部成员，则不进行RPF检查，直接接收。同时也不再向Mesh Group内其他成员转发。 SA消息过滤：缺省情况下，MSDP不过滤SA消息，从一个域中发出的SA消息可以被传递到全网的MSDP对等体。 然而，有些PIM-SM域的（S，G）表项只适用于本域内指导转发，如一些本地组播应用使用了全局的组播组地址，或组播源用的是私网地址10.x.x.x。如果不加过滤，这些（S，G）表项就会经过SA消息传递到其他MSDP对等体。针对这种情况，可以配置SA消息的过滤规则（一般使用ACL定义过滤的规则），并在创建、转发或接收SA消息时使用这些规则，就可以实现SA消息过滤。 MSDP配置命令行12345678910111213141516171819202122232425262728cache-sa-enable//使能SA缓存功能，收到SA消息后缓存其中包含的（S，G）表项。display msdp brief// 查看MSDP对等体的简要信息。display msdp rpf-peer//查看到指定源RP地址的所有RPF对等体信息，包括RPF对等体选取规则及依据的路由信息类型。encap-data-enable//使能在SA消息中封装组播数据报文。import-source//在MSDP创建SA消息时，限制本域内被通告的活动源信息。originating-rp//在RP创建SA消息时，使用指定接口IP地址代替实际的源RP地址，也称为“逻辑RP”。peer connect-interface//配置MSDP对等体。peer mesh-group //将一个MSDP对等体加入全连接组。peer minimum-ttl 0//配置向指定对等体转发封装了组播数据报文的SA消息TTL阈值。peer request-sa-enable//使能立即向指定的MSDP对等体发送SA请求消息的功能。peer sa-cache-maximum//配置SA Cache能够缓存从指定MSDP对等体学到的（S，G）表项的最大数量。//缺省情况下，SA Cache最多缓存1638个（S，G）表项。static-rpf-peer//指定MSDP对等体为静态RPF对等体，从该对等体发来的SA消息不需要进行RPF检查。timer retry 30//配置MSDP对等体连接请求重试周期。//缺省情况下，MSDP对等体连接请求重试周期是30秒。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>组播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协议无关组播-PIM]]></title>
    <url>%2F2018%2F02%2F13%2F%E5%8D%8F%E8%AE%AE%E6%97%A0%E5%85%B3%E7%BB%84%E6%92%AD-PIM%2F</url>
    <content type="text"><![CDATA[PIM简介PIM（Protocol Independent Multicast）称为协议无关组播。这里的协议无关指的是与单播路由协议无关，即PIM不需要维护专门的单播路由信息。作为组播路由解决方案，它直接利用单播路由表的路由信息，对组播报文执行RPF（Reverse Path Forwarding，逆向路径转发）检查，检查通过后创建组播路由表项，从而转发组播报文。 目前设备实际支持的PIM协议包括：PIM-DM（PIM-Dense Mode）、PIM-SM（PIM-Sparse Mode）。 PIM的基本概念：组播分发树：PIM网络以组播组为单位在路由器上建立一点到多点的组播转发路径。由于组播转发路径呈现树型结构，也称为组播分发树MDT（Multicast Distribution Tree）。 组播分发树主要包括以下两种： 以组播源为根，组播组成员为叶子的组播分发树称为SPT（Shortest Path Tree）。SPT同时适用于PIM-DM网络和PIM-SM网络。 以RP（Rendezvous Point）为根，组播组成员为叶子的组播分发树称为RPT（RP Tree）。RPT适用于PIM-SM网络。 PIM路由器：在接口上使能了PIM协议的路由器即为PIM路由器。在建立组播分发树的过程中，PIM路由器又分为以下几种： 叶子路由器：与用户主机相连的PIM路由器，但连接的用户主机不一定为组成员。 第一跳路由器：组播转发路径上，与组播源相连且负责转发该组播源发出的组播数据的PIM路由器。 最后一跳路由器：组播转发路径上，与组播组成员相连且负责向该组成员转发组播数据的PIM路由器。 中间路由器：组播转发路径上，第一跳路由器与最后一跳路由器之间的PIM路由器。 PIM路由表项：PIM路由表项即通过PIM协议建立的组播路由表项。PIM网络中存在两种路由表项：（S，G）路由表项或（ ，G）路由表项。S表示组播源，G表示组播组， 表示任意。 （S，G）路由表项主要用于在PIM网络中建立SPT。对于PIM-DM网络和PIM-SM网络适用。 （*，G）路由表项主要用于在PIM网络中建立RPT。对于PIM-SM网络适用。 PIM路由器上可能同时存在两种路由表项。当收到源地址为S，组地址为G的组播报文，且RPF检查通过的情况下，按照如下的规则转发： 如果存在（S，G）路由表项，则由（S，G）路由表项指导报文转发。 如果不存在（S，G）路由表项，只存在（ ，G）路由表项，则先依照（ ，G）路由表项创建（S，G）路由表项，再由（S，G）路由表项指导报文转发。 PIM路由表项中主要用于指导转发的信息如下： 组播源地址。 组播组地址。 上游接口：本地路由器上接收到组播数据的接口。 下游接口：将组播数据转发出去的接口。 PIM-DM基本原理：基本原理PIM-DM使用“推（Push）模式”转发组播报文，一般应用于组播组成员规模相对较小、相对密集的网络。在实现过程中，它会假设网络中的组成员分布非常稠密，每个网段都可能存在组成员。当有活跃的组播源出现时，PIM-DM会将组播源发来的组播报文扩散到整个网络的PIM路由器上，再裁剪掉不存在组成员的分支。PIM-DM通过周期性的进行“扩散（Flooding）—剪枝（Prune）”，来构建并维护一棵连接组播源和组成员的单向无环SPT（Source Specific Shortest Path Tree）。如果在下一次“扩散-剪枝”进行前，被裁剪掉的分支由于其叶子路由器上有新的组成员加入而希望提前恢复转发状态，也可通过嫁接（Graft）机制主动恢复其对组播报文的转发。 PIM-DM的关键工作机制包括邻居发现、扩散、剪枝、嫁接、断言和状态刷新。其中，扩散、剪枝、嫁接是构建SPT的主要方法。 邻居发现（Neighbor Discovery）：PIM路由器上每个使能了PIM协议的接口都会对外发送Hello报文。封装Hello报文的组播报文的目的地址是224.0.0.13（表示同一网段中所有PIM路由器）、源地址为接口的IP地址、TTL数值为1。 Hello报文的作用：发现PIM邻居、协调各项PIM协议报文参数、维持邻居关系。 发现PIM邻居 同一网段中的PIM路由器都必须接收目的地址为224.0.0.13的组播报文。这样直接相连的PIM路由器之间通过交互Hello报文以后，就可以彼此知道自己的邻居信息，建立邻居关系。 只有邻居关系建立成功后，PIM路由器才能接收其他PIM协议报文，从而创建组播路由表项。 协调各项PIM协议报文参数 Hello报文中携带多项PIM协议报文参数，主要用于PIM邻居之间PIM协议报文的控制。具体如下： DR_Priority：表示各路由器接口竞选DR的优先级，优先级越高越容易获胜。 Holdtime：表示保持邻居为可达状态的超时时间。如果在超时时间内没有收到PIM邻居发送的Hello报文，路由器则认为邻居不可达。 LAN_Delay：表示共享网段内传输Prune报文的延迟时间。 Neighbor-Tracking：表示邻居跟踪功能。 Override-Interval：表示Hello报文中携带的否决剪枝的时间间隔。 维持邻居关系 PIM路由器之间周期性地发送Hello报文。如果Holdtime超时还没有收到该PIM邻居发出的新的Hello报文，PIM路由器就认为该邻居不可达，将其从邻居列表中清除。 PIM邻居的变化将导致网络中组播拓扑的变化。如果组播分发树上的某上游邻居或下游邻居不可达，将导致组播路由重新收敛，组播分发树迁移。 扩散（Flooding）:当PIM-DM网络中出现活跃的组播源之后，组播源发送的组播报文将在全网内扩散。当PIM路由器接收到组播报文，根据单播路由表进行RPF检查通过后，就会在该路由器上创建（S，G）表项，下游接口列表中包括除上游接口之外与所有PIM邻居相连的接口，后续到达的组播报文将从各个下游接口转发出去。 最后组播报文扩散到达叶子路由器，会出现以下两种情况： 若与该叶子路由器相连用户网段上存在组成员，则将与该网段相连的接口加入（S，G）表项的下游接口列表中，后续的组播报文会向组成员转发。 若与该叶子路由器相连用户网段上不存在组成员，且不需要向其下游PIM邻居转发组播报文，则执行剪枝动作。 剪枝（Prune）：当PIM路由器接收到组播报文后，RPF检查通过，但是下游网段没有组播报文需求。此时PIM路由器会向上游发送剪枝报文，通知上游路由器禁止相应下游接口的转发，将其从（S，G）表项的下游接口列表中删除。剪枝操作由叶子路由器发起，逐跳向上，最终组播转发路径上只存在与组成员相连的分支。 路由器为被裁剪的下游接口启动一个剪枝定时器，定时器超时后接口恢复转发。组播报文重新在全网范围内扩散，新加入的组成员可以接收到组播报文。随后，下游不存在组成员的叶子路由器将向上发起剪枝操作。通过这种周期性的扩散-剪枝，PIM-DM周期性的刷新SPT。 当下游接口被剪枝后： 如果下游叶子路由器有组成员加入，并且希望在下次“扩散-剪枝”前就恢复组播报文转发，则执行嫁接动作。 如果下游叶子路由器一直没有组成员加入，希望该接口保持抑制转发状态，则执行状态刷新动作。 嫁接（Graft）：PIM-DM通过嫁接机制，使有新组成员加入的网段快速得到组播报文。叶子路由器通过IGMP了解到与其相连的用户网段上，组播组G有新的组成员加入。随后叶子路由器会向上游发送Graft报文，请求上游路由器恢复相应出接口转发，将其添加在（S，G）表项下游接口列表中。 嫁接过程从叶子路由器开始，到有组播报文到达的路由器结束。 状态刷新（State Refresh）：在PIM-DM网络中，为了避免被裁剪的接口因为“剪枝定时器”超时而恢复转发，离组播源最近的第一跳路由器会周期性地触发StateRefresh报文在全网内扩散。收到State Refresh报文的PIM路由器会刷新剪枝定时器的状态。被裁剪接口的下游叶子路由器如果一直没有组成员加入，该接口将一直处于抑制转发状态。 断言（Assert）：当一个网段内有多个相连的PIM路由器RPF检查通过向该网段转发组播报文时，则需要通过断言机制来保证只有一个PIM路由器向该网段转发组播报文。PIM路由器在接收到邻居路由器发送的相同组播报文后，会以组播的方式向本网段的所有PIM路由器发送Assert报文，其中目的地址为永久组地址224.0.0.13。其它PIM路由器在接收到Assert报文后，将自身参数与对方报文中携带的参数做比较，进行Assert竞选。竞选规则如下： 单播路由协议优先级较高者获胜。 如果优先级相同，则到组播源的开销较小者获胜。 如果以上都相同，则下游接口IP地址最大者获胜。 根据Assert竞选结果，路由器将执行不同的操作： 获胜一方的下游接口称为Assert Winner，将负责后续对该网段组播报文的转发。 落败一方的下游接口称为Assert Loser，后续不会对该网段转发组播报文，PIM路由器也会将其从（S，G）表项下游接口列表中删除。 Assert竞选结束后，该网段上只存在一个下游接口，只传输一份组播报文。所有Assert Loser可以周期性地恢复组播报文转发，从而引发周期性的Assert竞选。 PIM-SM基本原理（ASM模型）：在ASM（Any-Source Multicast）模型中，PIM-SM使用“拉（Pull）模式”转发组播报文，一般应用于组播组成员规模相对较大、相对稀疏的网络。基于这一种稀疏的网络模型，它的实现方法是： 在网络中维护一台重要的PIM路由器：汇聚点RP（Rendezvous Point），可以为随时出现的组成员或组播源服务。网络中所有PIM路由器都知道RP的位置。 当网络中出现组成员（用户主机通过IGMP加入某组播组G）时，最后一跳路由器向RP发送Join报文，逐跳创建（ * ，G）表项，生成一棵以RP为根的RPT。 当网络中出现活跃的组播源（组播源向某组播组G发送第一个组播数据）时，第一跳路由器将组播数据封装在Register报文中单播发往RP，在RP上创建（S，G）表项，注册源信息。 在ASM模型中，PIM-SM的关键机制包括邻居发现、DR竞选、RP发现、RPT构建、组播源注册、SPT切换、断言；同时也可通过配置BSR（Bootstrap Router）管理域来实现单个PIM-SM域的精细化管理。 DR竞选：在组播源或组成员所在的网段，通常同时连接着多台PIM路由器。这些PIM路由器之间通过交互Hello报文成为PIM邻居，Hello报文中携带DR优先级和该网段接口地址。PIM路由器将自身条件与对方报文中携带的信息进行比较，选举出DR来负责源端或组成员端组播报文的收发。竞选规则如下： DR优先级较高者获胜（网段中所有PIM路由器都支持DR优先级）。 如果DR优先级相同或该网段存在至少一台PIM路由器不支持在Hello报文中携带DR优先级，则IP地址较大者获胜。 如果当前DR出现故障，将导致PIM邻居关系超时，其他PIM邻居之间会触发新一轮的DR竞选。 在ASM模型中，DR主要作用如下： 在连接组播源的共享网段，由DR负责向RP发送Register注册报文。与组播源相连的DR称为源端DR。 在连接组成员的共享网段，由DR负责向RP发送Join加入报文。与组成员相连的DR称为组成员端DR。 RP发现：汇聚点RP为网络中一台重要的PIM路由器，用于处理源端DR注册信息及组成员加入请求，网络中的所有PIM路由器都必须知道RP的地址，类似于一个供求信息的汇聚中心。 一个RP可以同时为多个组播组服务，但一个组播组只能对应一个RP。目前可以通过以下方式配置RP： 静态RP：在网络中的所有PIM路由器上配置相同的RP地址，静态指定RP的位置。 动态RP：在PIM域内选择几台PIM路由器，配置C-RP（Candidate-RP，候选RP）来动态竞选出RP。同时，还需要通过配置C-BSR（Candidate-BSR，候选BSR）选举出BSR，来收集C-RP的通告信息，向PIM-SM域内的所有PIM路由器发布。 C-BSR在竞选的时候，开始时每个C-BSR都认为自己是BSR，向全网发送Bootstrap报文。Bootstrap报文中携带C-BSR地址、C-BSR的优先级。每一台PIM路由器都收到所有C-BSR发出的Bootstrap报文，通过比较这些C-BSR信息，竞选产生BSR。竞选规则如下： 优先级较高者获胜（优先级数值越大优先级越高）。 如果优先级相同，IP地址较大者获胜。 C-RP的竞选过程如下： C-RP向BSR发送Advertisement报文，报文中携带C-RP地址、服务的组范围和C-RP优先级。 BSR将这些信息汇总为RP-Set，封装在Bootstrap报文中，发布给全网的每一台PIM-SM路由器。 各PIM路由器根据RP-Set，使用相同的规则进行计算和比较，从多个针对特定组的C-RP中竞选出该组RP。规则如下：​ 与用户加入的组地址匹配的C-RP服务的组范围掩码最长者获胜。 如果以上比较结果相同，则C-RP优先级较高者获胜（优先级数值越小优先级越高）。 如果以上比较结果都相同，则执行Hash函数，计算结果较大者获胜。 如果以上比较结果都相同，则C-RP的IP地址较大者获胜 由于所有PIM路由器使用相同的RP-Set和竞选规则，所以得到的组播组与RP之间的对应关系也相同。PIM路由器将“组播组—RP”对应关系保存下来，指导后续的组播操作。 RPT构建：PIM-SM RPT是一棵以RP为根，以存在组成员关系的PIM路由器为叶子的组播分发树。 在RPT构建过程中，PIM路由器在发送Join报文时，会进行RPF检测查找到达RP的单播路由，单播路由的出接口为上游接口，下一跳为RPF邻居。Join报文从组成员端DR开始逐跳发送，直至到RP。 组播源注册：在PIM-SM网络中，任何一个新出现的组播源都必须首先在RP处“注册”，继而才能将组播报文传输到组成员。具体过程如下： 组播源将组播报文发给源端DR。 源端DR接收到组播报文后，将其封装在Register报文中，发送给RP。 RP接收到Register报文，将其解封装，建立（S，G）表项，并将组播数据沿RPT发送到达组成员。 SPT切换：在PIM-SM网络中，一个组播组只对应一个RP，只构建一棵RPT。在未进行SPT切换的情况下，所有发往该组的组播报文都必须先封装在注册报文中发往RP，RP解封装后，再沿RPT分发。RP是所有组播报文必经的中转站，当组播报文速率逐渐变大时，对RP形成巨大的负担。为了解决此问题，PIM-SM允许RP或组成员端DR通过触发SPT切换来减轻RP的负担。 RP触发SPT切换 RP收到源端DR的注册报文后，将封装在Register报文中的组播报文沿RPT转发给组成员，同时RP会向源端DR逐跳发送Join报文。发送过程中在PIM路由器创建（S，G）表项，从而建立了RP到源的SPT。 SPT树建立成功后，源端DR直接将组播报文转发到RP，使源端DR和RP免除了频繁的封装与解封装。 组成员端DR触发SPT切换 STP切换机制：组成员端DR周期性检测组播报文的转发速率，一旦发现（S，G）报文的转发速率超过阈值，则触发SPT切换： 组成员端DR逐跳向源端DR逐跳发送Join报文并创建（S，G）表项，建立源端DR到组成员DR的SPT。 SPT建立后，组成员端DR会沿着RPT逐跳向RP发送剪枝报文，删除（*，G）表项中相应的下游接口。剪枝结束后，RP不再沿RPT转发组播报文到组成员端。 如果SPT不经过RP，RP会继续向源端DR逐跳发送剪枝报文，删除（S，G）表项中相应的下游接口。剪枝结束后，源端DR不再沿“源端DR-RP”的SPT转发组播报文到RP。 缺省情况下，设备一般未设置组播报文转发速率的阈值，RP或者组成员端DR在接收到第一份组播报文时都会触发各自的SPT切换。 BSR管理域：为了实现网络管理精细化，可以选择将一个PIM-SM网络划分为多个BSR管理域和一个Global域。这样一方面可以有效地分担单一BSR的管理压力，另一方面可以使用私有组地址为特定区域的用户提供专门服务。 每个BSR管理域中维护一个BSR，为某一特定地址范围的组播组服务。Global域中维护一个BSR，为所有剩余的组播组服务。 下文将从地域空间、组地址范围、组播功能三个角度分析BSR管理域和Global域的关系。 地域空间： 图：BSR管理域_地址空间 如上图所示，对于有相同组地址的不同管理域，各BSR管理域所包含的PIM路由器互不相同，同一PIM路由器不能同时属于多个BSR管理域。各BSR管理域在地域上相互独立，且相互隔离。BSR管理域是针对特定地址范围的组播组的管理区域，属于此范围的组播报文只能在本管理域内传播，无法通过BSR管理域边界。 Global域包含PIM-SM网络内的全部PIM路由器。不属于任意BSR管理域的组播报文，可以在整个PIM网络范围内传播。 组地址范围： 图：BSR管理域_组地址范围 每个BSR管理域为特定地址范围的组播组提供服务，不同的BSR管理域服务的组播组范围可以重叠。该组播地址只在本BSR管理域内有效，相当于私有组地址。如上图所示，BSR1域和BSR3域对应的组地址范围出现重叠。 不属于任何BSR管理域的组播组，一律属于Global域的服务范围。如上图所示，Global域组地址范围是除G1、G2之外的G-G1-G2。 组播功能：Global域和每个BSR管理域都包含针对自己域的C-RP和BSR设备，这些设备在行使相应功能时，仅在本域内有效。即BSR机制和RP竞选在各管理域之间是隔离的。 每个BSR管理域都有自己的边界，该管理域的组播信息（C-RP宣告报文、BSR自举报文等）不能跨越域传播。同时Global域的组播信息可以在整个Global域内传递，可以穿越任意BSR管理域。 基本原理（SSM模型）：SSM模型是借助PIM-SM的部分技术和IGMPv3/MLDv2来实现的，无需维护RP、无需构建RPT、无需注册组播源，可以直接在源与组成员之间建立SPT。 SSM的特点是网络用户能够预先知道组播源的具体位置。因此用户在加入组播组时，可以明确指定从哪些源接收信息。组成员端DR了解到用户主机的需求后，直接向源端DR发送Join报文。Join报文逐跳向上传输，在源与组成员之间建立SPT。 在SSM模型中，PIM-SM的关键机制包括邻居发现、DR竞选、构建SPT。 Anycast RP:配置基于PIM协议的Anycast RP功能时，当RP收到源DR发送的注册报文后，对注册报文的源地址进行判断，如果是从源DR发送过来的，将注册报文转发给Anycast RP对等体，如果注册报文是从Anycast RP对等体发送过来的，则不进行转发。 RP转发注册报文时，需要将源地址替换为Anycast RP本地地址，目的地址替换为Anycast RP对等体地址。从而达到Anycast RP之间相互学习源组信息的目的。 Anycast RP集合的成员与外部均建立MSDP对等体； 将Anycast RP集合中的RP分为两部分，其中一部分与外部建立MSDP对等体，另外一部分不建立MSDP对等体，当与外部建立了MSDP对等体的RP收到MSDP SA报文时，转换为注册报文发送给其它未建立MSDP对等体的RP。 注意事项 每个Anycast RP最多可以配置16个对等体。 在同一PIM SM域内配置Anycast RP，Anycast RP之间逻辑上需要配置为全连接结构，即任意两两Anycast RP之间配置为Anycast RP对等体。 通过Anycast RP，可以实现： RP路径最优：组播源向距离最近的RP进行注册，建立路径最优的SPT；接收者向距离最近的RP发起加入，建立路径最优的RPT。 RP间的负载分担：每个RP上只需维护PIM-SM域内的部分源/组信息、转发部分的组播数据，从而实现了RP间的负载分担。 RP间的冗余备份：当某RP失效后，原先在该RP上注册或加入的组播源或接收者会自动选择就近的RP进行注册或加入操作，从而实现了RP间的冗余备份。 PIM BFD和PIM GRPIM BFD：为了减小设备故障对业务的影响，提高网络的可靠性，网络设备需要快速检测到与相邻设备间的通信故障，以便及时采取措施，保证业务继续进行。 BFD（Bidirectional Forwarding Detection）检测机制可提供毫秒级的快速检测，并采用单一机制对所有类型的介质、协议层进行检测，实现全网统一的检测机制。其检测原理是在两个系统间建立BFD会话，并沿它们之间的路径周期性发送BFD检测报文，如果一方在检测周期内没有收到BFD检测报文，则认为该路径发生了故障。 在PIM中的应用：在组播的应用中，如果共享网段上的当前DR或Assert winner发生故障，其他PIM邻居会等到邻居关系超时或Assert timer超时才触发新一轮的DR竞选或Assert竞选过程，导致组播数据传输中断，中断的时间将不小于邻居关系的超时时间或Assert timer超时时间，通常是秒级。 PIM BFD能够在毫秒级内检测共享网段内的链路状态，快速响应PIM邻居故障。如果配置了PIM BFD功能的接口在检测周期内没有收到当前DR或Assert winner发送的BFD检测报文，则认为当前DR或Assert winner发生故障，BFD快速把会话状态通告给RM，再由RM通告给PIM。PIM模块触发新一轮的DR竞选或Assert竞选过程，而不是等到邻居关系超时或Assert timer超时，从而缩小组播数据传输的中断时间，提高组播数据传输的可靠性。 PIM GR：滑重启GR（Graceful Restart）属于高可靠性HA（High Availability）技术的一种，实现协议重启时业务的不间断转发（Multicast Non-Stop Forwarding）能力。PIM GR是一种组播协议GR。在具有双主控板的设备上，PIM GR可以在设备进行主备倒换时实现用户组播流量的正常转发。 目前，仅PIM-SM（ASM模型）与PIM-SM（SSM模型）支持PIM GR，PIM-DM不支持PIM GR。 基本原理：PIM GR依赖于单播GR。设备进行主备倒换期间，新主控板的PIM协议需要从下游邻居重新学习PIM加入状态，同时还需要从IGMP成员主机学习加入的组成员。新主控板的PIM协议通过以上过程完成如下动作： 重新计算PIM组播路由表项。 维持下游邻居的加入状态。 更新转发平面的组播路由表项。 通过PIM GR，设备可以达到主备倒换后快速恢复新的主用主控板的PIM路由表项及刷新接口板组播转发表项的目的，从而最大限度地减少主备倒换对用户组播流量转发的影响。 工作机制：PIM GR建立在单播GR的基础上，整个PIM GR的过程分为三个阶段：开始阶段（GR_START）、同步阶段（GR_SYNC）和完成阶段（GR_END）。 图：PIM GR示意图 GR_START RouterA发生主备倒换，PIM协议启动GR定时器，PIM GR进入开始阶段，同时单播开始进行GR。 PIM协议向所有使能PIM-SM的接口发送携带新的Generation ID的Hello报文。 RouterA的下游邻居RouterB、RouterD发现RPF邻居的Generation ID改变，向RouterA重新发送Join/Prune报文。 若网络中使用动态RP，当网络中的邻居收到Generation ID改变的Hello报文后，向RouterA单播发送BSR报文，恢复RouterA的BSR及RP信息。 RouterA通过接收下游RouterB、RouterD发送的Join/Prune报文，在空的入接口表中创建PIM路由表项，记录下游的加入信息。 在此期间，转发模块转发表项保持不变，维持组播业务数据的转发。 GR_SYNC 单播GR结束，PIM GR进入同步阶段，根据单播路由信息建立组播分发树，恢复PIM路由表项的入接口，更新到源或到RP的加入队列，并通知组播转发模块更新转发表。 GR_END GR定时器超时，PIM协议完成GR，并通知组播转发模块。组播转发模块老化GR期间未更新的转发表项。 PIM学习笔记：Hello消息作用：PIM中的hello报文发送间隔是30s，邻居的超时时间为3.5（105s）倍的hello interval时间。 在PIM-DM网络中，刚启动的组播路由器需要使用Hello消息来发现邻居，并维护邻居关系。路由器之间周期性的发送Hello 消息来构建和维护SPT数。 Pim timer hello interval， 在接口视图下配置发送hello消息的时间间隔。hello消息默认周期是30s。 除了维护邻居关系外，Hello消息还具有一个重要的功能就是在多个路由器网段中选举DR指定路由器。DR充当IGMPv1查询器。在IGMP概述中已经提到过IGMPv1中查询器的选举路由组播协议决定。 在PIM-DM中各路由器通过比较hello消息中携带的优先级和IP地址，为多路由器网段选举指定路由器DR，充当IGMPv1的查询器。 当DR出现故障时，接收hello消息将会超时，邻居路由器之间会触发新的DR选举过程。 pim hello-opthion holdtime interval在接口视图下配置hello消息超时时间。默认情况下超时时间为105s. PIM DR的选举过程： 优先级大的。（默认为1） IP地址大的。 注：在PIM-DM模式下，DR只用于充当IGMPv1版本的查询者，没有其他用途。 RPF检测的顺序：一、优先级优先（默认）: 如果同时存在单播和组播路由（用于RPF检查的组播路由条目），比较优先级，优先级越小越优。 如果优先级一样，组播静态&gt;MBGP&gt;单播（默认情况下组播静态优先级为1，MBGP优先级为255，单播路由需要视协议而定。） 如果都是单播路由，比较路由的掩码长度，掩码查毒越长越优。 如果掩码长度一样，比较下一跳的IP地址，IP地址越大越优。 二、掩码长度优先： 如果同时存在单播和组播路由，比较掩码长度，掩码长度越长越优。 如有掩码长度一样，比较路由协议优先级，优先级越小越优。 如果优先级一样，组播静态&gt;MBGP&gt;单播。 如果都是单播路由，比较下一跳的IP地址，IP地址越大越优。 Assert:利用Assert选举出广播网中的winner和loser，winner在广播网中只能有一个，loser可以有多个。只有weinner可以装发组播流量，而loser只能被动监听winner状态，而不能发送组播流。 什么情况下才会触发assert机制？ 如果下游接口接受到自己发送的组播流，就会触发assert选举。 Assert报文中携带的内容： 包含Assert报文发送者到达组播源所使用的路由协议优先级。 包含Assert报文发送者到达组播源的距离（metric）。 包含Assert报文发送者的IP地址。 Assert的选举过程： 比较发送者到达组播路由协议的优先级，越小越优。 如果优先级一样， 比较到达组播源的距离（metric），距离越小越优。 如果metric也一样，比较报文发送者的IP地址，IP地址越大越优。 RP:在PIM-SM组播网络里，当当共享树树根的节点称为RP（Rendezovous Ponit）。 RP的作用： 共享树里所有组播流都通过RP装发到接收者。 RP可以负责几个或者所有组播组的转发，网络中可以有一个或过个RP。用户通过配置命令，可以限制RP只为IP地址在一定范围的组播组服务。一个RP可以同时为多个组播组服务，但一个组播组只能对应一个RP。所有该组成员和向该组播发送数据的组播源都向唯一的RP汇聚。 RP的发现： 静态RP：在PIM域中所有PIM路由器上逐一进行配置，静态指定RP。 static-rp rp-Address //指定静态RP的IP地址。 动态RP：在PIM域内选择几台PIM路由器，配置称为C-RP(Candidate-RP),最后从C-RP中竞选产生RP。 使用动态RP，必须同时配置C-BSR（Candidate-BootStarp Router）。由C-BSR竞选产生BSR。 RP是PIM-SM域中的核心路由器，在小型并且简单的网络中，组播信息量少，全网络仅依靠给一个RP进行信息装发即可，此时可以在SM域中个路由器上静态指定RP位置。但是更多的情况下，PIM-SM网络规模都很大，通过RP转发的组播信息量巨大，为了缓解RP的负担同时优化共享树的拓扑结构，不同组播组应该对应不同的RP，此时就需要自举机制来动态选举RP，配置自举路由器BSR（BootStrap ROuter）。 BSR：第一步：需要在组播网络中选举BSR，在组播网络中可以指定多个C—BSR（候选BSR），多个C-BSR之间需要进行比较，选举出一台BSR设备。在一个组播网络中只能有一台BSR，但可以有多台C-BSR。 BSR的选举过程： 比较优先级，优先级越大优越。（默认优先级为0） 如果优先级一样，比较IP地址，IP地址越大越优。 注：BSR只负责收集C-RP的信息，然后利用BSR报文通告到整个组播网络，最终的RP选举由叶路由器决定。 RP的选举过程： 比较C-RP可以负责的组播组掩码长度，掩码长度越长越优。 如果组播掩码长度一致，比较C-RP的优先级，优先级越小越优。（默认优先级为0） 如果优先级也一样，比较HASH值，hash值越大越优。 HASH值的计算涉及：组地址、Hash Mask（由BSR通告）、C-RP地址。 ​ PIM（IPv4）配置命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157display pim grafts//anycast-rp//来配置Anycast RP，并进入Anycast-RP视图auto-rp listening enable//使能Auto-RP侦听功能，即路由器能够接收Auto-RP宣告和发现报文，从中学习RP信息。bsm semantic fragmentation//使能BSR报文分片功能。bsr-policy//限定合法BSR地址范围，使路由器丢弃来自该地址范围之外的自举报文，从而防止BSR欺骗。c-bsr//配置C-BSR。c-bsr admin-scope//使能路由器的BSR管理域功能。c-bsr global//配置路由器为Global域中的C-BSR。c-bsr group//配置C-BSR服务的管理域组地址范围。c-bsr hash-length 30//配置C-BSR的全局性哈希掩码长度。c-bsr holdtime 130//配置C-BSR等待接收BSR发送的Bootstrap报文的超时时间。c-bsr interval 60//来配置BSR发送Bootstrap报文的时间间隔。c-bsr priority 0//配置C-BSR的全局优先级。c-rp//配置路由器向BSR通告自己为候选RP。c-rp advertisement-interval 60//配置C-RP周期性发送Advertisement报文的时间间隔。c-rp holdtime 150//配置BSR等待接收该C-RP发送Advertisement报文的超时时间。c-rp priority 0//配置C-RP的全局性优先级。crp-policy//限定合法的C-RP地址范围及其服务的组播组地址范围，使//BSR丢弃来自该地址范围之外的C-RP报文，从而防止C-RP欺骗。display pim bsr-info//查看PIM-SM域中BSR自举路由器的信息。display pim claimed-route//查看PIM使用的单播路由信息。display pim grafts//查看未确认的PIM-DM嫁接报文。display pim interface//查看接口上的PIM信息。display pim neighbor//查看PIM邻居信息。display pim routing-table//查看PIM协议组播路由表的内容。display pim rp-info//查看组播组对应的RP信息。graceful-restart//使能PIM GR功能。graceful-restart period 120//配置PIM GR的最小周期。//缺省情况下，PIM GR最小周期为120秒。hello-option dr-priority 1//配置路由器竞选成为DR（Designated Router）的优先级。hello-option holdtime 105//配置路由器等待接收其PIM邻居发送Hello报文的超时时间。//缺省情况下，路由器等待接收其PIM邻居发送Hello报文的超时时间是105秒。hello-option lan-delay 500//配置共享网段上传输Prune报文的延迟时间。//缺省情况下，共享网段上传输Prune报文的延迟时间是500毫秒。hello-option neighbor-tracking//使能邻居跟踪功能。hello-option override-interval 2500//配置Hello报文中携带的否决剪枝的时间间隔。//缺省情况下，Hello报文中携带的否决剪枝的时间间隔是2500毫秒。holdtime assert 180//配置路由器上所有PIM接口保持Assert状态的超时时间。//缺省情况下，路由器上所有PIM接口保持Assert状态的超时时间是180秒。holdtime join-prune 210/* 配置Join/Prune报文的保持时间。接收到Join/Prune报 文的路由器依据该报文自身携带的保持时间来确定对应下游 接口保持加入或剪枝状态的时间。 缺省情况下，Join/Prune报文的保持时间是210秒。*/join-prune max-packet-length 8100//配置PIM-SM发送的Join/Prune报文的最大长度。join-prune periodic-messages queue-size 1020//配置PIM-SM每秒发送周期性Join/Prune报文中包含的表项数目。join-prune triggered-message-cache disable//配置去使能实时触发的Join/Prune报文打包功能。local-address//配置Anycast RP本地地址。neighbor-check//使能PIM邻居检查功能。peer 10.2.2.2 fwd-msdp-sa//配置Anycast RP对等体。//fwd-msdp-sa:指定将收到的MSDP SA报文提取源组信息//后封装成注册报文向Anycast RP对等体转发。pim bfd//调整接口上的PIM BFD参数。pim bfd enable//在接口上使能PIM BFD功能。pim bsr-boundary//在接口上配置PIM-SM域的BSR边界。pim dm//在接口上使能PIM-DM。pim hello-option dr-priority//配置PIM接口竞选成为DR的优先级。pim hello-option holdtime 105//配置PIM接口等待接收PIM邻居发送Hello报文的超时时间。 pim holdtime assert180 //配置PIM接口保持Assert状态的超时时间。 pim neighbor-policy //用来过滤接口上的PIM邻居。 pim require-genid //配置PIM接口拒绝无Generation ID参数的Hello报文。 //缺省情况下，PIM接口接收无Generation ID参数的Hello报文。 pim silent //在接口上使能PIM Silent功能。 /* 为了避免恶意主机模拟PIM Hello报文攻击路由器，可 以在直连用户的接口上执行pim silent命令，将接口设 置为PIM消极模式。接口进入消极状态后，禁止接收和转 发任何PIM协议报文，删除该接口上的所有PIM邻居以及 PIM状态机，并自动成为DR。同时，该接口上的IGMP功 能不受影响。 PIM silent仅适用于与用户主机网段直连的接口，且 网段上只能连接一台PIM路由器。*/pim sm//在接口上使能PIM-SM。pim state-refresh-capable//在接口上使能PIM-DM状态刷新。//缺省情况下，PIM-DM状态刷新功能已使能。pim timer dr-switch-delay//在接口上使能PIM DR切换延迟功能 pim timer graft-retry 3//在接口上配置重传嫁接（Graft）报文的时间间隔。 pim timer hello 30//在接口上配置发送Hello报文的时间间隔。 probe-interval 5//配置路由器向RP发送Probe报文（空注册报文）的时间间隔。register-header-checksum//配置仅根据Register注册报文头信息来计算校验和。register-source//指定源DR发送注册报文的源地址。register-suppression-timeout 60//来配置路由器保持注册抑制状态的超时时间。source-lifetime 210//配置路由器上（S，G）或者（*，G）表项的超时时间。spt-switch-threshold //设置组成员端DR加入SPT的组播报文速率阈值。//缺省情况下，从RPT收到第一个组播数据包后立即进行SPT切换。state-refresh-interval60//配置路由器发送PIM状态刷新报文（State-Refresh）的时间间隔。state-refresh-rate-limit 30//配置接收下一个PIM状态刷新报文前必须经过的最小时间长度。 state-refresh-ttl 255//配置发送PIM状态刷新报文的TTL值。static-rp//配置静态RP。 timer spt-switch 15 //配置在RPT切换到SPT前检查组播数据速率是否达到阈值的时间间隔。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>组播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[组播侦听者发现协议MLD]]></title>
    <url>%2F2018%2F02%2F13%2F%E7%BB%84%E6%92%AD%E4%BE%A6%E5%90%AC%E8%80%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AEMLD%2F</url>
    <content type="text"><![CDATA[MLD简介组播侦听者发现协议MLD（Multicast Listener Discovery）是负责IPv6组播成员管理的协议，用来在IPv6成员主机和与其直接相邻的组播路由器之间建立和维护组播组成员关系。MLD通过在成员主机和组播路由器之间交互MLD报文实现组成员管理功能，MLD报文封装在IPv6报文中。 目的：出现于IPv4时代的组播技术，有效解决了单点发送、多点接收的问题，实现了网络中点到多点的高效数据传送，能够大量节约网络带宽、降低网络负载。在IPv6网络中，组播技术的应用得到了进一步的丰富和加强。MLD可以理解为IGMP的IPv6版本，两者的协议行为完全相同，区别仅仅在于报文格式。 原理描述MLD版本：到目前为止，MLD有两个版本： MLDv1版本（由RFC 2710定义），对应IGMPv2。 MLDv2版本（由RFC 3810定义），对应IGMPv3。 MLDv1的工作机制与IGMPv2相同，基于查询和响应机制完成对IPv6组播组成员的管理。MLDv2在MLDv1的基础上，增加的主要功能是成员主机可以指定接收或不接收某些组播源的报文。MLD两个版本在演进过程中对协议报文的处理是向前兼容的，即运行MLDv2的组播路由器可以识别MLDv1的协议报文。 所有MLD版本都支持ASM（Any-Source Multicast）模型。MLDv2可以直接应用于SSM（Source-Specific Multicast）模型，而MLDv1则需要MLD SSM Mapping技术的支持才可以应用于SSM模型。 MLDv1工作原理：MLDv1的工作机制与IGMPv2相同，定义了查询器选举机制、普遍组查询和响应机制、新组成员加入机制以及离开组机制。 MLD查询器周期性地向本网段内所有主机和组播路由器发送普遍组查询报文，通过成员主机反馈的报告报文来维护组成员关系；当MLD查询器收到成员主机发送的针对某组的离开报文时，会发送特定组查询报文来了解网段内是否还存在该组的成员，如果没有则删除对应的组成员关系。MLD查询器根据组成员关系来决定是否将对应组的组播数据报文转发到该网段。 MLDv1报文：MLDv1包括四种类型的报文： 普遍组查询报文（General Query）：查询器向共享网络上所有主机和路由器发送的查询报文，用于了解哪些组播组存在成员。 特定组查询报文（Multicast Address Specific Query）：查询器向共享网段内指定组播组发送的查询报文，用于查询该组播组是否存在成员。 成员报告报文（Multicast Listener Report）：主机向查询器发送的报告报文，用于申请加入某个组播组或者应答查询报文。 成员离开报文（Multicast Listener Done）：主机离开组播组时主动向查询器发送的报文，用于宣告自己离开了某个组播组。 图：MLDv1报文格式 字段解释说明： 字段 说明 Type 报文类型。该字段有以下三种取值：130：表示查询报文。包括普遍组查询报文和特定组查询报文两类。131：表示成员报告报文。132：表示成员离开报文。 Code 该字段在发送时被设为0，并在接收时被忽略。 Checksum 标准的ICMPv6校验和。 Maximum Response Delay 最大响应时间。成员主机在收到MLD查询器发送的普遍组查询报文后，需要在最大响应时间内做出回应。该字段仅在MLD查询报文中有效。 Reserved 保留字段。 Multicast Address 组播组地址。 MLDv1工作机制：查询器选举机制 当一个网段内有多台IPv6组播路由器时，由于它们都可以接收到主机发送的报告报文，因此只需要选取其中一台组播路由器发送查询报文就足够了，该组播路由器称为MLD查询器（Querier）。 图：查询器选举示意图 如上图所示，查询器的选举过程如下： 最初，所有运行MLD的组播路由器（RouterA和RouterB）都认为自己是查询器，向本网段内的所有主机和组播路由器发送普遍组查询报文。 RouterA和RouterB在收到对方发送的普遍组查询报文后，将报文的源IPv6地址与自己的接口地址作比较。通过比较，IPv6地址最小的组播路由器将成为查询器，其他组播路由器成为非查询器（Non-Querier）。如上图所示，RouterA的接口地址小于RouterB，则RouterA当选为查询器，RouterB为非查询器。 此后，由MLD查询器（RouterA）向本网段内的所有主机和其他组播路由器发送普遍组查询报文，而非查询器（RouterB）不再发送普遍组查询报文。 非查询器（RouterB）上都会启动一个定时器（即其他查询器存在时间定时器Other Querier Present Timer）。在该定时器超时前，如果收到了来自查询器的查询报文，则重置该定时器；否则，就认为原查询器失效，并发起新的查询器选举过程。 普遍组查询和响应机制 通过普遍组查询和响应，MLD查询器可以了解到该网段内哪些组播组存在成员。 图：普遍组查询和响应示意图 如上图所示，普遍组查询和响应过程如下： MLD查询器发送目的地址为FF02::1（表示同一网段内所有主机和路由器）的普遍组查询报文；收到该查询报文的组成员启动定时器。 普遍组查询报文是周期性发送的，发送周期可以通过命令配置，缺省情况下每隔125秒发送一次。HostA和HostB是组播组G1的成员，则在本地启动定时器Timer-G1。缺省情况下，定时器的范围为0～10秒之间的随机值。 第一个定时器超时的组成员发送针对该组的报告报文。 假设HostA上的Timer-G1首先超时，HostA向该网段发送目的地址为G1的报告报文。HostB收到此报告报文，则停止定时器Timer-G1，不再发送针对G1的报告报文。这样报告报文被抑制，可以减少网段上的MLD报文的数量。 MLD查询器接收到HostA的报告报文后，了解到本网段内存在组播组G1的成员，则由IPv6组播路由协议生成（ ，G1）组播转发表项，“”代表任意IPv6组播源。网络中一旦有组播组G1的数据到达路由器，将向该网段转发。 新成员加入机制 共享网段内有新组成员需要加入组播组时，会主动向MLD查询器发送报告报文，而不必等待普遍组查询报文的到来。 离开组机制 通过离开组机制，MLD查询器可以及时了解到网段内哪些组播组已不存在成员，从而及时更新组成员关系，减少网络中冗余的组播流量。 离开过程如下： HostA向本地网段内的所有组播路由器（目的地址为FF02::2）发送针对组G1的离开报文（Done）。 查询器收到离开报文，会发送针对组G1的特定组查询报文。发送间隔和发送次数可以通过命令配置，缺省情况下每隔1秒发送一次，共发送两次。同时查询器启动组成员关系定时器（Timer-Membership = 发送间隔 × 发送次数）。 该网段内还存在组G1的其他成员（HostB），这些成员在收到查询器发送的特定组查询报文后，会立即发送针对组G1的报告报文。查询器收到针对组G1的报告报文后将继续维护该组成员关系。 如果该网段内不存在组G1的其他成员，查询器将不会收到针对组G1的报告报文。在Timer-Membership超时后，查询器将删除记录的（*，G1）组信息。当有组G1的组播数据到达查询器时，查询器将不会向下游转发。 MLDv2工作原理：MLDv1报文中只能携带组播组的信息，不能携带组播源的信息，这样运行MLDv1的成员主机在加入组时无法选择加入哪个指定源的组。MLDv2解决了这个问题。运行MLDv2的成员主机不仅能够选择组播组，还能够根据需要选择接收哪些组播源的数据。同时，与MLDv1的成员报告只能携带一个组播组信息相比，MLDv2报文可以携带多个组播组信息，这就大大减少了成员主机与查询器之间交互的报文数量。 MLDv2报文：与MLDv1相比，MLDv2报文的变化如下： MLDv2报文包含两大类：查询报文和成员报告报文。MLDv2没有定义专门的成员离开报文，成员离开通过特定类型的报告报文来传达。 查询报文中不仅包含普遍组查询报文和特定组查询报文，还新增了特定源组查询报文（Multicast Address and Source Specific Query）。该报文由查询器向共享网段内特定组播组成员发送，用于查询该组成员是否愿意接收特定源发送的数据。特定源组查询通过在报文中携带一个或多个组播源地址来达到这一目的。 成员报告报文不仅包含主机想要加入的组播组，而且包含主机想要接收来自哪些组播源的数据。MLDv2增加了针对组播源的过滤模式（INCLUDE/EXCLUDE），将组播组与源列表之间的对应关系简单的表示为（G，INCLUDE，(S1、S2…)），表示只接收来自指定组播源S1、S2…发往组G的数据；或（G，EXCLUDE，(S1、S2…)），表示接收除了组播源S1、S2…之外的组播源发给组G的数据。当组播组与组播源列表的对应关系发生了变化，MLDv2报告报文会将该关系变化存放于组播地址记录（Multicast Address Record）字段，发送给MLD查询器。 图：MLDv2报文格式 Type:报文类型。取值为130，表示查询报文。MLDv2的查询报文包括普遍组查询报文、特定组查询报文和特定源组查询报文三类。 S: 该比特位为1时，所有收到此查询报文的其他路由器不启动定时器刷新过程，但是此查询报文并不抑制查询器选举过程和路由器的主机侧处理过程。 QRV: 如果该字段非0，则表示查询器的健壮系数（Robustness Variable）。如果该字段为0，则表示查询器的健壮系数大于7。路由器接收到查询报文时，如果发现该字段非0，则将自己的健壮系数调整为该字段的值；如果发现该字段为0，则不做处理。 QQIC: MLD查询器的查询间隔，单位为秒。非查询器收到查询报文时，如果发现该字段非0，则将自己的查询间隔参数调整为该字段的值；如果发现该字段为0，则不做处理。 MLDv2工作机制：在工作机制上，与MLDv1相比，MLDv2增加了主机对组播源的选择能力。 特定源组加入 MLDv2的成员报告报文的目的地址为FF02::16（表示本地网段内所有使能MLDv2的路由器）。通过在报告报文中携带组播地址记录，主机在加入组播组的同时，能够明确要求接收或不接收特定组播源发出的组播数据。 MLD SSM Mapping：SSM（Source-Specific Multicast）称为指定源组播，要求路由器能了解成员主机加入组播组时所指定的组播源。如果成员主机上运行MLDv2，可以在MLDv2报告报文中直接指定组播源地址。但是某些情况下，成员主机只能运行MLDv1，为了使其也能够使用SSM服务，组播路由器上需要提供MLD SSM Mapping功能。 MLD SSM Mapping的机制是：通过在组播路由器上静态配置SSM地址的映射规则，将MLDv1报告报文中的（*，G）信息转化为对应的（G，INCLUDE，（S1，S2…））信息，以提供SSM组播服务。 MLD命令行配置1234567891011121314151617181920mld enable//在接口上使能MLD功能。mld lastlistener-queryinterval 1//在接口上配置MLD查询器在收到成员主机发送的离开报文时，//发送特定组\源组查询报文的时间间隔。mld limit//当前接口可以维护MLD组成员关系的最大个数。mld max-response-time//接口上配置MLD普遍组查询报文的最大响应时间。mld prompt-leave//在接口上配置组播组成员快速离开功能mld require-router-alert//配置丢弃不包含Router-Alert选项的MLD报文mld send-router-alert//设置接口上发送的MLD报文在IPv6报文头里包含Router-Alert选项。//缺省情况下，设备接口上发送包含Router-Alert选项的MLD报文。mld ssm-mapping enable//在接口上使能MLD SSM Mapping功能。mld timer query 125//配置MLD普遍组查询报文的发送时间间隔。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>组播</tag>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IGMP基础]]></title>
    <url>%2F2018%2F02%2F12%2FIGMP%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[IGMP简介IGMP是Internet Group Management Protocol的简称，又被称为互联网组管理协议，是TCP/IP协议族中负责IPv4组播成员管理的协议。IGMP用来在接收者主机和与其直接相邻的组播路由器之间建立和维护组播组成员关系。IGMP通过在接收者主机和组播路由器之间交互IGMP报文实现组成员管理功能，IGMP报文封装在IP报文中。 目的：IP组播通信的特点是报文从一个源发出，被转发到一组特定的接收者。但在组播通信模型中，发送者不关注接收者的位置信息，只是将数据发送到约定的目的组播地址。要使组播报文最终能够到达接收者，需要某种机制使连接接收者网段的组播路由器能够了解到该网段存在哪些组播接收者，同时保证接收者可以加入相应的组播组中。IGMP就是用来在接收者主机和与其所在网段直接相邻的组播路由器之间建立、维护组播组成员关系的协议。 IGMPv1工作原理ICMPv1报文：IGMPv1包括两种类型的报文： 普遍组查询报文（General Query）：查询器向共享网络上所有主机和路由器发送的查询报文，用于了解哪些组播组存在成员。 成员报告报文（Report）：主机向查询器发送的报告报文，用于申请加入某个组播组或者应答查询报文。 图：IGMPv1报文格式 字段 说明 Version IGMP版本，值为1。 Type 报文类型。该字段有以下两种取值：0x11：表示普遍组查询报文。0x12：表示成员报告报文。 Unused 在IGMPv1中，该字段在发送时被设为0，并在接收时被忽略。 Checksum IGMP报文的校验和。校验和是IGMP报文长度（即IP报文的整个有效负载）的16位检测，表示IGMP信息补码之和的补码。Checksum字段在进行校验计算时设为0。当发送报文时，必须计算校验和并插入到Checksum字段中去。当接收报文时，校验和必须在处理该报文之前进行检验。 Group Address 组播组地址。在普遍组查询报文中，该字段设为0；在成员报告报文中，该字段为成员加入的组播组地址。 IGMPv1报文抓包示例： 图：IGMPv1报文实例 IGMPv1工作机制：IGMPv1协议主要基于查询和响应机制完成组播组管理。当一个网段内有多个组播路由器时，由于它们都可以接收到主机发送的成员报告报文，因此只需要选取其中一台组播路由器发送查询报文就足够了，该组播路由器称为IGMP查询器（Querier）。在IGMPv1中，由组播路由协议PIM选举出唯一的组播信息转发者（Assert Winner或DR）作为IGMPv1的查询器，负责该网段的组成员关系查询。 IGMPv1的工作机制可以分为：普遍组查询和响应机制、新成员加入机制和组成员离开机制三个方面。 普遍组查询和响应机制：通过普遍组查询和响应，IGMP查询器可以了解到该网段内哪些组播组存在成员。 图：IGMPv1查询和响应示意图 如上图所示，普遍组查询和响应过程如下： IGMP查询器发送目的地址为224.0.0.1（表示同一网段内所有主机和路由器）的普遍组查询报文；收到该查询报文的组成员启动定时器。 普遍组查询报文是周期性发送的，发送周期可以通过命令配置，缺省情况下每隔60秒发送一次。HostA和HostB是组播组G1的成员，则在本地启动定时器Timer-G1。缺省情况下，定时器的范围为0～10秒之间的随机值。 图：IGMPv1普遍组查询报文 如上图，为v1的查询报文，类型为0x11,目的IP地址为224.0.0.1。源IP地址为自己接口的IP地址。在组播地址中，填充为0.0.0.0。 第一个定时器超时的组成员发送针对该组的报告报文。 假设HostA上的Timer-G1首先超时，HostA向该网段发送目的地址为G1的报告报文。也想加入组G1的HostB收到此报告报文，则停止定时器Timer-G1，不再发送针对G1的报告报文。这样报告报文被抑制，可以减少网段上的流量。 图：IGMPv1报告报文抓包示例 如上图，为主机向路由器发送的报告报文，类型值为0x12，源IP地址为自己主机的IP地址，目的IP地址为组播地址。 IGMP查询器接收到HostA的报告报文后，了解到本网段内存在组播组G1的成员，则由组播路由协议生成（，G1）组播转发表项，“ ”代表任意组播源。网络中一旦有组播组G1的数据到达路由器，将向该网段转发。 新组成员加入机制： 图：新组成员加入示意图 如上图所示，主机HostC加入组播组G2的过程如下： 主机HostC不等待普遍组查询报文的到来，主动发送针对G2的报告报文以声明加入。 IGMP查询器接收到HostC的报告报文后，了解到本网段内出现了组播组G2的成员，则生成组播转发项（*，G2）。网络中一旦有G2的数据到达路由器，将向该网段转发。 组成员离开机制：IGMPv1没有专门定义离开组的报文。主机离开组播组后，便不会再对普遍组查询报文做出回应。 假设HostA想要退出组播组G1 HostA收到IGMP查询器发送的普遍组查询报文时，不再发送针对G1的报告报文。由于网段内还存在G1组成员HostB，HostB会向IGMP查询器发送针对G1的报告报文，因此IGMP查询器感知不到HostA的离开。 假设HostC想要退出组播组G2 HostC收到IGMP查询器发送的普遍组查询报文时，不再发送针对G2的报告报文。由于网段内不存在组G2的其他成员，IGMP查询器不会收到G2组成员的报告报文，则在一定时间（缺省值为130秒）后，删除G2所对应的组播转发表项。 IGMPv2工作原理IGMPv2的工作机制与IGMPv1基本相同，最大的不同之处在于IGMPv2增加了离开组机制。成员主机离开组播组时，会主动发送成员离开报文通知IGMP查询器；IGMP查询器收到成员离开报文后，会连续发送特定组查询报文，询问该组播组是否还存在组成员。如果在一段时间内没有收到成员主机发送的报告报文，IGMP查询器将不再维护该组的组成员关系。IGMPv2可以使IGMP查询器及时了解到网段内哪些组播组已不存在成员，从而及时更新组成员关系，减少网络中冗余的组播流量。 IGMPv2报文：与IGMPv1相比，IGMPv2的变化如下： 除了普遍组查询报文和成员报告报文之外，IGMPv2新增了两种报文： 成员离开报文（Leave）：成员离开组播组时主动向查询器发送的报文，用于宣告自己离开了某个组播组。 特定组查询报文（Group-Specific Query）：查询器向共享网段内指定组播组发送的查询报文，用于查询该组播组是否存在成员。 IGMPv2对普遍组查询报文格式也做了改进，添加了最大响应时间（Max Response Time）字段。此字段取值可以通过命令配置，用于控制成员对于查询报文的响应速度。 图：IGMPv2报文格式 字段解释： Type：报文类型。该字段有以下四种取值： 0x11:表示查询报文。IGMPv2的查询报文包括普遍组查询报文和特定组查询报文两类。 0x12:表示IGMPv1成员报告报文。 0x16:表示IGMPv2成员报告报文。 0x17:表示成员离开报文。 Max Response Time：最大响应时间。 成员主机在收到IGMP查询器发送的普遍组查询报文后，需要在最大响应时间内做出回应。该字段仅在IGMP查询报文中有效。 Group Address：组播组地址。 在普遍组查询报文中，该字段设为0.0.0.0。 在特定组查询报文中，该字段为要查询的组播组地址。 在成员报告报文和离开报文中，该字段为成员要加入或离开的组播组地址。 IGMPv2报文抓包示例： 图：IGMPv2查询报文 IGMPv2工作机制：在工作机制上，与IGMPv1相比，IGMPv2增加了查询器选举和离开组机制。 查询器选举机制：IGMPv2使用独立的查询器选举机制，当共享网段上存在多个组播路由器时，IP地址最小的路由器成为查询器。 图：查询器选举机制 如上图所示，在IGMPv2中，查询器的选举过程如下： 最初，所有运行IGMPv2的组播路由器（RouterA和RouterB）都认为自己是查询器，向本网段内的所有主机和组播路由器发送普遍组查询报文。 RouterA和RouterB在收到对方发送的普遍组查询报文后，将报文的源IP地址与自己的接口地址作比较。通过比较，IP地址最小的组播路由器将成为查询器，其他组播路由器成为非查询器（Non-Querier）。 图：V2查询报文示例 图：IGMPv2报告报文 此后，将由IGMP查询器（RouterA）向本网段内的所有主机和其他组播路由器发送普遍组查询报文，而非查询器（RouterB）则不再发送普遍组查询报文。 非查询器（RouterB）上都会启动一个定时器（即其他查询器存在时间定时器Other Querier Present Timer）。在该定时器超时前，如果收到了来自查询器的查询报文，则重置该定时器；否则，就认为原查询器失效，并发起新的查询器选举过程。 离开组机制： 图：离开组示意图 如上图所示，在IGMPv2中，主机HostA离开组播组G1的过程如下： HostA向本地网段内的所有组播路由器（目的地址为224.0.0.2）发送针对组G1的离开报文。 查询器收到离开报文，会发送针对组G1的特定组查询报文。发送间隔和发送次数可以通过命令配置，缺省情况下每隔1秒发送一次，共发送两次。同时查询器启动组成员关系定时器（Timer-Membership=发送间隔x发送次数）。 该网段内还存在组G1的其他成员，这些成员在收到查询器发送的特定组查询报文后，会立即发送针对组G1的报告报文。查询器收到针对组G1的报告报文后将继续维护该组成员关系。 如果该网段内不存在组G1的其他成员，查询器将不会收到针对组G1的报告报文。在Timer-Membership超时后，查询器将删除（*，G1）对应的IGMP组表项。当有组G1的组播数据到达查询器时，查询器将不会向下游转发。 IGMPv3工作原理：IGMPv3主要是为了配合SSM（Source-Specific Multicast）模型发展起来的，提供了在报文中携带组播源信息的能力，即主机可以对组播源进行选择。 IGMPv3报文：与IGMPv2相比，IGMPv3报文的变化如下： IGMPv3报文包含两大类：查询报文和成员报告报文。IGMPv3没有定义专门的成员离开报文，成员离开通过特定类型的报告报文来传达。 查询报文中不仅包含普遍组查询报文和特定组查询报文，还新增了特定源组查询报文（Group-and-Source-Specific Query）。该报文由查询器向共享网段内特定组播组成员发送，用于查询该组成员是否愿意接收特定源发送的数据。特定源组查询通过在报文中携带一个或多个组播源地址来达到这一目的。 成员报告报文不仅包含主机想要加入的组播组，而且包含主机想要接收来自哪些组播源的数据。IGMPv3增加了针对组播源的过滤模式（INCLUDE/EXCLUDE），将组播组与源列表之间的对应关系简单的表示为（G，INCLUDE，(S1、S2…)），表示只接收来自指定组播源S1、S2……发往组G的数据；或（G，EXCLUDE，(S1、S2…)），表示接收除了组播源S1、S2……之外的组播源发给组G的数据。当组播组与组播源列表的对应关系发生了变化，IGMPv3报告报文会将该关系变化存放于组记录（Group Record）字段，发送给IGMP查询器。 在IGMPv3中一个成员报告报文可以携带多个组播组信息，而之前的版本一个成员报告只能携带一个组播组。这样在IGMPv3中报文数量大大减少。 IGMPv3查询报文格式： 图：IGMPv3查询报文格式 IGMPv3查询报文字段说明： 字段 说明 Type 报文类型，取值为0x11。 Max Response Code 最大响应时间。成员主机在收到IGMP查询器发送的普遍组查询报文后，需要在最大响应时间内做出回应。 Checksum IGMP报文的校验和。 Group Address 组播组地址。在普遍组查询报文中，该字段设为0；在特定组查询报文和特定源组查询报文中，该字段为要查询的组播组地址。 Resv 保留字段。发送报文时该字段设为0；接收报文时，对该字段不做处理。 S 该比特位为1时，所有收到此查询报文的其他路由器不启动定时器刷新过程，但是此查询报文并不抑制查询器选举过程和路由器的主机侧处理过程。 QRV 如果该字段非0，则表示查询器的健壮系数（Robustness Variable）。如果该字段为0，则表示查询器的健壮系数大于7。路由器接收到查询报文时，如果发现该字段非0，则将自己的健壮系数调整为该字段的值；如果发现该字段为0，则不做处理。 QQIC IGMP查询器的查询间隔，单位为秒。非查询器收到查询报文时，如果发现该字段非0，则将自己的查询间隔参数调整为该字段的值；如果发现该字段为0，则不做处理。 Number of Sources 报文中包含的组播源的数量。对于普遍组查询报文和特定组查询报文，该字段为0；对于特定源组查询报文，该字段非0。此参数的大小受到所在网络MTU大小的限制。 Source Address 组播源地址，其数量受到Number of Sources字段值大小的限制。 IGMPv3成员报告报文格式： 图：IGMPv3成员报告报文格式 字段解释信息： 字段 说明 Type 报文类型，取值为0x22。 Reserved 保留字段。 Checksum IGMP报文的校验和。 Number of Group Records 报文中包含的组记录的数量。 Group Record 组记录。 图：Grounp Record字段格式 字段解释： Record Type：组记录的类型。共分为三大类。 当前状态报告。用于对查询报文进行响应，通告自己目前的状态，共两种：一种是MODE_IS_INCLUDE，表示接收源地址列表包含的源发往该组的组播数据。如果指定源地址列表为空，该报文无效；另一种是MODE_IS_EXCLUDE，表示不接收源地址列表包含的源发往该组的组播数据。 过滤模式改变报告。当组和源的关系在INCLUDE和EXCLUDE之间切换时，会通告过滤模式发生变化，共两种：一种是CHANGE_TO_INCLUDE_MODE，表示过滤模式由EXCLUDE转换到INCLUDE，接收源地址列表包含的新组播源发往该组播组的数据。如果指定源地址列表为空，主机将离开组播组；另一种是CHANGE_TO_EXCLUDE_MODE，表示过滤模式由INCLUDE转换到EXCLUDE，拒绝源地址列表包含的新组播源发往该组的组播数据。 源列表改变报告。当指定源发生改变时，会通告源列表发生变化，共两种：一种是ALLOW_NEW_SOURCES，表示在现有的基础上，需要接收源地址列表包含的组播源发往该组播组的组播数据。如果当前对应关系为INCLUDE，则向现有源列表中添加这些组播源；如果当前对应关系为EXCLUDE，则从现有阻塞源列表中删除这些组播源；另一种是BLOCK_OLD_SOURCES，表示在现有的基础上，不再接收源地址列表包含的组播源发往该组播组的组播数据。如果当前对应关系为INCLUDE，则从现有源列表中删除这些组播源；如果当前对应关系为EXCLUDE，则向现有源列表中添加这些组播源。 Aux Data Len：辅助数据长度。在IGMPv3的报告报文中，不存在辅助数据字段，该字段设为0。 Number of Sources：本记录中包含的源地址数量。 Multicast Address：组播组地址。 Sources Address：组播源地址。 Auxiliary Data：辅助数据。预留给IGMP后续扩展或后续版本。在IGMPv3的报告报文中，不存在辅助数据。 IGMPv3报文抓包示例: 图：IGMPv3报告报文示例 图：IGMPv3查询报文 IGMPv3工作机制：在工作机制上，与IGMPv2相比，IGMPv3增加了主机对组播源的选择能力。 特定组的加入：IGMPv3的成员报告报文的目的地址为224.0.0.22（表示同一网段所有使能IGMPv3的路由器）。通过在报告报文中携带组记录，主机在加入组播组的同时，能够明确要求接收或不接收特定组播源发出的组播数据。 如果Host和组播路由器之间运行的是IGMPv1或IGMPv2，Host加入组播组G时无法对组播源进行选择，无论其是否需要，都会同时接收到来自组播源S1和S2的数据。如果采用IGMPv3，成员主机可以选择仅接收S1组播数据。 方法一：Host发送IGMPv3报告（G，INCLUDE，(S1)），仅接收源S1向组播组G发送的数据。 方法二：Host发送IGMPv3报告（G，EXCLUDE，(S2)），不接收指定源S2向组播组G发送的数据，从而仅有来自S1的组播数据才能传递到Host。 特定组查询：当接收到组成员发送的改变组播组与源列表的对应关系的报告时（比如CHANGE_TO_INCLUDE_MODE、CHANGE_TO_EXCLUDE_MODE），IGMP查询器会发送特定源组查询报文。如果组成员希望接收其中任意一个源的组播数据，将反馈报告报文。IGMP查询器根据反馈的组成员报告更新该组对应的源列表。 IGMP各版本对比IGMPv1中定义了基本的组成员查询和报告过程，IGMPv2在此基础上添加了查询器选举和组成员离开的机制，IGMPv3中增加的主要功能是成员可以指定接收或指定不接收某些组播源的报文。三个版本在演进过程中对协议报文的处理是向前兼容的，因此尽管各个版本的协议报文格式不同，但是运行IGMP高版本的路由器可以识别低版本的IGMP报文。 所有IGMP版本都支持ASM（Any-Source Multicast）模型。IGMPv3可以直接应用于SSM（Source-Specific Multicast）模型，而IGMPv1和IGMPv2则需要IGMP SSM Mapping技术的支持才可以应用于SSM模型。 项目 IGMPv1 IGMPv2 IGMPv3 查询器选举方式 依靠组播路由协议PIM选举 同网段组播路由器之间竞争选举 同网段组播路由器之间竞争选举 普遍组查询报文 支持 支持 支持 成员报告报文 支持 支持 支持 特定组查询报文 不支持 支持 支持 成员离开报文 不支持 支持 没有定义专门的成员离开报文，成员离开通过特定类型的报告报文来传达 特定源组查询报文 不支持 不支持 支持 指定组播源 不支持 不支持 支持 可识别报文协议版本 IGMPv1 IGMPv1、IGMPv2 IGMPv1、IGMPv2、IGMPv3 ASM模型 支持 支持 支持 SSM模型 需要IGMP SSM Mapping技术支持 需要IGMP SSM Mapping技术支持 支持 IGMP SSM MappingSSM（Source-Specific Multicast）称为指定源组播，要求路由器能了解成员主机加入组播组时所指定的组播源。如果成员主机上运行IGMPv3，可以在IGMPv3报告报文中直接指定组播源地址。但是某些情况下，成员主机只能运行IGMPv1或IGMPv2，为了使其也能够使用SSM服务，路由器上需要提供IGMP SSM Mapping功能。 IGMP SSM Mapping的机制是：通过在路由器上静态配置SSM地址的映射规则，将IGMPv1和IGMPv2报告报文中的(*, G)信息转化为对应的(G, INCLUDE, (S1, S2…))信息，以提供SSM组播服务。 如果G在ASM（Any-Source Multicast）范围内，则只提供ASM服务。 如果G在SSM组地址范围内（缺省情况下为232.0.0.0～232.255.255.255）： 如果路由器上没有G对应的SSM Mapping规则，则无法提供SSM服务，丢弃该报文。 如果路由器上有G对应的SSM Mapping规则，则依据规则将报告报文中所包含的(*, G)信息映射为(G, INCLUDE, (S1, S2…))信息，提供SSM服务。 IGMP ProxyIGMP Proxy，也称为IGMP代理，通常被部署在接入设备（RouterA）和成员主机之间的三层设备上，IGMP Proxy设备可以收集下游成员主机的IGMP报告/离开报文，将报告/离开报文汇聚后代理下游成员主机统一上送给接入设备；另一方面，IGMP Proxy设备也可以代理IGMP查询器向下游成员主机发送查询报文，维护组成员关系，基于组成员关系进行组播转发。在接入设备RouterA看来，RouterB就是一台主机；在下游成员主机看来，RouterB就是IGMP查询器。 上游接口：指IGMP代理设备上配置IGMP Proxy功能的接口，该接口执行IGMP代理设备的主机行为，因此也称为主机接口（Host Interface）。 下游接口：指IGMP代理设备上配置IGMP功能的接口，该接口执行IGMP代理设备的路由器行为，因此也称为路由器接口（Router Interface）。 IGMP Proxy工作机制:IGMP代理设备实现的功能主要分为两种：主机行为和路由器行为。 主机行为 主机行为是指IGMP代理设备的上游接口收到查询报文时根据当前组播转发表的状态对查询报文做出响应，或者当组播转发表发生变化时上游接口主动向接入设备发送报告/离开报文。主机行为的工作机制如下： IGMP代理设备上游接口收到查询报文时，会根据当前组播转发表的状态对查询报文做出响应。 IGMP代理设备收到某组播组的报告报文后，会在组播转发表中查找该组播组： 如果没有找到相应的组播组，IGMP代理设备会向接入设备发送针对该组播组的报告报文，并在组播转发表中添加该组播组； 如果找到相应的组播组，IGMP代理设备就不需要向接入设备发送报告报文。 IGMP代理设备收到某组播组G的离开报文后，会向接收到该离开报文的接口发送一个特定组查询报文，检查该接口下是否还存在组播组G的其他成员： 如果没有其他成员，IGMP代理设备会向接入设备发送针对该组播组的离开报文，并在组播转发表中将对应的接口删除； 如果有其他成员，IGMP代理设备会继续向该接口转发组播数据。 路由器行为 路由器行为是指IGMP代理设备的下游接口通过成员主机加入/离开组播组的信息生成组播转发表项、接收接入设备下发的组播数据并根据组播转发表项的出接口信息向特定的接口转发组播数据。 IGMP Proxy备份机制：为了提高链路的可靠性，IGMP代理设备的上游接口配置完IGMP Proxy功能后，可以再在IGMP代理设备上配置一个IGMPProxy备份接口，作为上游接口的备份，如下图所示。这样，当上游接口所在链路发生故障时，备份链路会自动接管IGMP代理业务，使业务能够自动恢复。 图：IGMP Proxy备份机制 IGMP Proxy本身并没有检测机制，如果组播链路发生了故障，无法保证及时进行主、备链路的切换，可能造成较长时间的组播业务中断。通过IGMP Proxy与NQA联动可以解决此问题。IGMP Proxy与NQA测试例联动是利用NQA测试例检测端到端的链路状态，并根据NQA测试例的检测结果，进行主、备链路的切换，从而避免通信长时间中断。 IGMP常用命令行12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091接口上设置其他IGMP查询器的存活时间。display igmp explicit-tracking//查看使用Include模式加入特定源组的IGMPv3主机信息。display igmp group//查看通过主机发送报告报文动态加入的IGMP组播组信息。display igmp group ssm-mapping//查看根据SSM Mapping规则创建的组播组信息。display igmp group static//查看IGMP静态组播组的配置信息。display igmp routing-table//查看IGMP路由表信息。display igmp ssm-mapping//查看IGMP SSM Mapping的配置信息。igmp//进入IGMP视图。igmp enable//在接口上使能IGMP功能。igmp global limit//配置整个路由器上可以创建的所有IGMP表项的最大个数。igmp group-policy//在接口上设置IGMP组播组的过滤器，限制主机能够加入的组播组范围。igmp ip-source-policy//配置设备根据源地址对IGMP报告/离开报文进行过滤。igmp lastmember-queryinterval interval//在接口上配置IGMP查询器在收到主机发送的IGMP离开报文时，//发送IGMP特定组\源组查询报文的时间间隔。//缺省情况下，IGMP特定组\源组查询报文的发送时间间隔是1秒。igmp max-response-time 10//在接口上配置IGMP普遍组查询报文的最大响应时间。//缺省情况下，IGMP普遍组查询报文的最大响应时间是10秒。igmp on-demand/* 配置IGMP On-Demand功能. 使查询器不主动发送查询报文，而是根据成员的要求来维护 成员关系。配置IGMP On-Demand功能后，接口上动态加 入的组播组永不超时。*/igmp prompt-leave//在接口上配置组播组成员快速离开功能，//即IGMP查询器在接收到成员主机发送的离开报文后不发送//特定组查询报文，立即删除该组表项。igmp proxy//在接口上使能IGMP Proxy功能。igmp proxy backup//配置接口成为具有IGMP Proxy功能的备份接口。igmp query ip-source-policy//配置IGMP查询报文源地址过滤策略。igmp send-router-alert//在接口上配置发送的IGMP报文中包含Router-Alert选项。igmp require-router-alert//在接口上配置丢弃不包含Router-Alert选项的IGMP报文。igmp robust-count 2//在接口上设置IGMP查询器的健壮系数。//缺省情况下，IGMP查询器的健壮系数是2。igmp ssm-mapping enable//在接口上使能SSM Mapping。igmp static-group//在接口上配置静态组播组。igmp timer other-querier-present//接口上设置其他IGMP查询器的存活时间。//缺省时，其他IGMP查询器的存活时间的值为125秒。//其他IGMP查询器的存活时间 ＝ 健壮系数 × IGMP普遍查询报文发送间隔 +（1/2）× 最大查询响应时间。igmp timer query 60//在接口上配置IGMP普遍组查询报文的发送间隔。igmp version//在接口上配置运行的IGMP版本。lastmember-queryinterval 1//配置IGMP查询器在收到主机发送的IGMP离开报文时，//发送IGMP特定组\源组查询报文的时间间隔。//缺省情况下，IGMP特定组\源组查询报文的发送时间间隔是1秒。max-response-time 10 //全局配置IGMP普遍组查询报文的最大响应时间。 proxy source-lifetime 210//配置Proxy设备上生成（S，G）表项的超时时间。//缺省情况下，Proxy设备上生成（S，G）表项的超时时间是210秒。require-router-alert//配置丢弃不包含Router-Alert选项的IGMP报文。reset igmp control-message counters//清除IGMP报文统计数。reset igmp explicit-tracking//删除接口上通过IGMP动态加入组播组的主机。robust-count 2//设置IGMP查询器的健壮系数。send-router-alert//指定设备发送的IGMP报文中包含Router-Alert选项。ssm-mapping//配置SSM Mapping的源组映射规则。timer other-querier-present//设置其他IGMP查询器存活时间。timer query 60//全局配置IGMP普遍组查询报文的发送间隔。 #IGMP学习笔记 查询者的作用： 查询者可以转发组播流量，通过这种方式可以避免组播流量的重复。为了保证组播可靠性，非查询者的路由器也会创建并维护组播组，同时非查询者需要监听查询者的存在，如果查询者在Hold timer时间内没有发送查询报文，非查询者会认为查询者已经故障，需要重新选举查询者。查询者会转发组播流量，同时每隔interval（60s）的时间发送查询报文。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>组播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP组播基础]]></title>
    <url>%2F2018%2F02%2F12%2FIP%E7%BB%84%E6%92%AD%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[IP组播简介作为IP传输三种方式之一，IP组播通信指的是IP报文从一个源发出，被转发到一组特定的接收者。相较于传统的单播和广播，IP组播可以有效地节约网络带宽、降低网络负载，所以被广泛应用于IPTV、实时数据传送和多媒体会议等网络业务中。 目的：传统的IP通信有两种方式：单播（Unicast）和广播（Broadcast）。 对于单播通信，信息源为每个需要信息的主机都发送一份独立的报文。 对于广播通信，信息源将信息发送给该网段中的所有主机，而不管其是否需要该信息。 如果要将数据从一台主机发送给多个主机而非所有主机，可以采用广播方式，也可以由源主机采用单播方式向网络中的多台目标主机发送多份数据。 采用单播方式时，网络中传输的信息量与需要该信息的用户量成正比。当需要该信息的用户数量较大时，信息源需要将多份内容相同的信息发送给不同的用户，这对信息源以及网络带宽都将造成巨大的压力。因此，该传输方式不利于信息的批量发送，只适用于用户稀少的网络。 采用广播方式时，不需要接收信息的主机也将收到该信息，这样不仅信息的安全性得不到保障，而且会造成同一网段中信息泛滥。因此，该传输方式不利于与特定对象进行数据交互，同时会浪费大量的带宽。 由上述可见，传统的单播和广播通信方式不能有效地解决单点发送、多点接收的问题。 组播（Multicast）可以很好的解决点到多点的数据传输，源只发送一份数据，网络中只有需要该数据的主机可以接收该数据，其他主机不能收到该数据。 组播相对单播和广播有如下优势： 相比单播，由于被传递的信息在距信息源尽可能远的网络节点才开始被复制和分发，所以用户的增加不会导致信息源负载的加重以及网络资源消耗的显著增加。 相比广播，由于被传递的信息只会发送给需要该信息的接收者，所以不会造成网络资源的浪费，并能提高信息传输的安全性。 组播的优势： 提高效率：降低网络流量、减轻硬件负荷 优化性能：减少冗余流量、节约网络带宽、降低网络负载。 分布式应用：使多点应用成为可能 组播适用于任何“点到多点”的数据发布，主要包含以下几方面： 多媒体、流媒体的应用。 培训、联合作业场合的通信。 数据仓库、金融应用（股票）。 IP组播技术在ISP提供的互联网信息服务中已经得到了应用。例如：在线直播、网络电视、远程教育、远程医疗、网络电台和实时视/音频会议等。 组播的劣势： 组播技术有效地解决了单点发送多点接收的问题，实现了IP网络中点到多点的高效数据传送。但由于组播技术是基于UDP的，所以同时也存在着不足之处： 尽力而为 报文不能依赖组播网络进行可靠性保证，必须针对组播网络的这个特点进行特别设计。“可靠组播”目前仍然处于研究阶段。丢失是不可避免的。因此组播应用程序 没有拥塞避免机制 缺少TCP窗口机制和慢启动机制，组播可能会出现拥塞。如果可能的话，组播应用程序应该尝试检测避免拥塞。 报文重复 某些组播协议的特殊机制（如Assert机制和SPT切换机制）可能会造成偶尔的数据包的重复。组播应用程序应该容忍这种现象。 报文失序 同样组播协议有的时候会造成报文到达的次序错乱，组播应用程序必须自己采用某种手段进行纠正（比如缓冲池机制等）。 原理描述组播基本概念：组播传输的特点是单点发送，多点接收。 组播组：用IP组播地址进行标识的一个集合。任何用户主机（或其他接收设备），加入一个组播组，就成为了该组成员，可以识别并接收发往该组播组的组播数据。 组播源：信息的发送者称为“组播源”，一个组播源可以同时向多个组播组发送数据，多个组播源也可以同时向一个组播组发送报文。组播源通常不需要加入组播组，由源端DR负责管理组播源的注册和SPT（Shortest Path Tree）的建立。 组播组成员：所有加入某组播组的主机便成为该组播组的成员，组播组中的成员是动态的，主机可以在任何时刻加入或离开组播组。组播组成员可以广泛地分布在网络中的任何地方。 组播路由器：支持三层组播功能的路由器或交换机。组播路由器不仅能够提供组播路由功能，也能够在与用户连接的末梢网段上提供组播组成员的管理功能。 组播服务模型：组播服务模型的分类是针对接收者主机的，对组播源没有区别。组播源发出的组播数据中总是以组播源自己的IP地址为报文的源地址，组播组地址为目的地址。而接收者主机接收数据时可以对源进行选择，因此产生了ASM（Any-Source Multicast）和SSM（Source-Specific Multicast）两种服务模型。这两种服务模型默认使用不同的组播组地址范围。 ASM模型： ASM模型仅针对组地址提供组播分发。一个组播组地址作为一个网络服务的集合，任何源发布到该组地址的数据得到同样的服务。接收者主机加入组播组以后可以接收到任意源发送到该组的数据。 为了提高安全性，可以在路由器上配置针对组播源的过滤策略，允许或禁止来自某些组播源的报文通过。最终从接收者角度看，数据是经过筛选的。 ASM模型要求组地址必须整个组播网络中唯一。“唯一”指的是同一时刻一个ASM地址只能被一种组播应用使用。如果有两种不同的应用程序使用了同一个ASM组地址发送数据，它们的接收者会同时收到来自两个源的数据。这样一方面会导致网络流量拥塞，另一方面也会给接收者主机造成困扰。 SSM模型： SSM模型针对特定源和组的绑定数据流提供服务，接收者主机在加入组播组时，可以指定只接收哪些源的数据或指定拒绝接收来自哪些源的数据。加入组播组以后，主机只会收到指定源发送到该组的数据。 SSM模型对组地址不再要求全网唯一，只需要每个组播源保持唯一。这里的“唯一”指的是同一个源上不同的组播应用必须使用不同的SSM地址来区分。不同的源之间可以使用相同的组地址，因为SSM模型中针对每一个（源，组）信息都会生成表项。这样一方面节省了组播组地址，另一方面也不会造成网络拥塞。 组播地址：为了使组播源和组播组成员进行通信，需要提供网络层组播，使用IP组播地址。同时，为了在本地物理网络上实现组播信息的正确传输，需要提供链路层组播，使用组播MAC地址。组播数据传输时，其目的地不是一个具体的接收者，而是一个成员不确定的组，所以需要一种技术将IP组播地址映射为组播MAC地址。 IPv4组播地址：IANA（Internet Assigned Numbers Authority，互联网编号分配委员会）将D类地址空间分配给IPv4组播使用。IPv4地址一共32位，D类地址最高4位为1110，因此地址范围从224.0.0.0到239.255.255.255，具体分类及含义见下表： 地址范围 含义 224.0.0.0～224.0.0.255 永久组地址。IANA为路由协议预留的IP地址（也称为保留组地址），用于标识一组特定的网络设备，供路由协议、拓扑查找等使用，不用于组播转发。 224.0.1.0～231.255.255.255 233.0.0.0～238.255.255.255 ASM组播地址，全网范围内有效。说明： 其中，224.0.1.39和224.0.1.40是保留地址，不建议使用。 232.0.0.0～232.255.255.255 缺省情况下的SSM组播地址，全网范围内有效。 239.0.0.0～239.255.255.255 本地管理组地址，仅在本地管理域内有效。在不同的管理域内重复使用相同的本地管理组地址不会导致冲突。 常见的永久组地址列表： 永久组地址 含义 224.0.0.0 不分配 224.0.0.1 网段内所有主机和路由器（等效于广播地址） 224.0.0.2 所有组播路由器 224.0.0.3 不分配 224.0.0.4 DVMRP（Distance Vector Multicast Routing Protocol，距离矢量组播路由协议）路由器 224.0.0.5 OSPF（Open Shortest Path First，开放最短路径优先）路由器 224.0.0.6 OSPF DR（Designated Router，指定路由器） 224.0.0.7 ST（Shared Tree，共享树）路由器 224.0.0.8 ST主机 224.0.0.9 RIP-2（Routing Information Protocol version 2，路由信息协议版本2）路由器 224.0.0.11 移动代理（Mobile-Agents） 224.0.0.12 DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）服务器/中继代理 224.0.0.13 所有PIM（Protocol Independent Multicast，协议无关组播）路由器 224.0.0.14 RSVP（Resource Reservation Protocol，资源预留协议）封装 224.0.0.15 所有CBT（Core-Based Tree，有核树）路由器 224.0.0.16 指定SBM（Subnetwork Bandwidth Management，子网带宽管理） 224.0.0.17 所有SBM 224.0.0.18 VRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议） 224.0.0.22 所有使能IGMPv3（Internet Group Management Protocol, Version 3，因特网组管理协议）的路由器 224.0.0.19 ～ 224.0.0.21 224.0.0.23 ～ 224.0.0.255 未指定 IPv6组播地址： 图：IPv6组播地址格式 和IPv4组播地址相比，IPv6组播地址有了明确的Group ID字段用于标识组播组。 FF：最高8位为11111111，标识此地址为组播地址。即IPv6组播地址总是以FF开头。 Flags字段（4位），用来标识组播地址的状态。其含义如下: ​ | 取值 | 含义 || :–: | ———————— || 0 | 表示是IANA指定的常用组播地址，也叫保留组地址 || 1 | 表示是ASM范围的组播地址 || 2 | 表示是ASM范围的组播地址 || 3 | 表示是SSM范围的组播地址 || 其他 | 未分配 | Scope字段（4位）：用来标识组播组的应用范围，例如是只包含同一本地网络、同一站点、同一机构中的节点，还是包含全球地址空间内的任何节点。其含义如下： | 取值 | 含义 || —– | ————————————— || 0、3、F | 保留 || 1 | 节点（或接口）本地范围（node/interface-local scope） || 2 | 链路本地范围（link-local scope） || 4 | 管理本地范围（admin-local scope） || 5 | 站点本地范围（site-local scope） || 8 | 机构本地范围（organization-local scope） || E | 全球范围（global scope） || 其他 | 未分配 | Group ID（112位）：组播组标识号。用来在由Scope字段所指定的范围内唯一标识组播组，该标识可能是永久分配的或临时的，这由Flags字段的T位决定。 IPv6组播地址范围及含义： 范围 含义 FF0x::/32 保留组地址。 FF1x::/32（x不能是1或者2）FF2x::/32（x不能是1或者2） ASM组播地址，全网范围内有效。 FF3x::/32（x不能是1或者2） 缺省的SSM组地址范围，全网范围内有效。 IPv4组播MAC地址：以太网传输IPv4单播报文的时候，目的MAC地址使用的是接收者的MAC地址。但是在传输组播数据时，其目的地不再是一个具体的接收者，而是一个成员不确定的组，所以要使用IPv4组播MAC地址，即IPv4组播地址映射到链路层中的地址。 IANA规定，IPv4组播MAC地址的高24位为0x01005e，第25位为0，低23位为IPv4组播地址的低23位，例如组播组地址224.0.1.1对应的组播MAC地址为01-00-5e-00-01-01。 IPv4组播地址的前4位是固定的1110，对应组播MAC地址的高25位，后28位中只有23位被映射到MAC地址，因此丢失了5位的地址信息，直接结果是有32个IPv4组播地址映射到同一MAC地址上。 IPv6组播地址：IPv6组播MAC地址的高16位为0x3333，低32位为IPv6组播地址的低32位。 组播的相关协议：组播协议包括用于主机注册的组播组管理协议，和用于组播选路转发的组播路由协议。 IGMP（InternetGroup Management Protocol）在接收者主机和组播路由器之间运行，该协议定义了主机与路由器之间建立和维护组播成员关系的机制。 组播路由器之间运行组播路由协议，组播路由协议用于建立和维护组播路由，并正确、高效地转发组播数据包。 对于ASM模型，可以将组播路由分为域内和域间两大类。 域内组播路由协议用来在自治系统AS（AutonomousSystem）内发现组播源并构建组播分发树，将信息传递到接收者。域内组播路由协议包括：DVRMP、MOSPF、PIM。 DVRMP是距离矢量组播路由协议（DistanceVector Multicast Routing Protocol）是一种密集模式协议。该协议有跳数限制，最大跳数32跳。 MOSPF是OSPF路由协议的扩展协议。它通过定义新的LSA来支持组播。 PIM（Protocol Independent Multicast为稀疏时，）是典型的域内组播路由协议，分为DM（DenseMode）和SM（SparseMode）两种模型。当接收者在网络中的分布较为密集时，适用DM；较适用SM。PIM必须和单播路由协议协同工作。 域间组播路由协议用来实现组播信息在AS之间的传递。 MSDP（MulticastSource Discovery Protocol）能够跨越AS传播组播源信息。 MPBGP（MultiProtocolBorder Gateway Protocol）的组播扩展MBGP（MulticastBGP）能够跨越AS传播组播路由。 对于SSM模型，没有域内和域间的划分。由于接收者预先知道组播源的具体位置，因此可以借助PIMSM的部分功能直接创建组播传输路径。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>组播</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[流量监管和流量整形]]></title>
    <url>%2F2018%2F02%2F07%2F%E6%B5%81%E9%87%8F%E7%9B%91%E7%AE%A1%E5%92%8C%E6%B5%81%E9%87%8F%E6%95%B4%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[流量监管和流量整形概述流量监管和流量整形通过监督进入网络的流量速率，用来限制流量及其资源的使用，保证更好的为用户提供服务。 如果报文的发送速率大于接收速率，或者下游设备的接口速率小于上游设备的接口速率，就会引起网络拥塞。如果不限制用户发送的业务流量，大量用户不断突发的业务数据会使网络更加拥挤。为了使有限的网络资源能够更好地发挥效用，更好地为更多的用户服务，必须对用户的业务流量加以限制。 流量监管和流量整形就是一种通过对流量规格的监督，来限制流量及其资源使用的流控策略。 流量监管：流量监管TP（Traffic Policing）就是对流量进行控制，通过监督进入网络的流量速率，对超出部分的流量进行“惩罚”，使进入的流量被限制在一个合理的范围之内，从而保护网络资源和用户的利益。 流量整形：流量整形TS（Traffic Shaping）是一种主动调整流量输出速率的措施。当下游设备的入接口速率小于上游设备的出接口速率或发生突发流量时，下游设备入接口处可能出现流量拥塞的情况，此时用户可以通过在上游设备的接口出方向配置流量整形，将上游不规整的流量进行削峰填谷，输出一条比较平整的流量，从而解决下游设备的拥塞问题。 流量整形与流量监管的主要区别在于，流量整形对原本要被丢弃的报文进行缓存，当令牌桶有足够的令牌时，再均匀的向外发送这些被缓存的报文。流量整形与流量监管的另一区别是，整形可能会增加延迟，而监管几乎不引入额外的延迟。 监管和整形的区别： 应用方式： 监管可以同时应用在接口的出入方向。 整形值能用在接口的出方向。 监管可以实现报文的重标记。 整形不支持报文的重标记。 监管针对超出的流量采用直接丢弃的方式。 整形针对超出的流量不直接丢弃，而是放入缓存（shaping queue（默认使用WFQ队列机制））中并等待后续发送，如果缓存占满后执行Tail-Drop，丢弃方式可以更改为wred. 监管比较适合用于对延时要求较高的业务，例如：语音。但是会带来数据的重传。 整形比较适合用于对可靠性要求较高的业务，但是不适合对延时要求较高的业务，因为缓存的数据会造成延时的增大。 流量监管：Car(Committed Access Rate)约定访问速度、CB policing、Line rate 流量整形：GenericTraffic Shaping（通用流量整形，简称GTS、FRTS、DTS、CB Shapping、物理接口总速率限制，简称LR 令牌桶技术令牌桶可以看作是一个存放一定数量令牌的容器。系统按设定的速度向桶中放置令牌，当桶中令牌满时，多出的令牌溢出，桶中令牌不再增加。 在使用令牌桶对流量进行评估时，是以令牌桶中的令牌数量是否足够满足报文的转发为依据的。如果桶中存在足够的令牌可以用来转发报文，称流量遵守或符合约定值，否则称为流量超标或不符合约定值。 关于令牌桶处理报文的方式，RFC中定义了两种标记算法： 单速率三色标记（single rate three color marker，srTCM，或称为单速双桶算法）算法，主要关注报文尺寸的突发。 双速率三色标记（two rate three color marker，trTCM，或称为双速双桶算法）算法，主要关注报文速率的突发。 两种算法的评估结果都是为报文打上红、黄、绿三种颜色的标记，所以称为“三色标记”。QoS会根据报文的颜色做相应的处理，两种算法都可以工作于色盲模式和色敏模式下。以下以色盲模式为例对标记算法进行详细介绍。 单速双桶：单速双桶采用RFC2697的单速三色标记器srTCM（A Single Rate Three Color Marker）算法对流量进行测评，根据评估结果为报文打颜色标记，即绿色、黄色和红色。 图：单速双桶示意图 如上图所示：为方便描述将两个令牌桶称为C桶和E桶，用Tc和Te表示桶中的令牌数量。单速双桶有3个参数： CIR(Committed Information Rate)：承诺信息速率，表示向C桶中投放令牌的速率，即C桶允许传输或转发报文的平均速率； CBS(Committed Burst Size)：承诺突发尺寸，表示C桶的容量，即C桶瞬间能够通过的承诺突发流量； EBS（Excess Burst Size）：超额突发尺寸，表示E桶的容量，即E桶瞬间能够通过的超出突发流量。 系统按照CIR速率向桶中投放令牌： 若Tc&lt;CBS，Tc增加； 若Tc=CBS，Te&lt;EBS，Te增加； 若Tc=CBS，Te=EBS，则都不增加。 对于到达的报文，用B表示报文的大小： 若B≤Tc，报文被标记为绿色，且Tc减少B； 若Tc&lt;B≤Te，报文被标记为黄色，且Te减少B； 若Tc&lt;B并且Te&lt;B，报文被标记为红色，且Tc和Te都不减少。 双速双桶：双速双桶采用RFC2698的双速三色标记器trTCM（A Two Rate Three Color Marker）算法对流量进行测评，根据评估结果为报文打颜色标记，即绿色、黄色和红色。 图：双速双桶示意图 如上图所示，为方便描述将两个令牌桶称为P桶和C桶，用Tp和Tc表示桶中的令牌数量。双速双桶有4个参数： PIR（Peak information rate）：峰值信息速率，表示向P桶中投放令牌的速率，即P桶允许传输或转发报文的峰值速率，PIR大于CIR； CIR：承诺信息速率，表示向C桶中投放令牌的速率，即C桶允许传输或转发报文的平均速率； PBS（Peak Burst Size）：峰值突发尺寸，表示P桶的容量，即P桶瞬间能够通过的峰值突发流量； CBS：承诺突发尺寸，表示C桶的容量，即C桶瞬间能够通过的承诺突发流量。 系统按照PIR速率向P桶中投放令牌，按照CIR速率向C桶中投放令牌： 当Tp&lt;PBS时，P桶中令牌数增加，否则不增加。 当Tc&lt;CBS时，C桶中令牌数增加，否则不增加。 对于到达的报文，用B表示报文的大小： 若Tp&lt;B，报文被标记为红色； 若Tc&lt;B≤Tp，报文被标记为黄色，且Tp减少B； 若B≤Tp并且B≤Tc，报文被标记为绿色，且Tp和Tc都减少B。 色敏模式：色敏模式下，如果到达的报文本身已经被标记为红、黄、或者绿等颜色，令牌桶对流量的评估会参考报文已标记颜色，即报文本身已携带颜色会影响令牌桶的评估结果，评估机制简单的来说遵循以下原则： 如果报文已被标记为绿色，则令牌桶的评估机制与色盲模式保持一致。 如果报文已被标记为黄色，则令牌桶根据报文长度和令牌数的大小，为符合流量规定的报文标记为黄色，为不符合的报文标记为红色。 如果报文已被标记为红色，则令牌桶直接将到达报文标记为红色。 流量监管流量监管就是对流量进行控制，通过监督进入网络的流量速率，对超出部分的流量进行“惩罚”，使进入的流量被限制在一个合理的范围之内，从而保护网络资源和企业网用户的利益。 流量监管的原理： 图：流量监管组件图 流量监管由三部分组成： Meter：通过令牌桶机制对网络流量进行度量，向Marker输出度量结果。 Marker：根据Meter的度量结果对报文进行染色，报文会被染成green、yellow、red三种颜色。 Action：根据Marker对报文的染色结果，对报文进行一些动作，动作包括： pass：对测量结果为“符合”的报文继续转发。 remark + pass：修改报文内部优先级后再转发。 discard：对测量结果为“不符合”的报文进行丢弃。 默认情况下，green报文、yellow报文进行转发，red报文丢弃。 经过流量监管，如果某流量速率超过标准，设备可以选择降低报文优先级再进行转发或者直接丢弃。默认情况下，此类报文被丢弃。 流量整形流量整形是一种主动调整流量输出速率的措施，其作用是限制流量与突发，使这类报文以比较均匀的速率向外发送。流量整形通常使用缓冲区和令牌桶来完成，当报文的发送速度过快时，首先在缓冲区进行缓存，在令牌桶的控制下，再均匀地发送这些被缓冲的报文。 当下游设备的接口速率小于上游设备的接口速率或发生突发流量，在下游设备接口处可能出现流量拥塞的情况，此时用户可以通过在上游设备的接口出方向配置流量整形，将上游不规整的流量进行削峰填谷，输出一条比较平整的流量，从而解决下游设备的拥塞问题。 处理流程：流量整形是一种应用于接口、子接口或队列的流量控制技术，可以对从接口上经过的所有报文或某类报文进行速率限制。 下面以接口或子接口下采用单速单桶技术的基于流的队列整形为例介绍流量整形的处理流程，其处理流程如下图所示： 图：流量整形处理流程 具体处理流程如下： 当报文到来的时候，首先对报文进行分类，使报文进入不同的队列。 若报文进入的队列没有配置队列整形功能，则直接发送该队列的报文；否则，进入下一步处理。 按用户设定的队列整形速率向令牌桶中放置令牌： 如果令牌桶中有足够的令牌可以用来发送报文，则报文直接被发送，在报文被发送的同时，令牌做相应的减少。 如果令牌桶中没有足够的令牌，则将报文放入缓存队列，如果报文放入缓存队列时，缓存队列已满，则丢弃报文。 缓存队列中有报文的时候，系统按一定的周期从缓存队列中取出报文进行发送，每次发送都会与令牌桶中的令牌数作比较，直到令牌桶中的令牌数减少到缓存队列中的报文不能再发送或缓存队列中的报文全部发送完毕为止。 队列整形后，如果该接口和子接口同时配置了接口整形，则系统还要逐级按照子接口整形速率、接口整形速率对报文流进行速率控制。其处理流程与队列整形相似，但不需要步骤1和步骤2. 自适应流量整形：流量整形主要是为了解决下游设备的接口速率小于上游设备的接口速率，从而导致下游设备接口入方向丢包的问题。但有些场景下，下游设备的接口速率是不确定的，上游设备无法确定应该把整形参数设置为多少。此时可以配置自适应模板来实现自适应流量整形，通过在上游设备和下游设备间开启NQA检测，根据NQA检测到的下游设备丢包率动态调整整形参数。 自适应模板规定了： NQA测试例：通过此测试例检测下游设备接口入方向丢包率，根据检测结果调整整形参数。 整形速率范围：上游设备接口出方向的整形速率上下限，整形速率在此范围内动态调整。 整形速率调整步长：动态调整整形速率时，每次调整的速率大小。 丢包率范围：下游设备接口入方向允许的丢包率范围。当丢包率在此范围之内时，不调整整形速率；当丢包率过大，减小上游设备整形速率；当丢包率过小，且上游设备发生拥塞，增大上游设备整形速率。 整形速率增大的时间间隔：当丢包率在阈值附近频繁变化时，就需要频繁调整整形速率，用户可以通过设置此参数，限制增大整形速率的时间间隔，避免频繁更新。 系统根据NQA检测结果中的丢包率等调整整形速率： 触发条件（必须同时满足所有条件） 动作 NQA检测到丢包率大于自适应模板配置的丢包率上限 减小整形速率 NQA检测到丢包率小于自适应模板配置的丢包率下限。 上游发送端接口拥塞。 距离上次增大整形速率的时间间隔超过自适应模板配置的速率增大时间间隔 增大整形速率 NQA检测到丢包率小于自适应模板配置的丢包率下限上游发送端接口不拥塞 保持当前整形速率 丢包率在自适应模板配置的丢包率范围内 保持当前整形速率 检测失败 自适应模板配置的整形速率上限 流量整形与流量监管配置##常用命令行： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364bandwidth//配置基于MQC实现流量监管的承诺信息速率占接口带宽的百分比基值。car//在流行为中创建流量监管动作。/* cir:承诺信息速率，即保证能够通过的平均速率。 pct:指定承诺信息速率占接口带宽的百分比。 pir:峰值信息速率，即能够通过的最大速率。 share:指定对流做共享CAR，使绑定了同一流行为的流分类中的所有的规则共享CAR参数。 cbs:指定承诺突发尺寸，即瞬间能够通过的承诺突发流量。 pbs:指定峰值突发尺寸，即瞬间能够通过的峰值突发流量。 mode:HQoS的父策略行为，指定流量监管采取的颜色模式，如果不是HQoS的父策略行为，指定该参数无效。 color-blind:指定色盲模式。这种模式下，子策略行为对报文的着色不影响本次流量监管的动作。 color-aware:指定色敏模式。这种模式下，本次流量监管动作考虑子策略行为对报文的着色。*/display qos adaptation-profile//查看已配置的自适应模板信息。gts//流行为中创建流量整形动作。gts adaptation-profile//在流行为中绑定自适应模板。port-schedule high//配置接口的优先级为高。qos adaptation-profile//创建自适应模板，并进入自适应模板视图。qos car//配置流量监管。qos gts//对接口配置流量整形。qos gts adaptation-profile//在接口下应用自适应模板。qos lr//配置物理接口发送报文的速率占接口带宽的百分比。qos overhead layer &#123; link | physics &#125;//配置在流量监管或流量整形时报文长度的计算方式。/* layer:指定流量监管或流量整形计算报文长度时是否包括报文的物理层或链路层补偿信息。 link:指定流量监管或流量整形计算报文长度时仅包括报文的链路层补偿信息。 physics：指定流量监管或流量整形计算报文长度时包括报文的物理层和链路层的补偿信息。此为缺省配置。*/queue gts//配置各队列的流量整形。qos-profile//创建QoS模板并进入QoS模板视图，rate-adjust increase interval//配置自适应模板中整形速率增大的时间间隔。//缺省情况下，整形速率增大的时间间隔为30秒。rate-adjust loss//配置自适应模板的丢包率范围。//缺省情况下，丢包率范围为10%～20%rate-adjust step//配置自适应模板的整形速率调整步长。//缺省情况下，整形速率调整步长为64kbit/s。rate-range//配置自适应模板的整形速率范围。track nqa//为自适应模板绑定NQA测试例。 流量监管和流量整形配置示例：实验拓扑如下： 图：流量监管和流量整形配置实验拓扑 实验要求：如上图：VLAN10属于数据业务，VLAN20为语音业务，VLAN30为视频业务。在AR1上配置流量监管和流量整形，完成对不同的业务有不同的要求。 配置文件：AR1： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;AR1&gt;dis cur# sysname AR1#vlan batch 10 20 30#acl number 2000 rule 5 permit source 192.168.0.0 0.0.255.255 //用来匹配内网网段，做easy IP。#qos queue-profile qp //基于队列的流量整形 queue 2 gts cir 2000 cbs 50000 queue 5 gts cir 4000 cbs 10000 queue 6 gts cir 256 cbs 6400 schedule wfq 0 to 5 pq 6 to 7#//流分类，匹配vlan-idtraffic classifier video operator or if-match vlan-id 30traffic classifier date operator or if-match vlan-id 10traffic classifier voice operator or if-match vlan-id 20#//流行为，对于流量监管，配置合理的速率。//对于流量整形，对于匹配到的流标记规定的802.1q优先级traffic behavior video car cir 4000 cbs 752000 pbs 1252000 green pass yellow pass red discard statistic enable //使能接口的流量统计功能。 remark 8021p 5//标记优先级为5traffic behavior date car cir 2000 cbs 376000 pbs 626000 green pass yellow pass red discard statistic enable remark 8021p 2traffic behavior voice car cir 256 cbs 48128 pbs 80128 green pass yellow pass red discard statistic enable remark 8021p 6# //流策略，绑定对应的流分类与流行为traffic policy video classifier video behavior videotraffic policy date classifier date behavior datetraffic policy voice classifier voice behavior voice#interface GigabitEthernet0/0/0 ip address 12.1.1.1 255.255.255.0 qos queue-profile qp //在接口应用队列模板 qos gts cir 8000 cbs 200000 //将端口速率限制在8000kbit/s. nat outbound 2000 //做nat，easy ip#interface GigabitEthernet0/0/1 trust 8021p //接口信任802.1q优先级 qos car inbound cir 10000 cbs 1880000 pbs 3130000 green pass yellow pass red discard //配置入口的速率限制在10000kbit/s.#interface GigabitEthernet0/0/1.10 dot1q termination vid 10 //配置子接口Dot1q终结的单层VLAN ID。 ip address 192.168.10.254 255.255.255.0 traffic-policy date inbound //应用流策略 arp broadcast enable //使能终结子接口的ARP广播功能。#interface GigabitEthernet0/0/1.20 dot1q termination vid 20 ip address 192.168.20.254 255.255.255.0 traffic-policy voice inbound arp broadcast enable#interface GigabitEthernet0/0/1.30 dot1q termination vid 30 ip address 192.168.30.254 255.255.255.0 traffic-policy video inbound arp broadcast enable#ip route-static 0.0.0.0 0.0.0.0 12.1.1.2 //出外网的默认路由#return AR2： 12345678[AR2]dis current-configuration # sysname AR2#interface GigabitEthernet0/0/0 ip address 12.1.1.2 255.255.255.0 #return SW： 1234567891011121314151617181920212223&lt;SW&gt;dis current-configuration #sysname SW#vlan batch 10 20 30#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 2 to 4094#interface GigabitEthernet0/0/2 port link-type access port default vlan 10#interface GigabitEthernet0/0/3 port link-type access port default vlan 20#interface GigabitEthernet0/0/4 port link-type access port default vlan 30#return 配置结果： 图：流策略应用记录 图：流策略状态 图：队列模板情况 图：接口应用队列模板情况统计]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>QoS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拥塞管理与拥塞避免]]></title>
    <url>%2F2018%2F02%2F06%2F%E6%8B%A5%E5%A1%9E%E7%AE%A1%E7%90%86%E4%B8%8E%E6%8B%A5%E5%A1%9E%E9%81%BF%E5%85%8D%2F</url>
    <content type="text"><![CDATA[拥塞管理与拥塞避免概述拥塞避免通过指定报文丢弃策略来解除网络过载，拥塞管理通过指定报文调度次序来确保高优先级业务优先被处理。 传统网络所面临的服务质量问题主要由拥塞引起，拥塞是指由于网络资源不足而造成速率下降、引入额外延时的一种现象。拥塞会造成报文的传输时延、吞吐率低及资源的大量耗费。而在IP分组交换及多业务并存的复杂环境下，拥塞又极为常见。 拥塞避免和拥塞管理就是解决网络拥塞的两种流控方式。 拥塞避免：拥塞避免是指通过监视网络资源（如队列或内存缓冲区）的使用情况，在拥塞发生或有加剧趋势时主动丢弃报文，通过调整网络的流量来解除网络过载的一种流量控制机制。 设备支持以下拥塞避免功能： 尾部丢弃 传统的丢弃策略采用尾部丢弃的方法，同等对待所有报文，不对报文进行服务等级的区分。在拥塞发生时，队列尾部的数据报文将被丢弃，直到拥塞解除。 这种丢弃策略会引起TCP全局同步现象。所谓TCP全局同步现象，是指当多个队列同时丢弃多个TCP连接报文时，将造成一些TCP连接同时进入拥塞避免和慢启动状态，降低流量以解除拥塞；而后这些TCP连接又会在某个时刻同时出现流量高峰。如此反复，使网络流量忽大忽小，影响链路利用率。 WRED 加权随机先期检测WRED（Weighted Random Early Detection）基于丢弃参数随机丢弃报文。考虑到高优先级报文的利益并使其被丢弃的概率相对较小，WRED可以为不同业务的报文指定不同的丢弃策略。此外，通过随机丢弃报文，让多个TCP连接不同时降低发送速度，避免了TCP全局同步现象。 WRED技术为每个队列的长度都设定了阈值上下限，并规定： 当队列的长度小于阈值下限时，不丢弃报文。 当队列的长度大于阈值上限时，丢弃所有新收到的报文。 当队列的长度在阈值下限和阈值上限之间时，开始随机丢弃新收到的报文。方法是为每个新收到的报文赋予一个随机数，并用该随机数与当前队列的丢弃概率比较，如果大于丢弃概率则报文被丢弃。队列越长，报文被丢弃的概率越高。 拥塞管理：拥塞管理是指在网络间歇性出现拥塞，时延敏感业务要求得到比其它业务更高质量的QoS服务时，通过调整报文的调度次序来满足时延敏感业务高QoS服务的一种流量控制机制。 PQ调度 PQ（Priority Queuing）调度，就是严格按照队列优先级的高低顺序进行调度。只有高优先级队列中的报文全部调度完毕后，低优先级队列才有调度机会。 采用PQ调度方式，将延迟敏感的关键业务放入高优先级队列，将非关键业务放入低优先级队列，从而确保关键业务被优先发送。 PQ调度的缺点是：拥塞发生时，如果较高优先级队列中长时间有分组存在，那么低优先级队列中的报文就会得不到调度机会。 WRR调度 WRR（Weighted Round Robin）调度即加权轮询调度。WRR在队列之间进行轮流调度，保证每个队列都得到一定的服务时间。 以端口有8个输出队列为例，WRR可为每个队列配置一个加权值（依次为w7、w6、w5、w4、w3、w2、w1、w0），加权值表示获取资源的比重。例如：一个100M的端口，配置它的WRR队列调度算法的加权值为50、50、30、30、10、10、10、10（依次对应w7、w6、w5、w4、w3、w2、w1、w0），这样可以保证最低优先级队列至少获得5Mbit/s带宽，避免了采用PQ调度时低优先级队列中的报文可能长时间得不到服务的缺点。 WRR还有一个优点是，虽然多个队列的调度是轮询进行的，但对每个队列不是固定地分配服务时间片:如果某个队列为空，那么马上换到下一个队列调度，这样带宽资源可以得到充分的利用。 WRR调度按照报文个数进行调度，而用户一般关心的是带宽。当每个队列的平均报文长度相等或已知时，通过配置WRR权重，用户能够获得想要的带宽；但是，当队列的平均报文长度变化时，用户就不能通过配置WRR权重获取想要的带宽。 低延时需求业务（如语音）得不到及时调度。 DRR调度 DRR（Deficit Round Robin）调度实现原理与WRR调度基本相同。 DRR与WRR的区别是：WRR调度是按照报文个数进行调度，而DRR是按照报文长度进行调度。如果报文长度超过了队列的调度能力，DRR调度允许出现负权重，以保证长报文也能够得到调度。但下次轮循调度时该队列将不会被调度，直到权重为正，该队列才会参与DRR调度。 DRR调度避免了采用PQ调度时低优先级队列中的报文可能长时间得不到服务的缺点，也避免了各队列报文长度不等或变化较大时，WRR调度不能按配置比例分配带宽资源的缺点。 但是，DRR调度也具有低延时需求业务（如语音）得不到及时调度的缺点。 WFQ调度 公平队列FQ（Fair Queue）的目的是尽可能公平地分享网络资源，使所有流的延迟和抖动达到最优，让不同队列获得公平的调度机会。WFQ（Weighted Fair Queue）调度即加权公平队列调度，在FQ的基础上增加了优先权方面的考虑，使高优先权的报文获得优先调度的机会多于低优先权的报文。 WFQ能够按流的“会话”信息（协议类型、源和目的TCP或UDP端口号、源和目的IP地址、ToS域中的优先级位等）自动进行流分类，并且尽可能多地提供队列，以将每个流均匀地放入不同队列中，从而在总体上均衡各个流的延迟。在出队的时候，WFQ按流的优先级（precedence）来分配每个流应占有出口的带宽。优先级的数值越小，所得的带宽越少。优先级的数值越大，所得的带宽越多。 PQ+WRR/PQ+DRR/PQ+WFQ调度 PQ调度和WRR/DRR/WFQ调度各有优缺点。单纯采用PQ调度时，低优先级队列中的报文可能长期得不到调度，而单纯采用WRR/DRR/WFQ调度时低延时需求业务得不到优先调度，“PQ+WRR/PQ+DRR/PQ+WFQ”调度方式则将两种调度方式结合起来，不仅能发挥两种调度的优势，而且能克服两种调度各自的缺点。 用户可以借助“PQ+WRR/PQ+DRR/PQ+WFQ调度”调度方式，将重要的协议报文和有低延时需求的业务报文放入PQ队列中进行调度，并为该队列分配指定带宽；而将其他报文按各自的优先级放入采用WRR/DRR/WFQ调度的各队列中，按照权值对各队列进行循环调度。 CBQ调度 基于类的加权公平队列CBQ（Class-based Queueing）是对WFQ功能的扩展，为用户提供了定义类的支持。CBQ首先根据IP优先级或者DSCP优先级、输入接口、IP报文的五元组等规则来对报文进行分类，然后让不同类别的报文进入不同的队列。对于不匹配任何类别的报文，送入系统定义的缺省类。 EF队列：满足低时延业务 EF队列是具有高优先级的队列，一个或多个类的报文可以被设定进入EF队列，不同类别的报文可设定占用不同的带宽。 设备除了提供普通的EF队列，还支持一种特殊的EF队列—LLQ队列，时延更低。这为对时延敏感的应用（如VoIP业务）提供了良好的服务质量保证。 由于EF队列中的报文一般是语音报文（VoIP），采用的是UDP报文，所以没有必要采用WRED的丢弃策略，采用尾丢弃策略即可。 AF队列：满足需要带宽保证的关键数据业务 每个AF队列分别对应一类报文，用户可以设定每类报文占用的带宽。在系统调度报文出队的时候，按用户为各类报文设定的带宽将报文出队发送，可以实现各个类的队列的公平调度。当接口有剩余带宽时，AF队列按照权重分享剩余带宽。同时，在接口拥塞的时候，仍然能保证各类报文得到用户设定的最小带宽。 对于AF队列，当队列的长度达到队列的最大长度时，缺省采用尾丢弃的策略，但用户还可以选择用WRED丢弃策略。 BE队列：满足不需要严格QoS保证的尽力发送业务 当报文不匹配用户设定的所有类别时，报文被送入系统定义的缺省类。虽然允许为缺省类配置AF队列，并配置带宽，但是更多的情况是为缺省类配置BE队列。BE队列使用WFQ调度，使所有进入缺省类的报文进行基于流的队列调度。 对于BE队列，当队列的长度达到队列的最大长度时，缺省采用尾丢弃的策略，但用户还可以选择用WRED丢弃策略。 拥塞避免原理描述拥塞避免（Congestion Avoidance）是指通过监视网络资源（如队列或内存缓冲区）的使用情况，在拥塞发生或有加剧的趋势时主动丢弃报文，通过调整网络的流量来解除网络过载的一种流控机制。 拥塞避免常用的两种丢弃报文方式为：尾部丢包策略和WRED。 传统的尾部丢包策略 传统的丢包策略采用尾部丢弃（Tail-Drop）的方法。当队列的长度达到最大值后，所有新入队列的报文（缓存在队列尾部）都将被丢弃。 这种丢弃策略会引发TCP全局同步现象，导致TCP连接始终无法建立。所谓TCP全局同步现象如图，三种颜色表示三条TCP连接，当同时丢弃多个TCP连接的报文时，将造成多个TCP连接同时进入拥塞避免和慢启动状态而导致流量降低，之后又会在某个时间同时出现流量高峰，如此反复，使网络流量忽大忽小。 图：尾部丢包示意图 WRED 为避免TCP全局同步现象，出现了RED（Random Early Detection）技术。RED通过随机地丢弃数据报文，让多个TCP连接不同时降低发送速度，从而避免了TCP的全局同步现象。使TCP速率及网络流量都趋于稳定。 图：WRED丢包示意图 拥塞管理原理描述随着生活质量的提高，网络业务种类繁多，人们对网络质量的要求也越来越高，有限的带宽与超负荷的网络需求产生冲突，造成网络中时常会出现延迟、信号丢失等情况，这些都是由于拥塞产生的。当网络间歇性的出现拥塞，且时延敏感业务要求得到比非时延敏感业务更高质量的QoS服务时，需要进行拥塞管理；如果配置拥塞管理后仍然出现拥塞，则需要增加带宽。拥塞管理一般采用队列技术，使用不同的调度算法来发送队列中的报文流。 根据排队和调度策略的不同，WAN接口和二层VE接口上的拥塞管理技术分为PQ、WFQ和PQ+WFQ，设备其余LAN接口上的拥塞管理技术分为PQ、DRR、PQ+DRR、WRR、PQ+WRR。 设备上，每个接口出方向都拥有4个或8个队列，以队列索引号进行标识，队列索引号分别为0、1、2、3或0、1、2、3、4、5、6、7。设备根据本地优先级和队列之间的映射关系，自动将分类后的报文流送入各队列，然后按照各种队列调度机制进行调度。下面以每个接口8个队列对各种调度方式进行说明。 PQ调度：PQ调度，针对于关键业务类型应用设计，PQ调度算法维护一个优先级递减的队列系列并且只有当更高优先级的所有队列为空时才服务低优先级的队列。这样，将关键业务的分组放入较高优先级的队列，将非关键业务（如E-Mail）的分组放入较低优先级的队列，可以保证关键业务的分组被优先传送，非关键业务的分组在处理关键业务数据的空闲间隙被传送。 PQ调度过程如下图： 图：PQ调度过程示意图 如上图Queue7比Queue6具有更高的优先权，Queue6比Queue5具有更高的优先权，依次类推。只要链路能够传输分组，Queue7尽可能快地被服务。只有当Queue7为空，调度器才考虑Queue6。当Queue6有分组等待传输且Queue7为空时，Queue6以链路速率接受类似地服务。当Queue7和Queue6为空时，Queue5以链路速率接收服务，以此类推。 PQ调度算法对低时延业务非常有用。假定数据流X在每一个节点都被映射到最高优先级队列，那么当数据流X的分组到达时，则分组将得到优先服务。 然而PQ调度机制会使低优先级队列中的报文得不到调度机会。例如，如果映射到Queue7的数据流在一段时间内以100%的输出链路速率到达，调度器将从不为Queue6及以下的队列服务。 为了避免队列饥饿，上游设备需要精心规定数据流的业务特性，以确保映射到Queue7的业务流不超出输出链路容量的一定比例，这样Queue7会经常为空，低优先级队列中的报文才能得到调度机会。 WRR调度：加权循环调度WRR（Weight Round Robin）在循环调度RR（Round Robin）的基础上演变而来，在队列之间进行轮流调度，根据每个队列的权重来调度各队列中的报文流。实际上，RR调度相当于权值为1的WRR调度。 WRR队列示意图如下图所示： 图：WRR调度示意图 在进行WRR调度时，设备根据每个队列的权值进行轮循调度。调度一轮权值减一，权值减到零的队列不参加调度，当所有队列的权限减到0时，开始下一轮的调度。例如，用户根据需要为接口上8个队列指定的权值分别为4、2、5、3、6、4、2和1。 各队列中的报文流被调度的次数与该队列的权值成正比，权值越大被调度的次数相对越多。由于WRR调度的以报文为单位，因此每个队列没有固定的带宽，同等调度机会下大尺寸报文获得的实际带宽要大于小尺寸报文获得的带宽。 WRR调度避免了采用PQ调度时低优先级队列中的报文可能长时间得不到服务的缺点。WRR队列还有一个优点是，虽然多个队列的调度是轮询进行的，但对每个队列不是固定地分配服务时间片——如果某个队列为空，那么马上换到下一个队列调度，这样带宽资源可以得到充分的利用。但WRR调度无法使低延时需求业务得到及时调度。 DRR调度:DRR（Deficit Round Robin）调度同样也是RR的扩展，相对于WRR来言，解决了WRR只关心报文，同等调度机会下大尺寸报文获得的实际带宽要大于小尺寸报文获得的带宽的问题，在调度过程中考虑包长的因素以达到调度的速率公平性。 DRR调度中，Deficit表示队列的带宽赤字，初始值为0。每次调度前，系统按权重为各队列分配带宽，计算Deficit值，如果队列的Deficit值大于0，则参与此轮调度，发送一个报文，并根据所发送报文的长度计算调度后Deficit值，作为下一轮调度的依据；如果队列的Deficit值小于0，则不参与此轮调度，当前Deficit值作为下一轮调度的依据。 图：DRR调度示意图 假设用户配置各队列权重为40、30、20、10、40、30、20、10（依次对应Q7、Q6、Q5、Q4、Q3、Q2、Q1、Q0），调度时，队列Q7、Q6、Q5、Q4、Q3、Q2、Q1、Q0依次能够获取20%、15%、10%、5%、20%、15%、10%、5%的带宽。下面以Q7、Q6为例，简要描述DRR队列调度的实现过程（假设Q7队列获取400byte/s的带宽，Q6队列获取300byte/s的带宽）。 第1轮调度 Deficit[7][1] = 0+400 = 400，Deficit[6][1] = 0+300 = 300，从Q7队列取出一个900byte的报文发送，从Q6队列取出一个400byte的报文发送；发送后，Deficit[7][1] = 400–900 =–500，Deficit[6][1] = 300–400 =–100。 第2轮调度 Deficit[7][2] = -500+400 = -100，Deficit[6][2] = -100+300 = 200，Q7队列Deficit值小于0，此轮不参与调度，从Q6队列取出一个300byte的报文发送；发送后，Deficit[6][2] = 200–300 =–100。 第3轮调度 Deficit[7][3] = -100+400 = 300，Deficit[6][3] = -100+300 = 200，从Q7队列取出一个600byte的报文发送，从Q6队列取出一个500byte的报文发送；发送后，Deficit[7][3] = 300–600 =–300，Deficit[6][3] = 200–500 =–300。 如此循环调度，最终Q7、Q6队列获取的带宽将分别占总带宽的20%、15%，因此，用户能够通过设置权重获取想要的带宽。 但DRR调度仍然没有解决WRR调度中低延时需求业务得不到及时调度的问题。 WFQ调度：公平队列FQ（Fair Queuing）的目的是尽可能公平地分享网络资源，使所有流的延迟和抖动达到最优： 不同的队列获得公平的调度机会，从总体上均衡各个流的延迟。 短报文和长报文获得公平的调度：如果不同队列间同时存在多个长报文和短报文等待发送，让短报文优先获得调度，从而在总体上减少各个流的报文间的抖动。 与FQ相比，WFQ（Weighted Fair Queue）在计算报文调度次序时增加了优先权方面的考虑。从统计上，WFQ使高优先权的报文获得优先调度的机会多于低优先权的报文。 WFQ调度在报文入队列之前，先对流量进行分类，有两种分类方式： 按流的“会话”信息分类： 根据报文的协议类型、源和目的TCP或UDP端口号、源和目的IP地址、ToS域中的优先级位等自动进行流分类，并且尽可能多地提供队列，以将每个流均匀地放入不同队列中，从而在总体上均衡各个流的延迟。在出队的时候，WFQ按流的优先级（precedence）来分配每个流应占有带宽。优先级的数值越小，所得的带宽越少。优先级的数值越大，所得的带宽越多。这种方式只有CBQ的default-class支持。 按优先级分类： 通过优先级映射把流量标记为本地优先级，每个本地优先级对应一个队列号。每个接口预分配8个队列，报文根据队列号进入队列。默认情况，队列的WFQ权重相同，流量平均分配接口带宽。用户可以通过配置修改权重，高优先权和低优先权按权重比例分配带宽。 图：WFQ调度示意图 PQ+WRR调度：PQ调度和WRR调度各有优缺点，为了克服单纯采用PQ调度或WRR调度时的缺点，PQ+WRR调度以发挥两种调度的各自优势，不仅可以通过WRR调度可以让低优先级队列中的报文也能及时获得带宽，而且可以通过PQ调度可以保证了低延时需求的业务能优先得到调度。 在设备上，用户可以配置队列的WRR参数，根据配置将接口上的8个队列分为两组，一组（例如Queue7、Queue6、Queue5）采用PQ调度，另一组（例如Queue4、Queue3、Queue2、Queue1和Queue0队列）采用WRR调度。设备上只有LAN侧接口支持PQ+WRR调度。 PQ+WRR调度示意图如下： 图：PQ+WRR混合调度示意图 在调度时，设备首先按照PQ方式调度Queue7、Queue6、Queue5队列中的报文流，只有这些队列中的报文流全部调度完毕后，才开始以WRR方式循环调度其他队列中的报文流。Queue4、Queue3、Queue2、Queue1和Queue0队列包含自己的权值。重要的协议报文和有低延时需求的业务报文应放入采用PQ调度的队列中，得到优先调度的机会，其余报文放入以WRR方式调度的各队列中。 PQ+DRR调度：与PQ+WRR相似，其集合了PQ调度和DRR调度各有优缺点。单纯采用PQ调度时，低优先级队列中的报文流长期得不到带宽，而单纯采用DRR调度时低延时需求业务（如语音）得不到优先调度，如果将两种调度方式结合起来形成PQ+DRR调度，不仅能发挥两种调度的优势，而且能克服两种调度各自的缺点。 设备接口上的8个队列被分为两组，用户可以指定其中的某几组队列进行PQ调度，其他队列进行DRR调度。 图：PQ+DRR调度示意图 如上图，在调度时，设备首先按照PQ方式优先调度Queue7、Queue6和Queue5队列中的报文流，只有这些队列中的报文流全部调度完毕后，才开始以DRR方式调度Queue4、Queue3、Queue2、Queue1和Queue0队列中的报文流。其中，Queue4、Queue3、Queue2、Queue1和Queue0队列包含自己的权值。 重要的协议报文以及有低延时需求的业务报文应放入需要进行PQ调度的队列中，得到优先调度的机会，其他报文放入以DRR方式调度的各队列中。 PQ+WFQ调度：与PQ+WRR相似，其集合了PQ调度和WFQ调度各有优缺点。单纯采用PQ调度时，低优先级队列中的报文流长期得不到带宽，而单纯采用WFQ调度时低延时需求业务（如语音）得不到优先调度，如果将两种调度方式结合起来形成PQ+WFQ调度，不仅能发挥两种调度的优势，而且能克服两种调度各自的缺点。 设备接口上的8个队列被分为两组，用户可以指定其中的某几组队列进行PQ调度，其他队列进行WFQ调度。V200R008C30及以前版本，只有WAN侧接口支持PQ+WFQ调度。V200R008C50及以后版本，WAN侧接口和二层VE接口支持PQ+WFQ调度。 图：PQ+WFQ调度示意图 如上图,在调度时，设备首先按照PQ方式优先调度Queue7、Queue6和Queue5队列中的报文流，只有这些队列中的报文流全部调度完毕后，才开始以WFQ方式调度Queue4、Queue3、Queue2、Queue1和Queue0队列中的报文流。其中，Queue4、Queue3、Queue2、Queue1和Queue0队列包含自己的权值。 重要的协议报文以及有低延时需求的业务报文应放入需要进行PQ调度的队列中，得到优先调度的机会，其他报文放入以WFQ方式调度的各队列中。 CBQ调度：CBQ（Class-based Queueing）基于类的加权公平队列是对WFQ功能的扩展，为用户提供了定义类的支持。CBQ首先根据IP优先级或者DSCP优先级、输入接口、IP报文的五元组等规则来对报文进行分类，然后让不同类别的报文进入不同的队列。对于不匹配任何类别的报文，送入系统定义的缺省类。 图：CBQ调度示意图 CBQ提供三类队列： EF队列：满足低时延业务 AF队列：满足需要带宽保证的关键数据业务BE队列：满足不需要 严格QoS保证的尽力发送业务 确保转发队列（AF）：可以保证在网络发送的业务流量没有超过最小可确保带宽的情况下，此队列中报文的丢失概率非常低。确保转发适用于流量较大，且需要被保证的业务。 加速转发队列（EF）：匹配规则的报文进入EF队列后，进行绝对优先级调度，仅当EF队列中的报文调度完毕后，才会调度其他队列中的报文。而且当AF或BE队列有空闲带宽时，EF队列可以对空闲带宽进行占用。加速转发适用于需要保证低延时、低丢弃概率、确保带宽、且占用带宽不是很大的业务，例如语音报文。 设备除了提供普通的EF队列，还支持一种特殊的EF队列—LLQ队列。LLQ队列较EF队列而言，时延更低。 尽力而为队列（BE）：与系统定义的缺省类default-class关联使用，未进入AF队列和EF队列的剩余报文进入BE队列。BE队列使用WFQ算法调度，队列数越多，带宽被分享的越公平，但是占用的队列资源相对也多。WFQ调度的BE队列适用于那些对时延和丢包无特殊要求的业务，例如普通上网业务。 思科和华为WFQ的对比：Cisco WFQ(4096子队列)： 入队方式:基于流（通过6元组做Hash）。 调度方式：FT=finish time， FT=packert length/(IPP+1) cisco优化后的公式：weight=32284/(IP优先级+1)。 丢弃方式：CDT（8）和HQO（总队列长度）（10）。 HUAWEI WFQ： 入队方式：基于流，只用于CBQ中的default-class。 ​ 基于类,用于接口下配置。 调度方式：基于类的调度，为每一个自队列都分配一个权重，从而计算子队列的带宽。 ​ 基于流的调度机制见上面WFQ部分的介绍。 丢弃方式：Tail-drop。 ​ WRED。 各种队列调度技术的优缺点： 队列技术 调度的时延/抖动（在速率低的时候明显，速度绝对高的时候可忽略） 公平性 FIFO 差 无 RR 差 依赖包长 WRR 差 依赖包长 PQ 高优先级队列的时延控制非常好 无 CQ 配置字节数小的时候，带宽分配不准确，当 配置字节数大的时候，时延抖动比较大差 一般 WFQ 时延控制较好，抖动小 好 （一）FIFO： 优点： 简单。 缺点： 没有公平性，不同的流之间不互相隔离，当某一个流的带宽太大的时候会占用其他流的带宽，并且造成其他流的时延增加。 当拥塞发生的时候，FIFO对一部分报文进行丢弃。TCP的连接发现有丢包后，会降低传输的速度，来主动的避免拥塞，但是UDP是非连接的，不降低发送速率。导致FIFO中TCP和UDP的报文不平衡，TCP的流量太低。 一条流的突发流量可能占用全部buffer，将其他的流量全都阻断。 （二）RR： 优点： 隔离了不同的流，实现了队列之间对带宽的平等利用。 剩余带宽能够被其他队列平均分配。 缺点： 无法设置队列占用带宽的权重； 当不同队列中的报文长度不一的时候，调度不准确； 当调度速率低的时候，时延和抖动的问题比较突出，比如一个包到达一个空队列，而这个队列刚刚被调度完毕，则这个包要等到其他全部的队列调度完才能取得出接口的机会，这样会导致抖动比较大，但是如果调度速度非常高，则这种时延可以忽略，RR在高速路由器内部有很多应用。 （三）WRR： 优点： 能够按照权重来分配带宽，某个队列的剩余带宽能够为其他队列公平占用，低优先级的队列同样能够得到调度，不存在饥饿的问题。 实现简单、复杂度低。 适合diffserv聚合后的端口。 缺点： 与RR调度算法一致，在报文长度不一致的时候，调度不准确。 在调度速率低的时候报文的时延控制的不好，时延抖动无法预期。 （四）PQ 优点： 高优先级队列的时延控制非常好。 实现简单，能够区分多种业务。 缺点： 无法做到带宽的合理分配，高优先级的流量比较大的时候，导致低优先级的“饿死（starvation）”。 高优先级的时延得到保证的代价是牺牲低优先级的时延。 如果高优先级传送TCP流量，低优先级传送UDP流量，则TCP增加传送速率，导致UDP流量无法得到足够的带宽。 （五）CQ 优点： 按照比例来分配带宽，当某个队列的流量小的时候，其他队列能等比的占用带宽。 实现简单。 缺点： 当配置字节数小的时候，带宽分配不准确，当配置字节数大的时候，时延抖动比较大。 （六）WFQ 优点： 按照字节粒度进行调度，调度公平。 能区分业务，分配权重。 时延控制的好，抖动小。 缺点： 实现复杂。 配置命令行123456789101112131415161718192021222324252627282930313233343536373839404142434445display drop-profile//查看WRED丢弃模板的配置信息。display qos queue statistics//查看接口上基于队列的流量统计信息。display qos queue-profile//查看已配置的队列模板信息。dscp discard-percentage//配置基于DSCP优先级的WRED模板参数，包括丢弃上下门限百分比和最大丢弃概率。//缺省情况下，WRED模板的丢弃下限百分比为30//丢弃上限百分比为100，最大丢弃概率值为10。ip-precedence discard-percentage//配置基于IP优先级的WRED模板参数，包括丢弃上下限百分比和最大丢弃概率。drop-profile//在系统视图下，创建丢弃模板并进入丢弃模板视图//在流行为中为AF队列或使用WFQ方式调度的BE队列绑定丢弃模板。qos queue-profile//在接口下应用队列模板。//创建队列模板并进入队列模板视图queue af bandwidth //配置对匹配一定规则的某一类报文进行确保转发//（Assured-forwarding），并配置可确保的最小带宽。queue drop-profile//在队列模板中为指定队列绑定丢弃模板。queue ef //配置对匹配一定规则的某一类报文进行加速转发//（Expedited-forwarding），并配置最大允许带宽。//cbs:指定承诺突发尺寸，即瞬间能够通过的承诺突发流量。//pct:指定可确保的最大带宽占接口可用带宽的百分比。queue length//在队列模板中配置各队列的长度。queue-length//在流行为中配置队列的最大长度。queue llq//配置对匹配一定规则的某一类报文进行低延时转发，并配置允许的最大带宽。queue weight//用来在队列模板中配置队列的权重。queue wfq//用来配置缺省类报文进入使用WFQ方式调度的BE队列，并配置队列的总数。//缺省情况下，系统未配置缺省类报文进入使用WFQ方式调度的BE队列。reset qos queue statistics//清除接口上基于队列的流量统计信息。schedule//在队列模板中配置各队列之间的调度关系。wred &#123; dscp | ip-precedence &#125;//用来指定当前WRED丢弃模板基于DSCP优先级或IP优先级进行丢弃。 123456789101112131415//配置拥塞管理和拥塞避免示例：drop-profile data # wred dscp dscp af31 low-limit 40 high-limit 60 discard-percentage 40 dscp af32 low-limit 50 high-limit 70 discard-percentage 30 # drop-profile video wred dscp dscp af43 low-limit 60 high-limit 80 discard-percentage 20 # qos queue-profile queue-profile1 queue 3 drop-profile data queue 4 drop-profile video schedule wfq 3 to 4 pq 5 #]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>QoS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QoS概述]]></title>
    <url>%2F2018%2F02%2F05%2FQoS%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[QoS简介服务质量QoS（Quality of Service）用于评估服务方满足客户服务需求的能力。通过配置QoS，对企业的网络流量进行调控，避免并管理网络拥塞，减少报文的丢失率，同时也可以为企业用户提供专用带宽或者为不同的业务（语音、视频、数据等）提供差分服务。 影响网络质量的因素：网络带宽： 网络带宽是指在单位时间（一般指的是1秒钟）内能传输的数据量。 网络时延： ​ 时延是指一个报文从一个网络的一端传送到另一端所需要的时间。 ​ 实时应用通信质量都比较关注时延大小，如语音、视频等。以语音传输为例，时延是指从说话者开始说话到对方听到所说内容的时间。若时延太大，会引起通话声音不清晰、不连贯或破碎。 ​ 单个网络设备的时延包括传输时延、串行化时延、处理时延、以及队列时延。 传输时延：一个数据位从发送方到达接收方所需要的时间。该时延取决于传输距离和传输介质，与带宽无关。 串行化时延：指发送节点在传输链路上开始发送报文的第一个比特至发完该报文的最后一个比特所需的时间。该时延取决于链路带宽以及报文大小。 处理时延：指路由器把报文从入接口放到出接口队列需要的时间。它的大小跟路由器的处理性能有关。 队列时延：指报文在队列中等待的时间。它的大小跟队列中报文的大小和数量、带宽以及队列机制有关。 抖动： ​ 由于每个报文的端到端时延不一样，就会导致这些报文不能等间隔到达目的端，这种现象叫做抖动。一般来说，时延越小则时延抖动的范围越小。 ​ 某些业务类型（特别是语音和视频等实时业务）是极其不能容忍抖动的。报文到达时间的差异将在语音或视频中造成断续；另外，抖动也会影响一些网络协议的处理，有些协议是按固定的时间间隔发送交互性报文，抖动过大就会导致协议震荡，而实际上所有传输系统都有抖动，但只要抖动在规定容差之内就不会影响服务质量，另外，可利用缓存来克服过量的抖动，但这将会增加时延。 ​ 抖动的大小跟时延的大小直接相关，时延小则抖动的范围也小，时延大则可能抖动的范围也大。 丢包： 丢包率是指在网络传输过程中丢失报文占传输报文的百分比。丢包可用于衡量网络的可靠性。 丢包（packetloss）可能在所有环节中发生，例如： 处理过程：路由器在收到报文的时候可能由于CPU繁忙，无法处理报文而导致丢包； 排队过程：在把报文调度到队列的时候可能由于队列被装满而导致丢包； 传输过程：报文在链路上传输的过程中，可能由于种种原因（如链路故障等）导致的丢包。 少量的丢包对业务的影响并不大，例如，在语音传输中，丢失一个比特或一个报文的信息，通话双方往往注意不到；在视频广播期间，丢失一个比特或一个报文可能造成屏幕上瞬间的波形干扰，但视频很快就会恢复正常。即使使用传输控制协议（TCP）传送数据也能处理少量的丢包，但大量的丢包就会严重影响到传输效率。 QoS的功能： 分组分类器和标记器 网络边界上的路由器根据TCP/IP分组报头中的一个或多个字段，使用分类器功能来标记识别属于特定通信类的分组，然后用标记器功能标记已被分类的通信，这是通过设置IP优先字段或区分服务代码点（DSCP）字段来实现的。 通信速率管理 服务提供商使用控制(policing)功能度量进入网络的客户通信，并将其与客户的通信配置文件(profile)进行比较。同时，接入服务提供商网络的企业可能需要使用通信整形功能 来度量其所有的通信，并以恒定的速率将它们发送出去，以符合服务提供商的控制功能。令牌桶一种常用的通信度量方案。 资源分配 先进先出 (FIFO) 调度是一种被当前的 Internet 路由器和交换机所广泛采用的传统排队机制。虽然先进先出调度部署起来很简单，但是在提供 QoS 时有一些基本的问题。它没有提供优先级处理对延迟敏感的通信并将其移至队开头的手段，对所有的通信都完全同等地对待，不存在通信区分或服务区分的概念。 对于提供QoS的调度算法，至少要能区分队列中的不同分组，并知道每个分组的服务等级。调度算法决定接下来处理队列中的哪一个分组，而流分组获得服务的频度决定了为这个流分配的带宽或资源。 拥塞避免和分组丢弃策略 在传统的先进先出排队技术中，队列管理是这样实现的：当队列中的分组数量达到队列的最大长度后，将到达的分组全部丢弃。这种队列管理技术叫做尾部丢弃(tail drop), 它只在队列完全填满时发出拥塞信号。在这种情况下，没有使用积极的队列管理来避免拥塞，也没有减小队列尺寸来使排队延迟最小。积极的队列算法管理使得路由器在队列溢出前就可以检测到拥塞。 QoS信令协议 SVP 是在 Internet 上提供端到端 QoS 的 IETF Intserv 体系结构的一部分，它使得应用程序可以向网络提出每个流的服务质贯要求。服务参数用来量化这些要求，供管理控制使用。 交换 路由器的主要功能是根据转发表中的信息快速、高效地将所有输入通信交换到正确的输 出端口和下一中继段地址。传统的基于缓存的转发机制虽然高效，但是由于 它是由通信驱动 的，所以存在扩展性和性能方面的问题，并且在网络不稳定时会增加缓存维护工作，并降低 交换性能。 基于拓扑的转发方法通过建立一个与路由器路由表完全相同的转发表，解决了基于缓存的转发机制中存在的问题。 路由 传统的路由仅仅基于目的地，并且在最短路径上是根据路由表来路由分组的。对于某些网络情况，这显得不够灵活。策略路由是一种 QoS 功能，它使得用户可以不根据目的地进行路由，而是根据各种用户自己可以配置的分组参数进行路由。当前的路由选择协议提供了最短路径路由，它基于量度值（如管理成本、权重或中继段数）来选择路由。分组是根据路由表被传输的，而对流的要求或路由上可用的资源一无所知。 QoS 路由则是一种考虑了流的 QoS 要求的路由选择机制，它在选择路由时，对网络上可用的资源有一定的了解。 QoS服务模型尽力而为的服务模型（Best-Effort）： Best-Effort是一个单一的服务模型，也是最简单的服务模型。应用程序可以在任何时候，发出任意数量的报文，而且不需要事先获得批准，也不需要通知网络。 应用Best-Effort服务模型的网络尽最大的可能性来发送报文，但对时延、可靠性等性能不提供任何保证，但它适用于绝大多数网络应用，如FTP、E-Mail等。 Best-Effort服务是现在Internet的缺省服务模型，它是通过先入先出（FIFO）队列来实现的。 在尽力而为的服务模型下，可通过增大网络带宽和升级网络设备来提高端到端通信质量： 增大网络带宽：可以增大单位时间内传输的数据量，使其按照传统先进先出的方式在单位时间内传输更多的数据，改善网络拥塞问题。 升级网络设备：可以增大数据处理能力，使其按照传统先进先出的方式在单位时间内能够处理更多的数据，改善网络拥塞问题。 综合服务模型(Integrated Services)：RSVP协议工作过程：在应用程序发送报文前，需要向网络申请特定的带宽和所需的特定服务质量的请求，等收到确认信息后才发送报文。 综合服务模型（IntegratedServicesModel）： IntServ是一种最为复杂的服务模型，它需要用到RSVP（ResourceReservation Protocol）协议。该服务模型在发送报文前，需要向网络申请特定的服务。这个请求是通过信令（signal）来完成的，应用程序首先通知网络它自己的流量参数和所需的特定服务质量的请求，包括带宽、时延等。应用程序一般在收到网络的确认信息后，即认为网络已经为这个应用程序的报文发送预留了资源，然后立即发送报文。 IntServ模型要求端到端网络的所有节点都支持RSVP协议，且每个节点都需要周期性地同相邻节点交换状态信息，这样就会加大协议报文导致的开销。更关键的是，所有网络节点都需要为每个数据流保存状态信息，而当前在Internet骨干网上有着成千上万条数据流，因此IntServ模型在Internet骨干网上无法得到广泛应用。 区分服务模型（DiffServ）：DiffServ区分服务工作过程：首先将网络中的流量分成多个类，然后为每个类定义相应的处理行为，使其拥有不同的优先转发、丢包率、时延等。 Diffserv服务模型概述： 业务流分类和标记由边缘路由器来完成。边界路由器可以通过多种条件（比如报文的源地址和目的地址、ToS域中的优先级、协议类型等）灵活地对报文进行分类，然后对不同类型的报文设置不同的标记字段，而其他路由器只需要简单地识别报文中的这些标记，然后对其进行相应的资源分配和流量控制即可。因此，DiffServ是一种基于报文流的QoS模型。 它只包含有限数量的服务等级，少量的状态信息来提供有差别的流量控制和转发。 DS节点：实现DiffServ功能的网络节点称为DS节点。 DS边界节点：负责连接另一个DS域或者连接一个没有DS功能的域的节点。DS边界节点负责将进入此DS域的业务流进行分类和流量调整。 DS内部节点：用于在同一个DS域中连接DS边界节点和其他内部节点。DS内部节点仅需基于报文中的EXP、802.1p、IPP等字段值进行简单的流分类以及对相应的流进行流量控制。 DS域（DSDomain）：一组采用相同的服务提供策略和实现了相同PHB（PerHop Behaviors）的相连DS节点组成。一个DS域由相同管理部门的一个或多个网络组成，如一个DS域可以是一个ISP，也可以是一个企业的内部网络。 DiffServ模型充分考虑了IP网络本身所具有的灵活性、可扩展性强等特点，将复杂的服务质量保证通过报文自身携带的信息转换为单跳行为，从而大大减少了信令的工作。该模型是目前应用最广的服务模型。 三种服务模型的对比： 优点 缺点 尽力而为服务模型 实现机制简单 对不同业务流不能进行区分对待 综合服务模型 可提供端到端QoS服务，并保证带宽、延迟 需要跟踪和记录每个数据流的状态，实现较复杂，且扩展性较差，带宽利用率较低 区分服务模型 不需跟踪每个数据流状态，资源占用少，扩展性较强； 且能实现对不同业务流提供不同的服务质量 需要在端到端每个节点都进行手工部署，对人员能力要求较高 MQC简介模块化QoS命令行MQC（Modular QoS Command-Line Interface）是指通过将具有某类共同特征的报文划分为一类，并为同一类报文提供相同的服务，也可以对不同类的报文提供不同的服务。 随着网络中QoS业务的不断丰富，在网络规划时若要实现对不同流量（如不同业务或不同用户）的差分服务，会使部署比较复杂。MQC的出现，使用户能对网络中的流量进行精细化处理，用户可以更加便捷的针对自己的需求对网络中的流量提供不同的服务，完善了网络的服务能力。 MQC三要素：MQC包含三个要素：流分类（traffic classifier）、流行为（traffic behavior）和流策略（traffic policy）。 流分类 流分类用来定义一组流量匹配规则，以对报文进行分类。 流分类中各规则之间的关系分为：and或or，缺省情况下的关系为or 流行为 流行为用来定义针对某类报文所做的动作。 流策略 流策略用来将指定的流分类和流行为绑定，对分类后的报文执行对应流行为中定义的动作。 一个流策略可以绑定多个流分类和流行为。 MQC配置流程： 配置流分类：按照一定规则对报文进行分类，是提供差分服务的基础。 配置流行为：为符合流分类规则的报文指定流量控制或资源分配动作。 配置流策略：将指定的流分类和指定的流行为绑定，形成完整的策略。 应用流策略：将流策略应用到接口或子接口。 MQC配置命令行：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768classifier behavior//在流策略中为指定的流分类配置所需流行为，即绑定流分类和流行为。display traffic behavior//查看已配置的流行为信息。if-match 8021p 8021p-value &amp;&lt;1-8&gt;//创建基于VLAN报文的802.1p优先级进行分类的匹配规则。if-match acl//创建基于ACL进行分类的匹配规则。if-match any//创建基于所有数据报文进行分类的匹配规则。if-match cvlan-8021p 8021p-value &amp;&lt;1-8&gt;//创建基于QinQ报文内层802.1p优先级进行分类的匹配规则。if-match destination-mac//创建基于目的MAC地址进行分类的匹配规则。if-match [ ipv6 ] dscp dscp-value &amp;&lt;1-8&gt;//创建基于报文DSCP值进行分类的匹配规则。if-match fr-de//创建基于FR报文中的DE标志位进行分类的匹配规则。if-match inbound-interface//创建基于入接口对报文进行分类的匹配规则。if-match ip-precedence ip-precedence-value &amp;&lt;1-8&gt;//创建基于IP优先级进行分类的匹配规则。if-match l2-protocol &#123; arp | ip | mpls | rarp | protocol-value &#125;//创建基于二层封装的协议字段进行分类的匹配规则。if-match mpls-exp exp-value &amp;&lt;1-8&gt;//配置基于MPLS报文中的EXP字段进行分类的匹配规则。if-match outbound-interface//创建基于Cellular出通道口对报文进行分类的匹配规则。if-match packet-length//创建基于IPv4报文长度进行分类的匹配规则。if-match protocol &#123; ip | ipv6 &#125;//创建基于协议进行分类的匹配规则。if-match qos-group//创建基于QoS group索引进行分类的匹配规则。if-match source-mac//创建基于源MAC地址进行分类的匹配规则。if-match tcp syn-flag &#123; ack | fin | psh | rst | syn | urg &#125;*//创建基于TCP报文头中的SYN Flag进行分类的匹配规则。if-match user-set//创建基于用户组进行分类的匹配规则。if-match vlan-id//创建基于VLAN ID进行分类的匹配规则。if-match dlci//if-match dlciif-match pvc//创建基于ATM报文中的PVC信息进行分类的匹配规则。ip netstream sampler//配置IPv4报文的采样统计功能。qos pre-nat//使能NAT预分类功能。remark 8021p 8021p-value//标记VLAN报文802.1p优先级的动作。remark dscp &#123; dscp-name | dscp-value &#125;//标记IP报文的DSCP优先级的动作。remark local-precedence//创建重标记内部优先级的动作。remark cvlan-8021p//标记QinQ报文内层802.1p优先级值的动作。remark fr-de//标记FR报文的DE标志位的动作。remark mpls-exp//标记MPLS报文中的EXP优先级的动作。remark qos-group//配置报文所属的QoS group。url-filter-profile//在流行为中绑定URL过滤模板。 优先级映射概述优先级映射用来实现报文携带的QoS优先级与设备内部优先级（又称为本地优先级，是设备内部区分报文服务等级的优先级）之间的转换，从而设备根据内部优先级提供有差别的QoS服务质量。 用户可以根据网络规划在不同网络中使用不同的QoS优先级字段，例如在VLAN网络中使用802.1p，IP网络中使用DSCP，MPLS网络中使用EXP。当报文经过不同网络时，为了保持报文的优先级，需要在连接不同网络的设备上配置这些优先级字段的映射关系。当设备连接不同网络时，所有进入设备的报文，其外部优先级字段（包括802.1p、DSCP和MPLS EXP）都被映射为内部优先级；设备发出报文时，将内部优先级映射为某种外部优先级字段。 原理描述：不同的报文使用不同的QoS优先级，例如VLAN报文使用802.1p，IP报文使用DSCP，MPLS报文使用EXP。当报文经过不同网络时，为了保持报文的优先级，需要在连接不同网络的网关处配置这些优先级字段的映射关系。 优先级映射实现从QoS优先级到内部优先级（或者本地优先级）或从内部优先级到QoS优先级的映射，并利用DiffServ域来管理和记录QoS优先级和服务等级之间的映射关系。对于进入设备的报文，设备将报文携带的优先级或者端口优先级映射为内部优先级，然后根据内部优先级与队列之间的映射关系确定报文进入的队列，从而针对队列进行流量整形、拥塞避免、队列调度等处理，并可以根据配置修改报文发送出去时所携带的优先级，以便其他设备根据报文的优先级提供相应的QoS服务。 QoS优先级字段：为了在Internet上针对不同的业务提供有差别的QoS服务质量，人们根据报文头中的某些字段记录QoS信息，从而让网络中的各设备根据此信息提供有差别的服务质量。这些和QoS相关的报文字段包括： Precedence字段根据RFC791定义，IP报文头ToS（Type of Service）域由8个比特组成，其中3个比特的Precedence字段标识了IP报文的优先级，Precedence在报文中的位置如下图所示： 图：IP Precedenc/DSCP字段 比特0～2表示Precedence字段，代表报文传输的8个优先级，按照优先级从高到低顺序取值为7、6、5、4、3、2、1和0。最高优先级是7或6，经常是为路由选择或更新网络控制通信保留的，用户级应用仅能使用0～5。 除了Predecence字段外，ToS域中还包括D、T、R三个比特： D比特表示延迟要求（Delay，0代表正常延迟，1代表低延迟）。 T比特表示吞吐量（Throughput，0代表正常吞吐量，1代表高吞吐量）。 R比特表示可靠性（Reliability，0代表正常可靠性，1代表高可靠性）。 DSCP字段 RFC1349重新定义了IP报文中的ToS域，增加了C比特，表示传输开销（Monetary Cost）。之后，IETF DiffServ工作组在RFC2474中将IPv4报文头ToS域中的比特0～5重新定义为DSCP，并将ToS域改名为DS（Differentiated Service）字节。 DS字段的前6位（0位～5位）用作区分服务代码点DSCP（DS Code Point），后2位（6位、7位）是保留位。DS字段的前3位（0位～2位）是类选择代码点CSCP（Class Selector Code Point），相同的CSCP值代表一类DSCP。DS节点根据DSCP的值选择相应的PHB（Per-Hop Behavior）。 lDSCP值有两种表达方式：（PHB） 数字形式：DSCP取值范围为0~63； 关键字表达方式：用关键字标识的DSCP值。 图：DSCP优先级 AFxy中，x代表不同的类别，根据不同的分类后续可以定义进入相对应的队列，y代表当队列被装满的时候丢包的概率，例如AF1类中的报文，其中丢包概率由小到大排序为AF11&lt;AF12&lt;AF13。 不同关键字常用于标识不同报文（可自行定义）： CS6和CS7默认用于协议报文，而且是大多数厂商设备的硬件队列里最高优先级的报文，因为如果这些报文无法接收的话会引起协议中断。 EF常用于承载语音的流量，因为语音要求低延迟，低抖动，低丢包率，是仅次于协议报文的最重要的报文。 AF4用来承载语音的信令流量. AF3可以用来承载IPTV的直播流量，直播的实时性很强，需要连续性和大吞吐量的保证。 AF2可以用来承载VOD（Videoon Demand：视频点播）的流量，相对于直播流量来说，VOD对实时性要求没那么强烈，允许有时延或者缓冲。 AF1可以用来承载普通上网业务。 VLAN帧头中的802.1p优先级：通常二层设备之间交互VLAN帧。根据IEEE 802.1Q定义，VLAN帧头中的PRI字段（即802.1p优先级），或称CoS（Class of Service）字段，标识了服务质量需求。 VLAN帧中的PRI字段位置如下图所示： 图：VLAN帧中的802.1p优先级 在802.1Q头部中包含3比特长的PRI字段。PRI字段定义了8种业务优先级CoS，按照优先级从高到低顺序取值为7、6、5、4、3、2、1和0。 MPLS EXP字段：MPLS报文与普通的IP报文相比增加了标签信息。标签的长度为4个字节，封装结果如下图所示： 图：MPLS标签的封装格式 标签共有4个域： Label：20比特，标签值字段，用于转发的指针。 EXP：3比特，保留字段，用于扩展，现在通常用做CoS。 S：1比特，栈底标识。MPLS支持标签的分层结构，即多重标签，S值为1时表明为最底层标签。 TTL：8比特，和IP分组中的TTL（Time To Live）意义相同。 对于MPLS报文，通常将标签信息中的EXP域作为MPLS报文的CoS域，与IP网络的ToS域等效，用来区分数据流量的服务等级，以支持MPLS网络的DiffServ。EXP字段表示8个传输优先级，按照优先级从高到低顺序取值为7、6、5、4、3、2、1和0。 在IP网络，由IP报文的IP优先级或DSCP标识服务等级。但是对于MPLS网络，由于报文的IP头对LSR（Label Switching Router）设备是不可见的，所以需要在MPLS网络的边缘对MPLS报文的EXP域进行标记。 缺省的情况下，在MPLS网络的边缘，将IP报文的IP优先级直接拷贝到MPLS报文的EXP域；但是在某些情况下，如ISP不信任用户网络、或者ISP定义的差别服务类别不同于用户网络，则可以根据一定的分类策略，依据内部的服务等级重新设置MPLS报文的EXP域，而在MPLS网络转发的过程中保持IP报文的ToS域不变。 在MPLS网络的中间节点，根据MPLS报文的EXP域对报文进行分类，并实现拥塞管理，流量监管或者流量整形等PHB行为。 DSCP/ IP-Precedence/ 802.1p/ EXP值表: 图：映射表 配置优先级映射: 信任报文的802.1p优先级 对于带VLAN Tag的报文，设备根据报文携带的802.1p优先级查找优先级映射表，确定报文进入的队列，并可以修改报文的优先级值。 对于不带VLAN Tag的报文，设备将使用端口优先级作为802.1p优先级，查找优先级映射表，确定报文进入的队列，并可以修改报文的优先级值。 信任报文的DSCP优先级 设备按照报文携带的DSCP优先级查找DSCP优先级映射表，确定报文进入的队列，并可以修改报文的优先级值。 信任报文的MPLS EXP优先级 设备按照报文携带的MPLS EXP优先级查找MPLS EXP优先级映射表，确定报文进入的队列，并可以修改报文的优先级值。 12345678input 0 to 15 output 0//配置各优先级之间的映射关系。port priority priority-value//配置端口优先级值。qos map-table//用来进入Dot1p、MPLS EXP或DSCP映射表视图。trust &#123; 8021p [ override ] | dscp [ override ] | exp &#125;//指定对报文按照某类优先级进行映射。 简单流分类： 简单流分类是指根据IP报文的IP优先级或DSCP值、MPLS报文的EXP域值、VLAN报文的802.1p值，将报文划分为多个优先级或多个服务等级。配置基于简单流分类的流量策略可以将一种网络流量中的优先级映射到另外一种网络流量中，使流量在另外一种网络中按照原来的优先级传送。 简单流分类的应用场景：在IP，MPLS，VLAN报文跨域转换时，可以使用简单流分类实现DSCP/IP-PRE/EXP/802.1P之间的映射，并保证报文的服务等级不受变化。 简单流分类通常配置在网络的核心位置。 简单流分类不止应用在物理端口，还可以用于逻辑端口。在企业组网中逻辑端口有更加广阔的应用。 复杂流分类：复杂流分类是指根据五元组（源地址、源端口号、协议号码、目的地址、目的端口号）等报文信息对报文进行分类（一般的分类依据都局限在封装报文的头部信息，使用报文内容作为分类的标准比较少见），缺省应用于网络的边缘位置。报文进入边缘节点时，网络管理者可以灵活配置分类规则。分类的结果是没有范围限制的，它可以是一个由五元组（源地址、源端口号、协议号码、目的地址、目的端口号）确定的狭小范围，也可以是匹配某网段的所有报文。 复杂流分类通过提取报文信息，如报文优先级、源IP、目的IP、源MAC、目的MAC、802.1p、报文封装类型等等，组成关键字去匹配规则表，然后通过匹配规则得到一个索引，再根据索引查动作表，将报文映射为内部优先级，除了映射内部优先级外，复杂流分类还可以支持流量监管(CAR)、PBR（ Policy-basedRouting ）、重标记，报文过滤、采样、镜像等其它动作。 链路效率机制VRP提供了两种链路效率机制：IP报文头压缩协议（IPHeader Compression，IPHC）和链路分片与交叉（LinkFragmentation and Interleaving，LFI）。 其中IP报文头压缩协议可以对RTP和TCP报文头进行压缩。 对于同一个流的数据部，IP头部的大部分字段是相同的，因此可以对这些字段进行压缩，提高链路传输的效率。 LFI技术主要在低速链路上使用，目的是减小实时数据报文的延时和抖动。 ##IPHC： IP报文头压缩协议（IPHeader Compression，IPHC）是一个主机-主机协议，用于在IP网络上承载语音、视频等实时多媒体业务，是在PPP链路和FR链路应用的低速链路技术。IPHC支持对RTP和TCP报文头的压缩。 RTP包括数据部分和头部分，RTP的数据部分相对较小，而RTP的头部分较大。12字节的RTP头，加上20字节的IP头和8字节的UDP头，就是40字节的IP/UDP/RTP头。而RTP典型的负载是20字节到160字节。为了避免不必要的带宽消耗，可以使用IPHC特性对报文头进行压缩。IPHC将IP/UDP/RTP头从40字节压缩到2～4字节，对于40字节的负载，头压缩到4字节，压缩比为（40+40）/（40+4），约为1.82，可见效果是相当可观的。 对于TCP数据包，IP头加上TCP头一共40字节，使用TCP压缩，可以压缩到3～5字节。 LFI：链路分片与交叉是在PPP链路和FR链路应用的低速链路技术。 在低速串行链路上，实时交互式通信，如Telnet和VoIP，往往会由于大型分组的发送而导致阻塞延迟，例如，正好在大报文被调度而等待发送时，语音报文到达，它需要等该大报文被传输完毕后才能被调度。对于诸如交互式语音等实时应用而言，大报文导致的这种阻塞延迟太长了，对端将听到断断续续的话音。交互式语音要求端到端的延迟不大于100～150ms。 一个1500bytes（即通常MTU的大小）的报文需要花费215ms穿过56Kbps的链路，这超过了人所能忍受的延迟限制。为了在相对低速的链路上限制实时报文的延迟时间，例如56KbpsFrame Relay或64KbpsISDN B通道，需要一种方法将大报文进行分片，将小报文和大报文的分片一起加入到队列。 LFI将大型数据帧分割成小型帧，与其他小片的报文一起发送，从而减少在速度较慢的链路上的延迟和抖动。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>QoS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCPv6基础]]></title>
    <url>%2F2018%2F02%2F01%2FDHCPv6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[DHCPv6简介IPv6动态主机配置协议DHCPv6(Dynamic Host Configuration Protocol for IPv6)是针对IPv6编址方案设计，为主机分配IPv6地址/前缀和其他网络配置参数。 目的：IPv6协议具有地址空间巨大的特点，但同时长达128比特的IPv6地址又要求高效合理的地址自动分配和管理策略。IPv6无状态地址配置方式（参看协议RFC2462）是目前广泛采用的IPv6地址自动配置方式。配置了该协议的主机只需相邻设备开启IPv6路由通告功能，即可以根据通告报文包含的前缀信息自动配置本机地址。 无状态地址配置方案中设备并不记录所连接的IPv6主机的具体地址信息，可管理性差。而且当前无状态地址配置方式不能使IPv6主机获取DNS服务器的IPv6地址等配置信息，在可用性上有一定缺陷。对于互联网服务提供商来说，也没有相关的规范指明如何向设备自动分配IPv6前缀，所以在部署IPv6网络时，只能采用手动配置的方法为设备配置IPv6地址。 DHCPv6技术解决了这一问题。DHCPv6属于一种有状态地址自动配置协议。 与其他IPv6地址分配方式（手工配置、通过路由器通告消息中的网络前缀无状态自动配置等）相比，DHCPv6具有以下优点： 更好地控制IPv6地址的分配。DHCPv6方式不仅可以记录为IPv6主机分配的地址，还可以为特定的IPv6主机分配特定的地址，以便于网络管理。 DHCPv6支持为网络设备分配IPv6前缀，便于全网络的自动配置和网络层次性管理。 除了为IPv6主机分配IPv6地址/前缀外，还可以分配DNS服务器IPv6地址等网络配置参数。 DHCPv6原理描述DHCPv6概述：DHCPv6是一种运行在客户端和服务器之间的协议，与IPv4中的DHCP一样，所有的协议报文都是基于UDP的。但是由于在IPv6中没有广播报文，因此DHCPv6使用组播报文，客户端也无需配置服务器的IPv6地址。 IPv6地址分配类型：IPv6协议具有地址空间巨大的特点，但同时长达128比特的IPv6地址又要求高效合理的地址自动分配和管理策略。 手动配置。手动配置IPv6地址/前缀及其他网络配置参数（DNS、NIS、SNTP服务器地址等参数）。 无状态自动地址分配。由接口ID生成链路本地地址，再根据路由通告报文RA（Router Advertisement）包含的前缀信息自动配置本机地址。 有状态自动地址分配，即DHCPv6方式。DHCPv6又分为如下两种: DHCPv6有状态自动分配。DHCPv6服务器自动分配IPv6地址/PD前缀及其他网络配置参数（DNS、NIS、SNTP服务器地址等参数）。 DHCPv6无状态自动分配。主机IPv6地址仍然通过路由通告方式自动生成，DHCPv6服务器只分配除IPv6地址以外的配置参数，包括DNS、NIS、SNTP服务器等参数。 DHCPv6基本架构： 图：DHCPv6基本架构 DHCPv6基本协议架构中，主要包括以下三种角色： DHCPv6 Client： DHCPv6客户端，通过与DHCPv6服务器进行交互，获取IPv6地址/前缀和网络配置信息，完成自身的地址配置功能。 DHCPv6 Relay： DHCPv6中继代理，负责转发来自客户端方向或服务器方向的DHCPv6报文，协助DHCPv6客户端和DHCPv6服务器完成地址配置功能。一般情况下，DHCPv6客户端通过本地链路范围的组播地址与DHCPv6服务器通信，以获取IPv6地址/前缀和其他网络配置参数。如果服务器和客户端不在同一个链路范围内，则需要通过DHCPv6中继代理来转发报文，这样可以避免在每个链路范围内都部署DHCPv6服务器，既节省了成本，又便于进行集中管理。 DHCPv6基本协议架构中，DHCPv6中继代理不是必须的角色。如果DHCPv6客户端和DHCPv6服务器位于同一链路范围内，或DHCPv6客户端和DHCPv6服务器直接通过单播交互完成地址分配或信息配置的情况下，是不需要DHCPv6中继代理参与的。只有当DHCPv6客户端和DHCPv6服务器不在同一链路范围内，或DHCPv6客户端和DHCPv6服务器无法单播交互的情况下，才需要DHCPv6中继代理的参与。 DHCPv6 Server： DHCPv6服务器，负责处理来自客户端或中继代理的地址分配、地址续租、地址释放等请求，为客户端分配IPv6地址/前缀和其他网络配置信息。 DHCPv6基本概念：组播地址 在DHCPv6协议中，客户端不用配置DHCPv6 Server的IPv6地址，而是发送目的地址为组播地址的Solicit报文来定位DHCPv6服务器。 在DHCPv4协议中，客户端发送广播报文来定位服务器。为避免广播风暴，在IPv6中，已经没有了广播类型的报文，而是采用组播报文。DHCPv6用到的组播地址有两个： FF02::1:2（All DHCP Relay Agents and Servers）：所有DHCPv6服务器和中继代理的组播地址，这个地址是链路范围的，用于客户端和相邻的服务器及中继代理之间通信。所有DHCPv6服务器和中继代理都是该组的成员。 FF05::1:3（All DHCP Servers）：所有DHCPv6服务器组播地址，这个地址是站点范围的，用于中继代理和服务器之间的通信，站点内的所有DHCPv6服务器都是此组的成员。 UDP端口号 DHCPv6报文承载在UDPv6上。 客户端侦听的UDP目的端口号是546。 服务器、中继代理侦听的UDP端口号是547。 DHCP唯一标识符（DUID） DHCP设备唯一标识符DUID（DHCPv6 Unique Identifier），每个服务器或客户端有且只有一个唯一标识符，服务器使用DUID来识别不同的客户端，客户端则使用DUID来识别服务器。 客户端和服务器DUID的内容分别通过DHCPv6报文中的Client Identifier和Server Identifier选项来携带。两种选项的格式一样，通过option-code字段的取值来区分是Client Identifier还是Server Identifier选项。 身份联盟（IA） 身份联盟IA（Identity Association）是使得服务器和客户端能够识别、分组和管理一系列相关IPv6地址的结构。每个IA包括一个IAID和相关联的配置信息。 客户端必须为它的每一个要通过服务器获取IPv6地址的接口关联至少一个IA。客户端用给接口关联的IA来从服务器获取配置信息。每个IA必须明确关联到一个接口。 IA的身份由IAID唯一确定，同一个客户端的IAID不能出现重复。IAID不应因为设备的重启等因素发生丢失或改变。 IA中的配置信息由一个或多个IPv6地址以及T1和T2生存期组成。IA中的每个地址都有首选生存期和有效生存期。 一个接口至少关联一个IA，一个IA可以包含一个或多个地址信息。 DHCPv6报文类型DHCPv6报文格式： 图：DHCPv6的报文格式 字段 长度 含义 msg-type 1字节 表示报文的类型，取值为1～13，具体请参见DHCPv6报文类型。 transaction-ID 3字节 DHCPv6交互ID，也叫事务ID，用来标识一个来回的DHCPv6报文交互。例如Solicit/Advertise报文为一个交互。Request/Reply报文为另外一个交互，两者有不同的事务ID。交互ID特点如下：交互ID是DHCPv6客户端生成的一个随机值，DHCPv6客户端应当保证交互ID具有一定的随机性。对于DHCPv6服务器响应报文和相应的请求报文，两者交互ID保持一致。如果是DHCPv6服务器主动发起的会话报文，则交互ID为0。 Options 可变 表示DHCPv6的选项字段。此字段包含了DHCPv6服务器分配给IPv6主机的配置信息，如DNS服务器的IPv6地址等信息。 DHCPv6报文类型：目前DHCPv6定义了如下十三种类型报文，DHCPv6服务器和DHCPv6客户端之间通过这十三种类型的报文进行通信。 DHCPv6和DHCPv4报文对比： 报文类型 DHCPv6报文 DHCPv4报文 说明 1 SOLICIT DHCP DISCOVER DHCPv6客户端使用Solicit报文来确定DHCPv6服务器的位置。 2 ADVERTISE DHCP OFFER DHCPv6服务器发送Advertise报文来对Solicit报文进行回应，宣告自己能够提供DHCPv6服务。 3 REQUEST DHCP REQUEST DHCPv6客户端发送Request报文来向DHCPv6服务器请求IPv6地址和其它配置信息。 4 CONFIRM - DHCPv6客户端向任意可达的DHCPv6服务器发送Confirm报文检查自己目前获得的IPv6地址是否适用与它所连接的链路。 5 RENEW DHCP REQUEST DHCPv6客户端向给其提供地址和配置信息的DHCPv6服务器发送Renew报文来延长地址的生存期并更新配置信息。 6 REBIND DHCP REQUEST 如果Renew报文没有得到应答，DHCPv6客户端向任意可达的DHCPv6服务器发送Rebind报文来延长地址的生存期并更新配置信息。 7 REPLY DHCP ACK/NAK DHCPv6服务器在以下场合发送Reply报文：DHCPv6服务器发送携带了地址和配置信息的Reply消息来回应从DHCPv6客户端收到的Solicit、Request、Renew、Rebind报文。DHCPv6服务器发送携带配置信息的Reply消息来回应收到的Information-Request报文。用来回应DHCPv6客户端发来的Confirm、Release、Decline报文。 8 RELEASE DHCP RELEASE DHCPv6客户端向为其分配地址的DHCPv6服务器发送Release报文，表明自己不再使用一个或多个获取的地址。 9 DECLINE DHCP DECLINE DHCPv6客户端向DHCPv6服务器发送Decline报文，声明DHCPv6服务器分配的一个或多个地址在DHCPv6客户端所在链路上已经被使用了。 10 RECONFIGURE - DHCPv6服务器向DHCPv6客户端发送Reconfigure报文，用于提示DHCPv6客户端，在DHCPv6服务器上存在新的网络配置信息。 11 INFORMATION-REQUEST DHCP INFORM DHCPv6客户端向DHCPv6服务器发送Information-Request报文来请求除IPv6地址以外的网络配置信息。 12 RELAY-FORW - 中继代理通过Relay-Forward报文来向DHCPv6服务器转发DHCPv6客户端请求报文。 13 RELAY-REPL - DHCPv6服务器向中继代理发送Relay-Reply报文，其中携带了转发给DHCPv6客户端的报文。 DHCPv6报文抓包： Solicit报文（类型1）：DHCPv6客户端使用Solicit报文来确定DHCPv6服务器的位置。 图：Solicit报文抓包示例 Advertise报文（类型2）：DHCPv6服务器发送Advertise报文来对Solicit报文进行回应，宣告自己能够提供DHCPv6服务。 图：Advertise报文抓包示例 Request报文（类型3）：DHCPv6客户端发送Request报文来向DHCPv6服务器请求IPv6地址和其它配置信息。 图：Request报文抓包示例 Renew报文（类型5）：DHCPv6客户端向给其提供地址和配置信息的DHCPv6服务器发送Renew报文来延长地址的生存期并更新配置信息。 图：Renew报文抓包示例 Rebind报文（类型6）：如果Renew报文没有得到应答，DHCPv6客户端向任意可达的DHCPv6服务器发送Rebind报文来延长地址的生存期并更新配置信息。 图：Rebind报文抓包示例 Reply报文（类型7）：DHCPv6服务器在以下场合发送Reply报文：DHCPv6服务器发送携带了地址和配置信息的Reply消息来回应从DHCPv6客户端收到的Solicit、Request、Renew、Rebind报文。DHCPv6服务器发送携带配置信息的Reply消息来回应收到的Information-Request报文。用来回应DHCPv6客户端发来的Confirm、Release、Decline报文。 图：Reply报文抓包示例 Release(类型8);DHCPv6客户端向为其分配地址的DHCPv6服务器发送Release报文，表明自己不再使用一个或多个获取的地址。 图：Release报文抓包示例 Reply-forw报文（类型12）：中继代理通过Relay-Forward报文来向DHCPv6服务器转发DHCPv6客户端请求报文。 图：Relay-Forw报文抓包示例 Relay-reply报文（类型13）：DHCPv6服务器向中继代理发送Relay-Reply报文，其中携带了转发给DHCPv6客户端的报文。 图：Relay-Reply报文抓包示例 DHCPv6工作原理：：DHCPv6自动分配分为DHCPv6有状态自动分配和DHCPv6无状态自动分配。 DHCPv6有状态自动分配。DHCPv6服务器自动配置IPv6地址/前缀，同时分配DNS、NIS、SNTP服务器等网络配置参数。 DHCPv6无状态自动分配。主机IPv6地址仍然通过路由通告方式自动生成，DHCP服务器只分配除IPv6地址以外的配置参数，包括DNS、NIS、SNTP服务器地址等参数。 DHVPv6有状态自动分配：IPv6主机通过有状态DHCPv6方式获取IPv6地址和其他配置参数（例如DNS服务器的IPv6地址等）。 DHCPv6服务器为客户端分配地址/前缀的过程分为两类： DHCPv6四步交互分配过程 DHCPv6两步交互快速分配过程 DHCPv6四步交互 四步交互常用于网络中有多个DHCPv6服务器的情况。DHCPv6客户端首先通过组播发送Solicit报文来定位可以为其提供服务的DHCPv6服务器，在收到多个DHCPv6服务器的Advertise报文后，根据DHCPv6服务器的优先级选择一个为其分配地址和配置信息的服务器，接着通过Request/Reply报文交互完成地址申请和分配过程。 DHCPv6服务器端如果没有配置使能两步交互，无论客户端报文中是否包含Rapid Commit选项，服务器都采用四步交互方式为客户端分配地址和配置信息。 DHCPv6四步交互地址分配过程如下： 图：DHCPv6四步交互地址分配过程 DHCPv6四步交互地址分配过程如下： DHCPv6客户端发送Solicit报文，请求DHCPv6服务器为其分配IPv6地址和网络配置参数。 如果Solicit报文中没有携带Rapid Commit选项，或Solicit报文中携带Rapid Commit选项，但服务器不支持快速分配过程，则DHCPv6服务器回复Advertise报文，通知客户端可以为其分配的地址和网络配置参数。 如果DHCPv6客户端接收到多个服务器回复的Advertise报文，则根据Advertise报文中的服务器优先级等参数，选择优先级最高的一台服务器，并向所有的服务器发送Request组播报文，该报文中携带已选择的DHCPv6服务器的DUID。 DHCPv6服务器回复Reply报文，确认将地址和网络配置参数分配给客户端使用。 DHCPv6两步交互 两步交互常用于网络中只有一个DHCPv6服务器的情况。DHCPv6客户端首先通过组播发送Solicit报文来定位可以为其提供服务的DHCPv6服务器，DHCPv6服务器收到客户端的Solicit报文后，为其分配地址和配置信息，直接回应Reply报文，完成地址申请和分配过程。 两步交换可以提高DHCPv6过程的效率，但在有多个DHCPv6服务器的网络中，多个DHCPv6服务器都可以为DHCPv6客户端分配IPv6地址，回应Reply报文，但是客户端实际只可能使用其中一个服务器为其分配的IPv6地址和配置信息。为了防止这种情况的发生，管理员可以配置DHCPv6服务器是否支持两步交互地址分配方式。 DHCPv6服务器端如果配置使能了两步交互，并且客户端报文中也包含Rapid Commit选项，服务器采用两步交互方式为客户端分配地址和配置信息。 如果DHCPv6服务器不支持快速分配地址，则采用四步交互方式为客户端分配IPv6地址和其他网络配置参数。 DHCPv6两步交互地址分配过程如下图： 图：DHCPv6两步交互地址分配过程 DHCPv6两步交互地址分配过程如下： DHCPv6客户端在发送的Solicit报文中携带Rapid Commit选项，标识客户端希望服务器能够快速为其分配地址和网络配置参数。 DHCPv6服务器接收到Solicit报文后，将进行如下处理： 如果DHCPv6服务器支持快速分配地址，则直接返回Reply报文，为客户端分配IPv6地址和其他网络配置参数，Replay报文中也携带Rapid Commit选项。 如果DHCPv6服务器不支持快速分配过程，则采用四步交互方式为客户端分配IPv6地址/前缀和其他网络配置参数。 DHCPv6无状态自动分配：IPv6节点可以通过DHCPv6无状态方式获取配置参数（包括DNS、SIP、SNTP等服务器配置信息，不包括IPv6地址）。 DHCPv6无状态工作过程如下图所示： 图：DHCPv6无状态工作过程 DHCPv6无状态工作过程如下： DHCPv6客户端以组播方式向DHCPv6服务器发送Information-Request报文，该报文中携带Option Request选项，指定DHCPv6客户端需要从DHCPv6服务器获取的配置参数。 DHCPv6服务器收到Information-Request报文后，为DHCPv6客户端分配网络配置参数，并单播发送Reply报文，将网络配置参数返回给DHCPv6客户端。DHCPv6客户端根据收到Reply报文提供的参数完成DHCPv6客户端无状态配置。 DHCPv6 PD工作原理：DHCPv6前缀代理DHCPv6 PD(Prefix Delegation)是由Cisco公司提出的一种前缀分配机制，并在RFC3633中得以标准化。在一个层次化的网络拓扑结构中，不同层次的IPv6地址分配一般是手工指定的。手工配置IPv6地址扩展性不好，不利于IPv6地址的统一规划管理。 通过DHCPv6前缀代理机制，下游网络设备不需要再手工指定用户侧链路的IPv6地址前缀，它只需要向上游网络设备提出前缀分配申请，上游网络设备便可以分配合适的地址前缀给下游设备，下游设备把获得的前缀(一般前缀长度小于64)进一步自动细分成64前缀长度的子网网段，把细分的地址前缀再通过路由通告(RA)至与IPv6主机直连的用户链路上，实现IPv6主机的地址自动配置，完成整个系统层次的地址布局。 DHCPv6 PD工作过程下图所示： 图：DHCPv6 PD工作原理 DHCPv6 PD四步交互地址分配过程如下： DHCPv6 PD客户端发送Solicit报文，请求DHCPv6 PD服务器为其分配IPv6地址前缀。 如果Solicit报文中没有携带Rapid Commit选项，或Solicit报文中携带Rapid Commit选项，但服务器不支持快速分配过程，则DHCPv6服务器回复Advertise报文，通知客户端可以为其分配的IPv6地址前缀。 如果DHCPv6客户端接收到多个服务器回复的Advertise报文，则根据Advertise报文中的服务器优先级等参数，选择优先级最高的一台服务器，并向该服务器发送Request报文，请求服务器确认为其分配地址前缀。 DHCPv6 PD服务器回复Reply报文，确认将IPv6地址前缀分配给DHCPv6 PD客户端使用。 DHCPv6中继工作原理：DHCPv6客户端通过DHCPv6中继转发报文，获取IPv6地址/前缀和其他网络配置参数（例如DNS服务器的IPv6地址等）。 DHCPv6中继工作过程如下图所示： 图：DHCPv6中继工作原理 DHCPv6中继工作交互过程如下： DHCPv6客户端向所有DHCPv6服务器和DHCPv6中继发送目的地址为FF02::1:2（组播地址）的请求报文。 根据DHCPv6中继转发报文有如下两种情况： 如果DHCPv6中继和DHCPv6客户端位于同一个链路上，即DHCPv6中继为DHCPv6客户端的第一跳中继，中继转发直接来自客户端的报文，此时DHCPv6中继实质上也是客户端的IPv6网关设备。DHCPv6中继收到客户端的报文后，将其封装在Relay-Forward报文的中继消息选项（Relay Message Option）中，并将Relay-Forward报文发送给DHCPv6服务器或下一跳中继。 如果DHCPv6中继和DHCPv6客户端不在同一个链路上，中继收到的报文是来自其他中继的Relay-Forward报文。中继构造一个新的Relay-Forward报文，并将Relay-Forward报文发送给DHCPv6服务器或下一跳中继。 DHCPv6服务器从Relay-Forward报文中解析出DHCPv6客户端的请求，为DHCPv6客户端选取IPv6地址和其他配置参数，构造应答消息，将应答消息封装在Relay-Reply报文的中继消息选项中，并将Relay-Reply报文发送给DHCPv6中继。 DHCPv6中继从Relay-Reply报文中解析出DHCPv6服务器的应答，转发给DHCPv6客户端。如果DHCPv6客户端接收到多个DHCPv6服务器的应答，则根据报文中的服务器优先级选择一个DHCPv6服务器，后续从该DHCPv6服务器获取IPv6地址和其他网络配置参数。 IPv6地址/前缀的分配与更新原则：IPv6地址分配的优先次序：DHCPv6服务器按照如下次序为DHCPv6客户端选择IPv6地址/前缀。 选择IPv6地址池 DHCPv6服务器的接口可以绑定IPv6地址池，DHCPv6服务器将选择该IPv6地址池为接口下的DHCPv6客户端分配地址/前缀。对于存在中继的场景，DHCPv6服务器的接口可以不绑定IPv6地址池，而是根据报文中第一个不为0的“link-address”字段（标识DHCPv6客户端所在链路范围），选择与地址池中已配置的网络前缀或IPv6地址前缀属于同一链路范围的地址池。 选择IPv6地址/前缀 确定地址池后，DHCPv6服务器将按照下面步骤为DHCPv6客户端分配IPV6地址/前缀： 如果地址池中为客户端指定了地址/前缀，优先从地址池中选择与客户端DUID匹配的地址/前缀分配给客户端。 如果客户端报文中的IA选项携带了有效的地址/前缀，优先从地址池中选择该地址/前缀分配给客户端。如果该地址/前缀在地址池中不可用，则另外分配一个空闲地址/前缀给客户端。如果IPV6前缀长度比指定分配长度大，则按指定分配长度来分配。 从地址池中选择空闲地址/前缀分配给客户端，保留地址（例如RFC 2526中定义的任播地址）、冲突地址、已被分配的地址不能再分配给客户端。 如果没有合适的IPv6地址/前缀可以分配，则分配失败。 DHCPv6地址租约更新：DHCPv6服务器为DHCPv6客户端分配的地址是有租约的，租约由生命期（包括地址的首选生命期和有效生命期构成）和续租时间点（IA的T1、T2）构成。地址有效生命期结束后，DHCPv6客户端不能再使用该地址。在有效生命期到达之前，如果DHCPv6客户端希望继续使用该地址，则需要更新地址租约。 DHCPv6客户端为了延长其与IA关联的地址的有效生命期和首选生命期，在T1时刻，发送包含IA选项的Renew报文给服务器，其中IA选项中携带需要续租的IA地址选项。如果DHCPv6客户端一直没有收到T1时刻续租报文的回应报文，那么在T2时刻，DHCPv6客户端通过Rebind报文向DHCPv6服务器继续续租地址。 T1时刻地址租约更新过程如下： DHCPv6客户端在T1时刻（推荐值为优先生命期的0.5倍）发送Renew报文进行地址租约更新请求。 DHCPv6服务器回应Reply报文。 如果DHCPv6客户端可以继续使用该地址，则DHCPv6服务器回应续约成功的Reply报文，通知DHCPv6客户端已经成功更新地址租约。 如果该地址不可以再分配给该DHCPv6客户端，则DHCPv6服务器回应续约失败的Reply报文，通知DHCPv6客户端不能获得新的租约。 T2时刻地址租约更新过程如下： DHCPv6客户端在T1时刻发送Renew请求更新租约，但是没有收到DHCPv6服务器的回应报文。 DHCPv6客户端在T2时刻（推荐值为优先生命期的0.8倍），向所有DHCPv6服务器组播发送Rebind报文请求更新租约。 DHCPv6服务器回应Reply报文。 如果DHCPv6客户端可以继续使用该地址，则DHCPv6服务器回应续约成功的Reply报文，通知DHCPv6客户端已经成功更新地址/前缀租约。 如果该地址不可以再分配给该DHCPv6客户端，则DHCPv6服务器回应续约失败的Reply报文，通知DHCPv6客户端不能获得新的租约。 如果DHCPv6客户端没有收到DHCPv6服务器的应答报文，则到达有效生命期后，DHCPv6客户端停止使用该地址。 IP地址预留：DHCPv6服务器支持预留IPv6地址，即保留部分IPv6地址不参与动态分配。比如预留的IPv6地址可作为DNS服务器的IPv6地址。 DHCPv6基础配置命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687address prefix //IPv6地址池视图下配置网络前缀和生命周期。//infinite:指定生命周期为无穷大。//生命周期默认值为86400，即1天。capwap-ac ipv6-address//在IPv6地址池视图下配置AC的IPv6地址。conflict-address expire-time expire-time//配置IPv6地址池下冲突地址老化时间。//缺省情况下，地址池下的冲突地址老化时间是172800秒，即2天。dhcpv6 client information-request//使能接口以DHCPv6无状态自动分配方式获取网络配置参数//（不包括IPv6地址）的功能。dhcpv6 client pd//配置DHCPv6 PD客户端功能。//hint ipv6-address:指定期望申请的IPv6地址//hint ipv6-prefix/ipv6-prefix-length:// 指定期望申请的IPv6地址前缀和前缀长度。//rapid-commit:指定客户端以两步交互申请IPv6地址前缀。//unicast-option:指定客户端以单播方式申请IPv6地址前缀。//union-mode:指定客户端使用一个报文同时获取IPv6地址和前缀。dhcpv6 duid &#123; ll | llt | duid &#125;//配置DHCPv6设备的唯一标识符DUID。//缺省情况下，设备以ll的方式生成DUID。//ll:指定设备采用链路层地址（即MAC地址）方式生成DUID。//llt:指定设备采用链路层地址（即MAC地址）加时间的方式生成DUID。dhcpv6 client renew//手动更新DHCPv6客户端申请到的IPv6地址/前缀。renew-time-percent rebind-time-percent//配置IPv6地址池的续租时间和重绑定时间占优先生命周期的百分比。//缺省情况下，IPv6地址池的续租时间占优先生命周期的50%//重绑定时间占优先生命周期的80%。dhcpv6 interface-id format &#123; default | user-defined text &#125;//配置DHCPv6报文中Interface-ID选项的格式。dhcpv6 packet-rate//使能DHCPv6报文限速功能，并配置速率抑制值。//缺省情况下，DHCPv6报文限速功能处于未使能状态。dhcpv6 packet-rate drop-alarm enable//使能DHCPv6报文限速丢弃告警功能。dhcpv6 packet-rate drop-alarm threshold 100 //配置DHCPv6报文限速丢弃告警阈值.缺省值为100包dhcpv6 pool pool-name//创建IPv6/IPv6 PD地址池或进入IPv6/IPv6 PD地址池视图dhcpv6 relay destination//使能接口的DHCPv6中继代理功能//并配置DHCPv6服务器或下一跳中继代理的IPv6地址。dhcpv6 relay server-select group-name //来配置DHCPv6中继所对应的DHCPv6服务器组。 dhcpv6 relay source-interface//配置接口地址作为报文源IPv6地址。dhcpv6 remote-id format//配置DHCPv6报文中Remote-ID选项的格式。dhcpv6 remote-id insert enable//使能在DHCPv6中继报文中插入remote-id选项的功能。dhcpv6 server//使能DHCPv6服务器或DHCPv6 PD服务器功能。dhcpv6-server ipv6-address//配置在DHCPv6服务器组中添加DHCPv6服务器或下一跳中继的成员。dhcpv6 server database//使能DHCPv6数据保存功能。//write-delay :指定DHCPv6数据保存的时间间隔。dhcpv6 server group group-name //创建一个DHCPv6服务器组并进入DHCPv6服务器组视图dns-domain-name//配置DHCPv6服务器为DHCPv6客户端分配的域名后缀。dns-server ipv6-address //配置DNS服务器IPv6地址。excluded-address//配置IPv6地址池中不参与自动分配的IPv6地址范围。information-refresh time//设置无状态DHCPv6方式分配给客户端的配置信息刷新时间。//缺省情况下，IPv6地址池配置信息刷新时间86400秒，即24小时。ipv6 address auto dhcp命//使能接口通过DHCPv6协议自动获取IPv6地址及其他网络配置参数。link-address//在IPv6地址池视图下配置网络前缀。lock//锁定IPv6地址池。nis-domain-name//配置DHCPv6服务器为DHCPv6客户端分配的NIS域名后缀nisp-domain-name//配置DHCPv6服务器为DHCPv6客户端分配的NISP域名后缀。prefix-delegation//配置地址池视图下的代理前缀。static-bind prefix//在DHCPv6地址池下静态绑定地址前缀与DHCPv6 PD客户端。import all//使能设备向DHCPv6客户端动态分配DNS服务器和SNTP服务器配置信息的功能。 DHCPv6服务器、中继配置示例实验拓扑： 图：DHCPv6实验拓扑 实验要求：在AR1为DHCPv6服务器，AR2为DHCP中继。通过配置，为主机分配IPv6地址。 配置文件：AR1： 123456789101112131415161718192021&lt;DHCPv6&gt;dis current-configuration # sysname DHCPv6#ipv6 #dhcp enable#dhcpv6 pool pool1 address prefix 2000::/64 //配置IPv6地址前缀 excluded-address 2000::1#interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 3000::1/64 dhcpv6 server pool1#ipv6 route-static :: 0 3000::2 #return AR2： 123456789101112131415161718192021222324&lt;Realy&gt;dis current-configuration # sysname Realy#ipv6 #dhcp enable#interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 3000::2/64 #interface GigabitEthernet0/0/1 ipv6 enable ipv6 address 2000::1/64 undo ipv6 nd ra halt //使能路由器向主机发送路由通告信息 ipv6 nd autoconfig managed-address-flag //使M和O标志位置位。实现主机通过DHCPv6方式获取地址 ipv6 nd autoconfig other-flag dhcpv6 relay destination 3000::1 //指明DHCP服务器的地址#return 图：DHCPv6服务器地址分配状况]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>IPv6</tag>
        <tag>DHCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6命令行配置]]></title>
    <url>%2F2018%2F02%2F01%2FIPv6%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[IPv6基础配置命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102ipv6 neighbor ipv6-address mac-addressipv6//使能设备转发IPv6单播报文，包括本地IPv6报文的发送与接收。ipv6 address anycast//用来配置IPv6任播地址。ipv6 address auto global//使能无状态自动生成IPv6全局地址功能。ipv6 address auto link-local//配置自动生成的链路本地地址。ipv6 address link-local//配置接口的链路本地地址ipv6 address eui-64//配置接口的EUI-64格式的全球单播地址ipv6 enable//接口上使能IPv6功能。ipv6 icmp blackhole unreachable send//使能在匹配IPv6黑洞路由后回应ICMP目的不可达报文的功能。ipv6 icmp redirect send//使能系统发送ICMPv6重定向报文功能。ipv6 icmp port-unreachable send//使能接口的ICMPv6端口不可达报文的发送功能。ipv6 icmp hop-limit-exceeded send//使能接口的ICMPv6跳数超大报文的发送功能。ipv6 icmp receive//使能系统接收ICMPv6报文功能。//缺省情况下，系统接收ICMPv6报文的功能处于使能状态。ipv6 icmp send//使能系统发送ICMPv6报文功能。ipv6 icmp too-big-rate-limit//使能ICMPv6超大差错报文接收抑制功能。ipv6 mtu//置接口上发送IPv6报文的MTU。//缺省情况下，接口的IPv6的MTU值为1500字节。ipv6 nd autoconfig managed-address-flag//设置RA报文中的有状态自动配置地址的标志位。//缺省情况下，没有设置有状态自动配置地址的标志位。/* 如果设置了该标志位，则主机通过有状态自动配置获得IPv6地址。 如果清除了该标志位，则主机通过无状态自动配置获得IPv6地址，即通过RA报文向主机发布IPv6地址前缀信息自动生成IPv6地址。*/ipv6 nd autoconfig other-flag//设置RA报文中的有状态自动配置其他信息的标志位。//缺省情况下，系统未设置有状态自动配置其他信息的标志位。/* 如果设置了该标志位，则主机可通过有状态自动配置获得除IPv6地址外的其他配置信息，包括路由器生存时间、邻居可达时间、邻居的重传时间、链路的MTU信息。 如果清除了该标志位，则主机进行无状态自动配置。即路由设备通过RA报文向主机发布除IPv6地址外的其他配置信息，包括路由器生存时间、邻居可达时间、邻居的重传时间、链路的MTU信息。 */ipv6 nd dad attempts//配置系统进行重复地址检测DAD时发送邻居请求报文的次数。//缺省情况下，系统进行重复地址检测时发送邻居请求报文的次数是1。ipv6 nd hop-limit//配置由设备初始发送的IPv6单播报文的跳数限制。//缺省情况下，由路由设备初始发送的IPv6单播报文的跳数限制是64。ipv6 nd learning strict//配置IPv6 ND严格学习。ipv6 nd neighbor-limit 1024//配置接口上允许动态学习的邻居表项的最大个数。ipv6 nd ns multicast-enable//使能QinQ或Dot1q终结子接口发送NS组播报文的功能。ipv6 nd ns retrans-timer//设置系统发送邻居请求报文的时间间隔。//缺省情况下，系统发送邻居请求报文的时间间隔是1000毫秒。ipv6 nd nud reachable-time//来配置IPv6邻居节点的可达时间。//缺省情况下，IPv6邻居节点的可达时间为1200000毫秒。ipv6 nd ra//置RA（Router Advertisement）报文的发布时间间隔。//缺省情况下，最大时间间隔是600秒，最小时间间隔是200秒。ipv6 nd ra halt//去使能系统发布RA报文功能。//缺省情况下，系统发布RA报文功能处于未使能状态。ipv6 nd ra hop-limit 64//配置RA报文的跳数限制。ipv6 nd ra preference medium &#123;high | medium | low &#125;//配置RA报文中的默认路由器优先级信息。ipv6 nd ra prefix//配置RA报文中的前缀信息。ipv6 nd ra route-information//配置RA报文中的路由选项信息。ipv6 nd ra router-lifetime//配置RA报文的存活时间。ipv6 nd stale-timeout 1200 //配置邻居表项在STALE状态的老化时间。 //缺省情况下，系统视图邻居表项STALE状态的老化时间是1200秒； //接口视图未配置邻居表项STALE状态的老化时间。 ipv6 neighbor ipv6-address mac-address //配置静态邻居表项信息。 ipv6 pathmtu //配置到指定IPv6目的地址的PMTU值。 ipv6 pathmtu age //配置动态PMTU表项的老化时间。 ipv6 soft-forward enhance enable //使能设备产生的IPv6控制报文的增强转发功能。 dns relay ipv6 enable //开启IPv6 DNS Relay功能。 dns server ipv6 //配置实现动态域名解析的DNS服务器的IPv6地址。 dns server ipv6 source-ip //配置本端作为DNS客户端与DNS服务端通信时的源IPv6地址。 dns spoofing ipv6 //使能IPv6 DNS Spoofing功能，并指定欺骗性应答的IPv6地址。ipv6 host//来配置IPv6静态域名解析表项。 IPv6综合实验实验拓扑如下： 图：IPv6综合实验拓扑 实验要求：IPv6网络如实验拓扑所示，请根据如下需求对网络进行部署： R1，R2和R3之间运行OSPFv3，区域ID为0，Router ID分别为10.1.1.1，10.2.2.2，10.3.3.3； R4，R5和R6之间运行ISIS IPv6区域ID为49.0001，并且都是Level-2级别路由器； R2和R4间的网络是一个纯IPv4网络，运行的是OSPFv2，区域ID为0，包含Loopback地址； R6，R7间的网络是纯IPv4网络，建立ISIS IPv4邻居，区域ID为49.0001； R1，R2和R3之间建立全互连IBGP4+ IPv6邻居关系，AS号为100，且R2向AS100通告默认路由；R4和R5建立IBGP4+ IPv6邻居关系，AS号为200； R2与R4间使用GRE手工隧道,隧道的地址为2001:db8:24::/64，R2和R4之间通过直连IPv6地址建立EBGP IPv6邻居关系；要求R2 将AS100中的2001:db8:100:00通告给AS200； 在R4和R5上要求将ISIS IPv6路由引入进BGP，保证AS100和AS200所有IPv6网段间的互通； R7的G0/0/1下用户连接到网络后有状态自动获取IPv6地址，DNS为R1。这里使用R8来模拟一台IPv6终端； R6和R7间使用6to4隧道，保证R7能Ping通AS200内的IPv6网络。 配置文件：AR1： 123456789101112131415161718192021222324252627282930313233&lt;AR1&gt;display current-configuration # sysname AR1#ipv6 #ospfv3 1 router-id 10.1.1.1#interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2001:DB8:100::1/64 ospfv3 1 area 0.0.0.0#interface LoopBack0 ip address 10.1.1.1 255.255.255.255 ospfv3 1 area 0.0.0.0#bgp 100 router-id 10.1.1.1 undo default ipv4-unicast peer 2001:DB8:100::2 as-number 100 peer 2001:DB8:100::3 as-number 100 # ipv4-family unicast undo synchronization # ipv6-family unicast undo synchronization peer 2001:DB8:100::2 enable peer 2001:DB8:100::3 enable#return AR2： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;AR2&gt;dis current-configuration # sysname AR2#ipv6 #ospfv3 1 router-id 10.3.3.3#interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2001:DB8:100::2/64 ospfv3 1 area 0.0.0.0#interface GigabitEthernet0/0/1 ip address 192.168.24.2 255.255.255.0 #interface LoopBack0 ip address 10.2.2.2 255.255.255.255 ospfv3 1 area 0.0.0.0#interface Tunnel0/0/0 ipv6 enable ipv6 address 2001:DB8:24::2/64 tunnel-protocol gre source 192.168.24.2 destination 192.168.24.4#bgp 100 router-id 10.2.2.2 peer 2001:DB8:24::4 as-number 200 peer 2001:DB8:100::1 as-number 100 peer 2001:DB8:100::3 as-number 100 # ipv4-family unicast undo synchronization # ipv6-family unicast undo synchronization network 2001:DB8:100:: 64 peer 2001:DB8:24::4 enable peer 2001:DB8:100::1 enable peer 2001:DB8:100::1 default-route-advertise peer 2001:DB8:100::3 enable peer 2001:DB8:100::3 default-route-advertise#ospf 1 router-id 10.2.2.2 area 0.0.0.0 network 10.2.2.2 0.0.0.0 network 192.168.24.0 0.0.0.255 #return AR3： 12345678910111213141516171819202122232425262728293031323334353637&lt;AR3&gt;dis current-configuration # sysname AR3#ipv6 #ospfv3 1 router-id 10.2.2.2#interface Serial4/0/0 link-protocol ppp ip address 192.168.35.3 255.255.255.0 #interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2001:DB8:100::3/64 ospfv3 1 area 0.0.0.0#interface LoopBack0 ip address 10.3.3.3 255.255.255.255 ospfv3 1 area 0.0.0.0#bgp 100 router-id 10.3.3.3 undo default ipv4-unicast peer 2001:DB8:100::1 as-number 100 peer 2001:DB8:100::2 as-number 100 # ipv4-family unicast undo synchronization # ipv6-family unicast undo synchronization peer 2001:DB8:100::1 enable peer 2001:DB8:100::2 enable#return AR4： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;AR4&gt;dis current-configuration # sysname AR4#ipv6 #isis 1 is-level level-2 cost-style wide network-entity 49.0001.0000.0000.0004.00 # ipv6 enable topology standard ipv6 default-route-advertise always #interface GigabitEthernet0/0/0 ip address 192.168.24.4 255.255.255.0 isis enable 1#interface GigabitEthernet0/0/1 ipv6 enable ipv6 address 2002:A06:606:46::4/64 isis ipv6 enable 1#interface LoopBack0 ip address 10.4.4.4 255.255.255.255 #interface Tunnel0/0/0 ipv6 enable ipv6 address 2001:DB8:24::4/64 tunnel-protocol gre source 192.168.24.4 destination 192.168.24.2#bgp 200 router-id 10.4.4.4 undo default ipv4-unicast peer 2001:DB8:24::2 as-number 100 peer 2002:A06:606:56::5 as-number 200 # ipv4-family unicast undo synchronization # ipv6-family unicast undo synchronization import-route isis 1 peer 2001:DB8:24::2 enable peer 2002:A06:606:56::5 enable peer 2002:A06:606:56::5 next-hop-local #ospf 1 router-id 10.4.4.4 area 0.0.0.0 network 10.4.4.4 0.0.0.0 network 192.168.24.0 0.0.0.255 #return AR5： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;AR5&gt;dis current-configuration # sysname AR5#ipv6 #isis 1 is-level level-2 cost-style wide network-entity 49.0001.0000.0000.0005.00 # ipv6 enable topology standard#interface Serial4/0/0 link-protocol ppp ip address 192.168.35.5 255.255.255.0 #interface Serial4/0/1 link-protocol ppp#interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2002:A06:606:56::5/64 isis ipv6 enable 1#interface LoopBack0 ip address 10.5.5.5 255.255.255.255 isis enable 1#bgp 200 router-id 10.5.5.5 undo default ipv4-unicast peer 2002:A06:606:46::4 as-number 200 # ipv4-family unicast undo synchronization # ipv6-family unicast undo synchronization import-route isis 1 peer 2002:A06:606:46::4 enable#return AR6： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;AR7&gt;dis current-configuration # sysname AR7#ipv6 #dhcp enable#dhcpv6 pool pool address prefix 2002:A07:707::/64 dns-server 2001:DB8:100::1#isis 1 is-level level-2 cost-style wide network-entity 49.0001.0000.0000.0007.00 # ipv6 enable topology standard #interface GigabitEthernet0/0/0 ip address 192.168.67.7 255.255.255.0 isis enable 1#interface GigabitEthernet0/0/1 ipv6 enable ipv6 address 2002:A07:707::7/64 undo ipv6 nd ra halt ipv6 nd autoconfig other-flag isis ipv6 enable 1 dhcpv6 server pool#interface LoopBack0 ip address 10.7.7.7 255.255.255.255 isis enable 1#interface Tunnel0/0/0 ipv6 enable ipv6 address 2002:A07:707:67::7/64 tunnel-protocol ipv6-ipv4 6to4 source LoopBack0#ipv6 route-static :: 0 Tunnel0/0/0 #return AR7： 123456789101112131415&lt;AR8&gt;dis current-configuration # sysname AR8#ipv6 #dhcp enable#interface GigabitEthernet0/0/0 ipv6 enable ipv6 address auto link-local ipv6 address auto dhcp //配置通过dhcpv6获取IP地址#return]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6过渡技术]]></title>
    <url>%2F2018%2F01%2F30%2FIPv6%E8%BF%87%E6%B8%A1%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[IPv6过渡技术概述双栈技术 节点同时支持IPv4和IPv6协议栈。 IPv6 over IPv4隧道 过渡初期使用 过渡初期使用 通过隧道技术，使IPv6报文在IPv4网络中传输。 手动隧道包括IPv6 over IPv4手动隧道和IPv6 over IPv4 GRE隧道。 自动隧道包括IPv4兼容IPv6自动隧道、6to4隧道和ISATAP隧道 IPv4 over IPv6隧道 过渡后期使用 通过隧道技术，是IPv4报文在IPv6网络中传输 双栈协议双栈技术是IPv4向IPv6过渡的一种有效的技术。网络中的节点同时支持IPv4和IPv6协议栈，源节点根据目的节点的不同选用不同的协议栈，而网络设备根据报文的协议类型选择不同的协议栈进行处理和转发。双栈可以在一个单一的设备上实现，也可以是一个双栈骨干网。对于双栈骨干网，其中的所有设备必须同时支持IPv4/IPv6协议栈，连接双栈网络的接口必须同时配置IPv4地址和IPv6地址。 但协议栈和双协议栈结构示例如下： 双协议栈 双协议栈具有以下特点： 多种链路协议支持双协议栈 多种链路协议（如以太网）支持双协议栈。图中的链路层是以太网，在以太网帧上，如果协议ID字段的值为0x0800，表示网络层收到的是IPv4报文，如果为0x86DD，表示网络层是IPv6报文。 多种应用支持双协议栈 多种应用（如DNS/FTP/Telnet等）支持双协议栈。上层应用（如DNS）可以选用TCP或UDP作为传输层的协议，但优先选择IPv6协议栈，而不是IPv4协议栈作为网络层协议。 IPv6 over IPv4隧道IPv6 over IPv4隧道原理：隧道（Tunnel）是一种封装技术。它利用一种网络协议来传输另一种网络协议，即利用一种网络传输协议，将其他协议产生的数据报文封装在自身的报文中，然后在网络中传输。隧道是一个虚拟的点对点的连接。一个Tunnel提供了一条使封装的数据报文能够传输的通路，并且在一个Tunnel的两端可以分别对数据报文进行封装及解封装。隧道技术就是指包括数据封装、传输和解封装在内的全过程。隧道技术是IPv6向IPv4过渡的一个重要手段。 由于IPv4地址的枯竭和IPv6的先进性，IPv4过渡为IPv6势在必行。因为IPv6与IPv4的不兼容性，所以需要对原有的IPv4设备进行替换。但是IPv4设备大量替换所需成本会非常巨大，且现网运行的业务也会中断，显然并不可行。所以，IPv4向IPv6过渡是一个渐进的过程。在过渡初期，IPv4网络已经大量部署，而IPv6网络只是散落在各地的“孤岛”，IPv6 over IPv4隧道就是通过隧道技术，使IPv6报文在IPv4网络中传输，实现IPv6网络之间的孤岛互连。 IPv6 over IPv4隧道基本原理如下图： 图：IPv6 over IPv4隧道原理图 边界设备启动IPv4/IPv6双协议栈，并配置IPv6 over IPv4隧道。 边界设备在收到从IPv6网络侧发来的报文后，如果报文的目的地址不是自身且下一跳出接口为Tunnel接口，就要把收到的IPv6报文作为数据部分，加上IPv4报文头，封装成IPv4报文。 在IPv4网络中，封装后的报文被传递到对端的边界设备。 对端边界设备对报文解封装，去掉IPv4报文头，然后将解封装后的IPv6报文发送到IPv6网络中。 一个隧道需要有一个起点和一个终点，起点和终点确定了以后，隧道也就可以确定了。IPv6 over IPv4隧道的起点的IPv4地址必须为手工配置，而终点的确定有手工配置和自动获取两种方式。根据隧道终点的IPv4地址的获取方式不同可以将IPv6 over IPv4隧道分为手动隧道和自动隧道。 手动隧道：手动隧道即边界设备不能自动获得隧道终点的IPv4地址，需要手工配置隧道终点的IPv4地址，报文才能正确发送至隧道终点。 自动隧道：自动隧道即边界设备可以自动获得隧道终点的IPv4地址，所以不需要手工配置终点的IPv4地址，一般的做法是隧道的两个接口的IPv6地址采用内嵌IPv4地址的特殊IPv6地址形式，这样路由设备可以从IPv6报文中的目的IPv6地址中提取出IPv4地址。 手动隧道：根据IPv6报文封装的不同，手动隧道又可以分为IPv6 over IPv4手动隧道和IPv6 over IPv4 GRE隧道两种。 IPv6 over IPv4手动隧道手动隧道直接把IPv6报文封装到IPv4报文中去，IPv6报文作为IPv4报文的净载荷。手动隧道的源地址和目的地址也是手工指定的，它提供了一个点到点的连接。手动隧道可以建立在两个边界路由器之间为被IPv4网络分离的IPv6网络提供稳定的连接，或建立在终端系统与边界路由器之间为终端系统访问IPv6网络提供连接。隧道的边界设备必须支持IPv6/IPv4双协议栈。其它设备只需实现单协议栈即可。因为手动隧道要求在设备上手工配置隧道的源地址和目的地址，如果一个边界设备要与多个设备建立手动隧道，就需要在设备上配置多个隧道，配置比较麻烦。所以手动隧道通常用于两个边界路由器之间，为两个IPv6网络提供连接。 图：IPv6 over IPv4手动隧道封装格式 IPv6 over IPv4手动隧道转发机制为：当隧道边界设备的IPv6侧收到一个IPv6报文后， 根据IPv6报文的目的地址查找IPv6路由转发表，如果该报文是从此虚拟隧道接口转发出去，则根据隧道接口配置的隧道源端和目的端的IPv4地址进行封装。封装后的报文变成一个IPv4报文，交给IPv4协议栈处理。报文通过IPv4网络转发到隧道的终点。隧道终点收到一个隧道协议报文后，进行隧道解封装。并将解封装后的报文交给IPv6协议栈处理。 IPv6 over IPv4 GRE隧道IPv6 over IPv4 GRE隧道使用标准的GRE隧道技术提供了点到点连接服务，需要手工指定隧道的端点地址。GRE隧道本身并不限制被封装的协议和传输协议，一个GRE隧道中被封装的协议可以是协议中允许的任意协议（可以是IPv4、IPv6、OSI、MPLS等）。 图：IPv6 over IPv4 GRE 隧道 IPv6 over IPv4 GRE隧道的在隧道的边界路由器的传输机制和IPv6 over IPv4手动隧道相同。 自动隧道：自动隧道中，用户仅需要配置设备隧道的起点，隧道的终点由设备自动生成。为了使设备能够自动产生终点，隧道接口的IPv6地址采用内嵌IPv4地址的特殊IPv6地址形式。设备从IPv6报文中的目的IPv6地址中解析出IPv4地址，然后以这个IPv4地址代表的节点作为隧道的终点。 根据IPv6报文封装的不同，自动隧道又可以分为IPv4兼容IPv6自动隧道、6to4隧道和ISATAP隧道三种。 IPv4兼容IPv6自动隧道IPv4兼容IPv6自动隧道，其承载的IPv6报文的目的地址（即自动隧道所使用的特殊地址）是IPv4兼容IPv6地址。IPv4兼容IPv6地址的前96位全部为0，后32位为IPv4地址。其格式如下： 图：IPv4兼容IPv6地址 IPv4兼容IPv6自动隧道的转发机制： 图：ipv4兼容IPv6隧道 需要经过Router A发给Router B的IPv6报文到达Router A后，以目的地址::2.1.1.1查找IPv6路由，发现路由的下一跳为虚拟的Tunnel口。由于Router A上的配置的隧道的类型是IPv4兼容IPv6自动隧道。于是Router A对IPv6报文进行了封装。封装的时候，IPv6报文被封装为IPv4报文，IPv4报文中的源地址为隧道的起始点地址1.1.1.1，而目的IP地址直接从IPv4兼容IPv6地址::2.1.1.1的后32位拷贝过来即2.1.1.1。这个报文被路由器从隧道口发出后，在IPv4的网络中被路由转发到目的地2.1.1.1，也就是Router B。Router B收到报文后，进行解封装，把其中的IPv6报文取出，送给IPv6协议栈进行处理。Router B返回Router A的报文也是按照这个过程来进行的。 注：如果IPv4兼容IPv6地址中的IPv4地址是广播地址、组播地址、网络广播地址、出接口的子网广播地址、全0地址、环回地址，则该IPv6报文被丢弃，不会进行隧道封装处理。 由于IPv4兼容IPv6隧道要求每一个主机都要有一个合法的IP地址，而且通讯的主机要支持双栈、支持IPv4兼容IPv6隧道，不适合大面积部署。目前该技术已经被6to4隧道所代替。 6to4隧道：6to4隧道也属于一种自动隧道，隧道也是使用内嵌在IPv6地址中的IPv4地址建立的。与IPv4兼容自动隧道不同，6to4自动隧道支持Router到Router、Host到Router、Router到Host、 Host到Host。这是因为6to4地址是用IPv4地址做为网络标识，其地址格式如下所示： 图：6to4地址格式 FP：可聚合全球单播地址的格式前缀（Format Prefix），其值为001。 TLA：顶级聚合标识符（Top Level Aggregator），其值为0x0002。 SLA：站点级聚合标识符（Site Level Aggregator）。 6to4地址可以表示为2002::/16，而一个6to4网络可以表示为2002:IPv4地址::/48。6to4地址的网络前缀长度为64bit，其中前48bit（2002: a.b.c.d）被分配给路由器上的IPv4地址决定了，用户不能改变，而后16位（SLA）是由用户自己定义的。 6to4隧道的封装和装发过程如下图所示： 图：6to4隧道示例一 一个IPv4地址只能用于一个6to4隧道的源地址，如果一个边界设备连接了多个6to4网络使用同样的IPv4地址做为隧道的源地址，则使用6to4地址中的SLA ID来区分，但他们共用一个隧道。如下图所示： 图：6to4隧道示例二 随着IPv6网络的发展，普通IPv6网络需要与6to4网络通过IPv4网络互通，这可以通过6to4中继路由器方式实现。所谓6to4中继，就是通过6to4隧道转发的IPv6报文的目的地址不是6to4地址，但转发的下一跳是6to4地址，该下一跳为路由器我们称之为6to4中继。隧道的IPv4目的地址依然从下一跳的6to4地址中获得。6to4中继示意图如下所示： 图：6to4中继示例 如果6to4网络2中的主机要与IPv6网络互通，在其边界路由器上配置路由指向的下一跳为6to4中继路由器的6to4地址，中继路由器的6to4地址是与中继路由器的6to4隧道的源地址相匹配的。6to4网络2中去往普通IPv6网络的报文都会按照路由表指示的下一跳发送到6to4中继路由器。6to4中继路由器再将此报文转发到纯IPv6网络中去。当报文返回时，6to4中继路由器根据返回报文的目的地址（为6to4地址）进行IPv4报文头封装，数据就能够顺利到达6to4网络中了。 ISATAP隧道：ISATAP（Intra-Site Automatic Tunnel Addressing Protocol）是另外一种自动隧道技术。ISATAP隧道同样使用了内嵌IPv4地址的特殊IPv6地址形式，只是和6to4不同的是，6to4是使用IPv4地址做为网络前缀，而ISATAP用IPv4地址做为接口标识。其接口标识符格式如下图所示： 图：ISATAP地址接口标识格式 如果IPv4地址是全局唯一的，则u位为1，否则u位为0。g位是IEEE群体/个体标志。由于ISATAP是通过接口标识来表现的，所以，ISATAP地址有全局单播地址、链路本地地址、ULA地址、组播地址等形式。ISATAP地址的前64位是通过向ISATAP路由器发送请求来得到的，它可以进行地址自动配置。在ISATAP隧道的两端设备之间可以运行ND协议。ISATAP隧道将IPv4网络看作一个非广播的点到多点的链路（NBMA）。 ISATAP过渡机制允许在现有的IPv4网络内部署IPv6，该技术简单而且扩展性很好，可以用于本地站点的过渡。ISATAP支持IPv6站点本地路由和全局IPv6路由域，以及自动IPv6隧道。ISATAP同时还可以与NAT结合，从而可以使用站点内部非全局唯一的IPv4地址。典型的ISATAP隧道应用是在站点内部，所以，其内嵌的IPv4地址不需要是全局唯一的。 下图为ISATAP隧道一个典型应用场景： 图：ISATAP隧道示例 如上图所示，在IPv4网络内部有两个双栈主机Host B和Host C，它们分别有一个私网IPv4地址。要使其具有ISATAP功能，需要进行如下操作： 首先配置ISATAP隧道接口，这时会根据IPv4地址生成ISATAP类型的接口ID。 根据接口ID生成一个ISATAP链路本地IPv6地址，生成链路本地地址以后，主机就有了在本地链路上进行IPv6通信的能力。 进行自动配置，主机获得IPv6全球单播地址、ULA地址等。 当主机与其它IPv6主机进行通讯时，从隧道接口转发，将从报文的下一跳IPv6地址中取出IPv4地址作为IPv4封装的目的地址。如果目的主机在本站点内，则下一跳就是目的主机本身，如果目的主机不在本站点内，则下一跳为ISATAP路由器的地址。 IPv6 over IPv4配置示例配置IPv6 over IPv4手动隧道示例：实验拓扑如下： 图：IPv6 over IPv4手动隧道配置拓扑 实验要求：PC1和PC2与路由器之间为IPv6网络。两台路由器之间为IPv4网络，通过配置，要求是PC1与PC2能互通。即使IPv6可以在IPv4网络中通信。 配置文件：AR1： 1234567891011121314151617181920212223242526272829&lt;AR1&gt;display current-configuration # sysname AR1#ipv6 #interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2000::2/64 #interface GigabitEthernet0/0/1 ip address 12.1.1.1 255.255.255.0 #interface Tunnel0/0/0 ipv6 enable //使能接口的IPv6功能。 ipv6 address 2001::1/64 //设置Tunnel接口的IPv6地址。 tunnel-protocol ipv6-ipv4 //指定Tunnel为手动隧道模式。 source 12.1.1.1 //指定Tunnel的源地址。 destination 12.1.1.2 //指定Tunnel的目的地址#ipv6 route-static 3000:: 64 Tunnel0/0/0 //配置静态路由指向Tunnel接口#return AR2： 1234567891011121314151617181920212223&lt;AR2&gt;display current-configuration # sysname AR2#ipv6 #interface GigabitEthernet0/0/0 ip address 12.1.1.2 255.255.255.0 #interface GigabitEthernet0/0/1 ipv6 enable ipv6 address 3000::2/64 #interface Tunnel0/0/0 ipv6 enable ipv6 address 2001::2/64 tunnel-protocol ipv6-ipv4 source 12.1.1.2 destination 12.1.1.1#ipv6 route-static 2000:: 64 Tunnel0/0/0 #return IPv6 over IPv4报文抓包示例: 图：IPv6 over IPv4报文抓包示例 配置IPv6 over IPv4自动隧道示例:实验拓扑如下： 图：IPv6 over IPv4自动隧道配置拓扑示例 实验要求：如上图：AR1与AR2，AR3之间运行的是IPv4网络。现在需要在IPv4网络之间传输IPv6网络的数据。使用自动隧道配置。 配置文件：AR1： 1234567891011121314151617181920212223&lt;AR1&gt;dis current-configuration # sysname AR1#ipv6 #interface GigabitEthernet0/0/0 ip address 12.1.1.1 255.255.255.0 #interface Tunnel0/0/0 ipv6 enable //使能接口的IPv6功能。 ipv6 address ::12.1.1.1/96 tunnel-protocol ipv6-ipv4 auto-tunnel //指定Tunnel为自动隧道模式 source 12.1.1.1#rip 1 //配置rip使IPv4网络能互通 version 2 network 12.0.0.0#return AR2： 12345678910111213141516&lt;AR2&gt;dis current-configuration # sysname AR2#interface GigabitEthernet0/0/0 ip address 12.1.1.2 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 23.1.1.2 255.255.255.0 #rip 1 version 2 network 12.0.0.0 network 23.0.0.0#return AR3： 1234567891011121314151617181920&lt;AR3&gt;dis current-configuration # sysname AR3#ipv6 #interface GigabitEthernet0/0/0 ip address 23.1.1.3 255.255.255.0 #interface Tunnel0/0/0 ipv6 enable ipv6 address ::23.1.1.3/96 tunnel-protocol ipv6-ipv4 auto-tunnel source 23.1.1.3#rip 1 version 2 network 23.0.0.0#return 在以上配置中，AR1和AR3使能了IPv6功能，而AR2没有使能IPv6功能，通过配置了自动隧道，实现IPv6网络在iPv4网络中的互通。 图：在AR1上可以ping通AR3上的IPv6网络 图：IPv6 over iPv4 自动隧道抓包示例 配置IPv6 over IPv4GRE隧道示例：实验拓扑如下： 图：IPv6 over IPv4 GRE隧道 实验要求：PC1和PC2与路由器之间为IPv6网络。两台路由器之间为IPv4网络，通过配置，要求是PC1与PC2能互通。即使IPv6可以在IPv4网络中通信。通过配置GRE隧道实现要求。 配置文件：AR1： 123456789101112131415161718192021222324&lt;AR1&gt;dis current-configuration # sysname AR1#ipv6 #interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2000::2/64 #interface GigabitEthernet0/0/1 ip address 12.1.1.1 255.255.255.0 #interface Tunnel0/0/0 ipv6 enable ipv6 address 2001::1/64 tunnel-protocol gre //指定隧道模式为GRE source 12.1.1.1 destination 12.1.1.2#ipv6 route-static :: 0 Tunnel0/0/0 #return AR2： 1234567891011121314151617181920212223&lt;AR2&gt;dis current-configuration # sysname AR2#ipv6 #interface GigabitEthernet0/0/0 ip address 12.1.1.2 255.255.255.0 #interface GigabitEthernet0/0/1 ipv6 enable ipv6 address 3000::2/64 #interface Tunnel0/0/0 ipv6 enable ipv6 address 2001::2/64 tunnel-protocol gre source 12.1.1.2 destination 12.1.1.1#ipv6 route-static :: 0 Tunnel0/0/0 #return 图：IPv6 over IPv4 GRE隧道抓包示例 配置6to4隧道示例：实验拓扑如下： 图：6to4隧道配置拓扑 实验要求：PC1和PC2与路由器之间为IPv6网络。两台路由器之间为IPv4网络，通过配置，要求是PC1与PC2能互通。即使IPv6可以在IPv4网络中通信。通过配置6to4隧道实现要求。 配置文件：AR1： 12345678910111213141516171819202122[AR1]dis current-configuration # sysname AR1#ipv6 #interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2002:C01:101::2/64 #interface GigabitEthernet0/0/1 ip address 12.1.1.1 255.255.255.0 #interface Tunnel0/0/0 ipv6 enable ipv6 address 2000::1/64 tunnel-protocol ipv6-ipv4 6to4 source GigabitEthernet0/0/1#ipv6 route-static :: 0 Tunnel0/0/0 #return AR2： 1234567891011121314151617181920212223&lt;AR2&gt;dis current-configuration # sysname AR2#ipv6 #interface GigabitEthernet0/0/0 ip address 12.1.1.2 255.255.255.0 #interface GigabitEthernet0/0/1 ipv6 enable ipv6 address 2002:C01:102::2/64 //6to4中，ipv4地址会汇聚在IPv6的网络前缀中#interface Tunnel0/0/0 ipv6 enable ipv6 address 2000::2/64 tunnel-protocol ipv6-ipv4 6to4 source GigabitEthernet0/0/0#ipv6 route-static :: 0 Tunnel0/0/0 #return 图：IPv6 over IPv4 6to4隧道报文抓包 ISATAP隧道配置示例：实验拓扑如下： 图：ISATAP隧道配置示例 实验要求：主机与路由器直连为iPv4网络，通过配置ISATAP隧道，使主机可以访问IPv6网络。 配置文件：AR1： 12345678910111213141516171819202122&lt;AR1&gt;dis current-configuration # sysname AR1#ipv6 #interface GigabitEthernet0/0/0 ip address 192.168.65.2 255.255.255.0 //配置与主机直连的接口IP地址#interface Tunnel0/0/0 ipv6 enable ipv6 address 2009::/64 eui-64 //配置isatap隧道，IPv6地址前缀 undo ipv6 nd ra halt //允许发布路由器通告消息 tunnel-protocol ipv6-ipv4 isatap //指定Tunnel为ISATAP模式。 source 192.168.65.2 //指定源地址#return 主机上的配置： 12345netsh interface ipvt isatap set state enable//开启主机的Isatap隧道功能netsh interface ipv6 isatap set router 192.168.65.2netsh interface ipv6 isatap set router 192.168.65.2 enabled//添加到边界设备的静态路由 配置成功够，状态如下,可以由路由器通告的IPv6地址前缀自动生成ISATAP地址： 图：主机isatap隧道配置 成功后的状态 图：在AR1上tunnel口自动生成的IPv6地址 图：在主机上可以ping通路由器上的IPv6地址,即ISATAP隧道配置成功 图：ISATAP隧道报文抓包示例 IPv4 over IPv6隧道利用隧道技术可以在IPv6网络上创建隧道，从而实现IPv4孤岛的互联，IPv4孤岛能通过IPv6公网访问其他IPv4网络。 在IPv4 Internet向IPv6 Internet过渡的后期，IPv6网络已被大量部署，此时可能出现IPv4孤岛。利用隧道技术可在IPv6网络上创建隧道，从而实现IPv4孤岛的互连。这类似于在IP网络上利用隧道技术部署VPN。在IPv6网络上用于连接IPv4孤岛的隧道，称为IPv4 over IPv6隧道。 IPv4 over IPv6隧道技术原理如下图: 图：IPv4 over IPv6 隧道原理 边界设备启动IPv4/IPv6双协议栈，并配置IPv4 over IPv6隧道。 边界设备在收到从IPv4网络侧发来的报文后，如果报文的目的地址不是自身，就要把收到的IPv4报文作为负载，加上IPv6报文头，封装到IPv6报文里。 在IPv6网络中，封装后的报文被传递到对端的边界设备。 对端边界设备对报文解封装，去掉IPv6报文头，然后将解封装后的IPv4报文发送到IPv4网络。 IPv4 over IPv6配置示例：实验拓扑如下： 图：IPv4 over IPv6实验拓扑 实验要求:PC1和PC2与路由器之间为IPv4网络。两台路由器之间为IPv6网络，通过配置，要求是PC1与PC2能互通。即使IPv4可以在IPv6网络中通信。 配置文件：AR1： 1234567891011121314151617181920212223&lt;AR1&gt;dis current-configuration # sysname AR1#ipv6 #interface GigabitEthernet0/0/0 ip address 192.168.1.254 255.255.255.0 #interface GigabitEthernet0/0/1 ipv6 enable ipv6 address 2000::1/64 #interface Tunnel0/0/0 ip address 12.1.1.1 255.255.255.0 tunnel-protocol ipv4-ipv6 //指定隧道模式为ipv4-ipv6 source 2000::1 destination 2000::2#ip route-static 192.168.2.0 255.255.255.0 Tunnel0/0/0#return AR2： 12345678910111213141516171819202122[AR2]display current-configuration # sysname AR2#ipv6 #interface GigabitEthernet0/0/0 ipv6 enable ipv6 address 2000::2/64 #interface GigabitEthernet0/0/1 ip address 192.168.2.254 255.255.255.0 #interface Tunnel0/0/0 ip address 12.1.1.2 255.255.255.0 tunnel-protocol ipv4-ipv6 source 2000::2 destination 2000::1#ip route-static 192.168.1.0 255.255.255.0 Tunnel0/0/0#return 图：AR1的路由表,出口指向Tnunel0/0/0口 图：IPv4 over IPv6报文抓包示例 IPv4 over IPv6其他配置项：12345678910111213interface tunnel 0/0/0 tunnel ipv4-ipv6 encapsulation-limit 4 // 指定本次IPv6封装后的报文可被再次进行多少次IPv6封装。 //缺省情况下，允许IPv4-over-IPv6封装4次。 tunnel ipv4-ipv6 flow-labe 0 //设置流量标识值。 //缺省情况下，流量标识值为0。 tunnel ipv4-ipv6 hop-limit 64 //设置跳数限制值。 //缺省情况下，跳数限制值为64。 tunnel ipv4-ipv6 traffic-class 0 //设置流量级别。 //缺省情况下，流量级别为0。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6邻居发现协议]]></title>
    <url>%2F2018%2F01%2F29%2FIPv6%E9%82%BB%E5%B1%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[邻居发现协议NDP邻居发现协议NDP（Neighbor Discovery Protocol）是IPv6协议体系中一个重要的基础协议。邻居发现协议替代了IPv4的ARP（Address Resolution Protocol）和ICMP路由器发现（Router Discovery），它定义了使用ICMPv6报文实现地址解析，跟踪邻居状态，重复地址检测，路由器发现以及重定向等功能。 地址解析在IPv4中，当主机需要和目标主机通信时，必须先通过ARP协议获得目的主机的链路层地址。在IPv6中，同样需要从IP地址解析到链路层地址的功能。邻居发现协议实现了这个功能。 ARP报文是直接封装在以太网报文中，以太网协议类型为0x0806，普遍观点认为ARP定位为第2.5层的协议。ND本身基于ICMPv6实现，以太网协议类型为0x86DD，即IPv6报文，IPv6下一个报头字段值为58，表示ICMPv6报文，由于ND协议使用的所有报文均封装在ICMPv6报文中，一般来说，ND被看作第3层的协议。在三层完成地址解析，主要带来以下几个好处： 地址解析在三层完成，不同的二层介质可以采用相同的地址解析协议。 可以使用三层的安全机制避免地址解析攻击。 使用组播方式发送请求报文，减少了二层网络的性能压力。 地址解析过程中使用了两种ICMPv6报文：邻居请求报文NS（Neighbor Solicitation）和邻居通告报文NA（NeighborAdvertisement）。 NS报文：Type字段值为135，Code字段值为0，在地址解析中的作用类似于IPv4中的ARP请求报文。 NA报文：Type字段值为136，Code字段值为0，在地址解析中的作用类似于IPv4中的ARP应答报文。 IPv6地址解析过程分析： 图：IPv6地址解析过程 Host A在向Host B发送报文之前它必须要解析出Host B的链路层地址，所以首先Host A会发送一个NS报文，其中源地址为Host A的IPv6地址，目的地址为Host B的被请求节点组播地址，需要解析的目标IP为Host B的IPv6地址，这就表示Host A想要知道Host B的链路层地址。同时需要指出的是，在NS报文的Options字段中还携带了Host A的链路层地址。 当Host B接收到了NS报文之后，就会回应NA报文，其中源地址为Host B的IPv6地址，目的地址为Host A的IPv6地址（使用NS报文中的Host A的链路层地址进行单播），Host B的链路层地址被放在Options字段中。这样就完成了一个地址解析的过程。 报文抓包分析：拓扑如下： 图：地址解析拓扑示例 地址解析过程分析： 首先在两端各配上IPv6地址，然后在AR1上ping ipv6 -a 2000::1 2000::2。抓包如下： 图：ping ipv6 -a 2000::1 2000::2抓包 ​ NS报文内容如下： 图：第一个NS报文 AR1会以2000::1作为源地址，目标地址为2000::2的被请求节点组播地址 ff02::1:ff00:2。然后将AR1的MAC地址携带在ICMPc6的Option中。在ICMPv6中还会携带Target Address：2000::2，这个用来防止在广播网中有多个前缀不同，最后24bit相同，而造成的混乱。携带这个字段后，当主机收到这个报文后，会首先检查该字段是否是自己的IPv6地址，如果是，则接收并回应NA报文。如果该字段的地址不是自己的IPv6地址，则丢弃。 NA报文内容如下： 图：NA报文抓包 当AR2收到AR1发送的NA报文后，检查Target Address字段，如果是自己的IPv6地址，接收，并将对端的IP地址和MAC地址绑定到自己的邻居表中。然后以自己IPv6地址2000::2为源地址，对端IPv6地址：2000::1为目的地址。并将自己的MAC地址封装在ICMPv6的Option中，发送给对方。从而两端都知道了对方的MAC地址。可以进行二次封装。 邻居通告报文中Flags字段解释： R：路由器标记。当置1时，R位指出发送者是路由器。R位由Neighbor Unreachability Detection使用，用于检测改变为主机的路由器。 S：请求标记。当置1时，S位指出通告被发送以响应来自目的地地址的Neighbor Solicitation。S位用作Neighbor Unreachability Detection的可达性确认。在多播通告和非请求单播通告中置0。 O：替代标记。替代标志，1表示通告中的信息替代缓存，如更新链路层地址时，对于任播的回应则不应置位。在针对任播地址的请求通告中，以及在请求的前缀通告中它不能被置1。在其他请求通告中和在非请求通告中它应当被置1。 Target Address：对于请求的通告，是在Neighbor Solicitation消息(该消息催促这个通告)中的Target Address字段。对于非请求通告，是其链路层地址已经改变的地址。Target Address必须不是多播地址。 跟踪邻居状态通过邻居或到达邻居的通信，会因各种原因而中断，包括硬件故障、接口卡的热插入等。如果目的地失效，则恢复是不可能的，通信失败；如果路径失效，则恢复是可能的。因此节点需要维护一张邻居表，每个邻居都有相应的状态，状态之间可以迁移。 RFC2461中定义了5种邻居状态，分别是： 未完成（Incomplete） 可达（Reachable） 陈旧（Stale） 延迟（Delay） 探查（Probe） 邻居状态的具体迁移过程如下图所示： 图：邻居状态迁移的具体过程 下面以A、B两个邻居节点之间相互通信过程中A节点的邻居状态变化为例（假设A、B之前从未通信），说明邻居状态迁移的过程。 A先发送NS报文，并生成缓存条目，此时，邻居状态为Incomplete。 若B回复NA报文，则邻居状态由Incomplete变为Reachable，否则固定时间后邻居状态由Incomplete变为Empty，即删除表项。 经过邻居可达时间，邻居状态由Reachable（默认30s）变为Stale，即未知是否可达。 如果在Reachable状态，A收到B的非请求NA报文（MAC地址修改），且报文中携带的B的链路层地址和表项中不同，则邻居状态马上变为Stale。 在Stale状态若A要向B发送数据，则邻居状态由Stale变为Delay，并发送NS请求。 在经过一段固定时间后，邻居状态由Delay（默认5s）变为Probe（每隔1s发送一次NS报文，连续发送3次），其间若有NA应答，则邻居状态由Delay变为Reachable。 在Probe状态，A每隔一定时间间隔z(1s)发送单播NS，发送固定次数(3)后，有应答则邻居状态变为Reachable，否则邻居状态变为Empty，即删除表项。 图：IPv6邻居状态 重复地址检测重复地址检测DAD（Duplicate Address Detect）是在接口使用某个IPv6单播地址之前进行的，主要是为了探测是否有其它的节点使用了该地址。尤其是在地址自动配置的时候，进行DAD检测是很必要的。一个IPv6单播地址在分配给一个接口之后且通过重复地址检测之前称为试验地址（Tentative Address）。此时该接口不能使用这个试验地址进行单播通信，但是仍然会加入两个组播组：ALL-NODES组播组和试验地址所对应的Solicited-Node组播组。 IPv6重复地址检测技术和IPv4中的免费ARP类似：节点向试验地址所对应的Solicited-Node组播组发送NS报文。NS报文中目标地址即为该试验地址。如果收到某个其他站点回应的NA报文，就证明该地址已被网络上使用，节点将不能使用该试验地址通讯。 重复地址检测原理如下： 图：重复地址检测原理 Host A的IPv6地址FC00::1为新配置地址，即FC00::1为Host A的试验地址。Host A向FC00::1的Solicited-Node组播组发送一个以FC00::1为请求的目标地址的NS报文进行重复地址检测，由于FC00::1并未正式指定，所以NS报文的源地址为未指定地址。当Host B收到该NS报文后，有两种处理方法： 如果Host B发现FC00::1是自身的一个试验地址，则Host B放弃使用这个地址作为接口地址，并且不会发送NA报文。 如果Host B发现FC00::1是一个已经正常使用的地址，Host B会向FF02::1发送一个NA报文，该消息中会包含FC00::1。这样，Host A收到这个消息后就会发现自身的试验地址是重复的。Host A上该试验地址不生效，被标识为duplicated状态。 当两端同时检测时情况如下： 图：两端同时进行检测的情况 若2个节点配置相同地址，同时作重复地址检测时，该地址处于Tentative状态，当一方收到对方发出的DAD NS，则接收方将不启用该地址 一种极端的情况，如果同时收到NS报文，则两端都放弃改地址 抓包分析： 图：地址冲突检测拓扑 当在AR3上配置2000::1/64地址时，AR3首先会以 :: 为源地址，以自己配置的2000::1的被请求节点组播地址为目的地址，发送NS报文。如果有来自2000::1的NA回复，则该地址不能用。如果没收到，则该地址可以使用。 图：重复地址检测NS报文 在这个报文中因为AR1上已经使用了2000::1/64地址，所以会回复一个NA。如下： 图：AR1回复的NA IPv6地址生命周期： 图：IPv6地址生命周期 在preferred time和valid lifetime之间叫做deprecated（弃用）状态，当地址达到这个时间段的时候，地址不能主动的发起连接只能是被动的接受连接，过了valid lifetime时间，地址就变为invalid，这时任何连接就会down掉。 路由器发现路由器发现功能用来发现与本地链路相连的设备，并获取与地址自动配置相关的前缀和其他配置参数。 在IPv6中，IPv6地址可以支持无状态的自动配置，即主机通过某种机制获取网络前缀信息，然后主机自己生成地址的接口标识部分。路由器发现功能是IPv6地址自动配置功能的基础，主要通过以下两种报文实现： 路由器通告RA（Router Advertisement）报文：每台设备为了让二层网络上的主机和设备知道自己的存在，定时都会组播发送RA报文，RA报文中会带有网络前缀信息，及其他一些标志位信息。RA报文的Type字段值为134。 图：RS报文抓包示例 路由器请求RS（Router Solicitation）报文：很多情况下主机接入网络后希望尽快获取网络前缀进行通信，此时主机可以立刻发送RS报文，网络上的设备将回应RA报文。RS报文的Tpye字段值为133。 图：RA邻居通告报文抓包示例 RA报文中字段解释： Cur Hop Limit：默认值应当放置在发出IP分组的IP首部的Hop Count字段中。 取0值意味着未(由该路由器)规定。 M：M位为0表示无状态自动配置生成IPv6地址，如果M=1表示需要通过有状态（DHCPv6）方式获取ipv6地址。 O：O位为0表示除了IPv6地址以外的其他参数需要通过无状态自动配置获取，如果O=1表示除了IPv6地址以外的其它需要通过有状态（DHCPv6）方式进行获取。 Router Lifetime：与默认路由器关联的生存期，以秒为单位。最大值18.2小时。取0值的Lifetime指出路由器不是默认路由器并且不应当出现在默认路由器列表中。Router Lifetime仅适用于作为默认路由器的路由器应用；对包括在其他消息字段或选项中的信息不适用。需要对它们的信息规定时间限制的选项有它们自己的生存期字段。 Reachable time：此时间以毫秒计，在收到可达性确认后节点假定该邻居是可到达的。它由Neighbor Unreachability Detection算法使用。此值为0意味着没有(由此路由器)作出规定。 Retrans Timer：重发的Neighbor Solicitation消息间隔时间，以毫秒计。由地址解析和Neighbor Unreachability Detection算法使用。此值为0意味着没有(由此路由器)作出规定。 ICMP Prefix Option中的flag字段： aoto-config:如果该位为1表示该前缀可以用于无状态自动配置，如果为0不能用于无状态自动配置。 on-link：指定0-flag标识位。若配置该参数，则只会本地链路内的主机RA报文中的前缀不是分配给本地链路的。主机若想该前缀指定的地址发送报文时，需要经过默认路由器转发。 路由器发现功能如下图所示： 图：路由器发现功能示例 RA在华为中的通告时间有两种： min-interval=200s。 max-interval=600s。 地址自动配置：IPv4使用DHCP实现自动配置，包括IP地址，缺省网关等信息，简化了网络管理。IPv6地址增长为128位，且终端节点多，对于自动配置的要求更为迫切，除保留了DHCP作为有状态自动配置外，还增加了无状态自动配置。无状态自动配置即自动生成链路本地地址，主机根据RA报文的前缀信息，自动配置全球单播地址等，并获得其他相关信息。 IPv6主机无状态自动配置过程： 根据接口标识产生链路本地地址。 发出邻居请求，进行重复地址检测。 如地址冲突，则停止自动配置，需要手工配置。 如不冲突，链路本地地址生效，节点具备本地链路通信能力。 主机会发送RS报文（或接收到设备定期发送的RA报文）。 根据RA报文中的前缀信息和接口标识得到IPv6地址。 默认路由器优先级和路由信息发现：当主机所在的链路中存在多个设备时，主机需要根据报文的目的地址选择转发设备。在这种情况下，设备通过发布默认路由优先级和特定路由信息给主机，提高主机根据不同的目的地选择合适的转发设备的能力。 在RA报文中，定义了默认路由优先级和路由信息两个字段，帮助主机在发送报文时选择合适的转发设备。 主机收到包含路由信息的RA报文后，会更新自己的路由表。当主机向其他设备发送报文时，通过查询该列表的路由信息，选择合适的路由发送报文。 主机收到包含默认设备优先级信息的RA报文后，会更新自己的默认路由列表。当主机向其他设备发送报文时，如果没有路由可选，则首先查询该列表，然后选择本链路内优先级最高的设备发送报文；如果该设备故障，主机根据优先级从高到低的顺序，依次选择其他设备。 重定向当网关设备发现报文从其它网关设备转发更好，它就会发送重定向报文告知报文的发送者，让报文发送者选择另一个网关设备。重定向报文也承载在ICMPv6报文中，其Type字段值为137，报文中会携带更好的路径下一跳地址和需要重定向转发的报文的目的地址等信息。 重定向示例： 图：重定向示例 Host A需要和Host B通信，Host A的默认网关设备是Router A，当Host A发送报文给Host B时报文会被送到Router A。Router A接收到Host A发送的报文以后会发现实际上Host A直接发送给Router B更好，它将发送一个重定向报文给主机A，其中报文中更好的路径下一跳地址为Router B，Destination Address为Host B。Host A接收到了重定向报文之后，会在默认路由表中添加一个主机路由，以后发往Host B的报文就直接发送给Router B。 当设备收到一个报文后，只有在如下情况下，设备会向报文发送者发送重定向报文： 报文的目的地址不是一个组播地址。 报文并非通过路由转发给设备。 经过路由计算后，路由的下一跳出接口是接收报文的接口。 设备发现报文的最佳下一跳IP地址和报文的源IP地址处于同一网段。 设备检查报文的源地址，发现自身的邻居表项中有用该地址作为全球单播地址或链路本地地址的邻居存在。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPv6基础]]></title>
    <url>%2F2018%2F01%2F29%2FIPv6%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[IPv6简介IPv6（Internet Protocol Version 6）是网络层协议的第二代标准协议，也被称为IPng（IP Next Generation）。它是Internet工程任务组IETF（Internet Engineering Task Force）设计的一套规范，是IPv4（Internet Protocol Version 4）的升级版本。 目的：IPv4协议是目前广泛部署的因特网协议。在因特网发展初期，IPv4以其协议简单、易于实现、互操作性好的优势而得到快速发展。但随着因特网的迅猛发展，IPv4设计的不足也日益明显，IPv6的出现，解决了IPv4的一些弊端。相比IPv4，IPv6具有如下优势： IPv4与IPv6的对比表： 问题 IPv4的缺陷 IPv6的优势 地址空间 IPv4地址采用32比特标识，理论上能够提供的地址数量是43亿（由于地址分配的原因，实际可使用的数量不到43亿）。另外，IPv4地址的分配也很不均衡：美国占全球地址空间的一半左右，而欧洲则相对匮乏；亚太地区则更加匮乏。与此同时，移动IP和宽带技术的发展需要更多的IP地址。目前IPv4地址已经消耗殆尽。针对IPv4的地址短缺问题，也曾先后出现过几种解决方案。比较有代表性的是无类别域间路由CIDR（Classless Inter-Domain Routing）和网络地址转换NAT（Network Address Translator）。但是CIDR和NAT都有各自的弊端和不能解决的问题，由此推动了IPv6的发展。 IPv6地址采用128比特标识。128位的地址结构使IPv6理论上可以拥有（43亿×43亿×43亿×43亿）个地址。近乎无限的地址空间是IPv6的最大优势。 报文格式 IPv4报头包含可选字段Options，内容涉及Security、Timestamp、Record route等，这些Options可以将IPv4报头长度从20字节扩充到60字节。携带这些Options的IPv4报文在转发过程中往往需要中间路由转发设备进行软件处理，对于性能是个很大的消耗，因此实际中也很少使用。 IPv6和IPv4相比，去除了IHL、Identifier、Flag、Fragment Offset、Header Checksum、 Option、Padding域，只增加了流标签域，因此IPv6报文头的处理较IPv4更为简化，提高了处理效率。另外，IPv6为了更好支持各种选项处理，提出了扩展头的概念，新增选项时不必修改现有结构，理论上可以无限扩展，体现了优异的灵活性。 自动配置和重新编址 由于IPv4地址只有32比特，并且地址分配不均衡，导致在网络扩容或重新部署时，经常需要重新分配IP地址，因此需要能够进行自动配置和重新编址，以减少维护工作量。目前IPv4的自动配置和重新编址机制主要依靠DHCP协议。 IPv6协议内置支持通过地址自动配置方式使主机自动发现网络并获取IPv6地址，大大提高了内部网络的可管理性。 路由聚合 由于IPv4发展初期的分配规划问题，造成许多IPv4地址分配不连续，不能有效聚合路由。日益庞大的路由表耗用大量内存，对设备成本和转发效率产生影响，这一问题促使设备制造商不断升级其产品，以提高路由寻址和转发性能。 巨大的地址空间使得IPv6可以方便的进行层次化网络部署。层次化的网络结构可以方便的进行路由聚合，提高了路由转发效率。 对端到端的安全的支持 IPv4协议制定时并没有仔细针对安全性进行设计，因此固有的框架结构并不能支持端到端的安全。 IPv6中，网络层支持IPSec的认证和加密，支持端到端的安全。 对QoS（Quality of Service）的支持 随着网络会议、网络电话、网络电视迅速普及与使用，客户要求有更好的QoS来保障这些音视频实时转发。IPv4并没有专门的手段对QoS进行支持。 IPv6新增了流标记域，提供QoS保证。 对移动特性的支持 随着Internet的发展，移动IPv4出现了一些问题，比如：三角路由，源地址过滤等。 IPv6协议规定必须支持移动特性。和移动IPv4相比，移动IPv6使用邻居发现功能可直接实现外地网络的发现并得到转交地址，而不必使用外地代理。同时，利用路由扩展头和目的地址扩展头移动节点和对等节点之间可以直接通信，解决了移动IPv4的三角路由、源地址过滤问题，移动通信处理效率更高且对应用层透明。 IPv6地址IPv6地址的表示方法：IPv6地址总长度为128比特，通常分为8组，每组为4个十六进制数的形式，每组十六进制数间用冒号分隔。例如：FC00:0000:130F:0000:0000:09C0:876A:130B，这是IPv6地址的首选格式。 为了书写方便，IPv6还提供了压缩格式，以上述IPv6地址为例，具体压缩规则为： 每组中的前导“0”都可以省略，所以上述地址可写为：FC00:0:130F:0:0:9C0:876A:130B。 地址中包含的连续两个或多个均为0的组，可以用双冒号“::”来代替，所以上述地址又可以进一步简写为：FC00:0:130F::9C0:876A:130B。 需要注意的是，在一个IPv6地址中只能使用一次双冒号“::”，否则当计算机将压缩后的地址恢复成128位时，无法确定每个“::”代表0的个数。 IPv6地址的结构:一个IPv6地址可以分为如下两部分： 网络前缀：n比特，相当于IPv4地址中的网络ID 接口标识：128-n比特，相当于IPv4地址中的主机ID 对于IPv6单播地址来说，如果地址的前三bit不是000，则接口标识必须为64位；如果地址的前三位是000，则没有此限制。 接口标识可通过三种方法生成：手工配置、系统通过软件自动生成或IEEE EUI-64规范生成。其中，EUI-64规范自动生成最为常用。 IEEE EUI-64规范是将接口的MAC地址转换为IPv6接口标识的过程。如下图所示，MAC地址的前24位（用c表示的部分）为公司标识，后24位（用m表示的部分）为扩展标识符。从高位数，第7位是0表示了MAC地址本地唯一。转换的第一步将FFFE插入MAC地址的公司标识和扩展标识符之间，第二步将从高位数，第7位的0改为1表示此接口标识全球唯一。 图：EUI-64规范示意图 例如：MAC地址：000E-0C82-C4D4；转换后020E:0CFF:FE82:C4D4。 这种由MAC地址产生IPv6地址接口标识的方法可以减少配置的工作量，尤其是当采用无状态地址自动配置时，只需要获取一个IPv6前缀就可以与接口标识形成IPv6地址。但是使用这种方式最大的缺点是任何人都可以通过二层MAC地址推算出三层IPv6地址。 IPv6的地址分类：IPv6地址分为单播地址、任播地址（Anycast Address）、组播地址三种类型。和IPv4相比，取消了广播地址类型，以更丰富的组播地址代替，同时增加了任播地址类型。 IPv6单播地址：IPv6单播地址标识了一个接口，由于每个接口属于一个节点，因此每个节点的任何接口上的单播地址都可以标识这个节点。发往单播地址的报文，由此地址标识的接口接收。 IPv6定义了多种单播地址，目前常用的单播地址有：未指定地址、环回地址、全球单播地址、链路本地地址、唯一本地地址ULA（Unique Local Address）。 未指定地址 IPv6中的未指定地址即 0:0:0:0:0:0:0:0/128 或者::/128。该地址可以表示某个接口或者节点还没有IP地址，可以作为某些报文的源IP地址（例如在NS报文的重复地址检测中会出现）。源IP地址是::的报文不会被路由设备转发。 环回地址 IPv6中的环回地址即 0:0:0:0:0:0:0:1/128 或者::1/128。环回与IPv4中的127.0.0.1作用相同，主要用于设备给自己发送报文。该地址通常用来作为一个虚接口的地址（如Loopback接口）。实际发送的数据包中不能使用环回地址作为源IP地址或者目的IP地址。 全球单播地址 全球单播地址是带有全球单播前缀的IPv6地址，其作用类似于IPv4中的公网地址。这种类型的地址允许路由前缀的聚合，从而限制了全球路由表项的数量。 全球单播地址由全球路由前缀（Global routing prefix）、子网ID（Subnet ID）和接口标识（Interface ID）组成，其格式如下如所示： 图：全球单播地址格式 Global routing prefix：全球路由前缀。由提供商（Provider）指定给一个组织机构，通常全球路由前缀至少为48位。目前已经分配的全球路由前缀的前3bit均为001。 Subnet ID：子网ID。组织机构可以用子网ID来构建本地网络（Site）。子网ID通常最多分配到第64位。子网ID和IPv4中的子网号作用相似。 Interface ID：接口标识。用来标识一个设备（Host）。 链路本地地址 链路本地地址是IPv6中的应用范围受限制的地址类型，只能在连接到同一本地链路的节点之间使用。它使用了特定的本地链路前缀FE80::/10（最高10位值为1111111010），同时将接口标识添加在后面作为地址的低64比特。 当一个节点启动IPv6协议栈时，启动时节点的每个接口会自动配置一个链路本地地址（其固定的前缀+EUI-64规则形成的接口标识）。这种机制使得两个连接到同一链路的IPv6节点不需要做任何配置就可以通信。所以链路本地地址广泛应用于邻居发现，无状态地址配置等应用。 以链路本地地址为源地址或目的地址的IPv6报文不会被路由设备转发到其他链路。链路本地地址的格式如下如所示： 图：链路本地地址格式 唯一本地地址 唯一本地地址是另一种应用范围受限的地址，它仅能在一个站点内使用。由于本地站点地址的废除（RFC3879），唯一本地地址被用来代替本地站点地址。 唯一本地地址的作用类似于IPv4中的私网地址，任何没有申请到提供商分配的全球单播地址的组织机构都可以使用唯一本地地址。唯一本地地址只能在本地网络内部被路由转发而不会在全球网络中被路由转发。唯一本地地址格式如下如所示： 图：唯一本地地址格式 Prefix：前缀；固定为FC00::/7。 L：L标志位；值为1代表该地址为在本地网络范围内使用的地址；值为0被保留，用于以后扩展。 Global ID：全球唯一前缀；通过伪随机方式产生。 Subnet ID：子网ID；划分子网使用。 Interface ID：接口标识。 唯一本地地址具有如下特点： 具有全球唯一的前缀（虽然随机方式产生，但是冲突概率很低）。 可以进行网络之间的私有连接，而不必担心地址冲突等问题。 具有知名前缀（FC00::/7），方便边缘设备进行路由过滤。 如果出现路由泄漏，该地址不会和其他地址冲突，不会造成Internet路由冲突。 应用中，上层应用程序将这些地址看作全球单播地址对待。 独立于互联网服务提供商ISP（Internet Service Provider）。 IPv6组播地址：IPv6的组播与IPv4相同，用来标识一组接口，一般这些接口属于不同的节点。一个节点可能属于0到多个组播组。发往组播地址的报文被组播地址标识的所有接口接收。例如组播地址FF02::1表示链路本地范围的所有节点，组播地址FF02::2表示链路本地范围的所有路由器。 一个IPv6组播地址由前缀，标志（Flag）字段、范围（Scope）字段以及组播组ID（Global ID）4个部分组成： 前缀：IPv6组播地址的前缀是FF00::/8。 标志字段（Flag）：长度4bit，目前只使用了最后一个比特（前三位必须置0），当该位值为0时，表示当前的组播地址是由IANA所分配的一个永久分配地址；当该值为1时，表示当前的组播地址是一个临时组播地址（非永久分配地址）。 范围字段（Scope）：长度4bit，用来限制组播数据流在网络中发送的范围。 组播组ID（Group ID）：长度112bit，用以标识组播组。目前，RFC2373并没有将所有的112位都定义成组标识，而是建议仅使用该112位的最低32位作为组播组ID，将剩余的80位都置0。这样每个组播组ID都映射到一个唯一的以太网组播MAC地址（RFC2464）。 IPv6组播地址格式如下图: 图：IPv6组播地址格式 被请求节点组播地址: 被请求节点组播地址通过节点的单播或任播地址生成。当一个节点具有了单播或任播地址，就会对应生成一个被请求节点组播地址，并且加入这个组播组。一个单播地址或任播地址对应一个被请求节点组播地址。该地址主要用于邻居发现机制和地址重复检测功能。 IPv6中没有广播地址，也不使用ARP。但是仍然需要从IP地址解析到MAC地址的功能。在IPv6中，这个功能通过邻居请求NS（Neighbor Solicitation）报文完成。当一个节点需要解析某个IPv6地址对应的MAC地址时，会发送NS报文，该报文的目的IP就是需要解析的IPv6地址对应的被请求节点组播地址；只有具有该组播地址的节点会检查处理。 被请求节点组播地址由前缀FF02::1:FF00:0/104和单播地址的最后24位组成。 IPv6任播地址：任播地址标识一组网络接口（通常属于不同的节点）。目标地址是任播地址的数据包将发送给其中路由意义上最近的一个网络接口。 任播地址设计用来在给多个主机或者节点提供相同服务时提供冗余功能和负载分担功能。目前，任播地址的使用通过共享单播地址方式来完成。将一个单播地址分配给多个节点或者主机，这样在网络中如果存在多条该地址路由，当发送者发送以任播地址为目的IP的数据报文时，发送者无法控制哪台设备能够收到，这取决于整个网络中路由协议计算的结果。这种方式可以适用于一些无状态的应用，例如DNS等。 IPv6中没有为任播规定单独的地址空间，任播地址和单播地址使用相同的地址空间。目前IPv6中任播主要应用于移动IPv6。 注：IPv6任播地址仅可以被分配给路由设备，不能应用于主机。任播地址不能作为IPv6报文的源地址。 子网路由器任播地址 子网路由器任播地址是已经定义好的一种任播地址（RFC3513）。发送到子网路由器任播地址的报文会被发送到该地址标识的子网中路由意义上最近的一个设备。所有设备都必须支持子网任播地址。子网路由器任播地址用于节点需要和远端子网上所有设备中的一个（不关心具体是哪一个）通信时使用。例如，一个移动节点需要和它的“家乡”子网上的所有移动代理中的一个进行通信。 子网路由器任播地址由n bit子网前缀标识子网，其余用0填充。格式如下如所示： 图：子网路由器任播地址 IPv6报文格式IPv6报文由IPv6基本报头、IPv6扩展报头以及上层协议数据单元三部分组成。 上层协议数据单元一般由上层协议报头和它的有效载荷构成，有效载荷可以是一个ICMPv6报文、一个TCP报文或一个UDP报文。 IPv6基本报头: 图：IPv6基本报文头部格式 IPv6报头格式中主要字段解释如下： Version：版本号，长度为4bit。对于IPv6，该值为6。 Traffic Class：流类别，长度为8bit。等同于IPv4中的TOS字段，表示IPv6数据报的类或优先级，主要应用于QoS。 Flow Label：流标签，长度为20bit。IPv6中的新增字段，用于区分实时流量，不同的流标签+源地址可以唯一确定一条数据流，中间网络设备可以根据这些信息更加高效率的区分数据流。 Payload Length：有效载荷长度，长度为16bit。有效载荷是指紧跟IPv6报头的数据报的其它部分（即扩展报头和上层协议数据单元）。该字段只能表示最大长度为65535字节的有效载荷。如果有效载荷的长度超过这个值，该字段会置0，而有效载荷的长度用逐跳选项扩展报头中的超大有效载荷选项来表示。 Next Header：下一个报头，长度为8bit。该字段定义紧跟在IPv6报头后面的第一个扩展报头（如果存在）的类型，或者上层协议数据单元中的协议类型。 Hop Limit：跳数限制，长度为8bit。该字段类似于IPv4中的Time to Live字段，它定义了IP数据报所能经过的最大跳数。每经过一个设备，该数值减去1，当该字段的值为0时，数据报将被丢弃。 Source Address：源地址，长度为128bit。表示发送方的地址。 Destination Address：目的地址，长度为128bit。表示接收方的地址。 IPv6和IPv4相比，去除了IHL、identifiers、Flags、Fragment Offset、Header Checksum、 Options、Paddiing域，只增了流标签域，因此IPv6报文头的处理较IPv4大大简化，提高了处理效率。另外，IPv6为了更好支持各种选项处理，提出了扩展头的概念，新增选项时不必修改现有结构就能做到，理论上可以无限扩展，体现了优异的灵活性。下面为读者介绍IPv6扩展报头的一些信息。 IPv6报文抓包示例： 图：IPv6报文抓包示例 IPv6扩展头部:在IPv4中，IPv4报头包含可选字段Options，内容涉及security、Timestamp、Record route等，这些Options可以将IPv4报头长度从20字节扩充到60字节。在转发过程中，处理携带这些Options的IPv4报文会占用设备很大的资源，因此实际中也很少使用。 IPv6将这些Options从IPv6基本报头中剥离，放到了扩展报头中，扩展报头被置于IPv6报头和上层协议数据单元之间。一个IPv6报文可以包含0个、1个或多个扩展报头，仅当需要设备或目的节点做某些特殊处理时，才由发送方添加一个或多个扩展头。与IPv4不同，IPv6扩展头长度任意，不受40字节限制，这样便于日后扩充新增选项，这一特征加上选项的处理方式使得IPv6选项能得以真正的利用。但是为了提高处理选项头和传输层协议的性能，扩展报头总是8字节长度的整数倍。 当使用多个扩展报头时，前面报头的Next Header字段指明下一个扩展报头的类型，这样就形成了链状的报头列表。如下图所示，IPv6基本报头中的Next Header字段指明了第一个扩展报头的类型，而第一个扩展报头中的Next Header字段指明了下一个扩展报头的类型（如果不存在，则指明上层协议的类型）。 图：IPv6扩展报头格式 IPv6扩展报头中主要字段解释如下： Next Header：下一个报头，长度为8bit。与基本报头的Next Header的作用相同。指明下一个扩展报头（如果存在）或上层协议的类型。 Extension Header Len：报头扩展长度，长度为8bit。表示扩展报头的长度（不包含Next Header字段）。 Extension Head Data：扩展报头数据，长度可变。扩展报头的内容，为一系列选项字段和填充字段的组合。 目前，RFC 2460中定义了6个IPv6扩展头：逐跳选项报头、目的选项报头、路由报头、分段报头、认证报头、封装安全净载报头. 逐跳选项报头： （代表该报头的Next Header字段值=0） 该选项主要用于为在传送路径上的每跳转发指定发送参数，传送路径上的每台中间节点都要读取并处理该字段。逐跳选项报头目前的主要应用有以下三种： 用于巨型载荷（载荷长度超过65535字节）。 用于设备提示，使设备检查该选项的信息，而不是简单的转发出去。 用于资源预留（RSVP）。 目的选项报头： （代表该报头的Next Header字段值=60） 目的选项报头携带了一些只有目的节点才会处理的信息。目前，目的选项报文头主要应用于移动IPv6。 路由报头： （代表该报头的Next Header字段值=43） 路由报头和IPv4的Loose Source and Record Route选项类似，该报头能够被IPv6源节点用来强制数据包经过特定的设备。 分段报头: （代表该报头的Next Header字段值=44） 同IPv4一样，IPv6报文发送也受到MTU的限制。当报文长度超过MTU时就需要将报文分段发送，而在IPv6中，分段发送使用的是分段报头。 认证报头： （代表该报头的Next Header字段值=51） 该报头由IPsec使用，提供认证、数据完整性以及重放保护。它还对IPv6基本报头中的一些字段进行保护。 封装安全净载报头： （代表该报头的Next Header字段值=50） 该报头由IPsec使用，提供认证、数据完整性以及重放保护和IPv6数据报的保密，类似于认证报头。 IPv6扩展报头规约：当超过一种扩展报头被用在同一个分组里时，报头必须按照下列顺序出现： IPv6基本报头 逐跳选项扩展报头 目的选项扩展报头 路由扩展报头 分段扩展报头 认证扩展报头 封装安全有效载荷扩展报头 目的选项扩展报头 上层协议数据报文 路由设备转发时根据基本报头中Next Header值来决定是否要处理扩展头，并不是所有的扩展报头都需要被转发路由设备查看和处理的。 除了目的选项扩展报头可能出现一次或两次（一次在路由扩展报头之前，另一次在上层协议数据报文之前），其余扩展报头只能出现一次。 ICMPv6ICMPv6（Internet Control Message Protocol for the IPv6）是IPv6的基础协议之一。 在IPv4中，Internet控制报文协议ICMP（Internet Control Message Protocol）向源节点报告关于向目的地传输IP数据包过程中的错误和信息。它为诊断、信息和管理目的定义了一些消息，如：目的不可达、数据包超长、超时、回应请求和回应应答等。在IPv6中，ICMPv6除了提供ICMPv4常用的功能之外，还是其它一些功能的基础，如邻接点发现、无状态地址配置（包括重复地址检测）、PMTU发现等。 ICMPv6的协议类型号（即IPv6报文中的Next Header字段的值）为58。ICMPv6的报文格式下图所示： 图：ICMPv6报文格式 报文中字段解释如下： Type：表明消息的类型，0至127表示差错报文类型，128至255表示消息报文类型。 Code：表示此消息类型细分的类型。 Checksum：表示ICMPv6报文的校验和。 ICMPv6报文抓包示例： 图：ICMPv6报文抓包示例 ICMPv6错误报文的分类：ICMPv6错误报文用于报告在转发IPv6数据包过程中出现的错误。ICMPv6错误报文可以分为以下4种： 目的不可达错误报文 在IPv6节点转发IPv6报文过程中，当设备发现目的地址不可达时，就会向发送报文的源节点发送ICMPv6目的不可达错误报文，同时报文中会携带引起该错误报文的具体原因。 目的不可达错误报文的Type字段值为1。根据错误具体原因又可以细分为： Code=0：没有到达目标设备的路由。 Code=1：与目标设备的通信被管理策略禁止。 Code=2：未指定。 Code=3：目的IP地址不可达。 Code=4：目的端口不可达。 数据包过大错误报文 在IPv6节点转发IPv6报文过程中，发现报文超过出接口的链路MTU时，则向发送报文的源节点发送ICMPv6数据包过大错误报文，其中携带出接口的链路MTU值。数据包过大错误报文是Path MTU发现机制的基础。 数据包过大错误报文的Type字段值为2，Code字段值为0。 时间超时错误报文 在IPv6报文收发过程中，当设备收到Hop Limit字段值等于0的数据包，或者当设备将Hop Limit字段值减为0时，会向发送报文的源节点发送ICMPv6超时错误报文。对于分段重组报文的操作，如果超过定时时间，也会产生一个ICMPv6超时报文。 时间超时错误报文的Type字段值为3，根据错误具体原因又可以细分为： Code=0：在传输中超越了跳数限制。 Code=1：分片重组超时。 参数错误报文 当目的节点收到一个IPv6报文时，会对报文进行有效性检查，如果发现问题会向报文的源节点回应一个ICMPv6参数错误差错报文。 参数错误报文的Type字段值为4，根据错误具体原因又可以细分为： Code=0：IPv6基本头或扩展头的某个字段有错误。 Code=1：IPv6基本头或扩展头的NextHeader值不可识别。 Code=2：扩展头中出现未知的选项。 ICMPv6信息报文的分类 回送请求报文：回送请求报文用于发送到目标节点，以使目标节点立即发回一个回送应答报文。回送请求报文的Type字段值为128，Code字段的值为0。 回送应答报文：当收到一个回送请求报文时，ICMPv6会用回送应答报文响应。回送应答报文的Type字段的值为129，Code字段的值为0。 其他报文:邻居发现ND： Type=133 路由器请求 RS（Router Solicitation） Type=134 路由器公告 RA（Router Advertisement） Type=135 邻居请求 NS（Neighbor Solicitation） Type=136 邻居通告 NA（Neighbor Advertisement） Type=137 重定向（Redirect） 多播侦听发现协议MLD： Type=130 多播听众查询 Type-131 多播听众报告 Type=132 多播听众退出 Path MTU在IPv4中，报文如果过大，必须要分片进行发送，所以在每个节点发送报文之前，设备都会根据发送接口的最大传输单元MTU（Maximum Transmission Unit）来对报文进行分片。但是在IPv6中，为了减少中间转发设备的处理压力，中间转发设备不对IPv6报文进行分片，报文的分片将在源节点进行。当中间转发设备的接口收到一个报文后，如果发现报文长度比转发接口的MTU值大，则会将其丢弃；同时将转发接口的MTU值通过ICMPv6报文的“Packet Too Big”消息发给源端主机，源端主机以该值重新发送IPv6报文，这样带来了额外流量开销。PMTU发现协议可以动态发现整条传输路径上各链路的MTU值，减少由于重传带来的额外流量开销。 PMTU协议是通过ICMPv6的Packet Too Big报文来完成的。首先源节点假设PMTU就是其出接口的MTU，发出一个试探性的报文，当转发路径上存在一个小于当前假设的PMTU时，转发设备就会向源节点发送Packet Too Big报文，并且携带自己的MTU值，此后源节点将PMTU的假设值更改为新收到的MTU值继续发送报文。如此反复，直到报文到达目的地之后，源节点就能知道到达目的地的PMTU了。 图：PMTU原理 整条传输路径需要通过4条链路，每条链路的MTU分别是1500、1500、1400、1300，当源节点发送一个分片报文的时候，首先按照PMTU为1500进行分片并发送分片报文，当到达MTU为1400的出接口时，设备返回Packet Too Big错误，同时携带MTU值为1400的信息。源节点接收到之后会将报文重新按照PMTU为1400进行分片并再次发送一个分片报文，当分片报文到达MTU值为1300的出接口时，同样返回Packet Too Big错误，携带MTU值为1300的信息。之后源节点重新按照PMTU为1300进行分片并发送分片报文，最终到达目的地，这样就找到了该路径的PMTU。 由于IPv6要求链路层所支持的最小MTU为1280，所以PMTU的值必须大于1280。建议您用1500作为链路的PMTU值。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP命令行配置]]></title>
    <url>%2F2018%2F01%2F23%2FBGP%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[BGP命令行简介配置BGP的基本功能：启动BGP进程：123bgp 100//启动bgp指定as号router-id 1.1.1.1//配置BGP的router-id 配置BGP对等体：配置BGP对等体时，如果指定对等体所属的AS编号与本地AS编号相同，表示配置IBGP对等体。如果指定对等体所属的AS编号与本地AS编号不同，表示配置EBGP对等体。为了增强BGP连接的稳定性，推荐使用路由可达的Loopback接口地址建立BGP连接。 注：当使用Loopback接口的IP地址建立BGP连接时，两端需同时配置peer connect-interface ，保证端TCP连接的接口和地址的正确性。如果仅有一端配置该命令，可能导致BGP连接建立失败。 当使用Loopback接口的IP地址建立EBGP连接时，必须配置命令peer ebgp-max-hop，否则EBGP连接将无法建立。 若需要对大量对等体进行相同的配置，可以通过配置BGP对等体组来减轻配置工作量。 12345678[BGP] peer 12.1.1.1 as-number 100//创建BGP对等体peer 12.1.1.1 connet-interface lookback 0//指定发送BGP报文的源接口，并可指定发起连接时使用的源地址。//缺省情况下，BGP使用报文的出接口作为BGP报文的源接口。peer 12.1.1.1 ebgp-max-hop 2//指定建立EBGP连接允许的最大跳数。 //缺省情况下，EBGP连接允许的最大跳数为1，即只能在物理直连链路上建立EBGP连接。 配置BGP对等体组：123456group 1 [ external | internal ]//创建对等体组。peer 1 as-number 100//配置EBGP对等体组的AS号。 peer 12.1.1.2 group 1//向对等体组中加入对等体。 配置BGP引入路由：BGP协议本身不发现路由，因此需要将其他路由（如IGP路由等）引入到BGP路由表中，从而将这些路由在AS之内和AS之间传播。BGP协议支持通过以下两种方式引入路由： Import方式：按协议类型，将RIP路由、OSPF路由、ISIS路由等协议的路由引入到BGP路由表中。为了保证引入的IGP路由的有效性，Import方式还可以引入静态路由和直连路由。 Network方式：逐条将IP路由表中已经存在的路由引入到BGP路由表中，比Import方式更精确。 123456import-router protocol //引入路由default-route imported//允许BGP引入本地IP路由表中已经存在的缺省路由。 network 1.1.1.1 mask 32 //配置BGP逐条引入IPv4路由表或IPv6路由表中的路由。 配置BGP安全性：配置MD5认证：BGP使用TCP作为传输协议，只要TCP数据包的源地址、目的地址、源端口、目的端口和TCP序号是正确的，BGP就会认为这个数据包有效，但数据包的大部分参数对于攻击者来说是不难获得的。为了保证BGP协议免受攻击，可以在BGP邻居之间使用MD5认证或者Keychain认证来降低被攻击的可能性。其中MD5算法配置简单，配置后生成单一密码，需要人为干预才可以更换密码。 12peer 12.1.1.2 password cipher Huawei //配置MD5认证密码 配置Keychain认证：Keychain具有一组密码，可以根据配置自动切换，但是配置过程较为复杂，适用于对安全性能要求比较高的网络。 12peer 12.1.1.2 keychain 1 //配置Keychain认证 BGP对等体两端必须都配置针对使用TCP连接的应用程序的Keychain认证，且配置的Keychain必须使用相同的加密算法和密码，才能正常建立TCP连接，交互BGP消息。Keychain认证推荐使用SHA256和HMAC-SHA256加密算法。 BGP MD5认证与BGP Keychain认证互斥。 配置BGP GTSM功能：为防止攻击者模拟真实的BGP协议报文对设备进行攻击，可以配置GTSM功能检测IP报文头中的TTL值。根据实际组网的需要，对于不符合TTL值范围的报文，GTSM可以设置为通过或丢弃。当配置GTSM缺省动作为丢弃时，可以根据网络拓扑选择合适的TTL有效范围，不符合TTL值范围的报文会被接口板直接丢弃，这样就避免了网络攻击者模拟的“合法”BGP报文攻击设备。 123456peer 12.1.1.2 valid-ttl-hops 254//配置BGP GTSM功能。 //缺省情况下，BGP对等体（组）上未配置GTSM功能。 gtsm default-action &#123; drop | pass&#125;//设置未匹配GTSM策略的报文的缺省动作。 //缺省情况下，未匹配GTSM策略的报文可以通过过滤。 简化IBGP网络连接：配置BGP路由反射器：在AS内部，为保证IBGP对等体之间的连通性，需要在IBGP对等体之间建立全连接关系。当IBGP对等体数目很多时，建立全连接网络的开销很大。使用路由反射器RR（Route Reflector）可以解决这个问题。 集群ID用于防止集群内多个路由反射器和集群间的路由环路。当一个集群里有多个路由反射器时，必须为同一个集群内的所有路由反射器配置相同的集群ID。 如果路由反射器的客户机之间重新建立了IBGP全连接关系，那么客户机之间的路由反射就是没有必要的，而且还占用带宽资源。此时可以配置禁止客户机之间的路由反射，减轻网络负担。 在一个AS内，RR主要有路由传递和流量转发两个作用。当RR连接了很多客户机和非客户机时，同时进行路由传递和流量转发会使CPU资源消耗很大，影响路由传递的效率。如果需要保证路由传递的效率，可以在该RR上禁止BGP将优选的路由下发到IP路由表，使RR主要用来传递路由。 12345678peer &#123; group-name | ipv4-address | ipv6-address &#125; reflect-client//配置路由反射器及其客户。 refelctor cluster-id 1.1.1.1//配置路由反射器的集群ID。 undo reflect between-clients//禁止客户机之间的路由反射。routing-table rib-noly [ route-policy route-policy-name ]//禁止BGP将优选的路由下发到IP路由表。 配置BGP联盟：联盟将一个自治系统划分为若干个子自治系统，每个子自治系统内部的IBGP对等体建立全连接关系或者配置反射器，子自治系统之间建立EBGP连接关系。大型BGP网络中，配置联盟不但可以减少IBGP连接的数量，还可以简化路由策略的管理，提高路由的发布效率。 123456confederation id &#123; as-number-plain | as-number-dot &#125;//配置联盟IDconfederation peer-as &#123; as-number-plain | as-number-dot &#125; &amp;&lt;1-32&gt;//指定属于同一个联盟的子AS号。 confederation nonstandard//配置联盟的兼容性。 注：同一联盟内不能同时配置2字节AS号的Old Speaker和4字节AS号的New Speaker。因为AS4_Path不支持联盟，这种配置可能会引起环路。 配置BGP路由选路和负载分担：配置BGP协议优先级：由于路由器上可能同时运行多个动态路由协议，就存在各个路由协议之间路由信息共享和选择的问题。系统为每一种路由协议设置一个缺省优先级。在不同协议发现同一条路由时，优先级高的路由将被优选。 1234preference 255//设定BGP的协议优先级。//缺省情况下，BGP的协议优先级为255。//配置优先级的值越小，优先级越高。 BGP有三种路由： 从外部对等体学到的路由（EBGP） 从内部对等体学到的路由（IBGP） 本地产生的路由（Local Origined）,是指通过聚合命令所聚合的路由。 可以为这三种路由设定不同的优先级。 另外，还可以通过应用路由策略，为符合匹配条件的特定路由配置优先级。对于不符合匹配条件的路由，则使用缺省优先级。 若同时配置了external internal local和route-policy route-policy-name，则通过策略的路由按路由策略中的规则设置，未通过策略的路由优先级按external internal local设置。 配置Next_Hop属性：当ASBR将从EBGP邻居学到的路由转发给IBGP邻居时，默认不修改下一跳。IBGP邻居收到该路由后，会发现下一跳不可达，于是将该路由设为非活跃路由，不通过该路由指导流量转发。当希望IBGP邻居通过该路由指导流量转发时，可以在ASBR上配置向IBGP对等体（组）转发路由时，将自身地址作为下一跳。这时，IBGP邻居收到ASBR从EBGP邻居学习来的路由后，发现下一跳可达，于是将路由设为活跃路由。 当BGP路由发生变化时，BGP需要对非直连的下一跳重新进行迭代。如果不对迭代后的路由进行任何限制，则BGP可能会将下一跳迭代到一个错误的转发路径上，从而造成流量丢失。此时，可配置BGP按路由策略迭代下一跳，避免流量丢失。 123456789peer 12.1.1.1 next-hop-local //配置BGP设备向IBGP对等体（组）发布路由时，把下一跳地址设为自身的IP地址。//缺省情况下，BGP设备向IBGP对等体发布路由时，不修改下一跳地址。nexthop recursive-loolup router-policy //配置BGP按路由策略进行下一跳迭代。peer 12.1.1.1 next-hop-invariable//配置发布引入的IGP路由时不改变该IGP路由的下一跳地址。 //缺省情况下，对等体在发布所引入的IGP路由时会将下一跳//地址改为本地与对端连接的接口地址。 配置BGP路由信息的首选值：协议首选值（PrefVal）是华为设备的特有属性，该属性仅在本地有效。当BGP路由表中存在到相同目的地址的路由时，将优先选择协议首选值高的路由。 123peer 12.1.1.1 perferred-value value//为从指定对等体学来的所有路由配置首选值。 //缺省情况下，从对等体学来的路由的初始首选值为0。 配置本地缺省Local_Pref属性：Local_Pref属性用于判断流量离开AS时的最佳路由。当BGP的设备通过不同的IBGP对等体得到到AS外的目的地址相同但下一跳不同的多条路由时，将优先选择Local_Pref属性值较高的路由。 123defaut local-preference 100//配置本机的缺省Local_Pref属性值。 //缺省情况下，BGP本地优先级的值为100。 配置AS_Path属性：AS_Path属性按矢量顺序记录了某条路由从本地到目的地址所要经过的所有AS编号。配置不同的AS_Path属性功能，可以实现灵活的路由选路。 通常情况下，AS_Path属性内AS_Path数量作为BGP选路条件。当不需要AS_Path属性作为选路条件时，可以配置不将AS_Path属性作为选路条件。 通常情况下，BGP通过AS号检测路由环路。但在Hub and Spoke组网方式下，为保证路由能够正确传递，从Hub-CE发布私网路由到Spoke-CE途中经过的相关BGP对等体需要配置允许AS_Path中AS号重复1次的路由通过。 公有AS号可以直接在Internet上使用，私有AS号直接发布到Internet上可能造成环路现象。为了解决上述情况，可以在把路由发布到Internet前，配置发送EBGP更新报文时，AS_Path属性中仅携带公有AS编号。 在重构AS_Path或聚合生成新路由时，可以对AS_Path中的AS号最大个数予以限制。配置AS_Path属性中AS号的最大个数后，接收路由时会检查AS_Path属性中的AS号是否超限，如果超限则丢弃路由。 通常情况下，一个设备只支持一个BGP进程，即只支持一个AS号。但是在某些特殊情况下，例如网络迁移更换AS号的时候来为了保证网络切换的顺利进行，可以为指定对等体设置一个伪AS号。 BGP会检查EBGP对等体发来的更新消息中AS_Path列表的第一个AS号，确认第一个AS号必须是该EBGP对等体所在的AS。否则，该更新信息被拒绝，EBGP连接中断。如果不需要BGP检查EBGP对等体发来的更新消息中AS_Path列表的第一个AS号，可以去使能此功能。 1234567891011121314151617181920212223route-policy AS-path permit node 10 apply as-path 100 &#123; additive | overwrite &#125;//设置BGP路由的AS_Path属性。peer 12.1.1.1 route-policy AS-path export//对向对等体（组）发布的路由添加AS_Path属性。import-route protocol route-policy AS-path//BGP以import方式引入的路由添加AS_Path属性。network 12.1.1.1 route-policy AS-path//对BGP以network方式引入的路由添加AS_Path属性。bestrouter as-path-ignore//不将AS_Path属性作为选路条件。peer 12.1.1.1 allow-as-loop 100//允许本地AS编号重复出现。//缺省情况下，不允许本地AS号重复。 peer 12.1.1.1 public-as-only//配置发送EBGP更新报文时，AS_Path属性中仅携带公有AS编号。//缺省情况下，发送EBGP更新报文时，AS_Path属性中可以同时携带公有AS号和私有AS号。 as-path-limit 255//配置AS_Path属性中AS号的最大个数。//缺省情况下，AS_Path属性中AS号的最大个数是255。peer 12.1.1.1 fake-as 200//配置EBGP对等体的伪AS号 配置MED属性：MED属性相当于IGP使用的度量值（Metrics），它用于判断流量进入AS时的最佳路由。当一个运行BGP的设备通过不同的EBGP对等体得到目的地址相同但下一跳不同的多条路由时，在其它条件相同的情况下，将优先选择MED值较小者作为最佳路由。 123456789101112131415default med 0//配置缺省MED值。配置缺省MED值。bestroute med-none-as-maximum//设置当路由没有MED值时将其作为最大值处理。//缺省情况下，当路由属性中没有MED值时，BGP在选路时将使用缺省MED值。compare-different-as-med//允许BGP比较属于任意AS的EBGP对等体的路由的MED值。//缺省情况下，BGP只比较属于同一AS的EBGP对等体的路由的MED属性值。deterministic-med//使能Deterministic-MED的功能。 //在路由选路时优先比较AS_Path最左边的AS号相同的路由。//Deterministic :确定性的bestroute med-confederation//比较联盟内路由的MED值。//缺省情况下，BGP仅比较来自同一AS的路由的MED属性值。 配置BGP选路是忽略下一跳IGP路由的度量值：在BGP网络中，BGP设备经常从多个邻居收到多条前缀相同但路径不同的路由。这时，BGP需要选择到达指定前缀的最佳路由来指导报文转发。缺省情况下，BGP会比较这些路由下一跳的IGP路由的度量值，并优选度量值最小的路由。 12bestroute igp-metric-ignore//配置BGP在选择最优路由时忽略下一跳IGP路由的度量值。 配置BGP团体属性：团体属性是BGP的私有属性，在BGP对等体之间传播，且不受AS的限制。利用团体属性可以使多个AS中的一组BGP设备共享相同的策略，从而简化路由策略的应用和降低维护管理的难度。BGP设备可以在发布路由时，新增或者改变路由的团体属性。 12345678910111213apply conmunity &#123; community-number | aa:nn | internet | no-advertise | no-export | no-export-subconfed &#125; &amp;&lt;1-32&gt; [ additive ]，//配置BGP路由信息的团体属性。//一条命令中最多可以配置32个团体属性。peer 12.1.1.1 route-policy conmunity erport//对向对等体（组）发布的路由添加团体属性peer 12.1.1.1 advertisse-community//配置允许将团体属性传给对等体或对等体组。//缺省情况下，不将团体属性发布给任何对等体或对等体组。peer 12.1.1.1 advertise-ext-community//配置将扩展团体属性发布给对等体或对等体组。ext-community-change enable//配置允许通过路由策略修改扩展团体属性。 配置BGP负载分担：在大型网路中，到达同一目的地通常会存在多条有效路由，但是BGP只将最优路由发布给对等体，这一特点往往会造成很多流量负载不均衡的情况。通过配置BGP负载分担，可以流量负载均衡，减少网络拥塞。 一般情况下，只有“BGP选择路由的策略”所描述的前8个属性完全相同，BGP路由之间才能相互等价，实现BGP的负载分担。但路由负载分担的规则也可以通过配置来改变，如忽略路由AS-Path属性的比较，但这些配置需要确保不会引起路由环路。 公私网互引路由和本地交叉路由不能进行负载分担。 123maximum load-balancing [ ebgp | ibgp] number [ ecmp-nexthop-changed ]//配置BGP负载分担的最大等价路由条数。 //缺省情况下，BGP负载分担的最大等价路由条数为1，即不进行负载分担。 控制BGP路由的发布和接收：控制BGP路由信息的发布：BGP路由表路由数量通常比较大，传递大量的路由对设备来说是一个很大的负担，为了减小路由发送规模，需要对发布的路由进行控制，只发送自己想要发布的路由或者只发布对等体需要的路由。另外，到达同一个目的地址，可能存在多条路由，这些路由分别需要穿越不同的AS，为了把业务流量引导向某些特定的AS，也需要对发布的路由进行筛选。 基于访问控制列表ACL：peer { group-name | ipv4-address | ipv6-address } filter-policy { acl-number | acl-name acl-name | acl6-number | acl6-name acl6-name } export 基于前缀列表：peer { ipv4-address | group-name } ip-prefix ip-prefix-name export 基于AS路径过滤器：peer { ipv4-address | group-name | ipv6-address } as-path-filter { as-path-filter-number | as-path-filter-name } export 基于Router-Policy：peer { ipv4-address | group-name | ipv6-address } route-policy route-policy-name export 控制BGP路由信息的接收：当设备遭到恶意攻击或者网络中出现错误配置时，会导致BGP从邻居接收到大量的路由，从而消耗大量设备的资源。因此管理员必须根据网络规划和设备容量，对运行时所使用的资源进行限制。BGP提供了基于对等体的路由控制，限定邻居发来的路由数量，这样可以避免上述问题。 基于访问控制列表ACL：peer { group-name | ipv4-address | ipv6-address } filter-policy { acl-number | acl-name acl-name | acl6-number | acl6-name acl6-name } import 基于前缀列表：peer { ipv4-address | group-name } ip-prefix ip-prefix-name import 基于AS路径过滤器：peer { ipv4-address | group-name | ipv6-address } as-path-filter { as-path-filter-number | as-path-filter-name }import 基于Router-Policy：peer { ipv4-address | group-name | ipv6-address } route-policy route-policy-name import 12peer &#123; group-name | ipv4-address &#125; route-limit limit [ percentage ] [ alert-only | idle-forever | idle-timeout times ]，//设置允许从对等体（组）收到的路由数量。 配置BGP软复位：BGP的入口策略改变后，为了使新的策略立即生效，可以复位BGP连接，但这样会造成短暂的BGP连接中断。BGP支持手工对BGP连接进行软复位，可在不中断BGP连接情况下完成路由表的刷新。对于不支持软复位的BGP对等体，可以同时配置保留该对等体的所有原始路由功能，在不复位BGP连接的情况下完成路由表的刷新。 对于支持Route-refresh能力的BGP对等体，同时配置手工对BGP连接进行软复位，可在不中断BGP连接情况下完成路由表的刷新。 12345peer 12.1.1.1 capability-advertise router-refresh//使能Route-refresh能力//缺省情况下，Route-refresh能力是使能的。&lt;Huawei&gt;refresh bgp all export //触发BGP软复位 配置调整BGP网络的收敛速度：配置BGP连接重传定时器：BGP发起TCP连接后，如果成功建立起TCP连接，则关闭连接重传定时器。如果TCP连接建立不成功，则会在连接重传定时器超时后重新尝试建立连接 设置较小的连接重传定时器，可以减少等待下次连接建立的时间，加快连接失败后重新建立的速度。 设置较大的连接重传定时器，可以减小由于邻居反复振荡引起的路由振荡。 BGP支持在全局或者单个对等体（组）配置连接重传定时器。定时器生效的优先级是单个对等体高于对等体组，对等体组高于全局。 123456timer connect-retry 32//配置BGP全局连接重传定时器。 //缺省情况下，连接重传定时器是32秒。peer 12.1.1.1 timer connect-retry 32//配置对等体或对等体组的连接重传定时器。 配置BGP存活时间和保持时间定时器：BGP的Keepalive消息用于维持BGP连接关系。 减小存活时间和保持时间，BGP可以更快速的检测到链路的故障，有利于BGP网络快速收敛。但是过短的保持时间会导致网络中的Keepalive消息会增多，使得设备的负担加重，并且会占用一定的网络带宽。 增大存活时间和保持时间，可以减轻设备负担和减少网络带宽的占用。但是过长的保持时间会导致网络中的Keepalive消息减少，使得BGP不能及时检测到链路状态的变化，不利于BGP网络快速收敛，还可能会造成流量损失。 BGP支持在全局或者单个对等体（组）配置存活时间和保持时间定时器。定时器生效的优先级单个对等体高于对等体组，对等体组高于全局。 1234567tiemer keepalive 60 hold 180//配置全局BGP定时器。 //合理的最大Keepalive消息发送间隔为保持时间的三分之一。//缺省情况下，存活时间为60秒，保持时间为180秒。 peer 12.1.1.1 tiemer keepalive 60 hold 180//配置对等体的keepalive发送间隔和保持时间 配置更新报文定时器：BGP协议不会定期更新路由表，当BGP路由发生变化时，会通过Update消息增量地更新路由表。 减小更新报文时间，BGP可以更快速的检测到路由变化，有利于BGP网络快速收敛。但是过短的更新报文时间会导致网络中的Update消息会增多，使得设备的负担加重，并且会占用一定的网络带宽。 增大更新报文时间，可以减轻设备负担和减少网络带宽的占用，避免不必要的路由振荡。但是过长的保持时间会导致网络中的Update消息减少，使得BGP不能及时检测到路由的变化，不利于BGP网络快速收敛，还可能会造成流量损失。 1234peer 12.1.1.1 route-update-interval 15//配置更新报文定时器。//缺省情况下，IBGP对等体的更新报文定时器为15秒//EBGP对等体的更新报文定时器为30秒。 配置EBGP连接快速复位：EBGP连接快速复位功能缺省情况下是使能的，目的是为了使BGP协议不必等待保持时间定时器超时，而立即快速响应接口故障，删除接口上的EBGP直连会话，便于BGP快速收敛。 但是如果EBGP连接所使用的接口状态反复变化，EBGP会话就会反复重建与删除，造成网络振荡。这时，可以去使能EBGP连接快速复位功能。BGP协议会等待保持时间定时器超时，才会删除接口上的EBGP直连会话，这样就在一定程度上抑制了BGP网络振荡，同时在一定程度上节约了网络带宽。 12undo ebgp-interface-sensitive//去使能EBGP连接快速复位 配置BGP下一跳延迟响应：BGP下一跳延时响应可以加快BGP收敛速度，减少流量的丢失。 BGP下一跳延时响应只适用于下游到达同一目的地有多个链路的场景。如果下游链路唯一，当链路故障时无法进行链路切换，那么此时配置BGP下一跳延时响应会造成更大流量损失。 123nexthop recursive-lookup delay 0//配置BGP响应下一跳变化的延迟时间。 //缺省情况下，没有配置BGP响应下一跳变化的延迟时间。 配置BGP路由震荡抑制：路由振荡（Route flapping）指路由表中的某条路由反复消失和重现。一般情况下，BGP都应用于复杂的网络环境中，路由变化十分频繁。而频繁的路由振荡会消耗大量的带宽资源和CPU资源，严重时会影响到网络的正常工作。通过配置EBGP或者IBGP路由振荡抑制功能可防止持续路由振荡带来的不利影响。 BGP可以按策略区分路由，对不同的路由采用不同的Dampening参数进行抑制。例如，实际网络中，对掩码较长的路由设置较长的抑制时间，而对掩码较短的（例如8位掩码长度）路由，则采用相对较短的抑制时间。 12dampening [ ibgp ] [ half-life-reach reuse suppress ceiling | route-policy route-policy-name ] *//使能BGP路由振荡抑制或修改各种BGP路由振荡抑制参数。 参数 参数说明 取值 half-life-reach 指定可达路由的半衰期。 整数形式，单位为分钟，取值范围为1～45。缺省值为15。 reuse 指定路由解除抑制状态的阈值。当惩罚降低到该值以下，路由就被再使用。 整数形式，取值范围为1～20000。缺省值为750。 suppress 指定路由进入抑制状态的阈值。当惩罚超过该值时，路由受到抑制。 整数形式，取值范围为1～20000，所配置的值必须大于reuse的值。缺省值为2000。 ceiling 惩罚上限值。 整数形式，取值范围为1001～20000。实际配置的值必须大于suppress。缺省值为16000。 route-policy route-policy-name 指定Route-Policy名称。 字符串形式，区分大小写，不支持空格，长度范围是1～40。当输入的字符串两端使用双引号时，可在字符串中输入空格。 ibgp 指定路由类型为IBGP路由。不指定该参数，则表示路由类型为IBGP。说明： ibgp参数仅在BGP-VPNv4地址族视图下生效。 配置慢对等体检测功能：通过慢对等体检测功能，可以将严重影响发送路由更新速度的对等体从打包组中切出，提高BGP网络的收敛速度。 一个打包组里可能包含有多个对等体。如果出现由于网络拥塞等原因而使本地设备向其中一个对等体发布路由的速度很慢的情况，则会影响本地设备向这个打包组中的其他对等体发布路由速度。为了不影响打包组内其他对等体发布路由，缺省情况下，慢对等体检测功能是使能的。 在使能慢对等体检测功能的情况下，系统会根据向每个对等体发送100个报文所消耗的时间检测出发布路由最慢的对等体关系。如果向这个对等体发送100个报文所消耗的时间超出平均时间的量大于慢对等体检测阈值，则该对等体将被认定为慢对等体，并把这个对等体切出打包组，以免影响向其他对等体发送路由更新的速度。缺省情况下，慢对等体检测阈值是300秒。 123slow-peer detection threshold 300//置慢对等体检测阈值。 //缺省情况下，慢对等体检测阈值是300秒。 配置BGP可靠性：配置BGP Trackong ：为了实现BGP快速收敛，可以通过配置BFD来探测邻居状态变化，但BFD需要全网部署，扩展性较差。在无法部署BFD检测邻居状态时，可以本地配置BGP Peer Tracking功能，快速感知链路不可达或者邻居不可达，实现网络的快速收敛。 通过部署BGP Tracking功能，调整从发现邻居不可达到中断连接的时间间隔，可以抑制路由震荡引发的BGP邻居关系震荡，提高BGP网络的稳定性。 12peer 12.1.1.1 tracking delay 100//使能对于指定对等体的BGP Tracking功能。 配置BFD for BGP：12peer 12.1.1.1 bgd enable//配置对等体或对等体组的BFD功能，使用缺省的BFD参数值建立BFD会话。 配置BGP GR：当BGP协议重启时会导致对等体关系重新建立和转发中断，使能平滑重启GR（Graceful Restart）功能后可以避免流量中断。 1234567graceful-restart//使能BGP协议的GR能力graceful-restart timer wait-for-rib 600//配置重启侧（Restarting Speaker）和接收侧（Receiving Speaker）等待End-of-RIB消息的时间。 //缺省情况下，等待End-of-RIB消息的时间为600秒。fraceful-restart peer-reset//配置设备以GR方式复位BGP连接。 配置BGP路由聚合：IPv4网络中BGP支持自动聚合和手动聚合两种聚合方式，自动聚合的路由优先级低于手动聚合的路由优先级。IPv6网络仅支持手动聚合方式。 12345summary automatic//配置按照自然网段聚合子网路由。 aggregate //用来在BGP路由表中创建一条聚合路由。aggregate ipv4-address &#123; mask | mask-length &#125; [ as-set | attribute-policy route-policy-name1 | detail-suppressed | origin-policy route-policy-name2 | suppress-policy route-policy-name3 ]* 参数 参数说明 取值 ipv4-address 指定聚合路由的IPv4地址。 点分十进制形式。 mask 指定聚合路由的网络掩码。 点分十进制形式。 mask-length 指定聚合路由的网络掩码长度。 整数形式，取值范围是0～32。 ipv6-address 指定聚合路由的IPv6地址。 32位16进制数，格式为X:X:X:X:X:X:X:X。 prefix-length 指定聚合IPv6路由的前缀长度。 整数形式，取值范围是0～128。 as-set 指定生成具有AS-SET的路由。 - attribute-policy route-policy-name1 指定设置聚合后路由的属性策略名称。 字符串形式，区分大小写，不支持空格，长度范围是1～40。当输入的字符串两端使用双引号时，可在字符串中输入空格。 detail-suppressed 指定仅通告聚合路由。 - origin-policy route-policy-name2 指定允许生成聚合路由的策略名称。 字符串形式，区分大小写，不支持空格，长度范围是1～40。当输入的字符串两端使用双引号时，可在字符串中输入空格。 suppress-policy route-policy-name3 指定抑制指定路由通告的策略名称。 字符串形式，区分大小写，不支持空格，长度范围是1～40。当输入的字符串两端使用双引号时，可在字符串中输入空格。 配置邻接按需发布路由：如果设备希望只接收自己需要的路由，但对端设备又无法针对每个与它连接的设备维护不同的出口策略。此时，可以通过配置基于前缀的ORF来满足两端设备的需求。 1234peer &#123; group-name | ipv4-address &#125; ip-prefix ip-prefix-name import//配置对等体/对等体组基于IP前缀列表的入口路由过滤策略。peer &#123; group-name | ipv4-address &#125; capability-advertise orf [ non-standard-compatible ] ip-prefix &#123; both | receive | send &#125;//配置BGP对等体（组）使能基于地址前缀的ORF功能。 配置向对等体发送缺省路由：当对等体的BGP路由表中的多条路由都只是由本端发送时，可以在本端配置向对等体发送缺省路由功能。配置向对等体发送缺省路由功能后，无论本端的路由表中是否存在缺省路由，都向对等体发布一条下一跳地址为本地地址的缺省路由，从而很大程度地减少网络路由数量，节省对等体的内存资源与网络资源。 12peer 12.1.1.1 default-route-advertise//向对等体或对等体组发送缺省路由。 配置路径MTU自动发现功能：路径最大传输单元MTU（Maximum Transmission Unit）是TCP在传输BGP消息时封装IP数据包的依据，使能路径MTU自动发现功能可以发现从源端到目的端的路径上最小MTU值。 12peer 12.1.1.1 path-mtu auto-discovery//使能路径MTU自动发现功能。 由于两个BGP邻居之间消息发送和应答的传输路径可能不一致，所以建议在两端都执行该命令，这样，两个BGP邻居在相互发送消息时都可以按照路径MTU发送。 配置BGP动态对等体：通过配置BGP动态对等体，可以使BGP侦听指定网段的BGP连接请求并动态建立BGP对等体，减少网络维护的工作量。 在BGP网络中，当多个对等体经常发生变动时，如果采用静态配置对等体的方式，则需频繁地在本端进行增加或删除对等体的配置，维护工作量很大。此时可以配置BGP动态对等体功能，使BGP侦听指定网段的BGP连接请求并动态建立BGP对等体，同时将这些对等体加入到同一个对等体组中。这样当对等体发生变动时，无需在本端进行增加或删除BGP对等体的配置，减少网络维护的工作量。 12345bgp dynamic-session-limit 100//配置允许建立的BGP动态对等体会话的最大数量。 //缺省情况下，允许建立的BGP动态对等体会话的最大数量为100。peer group-name listen-net network &#123; mask | mask-length &#125;，//配置BGP侦听指定网段的BGP连接请求并动态建立BGP对等体。 BGP常见问题为什么对两台设备间的接口执行shutdown命令后，BGP连接不立即断开？只有直连EBGP邻居，且在BGP下配置了ebgp-interface-sensitive命令（缺省为配置该命令）的前提下，BGP连接才会在接口下执行shutdown后立即断开。其它情况及其它类型的BGP邻居都会等HoldTimer超时后，BGP连接才会断开。 BGP引入其他协议的路由后，在BGP路由表中下一跳为什么都是0.0.0.0?因为这个路由能够被BGP引入，说明路由表中已经存在此路由表项，不是新增了一条路由，而是在该路由表项的基础上增加了引用计数。 BGP实验示例BGP综合实验1：实验拓扑如下： 图：BGP综合实验1拓扑 实验要求： 按照拓扑搭建网络，R1与R2间使用环回接口建立IBGP邻居关系，IGP协议使用OSPF。R3与R4间使用物理接口建立IGBP邻居关系，R2与R5间使用环回接口借助静态路由建立EBGP邻居关系，R1与R3间使用直连接口建立EBGP邻居关系； 每台设备的环回接口0的网段地址都使用合适的配置引入或通告入BGP进程中，并使得所有设备的环回接口间都能互相通信； 将R4和R5上业务网段通告入BGP中，并使得相互间都能正常通信； 优化所有设备上的BGP路由表，设备上仅需要维护环回接口所在网段和业务网段的路由条目； 汇总192.168.20.0/24与192.168.30.0/24这两个业务网段，并抑制192.168.30.0/24该业务网段的明细路由的发布，同时放行明细路由192.168.10.0/24； 在R3上汇总172.16.10.0/24与172.16.20.0/24这两个业务网段，并抑制所有明细路由的发布； 观察业务网段间的通信情况，解决网络中存在的次优路径问题； 通过配置团体属性使得AS 200中不接收192.168.20.0/24该业务网段的路由； 假设172.16.10.0/24该业务网段状态不稳定，时而出现网络中断现象，通过适当配置以减小其对整网的影响； 为了提高BGP网络安全性，在EBGP邻居间配置认证； 修改R2上BGP的存活时间为30s，同时适当调整保持时间。 实验配置信息：AR1： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;AR1&gt;display current-configuration sysname AR1#acl number 2000 rule 5 permit source 10.0.2.2 0 #interface GigabitEthernet0/0/0 ip address 10.0.134.1 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.12.1 255.255.255.0 #interface LoopBack0 ip address 10.0.1.1 255.255.255.255 #bgp 100 router-id 10.0.1.1 peer 10.0.2.2 as-number 100 peer 10.0.2.2 connect-interface LoopBack0 peer 10.0.134.3 as-number 200 peer 10.0.134.3 password simple Huawei # ipv4-family unicast undo synchronization network 10.0.1.1 255.255.255.255 import-route ospf 1 route-policy O2B peer 10.0.2.2 enable peer 10.0.2.2 next-hop-local peer 10.0.134.3 enable peer 10.0.134.3 advertise-community#ospf 1 router-id 10.0.1.1 area 0.0.0.0 network 10.0.1.1 0.0.0.0 network 10.0.12.0 0.0.0.255 #route-policy O2B permit node 10 if-match acl 2000 #return AR2： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;AR2&gt;display current-configuration # sysname AR2#acl number 2000 rule 5 permit source 10.0.1.1 0 acl number 2001 rule 5 permit source 10.0.5.5 0 #interface GigabitEthernet0/0/0 ip address 10.0.12.2 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.25.2 255.255.255.0 #interface LoopBack0 ip address 10.0.2.2 255.255.255.255 #bgp 100 router-id 10.0.2.2 timer keepalive 30 hold 90 peer 10.0.1.1 as-number 100 peer 10.0.1.1 connect-interface LoopBack0 peer 10.0.5.5 as-number 300 peer 10.0.5.5 ebgp-max-hop 2 peer 10.0.5.5 connect-interface LoopBack0 peer 10.0.5.5 password simple Huawei # ipv4-family unicast undo synchronization network 10.0.0.0 network 10.0.2.2 255.255.255.255 import-route static route-policy S2B import-route ospf 1 route-policy O2B peer 10.0.1.1 enable peer 10.0.1.1 advertise-community peer 10.0.5.5 enable#ospf 1 router-id 10.0.2.2 area 0.0.0.0 network 10.0.2.2 0.0.0.0 network 10.0.12.0 0.0.0.255 #route-policy O2B permit node 10 if-match acl 2000 #route-policy S2B permit node 10 if-match acl 2001 #ip route-static 10.0.5.5 255.255.255.255 10.0.25.5#return AR3： 1234567891011121314151617181920212223242526&lt;AR3&gt;display current-configuration sysname AR3#acl number 2000 #interface GigabitEthernet0/0/0 ip address 10.0.134.3 255.255.255.0 #interface LoopBack0 ip address 10.0.3.3 255.255.255.255 #bgp 200 router-id 10.0.3.3 peer 10.0.134.1 as-number 100 peer 10.0.134.1 password simple Huawei peer 10.0.134.4 as-number 200 # ipv4-family unicast undo synchronization aggregate 172.16.0.0 255.255.0.0 detail-suppressed network 10.0.3.3 255.255.255.255 peer 10.0.134.1 enable peer 10.0.134.4 enable peer 10.0.134.4 next-hop-local #return AR4： 12345678910111213141516171819202122232425262728293031323334353637&lt;AR4&gt;display current-configuration # sysname AR4#acl number 2000 rule 5 permit source 172.16.10.0 0.0.0.255 #interface GigabitEthernet0/0/0 ip address 10.0.134.4 255.255.255.0 #interface LoopBack0 ip address 10.0.4.4 255.255.255.255 #interface LoopBack1 ip address 172.16.10.1 255.255.255.0 #interface LoopBack2 ip address 172.16.20.1 255.255.255.0 #bgp 200 router-id 10.0.4.4 peer 10.0.134.3 as-number 200 # ipv4-family unicast undo synchronization deterministic-med dampening route-policy Deampend aggregate 172.16.0.0 255.255.0.0 detail-suppressed network 10.0.4.4 255.255.255.255 network 172.16.10.0 255.255.255.0 network 172.16.20.0 255.255.255.0 peer 10.0.134.3 enable#route-policy Deampend permit node 10 if-match acl 2000 #return AR5： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;AR5&gt;dis current-configuration # sysname AR5#acl number 2000 rule 5 permit source 192.168.20.0 0.0.0.255 acl number 2001 rule 5 permit source 192.168.30.0 0.0.0.255 #interface GigabitEthernet0/0/0 ip address 10.0.25.5 255.255.255.0 #interface LoopBack0 ip address 10.0.5.5 255.255.255.255 #interface LoopBack1 ip address 192.168.10.1 255.255.255.0 #interface LoopBack2 ip address 192.168.20.1 255.255.255.0 #interface LoopBack3 ip address 192.168.30.1 255.255.255.0 #bgp 300 router-id 10.0.5.5 peer 10.0.2.2 as-number 100 peer 10.0.2.2 ebgp-max-hop 2 peer 10.0.2.2 connect-interface LoopBack0 peer 10.0.2.2 password simple Huawei # ipv4-family unicast undo synchronization aggregate 192.168.0.0 255.255.0.0 suppress-policy sup origin-policy ori network 10.0.5.5 255.255.255.255 network 192.168.10.0 network 192.168.20.0 network 192.168.30.0 peer 10.0.2.2 enable peer 10.0.2.2 route-policy com export peer 10.0.2.2 advertise-community#route-policy sup permit node 10 if-match acl 2001 #route-policy ori deny node 10 if-match acl 2000 #route-policy ori permit node 20 #route-policy com permit node 10 if-match acl 2000 apply community no-export #route-policy com permit node 20 #ip route-static 10.0.2.2 255.255.255.255 10.0.25.2#return 设备信息截图： 图：AR1的BGP路由表 图：AR2的邻居AR5的详细信息 BGP综合实验2：实验拓扑如下： 图：BGP综合实验2拓扑 实验要求：某公司网络如实验拓扑所示，R4、R5、R6、R7为公司总部路由器，R1与R3分别为公司两个不同分支机构路由器，R2为运营商的网络设备，在R1与R3上分别设有不同的业务网段，其中192.168.10.0/24与172.16.10.0/24为业务A所用网段，192.168.20.0/24，172.16.20.0/24为业务B所用网段。两个不同分支机构与总部间都设有专线，使得两分支机构上的业务网段既可以通过运营商的设备实现访问，也可以通过专线，经由总部设备实现访问。请根据如下需求对网络进行部署： 按照拓扑搭建网络，在所有AS间使用直连接口建立EBGP邻居关系； 在公司总部AS400中，R4与R5，R5与R7，R7与R6，R6与R4间使用环回接口建立IBGP邻居关系，IGP协议使用OSPF； 所有业务网段，与所有设备上的Loopback 0所在网段都能通过BGP路由实现互相访问； 为了使网络资源能充分得到利用，要求业务网段A的流量通过运营商设备转发，业务网段B的流量通过专线转发； 网络管理员进行定期线路检查，现通过适当调整IGP的链路开销值，使得所有经过总部AS的流量都沿着R4-R5-R7-R6路径转发； 网络管理员在检查中发现业务网段B的流量非常大，决定将业务网段B的流量单独沿着R4-R6路径转发（要求BGP路由选路与实际转发路径一致）； 公司总部网络将进行改造，在不改变原有配置的基础上，通过增加少量配置实现，R5与R7不参与BGP路径选择。 实验配置信息：AR1： 123456789101112131415161718192021222324252627282930313233[AR1]display current-configuration # sysname AR1#interface GigabitEthernet0/0/0 ip address 10.0.12.1 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.14.1 255.255.255.0 #interface LoopBack0 ip address 10.0.1.1 255.255.255.255 #interface LoopBack1 ip address 192.168.10.1 255.255.255.0 #interface LoopBack2 ip address 192.168.20.1 255.255.255.0 #bgp 100 router-id 10.0.1.1 peer 10.0.12.2 as-number 200 peer 10.0.14.4 as-number 400 # ipv4-family unicast undo synchronization network 10.0.1.1 255.255.255.255 network 192.168.10.0 network 192.168.20.0 peer 10.0.12.2 enable peer 10.0.14.4 enable#return AR2： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;AR2&gt;dis current-configuration # sysname AR2#acl number 2000 rule 5 permit source 172.16.20.0 0.0.0.255 acl number 2001 rule 5 permit source 192.168.20.0 0.0.0.255 #interface GigabitEthernet0/0/0 ip address 10.0.12.2 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.23.2 255.255.255.0 #interface LoopBack0 ip address 10.0.2.2 255.255.255.255 #bgp 200 router-id 10.0.2.2 peer 10.0.12.1 as-number 100 peer 10.0.23.3 as-number 300 # ipv4-family unicast undo synchronization network 10.0.2.2 255.255.255.255 peer 10.0.12.1 enable peer 10.0.12.1 route-policy AS export peer 10.0.23.3 enable peer 10.0.23.3 route-policy MED export#route-policy AS permit node 10 if-match acl 2000 apply as-path 200 200 additive#route-policy AS permit node 20 #route-policy MED permit node 10 if-match acl 2001 apply cost 200 #route-policy MED permit node 20 #return AR3： 12345678910111213141516171819202122232425262728293031323334&lt;AR3&gt;dis current-configuration # sysname AR3#interface GigabitEthernet0/0/0 ip address 10.0.23.3 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.36.3 255.255.255.0 #interface LoopBack0 ip address 10.0.3.3 255.255.255.255 #interface LoopBack1 ip address 172.16.10.1 255.255.255.0 #interface LoopBack2 ip address 172.16.20.1 255.255.255.0 #bgp 300 router-id 10.0.3.3 peer 10.0.23.2 as-number 200 peer 10.0.36.6 as-number 400 # ipv4-family unicast undo synchronization compare-different-as-med network 10.0.3.3 255.255.255.255 network 172.16.10.0 255.255.255.0 network 172.16.20.0 255.255.255.0 peer 10.0.23.2 enable peer 10.0.36.6 enable#return AR4： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;AR4&gt;dis current-configuration # sysname AR4#acl number 2000 rule 5 permit source 10.0.5.5 0 acl number 2001 rule 10 permit source 192.168.20.0 0.0.0.255 #interface GigabitEthernet0/0/0 ip address 10.0.46.4 255.255.255.0 ospf cost 100#interface GigabitEthernet0/0/1 ip address 10.0.14.4 255.255.255.0 #interface GigabitEthernet0/0/2 ip address 10.0.45.4 255.255.255.0 #interface LoopBack0 ip address 10.0.4.4 255.255.255.255 #bgp 400 router-id 10.0.4.4 peer 10.0.5.5 as-number 400 peer 10.0.5.5 ignore peer 10.0.5.5 connect-interface LoopBack0 peer 10.0.6.6 as-number 400 peer 10.0.6.6 connect-interface LoopBack0 peer 10.0.14.1 as-number 100 # ipv4-family unicast undo synchronization preference 255 100 255 network 10.0.4.4 255.255.255.255 import-route ospf 1 route-policy O2B peer 10.0.5.5 enable peer 10.0.5.5 next-hop-local peer 10.0.6.6 enable peer 10.0.6.6 route-policy local export peer 10.0.6.6 next-hop-local peer 10.0.14.1 enable#ospf 1 router-id 10.0.4.4 import-route bgp route-policy B2O area 0.0.0.0 network 10.0.4.4 0.0.0.0 network 10.0.45.0 0.0.0.255 network 10.0.46.0 0.0.0.255 #route-policy O2B permit node 10 if-match acl 2000 #route-policy B2O permit node 10 if-match acl 2001 #route-policy local permit node 10 if-match acl 2001 apply ip-address next-hop 10.0.46.4 #route-policy local permit node 20 #return AR5： 123456789101112131415161718192021222324252627282930313233343536&lt;AR5&gt;dis current-configuration # sysname AR5#interface GigabitEthernet0/0/0 ip address 10.0.45.5 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.57.5 255.255.255.0 #interface LoopBack0 ip address 10.0.5.5 255.255.255.255 #bgp 400 router-id 10.0.5.5 peer 10.0.4.4 as-number 400 peer 10.0.4.4 connect-interface LoopBack0 peer 10.0.7.7 as-number 400 peer 10.0.7.7 connect-interface LoopBack0 # ipv4-family unicast undo synchronization reflector cluster-id 1 network 10.0.5.5 255.255.255.255 peer 10.0.4.4 enable peer 10.0.4.4 reflect-client peer 10.0.7.7 enable peer 10.0.7.7 reflect-client#ospf 1 router-id 10.0.5.5 area 0.0.0.0 network 10.0.5.5 0.0.0.0 network 10.0.45.0 0.0.0.255 network 10.0.57.0 0.0.0.255 #return AR6： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;AR6&gt;dis current-configuration # sysname AR6#acl number 2000 rule 15 permit source 10.0.7.7 0 acl number 2001 rule 5 permit source 172.16.20.0 0.0.0.255 #interface GigabitEthernet0/0/0 ip address 10.0.36.6 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.46.6 255.255.255.0 ospf cost 100 //修改ospf开销值，改变流量的走向#interface GigabitEthernet0/0/2 ip address 10.0.67.6 255.255.255.0 #interface LoopBack0 ip address 10.0.6.6 255.255.255.255 #bgp 400 router-id 10.0.6.6 peer 10.0.4.4 as-number 400 peer 10.0.4.4 connect-interface LoopBack0 peer 10.0.7.7 as-number 400 peer 10.0.7.7 connect-interface LoopBack0 peer 10.0.7.7 listen-only peer 10.0.36.3 as-number 300 # ipv4-family unicast undo synchronization preference 255 100 255 network 10.0.6.6 255.255.255.255 import-route ospf 1 route-policy O2B peer 10.0.4.4 enable peer 10.0.4.4 route-policy loacl export peer 10.0.4.4 next-hop-local //修改从EBGP邻居学来的路由，设置下一跳为本地与接收路由的对端接口地址 peer 10.0.7.7 enable peer 10.0.7.7 next-hop-local peer 10.0.36.3 enable#ospf 1 router-id 10.0.6.6 import-route bgp route-policy B2O area 0.0.0.0 network 10.0.6.6 0.0.0.0 network 10.0.46.0 0.0.0.255 network 10.0.67.0 0.0.0.255 #route-policy O2B permit node 10 if-match acl 2000 #route-policy B2O permit node 10 if-match acl 2001 #route-policy loacl permit node 10 if-match acl 2001 apply ip-address next-hop 10.0.46.6 #route-policy loacl permit node 20 #return AR7： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;AR7&gt;dis current-configuration # sysname AR7#interface GigabitEthernet0/0/0 ip address 10.0.57.7 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 10.0.67.7 255.255.255.0 #interface LoopBack0 ip address 10.0.7.7 255.255.255.255 #bgp 400 router-id 10.0.7.7 peer 10.0.5.5 as-number 400 peer 10.0.5.5 connect-interface LoopBack0 peer 10.0.6.6 as-number 400 peer 10.0.6.6 connect-interface LoopBack0 peer 10.0.6.6 listen-only //配置对端只监听，不主动请求连接 # ipv4-family unicast undo synchronization reflector cluster-id 2 //配置路由反射器的集群ID。 reflect change-path-attribute //使能路由反射器通过出口策略修改BGP路由的路径属性。 network 10.0.7.7 255.255.255.255 peer 10.0.5.5 enable peer 10.0.5.5 reflect-client //配置路由反射器客户端 peer 10.0.6.6 enable peer 10.0.6.6 reflect-client#ospf 1 router-id 10.0.7.7 area 0.0.0.0 network 10.0.7.7 0.0.0.0 network 10.0.57.0 0.0.0.255 network 10.0.67.0 0.0.0.255 #return 设备信息截图： 图：在AR3上测试业务A,B的路径 图：在AR1上测试业务A，B的路径 图：AR4上的邻居状态 在AR4上配置了：peer 10.0.5.5 ignore；所以状态为Idle（admin）。 peer ignore 用来禁止与对等体（组）建立会话。 图：AR7的邻居状态 因为在AR6和AR7上配置了 peer listen-only 。所以双方只进行TCP监听，不主动发起连接。BGP状态机为IDle。 peer listen-only 用来使能对等体（组）仅检测连接请求，而不主动发送连接请求功能。 BGP综合实验3：此实验主要做基于前缀的ORF，联盟，GTSM,BFD联动等配置。 实验拓扑如下： 图：BGP综合实验3拓扑 实验要求： 在AR上配置ORF只接收运营商的192.168.1.2/32网段。 在AS 在AS200内配置联盟。 在AR2和AR4之间配置BFD联动。 在AR5上配置GTSM。 实验配置信息：AR1： 12345678910111213141516171819202122232425262728[AR1]dis current-configuration # sysname AR1#interface GigabitEthernet0/0/0 ip address 12.1.1.1 255.255.255.0 #interface LoopBack1 ip address 192.168.1.1 255.255.255.255 #interface LoopBack2 ip address 192.168.1.2 255.255.255.255 #interface LoopBack3 ip address 192.168.1.3 255.255.255.255 #bgp 100 peer 12.1.1.2 as-number 200 # ipv4-family unicast undo synchronization network 192.168.1.1 255.255.255.255 network 192.168.1.2 255.255.255.255 network 192.168.1.3 255.255.255.255 peer 12.1.1.2 enable peer 12.1.1.2 capability-advertise orf ip-prefix both#return AR2： 1234567891011121314151617181920212223242526272829303132&lt;AR2&gt;dis current-configuration # sysname AR2#bfd#interface GigabitEthernet0/0/0 ip address 12.1.1.2 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 24.1.1.2 255.255.255.0 #interface GigabitEthernet0/0/2 ip address 23.1.1.2 255.255.255.0 #bgp 1000 confederation id 200 peer 12.1.1.1 as-number 100 peer 24.1.1.4 as-number 1000 peer 24.1.1.4 bfd min-tx-interval 100 min-rx-interval 100 detect-multiplier 4 peer 24.1.1.4 bfd enable # ipv4-family unicast undo synchronization peer 12.1.1.1 enable peer 12.1.1.1 ip-prefix direct import peer 12.1.1.1 capability-advertise orf ip-prefix both peer 24.1.1.4 enable#ip ip-prefix direct index 20 permit 192.168.1.2 32#return AR3： 123456789101112131415161718192021&lt;AR3&gt;dis current-configuration # sysname AR3#interface GigabitEthernet0/0/0 ip address 23.1.1.3 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 35.1.1.3 255.255.255.0 #bgp 2000 confederation id 200 peer 23.1.1.2 as-number 1000 peer 35.1.1.5 as-number 3000 # ipv4-family unicast undo synchronization peer 23.1.1.2 enable peer 35.1.1.5 enable#return AR4： 12345678910111213141516171819202122&lt;AR4&gt;dis current-configuration # sysname AR4#bfd#interface GigabitEthernet0/0/0 ip address 24.1.1.4 255.255.255.0 #bgp 1000 confederation id 200 peer 24.1.1.2 as-number 1000 peer 24.1.1.2 bfd min-tx-interval 100 min-rx-interval 100 detect-multiplier 4 //配置BFD会话参数 peer 24.1.1.2 bfd enable //使能BGP的BFD功能 # ipv4-family unicast undo synchronization peer 24.1.1.2 enable#return AR5： 12345678910111213141516171819&lt;AR5&gt;dis current-configuration # sysname AR5#interface GigabitEthernet0/0/0 ip address 35.1.1.5 255.255.255.0 #bgp 3000 confederation id 200 //配置联盟主AS号 peer 35.1.1.3 as-number 2000 peer 35.1.1.3 valid-ttl-hops 2 //配置GTSM，即最多只能通过两个路由器建立邻接关系。 # ipv4-family unicast undo synchronization peer 35.1.1.3 enable#return 设备信息截图： 图：AR4上查看BGP路由,通过ORF只接收一条路由]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>BGP</tag>
        <tag>路由基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP基础知识]]></title>
    <url>%2F2018%2F01%2F23%2FBGP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[BGP简介边界网关协议BGP（Border Gateway Protocol）是一种实现自治系统AS（Autonomous System）之间的路由可达，并选择最佳路由的距离矢量路由协议。 MP-BGP是对BGP-4进行了扩展，来达到在不同网络中应用的目的，BGP-4原有的消息机制和路由机制并没有改变。MP-BGP在IPv6单播网络上的应用称为BGP4+，在IPv4组播网络上的应用称为MBGP（Multicast BGP）。 目的：为方便管理规模不断扩大的网络，网络被分成了不同的自治系统。1982年，外部网关协议EGP（Exterior Gateway Protocol）被用于实现在AS之间动态交换路由信息。但是EGP设计得比较简单，只发布网络可达的路由信息，而不对路由信息进行优选，同时也没有考虑环路避免等问题，很快就无法满足网络管理的要求。 BGP是为取代最初的EGP而设计的另一种外部网关协议。不同于最初的EGP，BGP能够进行路由优选、避免路由环路、更高效率的传递路由和维护大量的路由信息。 虽然BGP用于在AS之间传递路由信息，但并不是所有AS之间传递路由信息都需要运行BGP。比如在数据中心上行的连入Internet的出口上，为了避免Internet海量路由对数据中心内部网络的影响，设备采用静态路由代替BGP与外部网络通信。 BGP的优点：BGP从多方面保证了网络的安全性、灵活性、稳定性、可靠性和高效性。 BGP采用认证和GTSM的方式，保证了网络的安全性。 BGP提供了丰富的路由策略，能够灵活的进行路由选路，并且能指导邻居按策略发布路由。 BGP提供了路由聚合和路由衰减功能由于防止路由震荡，有效提高了网络的稳定性。 BGP使用TCP作为其传输层协议（目的端口号179），并支持与BGP与BFD联动、BGP Tracking和BGP GR和NSR，提高了网络的可靠性。 在邻居数目多、路由量大且大部分邻居具有相同出口的策略的场景下，BGP使用按组打包技术极大的提高了BGP打包发包性能。 BGP原理描述BGP基本概念：自治系统ASAutonomous System：AS是指在一个实体管辖下的拥有相同选路策略的IP网络。BGP网络中的每个AS都被分配一个唯一的AS号，用于区分不同的AS。AS号分为2字节AS号和4字节AS号，其中2字节AS号的范围为1至65535，4字节AS号的范围为1至4294967295。支持4字节AS号的设备能够与支持2字节AS号的设备兼容。 BGP分类：BGP按照运行方式分为EBGP（External/Exterior BGP）和IBGP（Internal/Interior BGP）。 EBGP：运行于不同AS之间的BGP称为EBGP。为了防止AS间产生环路，当BGP设备接收EBGP对等体发送的路由时，会将带有本地AS号的路由丢弃。 IBGP：运行于同一AS内部的BGP称为IBGP。为了防止AS内产生环路，BGP设备不将从IBGP对等体学到的路由通告给其他IBGP对等体，并与所有IBGP对等体建立全连接。为了解决IBGP对等体的连接数量太多的问题，BGP设计了路由反射器和BGP联盟。 BGP报文交互中的角色：BGP报文交互中分为Speaker和Peer两种角色。 Speaker：发送BGP报文的设备称为BGP发言者（Speaker），它接收或产生新的报文信息，并发布（Advertise）给其它BGP Speaker。 Peer：相互交换报文的Speaker之间互称对等体（Peer）。若干相关的对等体可以构成对等体组（Peer Group）。 BGP的路由器号（Router ID）：BGP的Router ID是一个用于标识BGP设备的32位值，通常是IPv4地址的形式，在BGP会话建立时发送的Open报文中携带。对等体之间建立BGP会话时，每个BGP设备都必须有唯一的Router ID，否则对等体之间不能建立BGP连接。 BGP的Router ID在BGP网络中必须是唯一的，可以采用手工配置，也可以让设备自动选取。缺省情况下，BGP选择设备上的Loopback接口的IPv4地址作为BGP的Router ID。如果设备上没有配置Loopback接口，系统会选择接口中最大的IPv4地址作为BGP的Router ID。一旦选出Router ID，除非发生接口地址删除等事件，否则即使配置了更大的地址，也保持原来的Router ID。 BGP工作原理：BGP对等体的建立、更新和删除等交互过程主要有5种报文、6种状态机和5个原则。 BGP的报文：BGP对等体间通过以下5种报文进行交互，其中Keepalive报文为周期性发送，其余报文为触发式发送： Open报文：用于建立BGP对等体连接。 Update报文：用于在对等体之间交换路由信息。 Notification报文：用于中断BGP连接。 Keepalive报文：用于保持BGP连接。 Route-refresh报文：用于在改变路由策略后请求对等体重新发送路由信息。只有支持路由刷新（Route-refresh）能力的BGP设备会发送和响应此报文。 BGP状态机：BGP对等体的交互过程中存在6种状态机：空闲（Idle）、连接（Connect）、活跃（Active）、Open报文已发送（OpenSent）、Open报文已确认（OpenConfirm）和连接已建立（Established）。在BGP对等体建立的过程中，通常可见的3个状态是：Idle、Active和Established。 图：BGP对等体交互过程 Idle状态是BGP初始状态。在Idle状态下，BGP拒绝邻居发送的连接请求。只有在收到本设备的Start事件后，BGP才开始尝试和其它BGP对等体进行TCP连接，并转至Connect状态。 在Connect状态下，BGP启动连接重传定时器（Connect Retry），等待TCP完成连接。 如果TCP连接成功，那么BGP向对等体发送Open报文，并转至OpenSent状态。 如果TCP连接失败，那么BGP转至Active状态。 如果连接重传定时器超时，BGP仍没有收到BGP对等体的响应，那么BGP继续尝试和其它BGP对等体进行TCP连接，停留在Connect状态。 在Active状态下，BGP总是在试图建立TCP连接。 如果TCP连接成功，那么BGP向对等体发送Open报文，关闭连接重传定时器，并转至OpenSent状态。 如果TCP连接失败，那么BGP停留在Active状态。 如果连接重传定时器超时，BGP仍没有收到BGP对等体的响应，那么BGP转至Connect状态。 在OpenSent状态下，BGP等待对等体的Open报文，并对收到的Open报文中的AS号、版本号、认证码等进行检查。 如果收到的Open报文正确，那么BGP发送Keepalive报文，并转至OpenConfirm状态。 如果发现收到的Open报文有错误，那么BGP发送Notification报文给对等体，并转至Idle状态。 在OpenConfirm状态下，BGP等待Keepalive或Notification报文。如果收到Keepalive报文，则转至Established状态，如果收到Notification报文，则转至Idle状态。 在Established状态下，BGP可以和对等体交换Update、Keepalive、Route-refresh报文和Notification报文。 如果收到正确的Update或Keepalive报文，那么BGP就认为对端处于正常运行状态，将保持BGP连接。 如果收到错误的Update或Keepalive报文，那么BGP发送Notification报文通知对端，并转至Idle状态。 Route-refresh报文不会改变BGP状态。 如果收到Notification报文，那么BGP转至Idle状态。 如果收到TCP拆链通知，那么BGP断开连接，转至Idle状态。 BGP对等体之间的交互原则：BGP设备将最优路由加入BGP路由表，形成BGP路由。BGP设备与对等体建立邻居关系后，采取以下交互原则： 从IBGP对等体获得的BGP路由，BGP设备只发布给它的EBGP对等体。 从EBGP对等体获得的BGP路由，BGP设备发布给它所有EBGP和IBGP对等体。 当存在多条到达同一目的地址的有效路由时，BGP设备只将最优路由发布给对等体。 路由更新时，BGP设备只发送更新的BGP路由。 所有对等体发送的路由，BGP设备都会接收。 BGP与IGP交互：BGP与IGP在设备中使用不同的路由表，为了实现不同AS间相互通讯，BGP需要与IGP进行交互，即BGP路由表和IGP路由表相互引入。 BGP引入IGP路由：BGP协议本身不发现路由，因此需要将其他路由引入到BGP路由表，实现AS间的路由互通。当一个AS需要将路由发布给其他AS时，AS边缘路由器会在BGP路由表中引入IGP的路由。为了更好的规划网络，BGP在引入IGP的路由时，可以使用路由策略进行路由过滤和路由属性设置，也可以设置MED值指导EBGP对等体判断流量进入AS时选路。 BGP引入路由时支持Import和Network两种方式： Import方式是按协议类型，将RIP、OSPF、ISIS等协议的路由引入到BGP路由表中。为了保证引入的IGP路由的有效性，Import方式还可以引入静态路由和直连路由。 Network方式是逐条将IP路由表中已经存在的路由引入到BGP路由表中，比Import方式更精确。 IGP引入BGP路由：当一个AS需要引入其他AS的路由时，AS边缘路由器会在IGP路由表中引入BGP的路由。为了避免大量BGP路由对AS内设备造成影响，当IGP引入BGP路由时，可以使用路由策略，进行路由过滤和路由属性设置。 BGP安全性：BGP使用认证和通用TTL安全保护机制GTSM（Generalized TTL Security Mechanism）两个方法保证BGP对等体间的交互安全。 BGP认证：BGP认证分为MD5认证和Keychain认证，对BGP对等体关系进行认证是提高安全性的有效手段。MD5认证只能为TCP连接设置认证密码，而Keychain认证除了可以为TCP连接设置认证密码外，还可以对BGP协议报文进行认证。 BGP GTSM：BGP GTSM检测IP报文头中的TTL（time-to-live）值是否在一个预先设置好的特定范围内，并对不符合TTL值范围的报文进行允许通过或丢弃的操作，从而实现了保护IP层以上业务，增强系统安全性的目的。 例如将IBGP对等体的报文的TTL的范围设为254至255。当攻击者模拟合法的BGP协议报文，对设备不断的发送报文进行攻击时，TTL值必然小于254。如果没有使能BGP GTSM功能，设备收到这些报文后，发现是发送给本机的报文，会直接上送控制层面处理。这时将会因为控制层面处理大量攻击报文，导致设备CPU占用率高，系统异常繁忙。如果使能BGP GTSM功能，系统会对所有BGP报文的TTL值进行检查，丢弃TTL值小于254的攻击报文，从而避免了因网络攻击报文导致CPU占用率高的问题。 BGP的路由优选规则和负载分担：在BGP路由表中，到达同一目的地可能存在多条路由。此时BGP会选择其中一条路由作为最佳路由，并只把此路由发送给其对等体。BGP为了选出最佳路由，会根据BGP的路由优选规则依次比较这些路由的BGP属性。 BGP属性：路由属性是对路由的特定描述，所有的BGP路由属性都可以分为以下4类，常见BGP属性类型所示： 公认必须遵循（Well-known mandatory）：所有BGP设备都可以识别此类属性，且必须存在于Update报文中。如果缺少这类属性，路由信息就会出错。 公认任意（Well-known discretionary）：所有BGP设备都可以识别此类属性，但不要求必须存在于Update报文中，即就算缺少这类属性，路由信息也不会出错。 可选过渡（Optional transitive）：BGP设备可以不识别此类属性，如果BGP设备不识别此类属性，但它仍然会接收这类属性，并通告给其他对等体。 可选非过渡（Optional non-transitive）：BGP设备可以不识别此类属性，如果BGP设备不识别此类属性，则会被忽略该属性，且不会通告给其他对等体。 BGP常见属性类型： 属性名 类型 Origin属性 公认必须遵循 AS_Path属性 公认必须遵循 Next_Hop属性 公认必须遵循 Local_Pref属性 公认任意 MED属性 可选非过渡 团体属性 可选过渡 Originator_ID属性 可选非过渡 Cluster_List属性 可选非过渡 Origin属性：Origin属性用来定义路径信息的来源，标记一条路由是怎么成为BGP路由的。它有以下3种类型： IGP：具有最高的优先级。通过network命令注入到BGP路由表的路由，其Origin属性为IGP。 EGP：优先级次之。通过EGP得到的路由信息，其Origin属性为EGP。 Incomplete：优先级最低。通过其他方式学习到的路由信息。比如BGP通过import-route命令引入的路由，其Origin属性为Incomplete。 AS_Path属性：AS_Path属性按矢量顺序记录了某条路由从本地到目的地址所要经过的所有AS编号。在接收路由时，设备如果发现AS_Path列表中有本AS号，则不接收该路由，从而避免了AS间的路由环路。 当BGP Speaker传播自身引入的路由时： 当BGP Speaker将这条路由通告到EBGP对等体时，便会在Update报文中创建一个携带本地AS号的AS_Path列表。 当BGP Speaker将这条路由通告给IBGP对等体时，便会在Update报文中创建一个空的AS_Path列表。 当BGP Speaker传播从其他BGP Speaker的Update报文中学习到的路由时： 当BGP Speaker将这条路由通告给EBGP对等体时，便会把本地AS编号添加在AS_Path列表的最前面（最左面）。收到此路由的BGP设备根据AS_Path属性就可以知道去目的地址所要经过的AS。离本地AS最近的相邻AS号排在前面，其他AS号按顺序依次排列。 当BGP Speaker将这条路由通告给IBGP对等体时，不会改变这条路由相关的AS_Path属性。 Next_hop属性：Next_Hop属性记录了路由的下一跳信息。BGP的下一跳属性和IGP的有所不同，不一定就是邻居设备的IP地址。通常情况下，Next_Hop属性遵循下面的规则： BGP Speaker在向EBGP对等体发布某条路由时，会把该路由信息的下一跳属性设置为本地与对端建立BGP邻居关系的接口地址。 BGP Speaker将本地始发路由发布给IBGP对等体时，会把该路由信息的下一跳属性设置为本地与对端建立BGP邻居关系的接口地址。 BGP Speaker在向IBGP对等体发布从EBGP对等体学来的路由时，并不改变该路由信息的下一跳属性。 Local_pref属性：Local_Pref属性表明路由器的BGP优先级，用于判断流量离开AS时的最佳路由。当BGP的设备通过不同的IBGP对等体得到目的地址相同但下一跳不同的多条路由时，将优先选择Local_Pref属性值较高的路由。Local_Pref属性仅在IBGP对等体之间有效，不通告给其他AS。Local_Pref属性可以手动配置，如果路由没有配置Local_Pref属性，BGP选路时将该路由的Local_Pref值按缺省值100来处理。 MED属性：MED（Multi-Exit Discriminator）属性用于判断流量进入AS时的最佳路由，当一个运行BGP的设备通过不同的EBGP对等体得到目的地址相同但下一跳不同的多条路由时，在其它条件相同的情况下，将优先选择MED值较小者作为最佳路由。 MED属性仅在相邻两个AS之间传递，收到此属性的AS一方不会再将其通告给任何其他第三方AS。MED属性可以手动配置，如果路由没有配置MED属性，BGP选路时将该路由的MED值按缺省值0来处理。 团体属性：团体属性（Community）用于标识具有相同特征的BGP路由，使路由策略的应用更加灵活，同时降低了维护管理的难度。 团体属性分为自定义团体属性和公认团体属性。公认团体属性如下所示： Originator_ID属性和Cluster_List属性：Originator_ID属性和Cluster_List属性用于解决路由反射器场景中的环路问题。 BGP选择路由的策略：当到达同一目的地存在多条路由时，BGP依次对比下列属性来选择路由： 优选协议首选值（PrefVal）最高的路由。 协议首选值（PrefVal）是华为设备的特有属性，该属性仅在本地有效。 优选本地优先级（Local_Pref）最高的路由。 如果路由没有本地优先级，BGP选路时将该路由按缺省的本地优先级100来处理。 依次优选手动聚合路由、自动聚合路由、network命令引入的路由、import-route命令引入的路由、从对等体学习的路由。 优选AS路径（AS_Path）最短的路由。 依次优选Origin类型为IGP、EGP、Incomplete的路由。 对于来自同一AS的路由，优选MED值最低的路由。 依次优选EBGP路由、IBGP路由、LocalCross路由、RemoteCross路由。 PE上某个VPN实例的VPNv4路由的ERT匹配其他VPN实例的IRT后复制到该VPN实例，称为LocalCross；从远端PE学习到的VPNv4路由的ERT匹配某个VPN实例的IRT后复制到该VPN实例，称为RemoteCross。 优选到BGP下一跳IGP度量值（metric）最小的路由。 优选Cluster_List最短的路由。 优选Router ID最小的设备发布的路由。 优选从具有最小IP Address的对等体学来的路由。 BGP负载分担：当到达同一目的地址存在多条等价路由时，可以通过BGP等价负载分担实现均衡流量的目的。形成BGP等价负载分担的条件是“BGP选择路由的策略”的1至8条规则中需要比较的属性完全相同。 路由反射器：为保证IBGP对等体之间的连通性，需要在IBGP对等体之间建立全连接关系。假设在一个AS内部有n台设备，那么建立的IBGP连接数就为n(n-1)/2。当设备数目很多时，设备配置将十分复杂，而且配置后网络资源和CPU资源的消耗都很大。在IBGP对等体间使用路由反射器可以解决以上问题。 路由反射器相关角色：在一个AS内部关于路由反射器有以下几种角色： 路由反射器RR（Route Reflector）：允许把从IBGP对等体学到的路由反射到其他IBGP对等体的BGP设备，类似OSPF网络中的DR。 客户机（Client）：与RR形成反射邻居关系的IBGP设备。在AS内部客户机只需要与RR直连。 非客户机（Non-Client）：既不是RR也不是客户机的IBGP设备。在AS内部非客户机与RR之间，以及所有的非客户机之间仍然必须建立全连接关系。 始发者（Originator）：在AS内部始发路由的设备。Originator_ID属性用于防止集群内产生路由环路。 集群（Cluster）：路由反射器及其客户机的集合。Cluster_List属性用于防止集群间产生路由环路。 路由反射器原理：同一集群内的客户机只需要与该集群的RR直接交换路由信息，因此客户机只需要与RR之间建立IBGP连接，不需要与其他客户机建立IBGP连接，从而减少了IBGP连接数量。 RR突破了“从IBGP对等体获得的BGP路由，BGP设备只发布给它的EBGP对等体。”的限制，并采用独有的Cluster_List属性和Originator_ID属性防止路由环路。RR向IBGP邻居发布路由规则如下： 从非客户机学到的路由，发布给所有客户机。 从客户机学到的路由，发布给所有非客户机和客户机（发起此路由的客户机除外）。 从EBGP对等体学到的路由，发布给所有的非客户机和客户机。 Cluster_List属性：路由反射器和它的客户机组成一个集群（Cluster），使用AS内唯一的Cluster ID作为标识。为了防止集群间产生路由环路，路由反射器使用Cluster_List属性，记录路由经过的所有集群的Cluster ID。 当一条路由第一次被RR反射的时候，RR会把本地Cluster ID添加到Cluster List的前面。如果没有Cluster_List属性，RR就创建一个。 当RR接收到一条更新路由时，RR会检查Cluster List。如果Cluster List中已经有本地Cluster ID，丢弃该路由；如果没有本地Cluster ID，将其加入Cluster List，然后反射该更新路由。 Originator_ID属性Originator ID由RR产生，使用的Router ID的值标识路由的始发者，用于防止集群内产生路由环路。 当一条路由第一次被RR反射的时候，RR将Originator_ID属性加入这条路由，标识这条路由的发起设备。如果一条路由中已经存在了Originator_ID属性，则RR将不会创建新的Originator_ID属性。 当设备接收到这条路由的时候，将比较收到的Originator ID和本地的Router ID，如果两个ID相同，则不接收此路由。 备份路由反射器：为增加网络的可靠性，防止单点故障对网络造成影响，有时需要在一个集群中配置一个以上的RR。由于RR打破了从IBGP对等体收到的路由不能传递给其他IBGP对等体的限制，所以同一集群内的RR之间中可能存在环路。这时，该集群中的所有RR必须使用相同的Cluster ID，以避免RR之间的路由环路。 图：备份路由反射器 如上图，路由反射器RR1和RR2在同一个集群内，配置了相同的Cluster ID。 当客户机Client1从EBGP对等体接收到一条更新路由，它将通过IBGP向RR1和RR2通告这条路由。 RR1和RR2在接收到该更新路由后，将本地Cluster ID添加到Cluster List前面，然后向其他的客户机（Client2、Client3）反射，同时相互反射。 RR1和RR2在接收到该反射路由后，检查Cluster List，发现自己的Cluster ID已经包含在Cluster List中。于是RR1和RR2丢弃该更新路由，从而避免了路由环路。 多集群路由反射器：一个AS中可以存在多个集群，各个集群的RR之间建立IBGP对等体。当RR所处的网络层不同时，可以将较低网络层次的RR配成客户机，形成分级RR。当RR所处的网络层相同时，可以将不同集群的RR全连接，形成同级RR。 分级路由反射器： 图：分级路由反射器 在实际的RR部署中，常用的是分级RR的场景。如上图，ISP为AS100提供Internet路由。AS100内部分为两个集群，其中Cluster1内的四台设备是核心路由器，采用备份RR的形式保证可靠性。 同级路由反射器： 图：同级路由反射器 如上图，一个骨干网被分成多个集群。各集群的RR互为非客户机关系，并建立全连接。此时虽然每个客户机只与所在集群的RR建立IBGP连接，但所有RR和客户机都能收到全部路由信息。 BGP联盟：解决AS内部的IBGP网络连接激增问题，除了使用路由反射器之外，还可以使用联盟（Confederation）。联盟将一个AS划分为若干个子AS。每个子AS内部建立IBGP全连接关系，子AS之间建立联盟EBGP连接关系，但联盟外部AS仍认为联盟是一个AS。配置联盟后，原AS号将作为每个路由器的联盟ID。 这样有两个好处： 一是可以保留原有的IBGP属性，包括Local Preference属性、MED属性和NEXT_HOP属性等； 二是联盟相关的属性在传出联盟时会自动被删除，即管理员无需在联盟的出口处配置过滤子AS号等信息的操作。 图：联盟示意图 如上图所示：AS100使用联盟后被划分为3个子AS：AS65001、AS65002和AS65003，使用AS100作为联盟ID。此时IBGP的连接数量从10条减少到4条，不仅简化了设备的配置，也减轻了网络和CPU的负担。而AS100外的BGP设备因为仅知道AS100的存在，并不知道AS100内部的联盟关系，所以不会增加CPU的负担。 路由反射器和联盟的比较： 路由反射器 联盟 不需要更改现有的网络拓扑，兼容性好。 需要改变逻辑拓扑。 配置方便，只需要对作为反射器的设备进行配置，客户机并不需要知道自己是客户机。 所有设备需要重新进行配置。 集群与集群之间仍然需要全连接。 联盟的子AS之间是特殊的EBGP连接，不需要全连接。 适用于中、大规模网络。 适用于大规模网络。 路由聚合：在大规模的网络中，BGP路由表十分庞大，给设备造成了很大的负担，同时使发生路由振荡的几率也大大增加，影响网络的稳定性。 路由聚合是将多条路由合并的机制，它通过只向对等体发送聚合后的路由而不发送所有的具体路由的方法，减小路由表的规模。并且被聚合的路由如果发生路由振荡，也不再对网络造成影响，从而提高了网络的稳定性。 BGP在IPv4网络中支持自动聚合和手动聚合两种方式，而IPv6网络中仅支持手动聚合方式： 自动聚合：对BGP引入的路由进行聚合。配置自动聚合后，BGP将按照自然网段聚合路由（例如非自然网段A类地址10.1.1.1/24和10.2.1.1/24将聚合为自然网段A类地址10.0.0.0/8），并且BGP向对等体只发送聚合后的路由。 手动聚合：对BGP本地路由表中存在的路由进行聚合。手动聚合可以控制聚合路由的属性，以及决定是否发布具体路由。 为了避免路由聚合可能引起的路由环路，BGP设计了AS_Set属性。AS_Set属性是一种无序的AS_Path属性，标明聚合路由所经过的AS号。当聚合路由重新进入AS_Set属性中列出的任何一个AS时，BGP将会检测到自己的AS号在聚合路由的AS_Set属性中，于是会丢弃该聚合路由，从而避免了路由环路的形成。 路由衰减：当BGP应用于复杂的网络环境时，路由振荡十分频繁。为了防止频繁的路由振荡带来的不利影响，BGP使用路由衰减来抑制不稳定的路由。 路由振荡指路由表中添加一条路由后，该路由又被撤销的过程。当发生路由振荡时，设备就会向邻居发布路由更新，收到更新报文的设备需要重新计算路由并修改路由表。所以频繁的路由振荡会消耗大量的带宽资源和CPU资源，严重时会影响到网络的正常工作。 图：BGP衰减示意图 路由衰减使用惩罚值（Penalty value）来衡量一条路由的稳定性，惩罚值越高说明路由越不稳定。如上图所示，路由每发生一次振荡，BGP便会给此路由增加1000的惩罚值，其余时间惩罚值会慢慢下降。当惩罚值超过抑制阈值（suppress value）时，此路由被抑制，不加入到路由表中，也不再向其他BGP对等体发布更新报文。被抑制的路由每经过一段时间，惩罚值便会减少一半，这个时间称为半衰期（half-life）。当惩罚值降到再使用阈值（reuse value）时，此路由变为可用并被加入到路由表中，同时向其他BGP对等体发布更新报文。从路由被抑制到路由恢复可用的时间称为抑制时间（suppress time）。 路由衰减只对EBGP路由起作用，对IBGP路由不起作用。这是因为IBGP路由可能含有本AS的路由，而IGP网络要求AS内部路由表尽可能一致。如果路由衰减对IBGP路由起作用，那么当不同设备的衰减参数不一致时，将会导致路由表不一致。 BGP与BFD联动：BGP协议通过周期性的向对等体发送报文来实现邻居检测机制。但这种机制检测到故障所需时间比较长，超过1秒钟。当数据的传输速度达到Gbit/s级别时，这种机制的检测时间将导致大量数据丢失，无法满足网络高可靠性的需求。BGP与BFD （Bidirectional Forwarding Detection）联动可以利用BFD的毫秒级快速检测机制解决上述问题。 BGP Rracking：BGP Tracking可以为BGP提供快速的链路故障检测，加速BGP网络的收敛速度。当使能了BGP Tracking功能的BGP对等体之间的链路发生故障时，BGP Tracking将快速感知到达邻居的路由的不可达，并由路由管理模块通知到BGP，从而实现快速收敛。 与BFD特性相比，BGP Tracking配置简单，只需在本地配置而不需要全网配置。但是由于BGP Tracking是路由层面的感知方式，而BFD是链路层面的感知方式，所以BGP Tracking收敛速度比BFD慢，不适用于对收敛时间要求较高的语音等业务。 BGP GR：BGP的平滑重启GR（Graceful Restart）作为高可靠性的解决方案，其根本目的都是为了保证用户业务在设备故障的时候不受影响或者影响最小。 BGP GR技术保证了在设备重启或者主备倒换过程中转发层面能够继续指导数据的转发，同时控制层面邻居关系的重建以及路由计算等动作不会影响转发层面的功能，从而避免了路由震荡引发的业务中断，提高了整网的可靠性。 GR相关概念： GR Restarter：指由管理员触发或故障触发后，以GR方式重启的设备。 GR Helper：GR Restarter的邻居，协助GR Restarter进行GR的设备。 GR Time：是GR Helper检测到GR Restarter重启或者主备倒换后，保持转发信息不删除的时间。 BGP GR的过程是： 利用BGP的能力协商机制，GR Restarter和GR Helper了解彼此的GR能力，建立有GR能力的会话。 当GR Helper检查到GR Restarter重启或者主备倒换后，不删除和GR Restarter相关的路由和转发表项，也不通知其他邻居，而是等待重建BGP连接。 GR Restarter在GR Time超时前与重启前的所有GR Helper新建立好邻居关系。 BGP ORF：RFC5291、RFC5292规定了BGP基于前缀的ORF（Outbound Route Filtering）能力，能将本端设备配置的基于前缀的入口策略通过路由刷新报文发送给BGP邻居。BGP邻居根据这些策略构造出口策略，在路由发送时对路由进行过滤。这样不仅避免了本端设备接收大量无用的路由，降低了本端设备的CPU使用率，还有效减少了BGP邻居的配置工作，降低了链路带宽的占用率。 BGP按组打包：目前现网路由表的快速增长，以及网络拓扑的复杂性导致BGP需要支持更多的邻居。特别是一些邻居数目多且路由量大的场景下，针对路由器需要给大量的BGP邻居发送路由，且大部分邻居具有相同出口策略的特点，要求较高的打包发包性能。 按组打包技术将所有拥有共同出口策略的BGP邻居当作是一个打包组。这样每条待发送路由只被打包一次然后发给组内的所有邻居，使打包效率指数级提升。例如，一个反射器有100个客户机，有10万条路由需要反射。如果按照每个邻居分别打包的方式，反射器RR在向100个客户机发送路由的时候，所有路由被打包的总次数是10万×100。而按组打包技术将这个过程变为10万×1，性能相当于提升了100倍。 MP-BGP：传统的BGP-4只能管理IPv4单播路由信息，对于使用其它网络层协议（如IPv6、组播等）的应用，在跨AS传播时就受到一定限制。BGP多协议扩展MP-BGP（MultiProtocol BGP）就是为了提供对多种网络层协议的支持，对BGP-4进行的扩展。目前的MP-BGP标准是RFC4760，使用扩展属性和地址族来实现对IPv6、组播和VPN相关内容的支持，BGP协议原有的报文机制和路由机制并没有改变。 MP-BGP对IPv6单播网络的支持特性称为BGP4+，对IPv4组播网络的支持特性称为MBGP（Multicast BGP）。MP-BGP为IPv6单播网络和IPv4组播网络建立独立的拓扑结构，并将路由信息储存在独立的路由表中，保持单播IPv4网络、单播IPv6网络和组播网络之间路由信息相互隔离，也就实现了用单独的路由策略维护各自网络的路由。 扩展属性BGP使用的报文中，与IPv4相关的三处信息都由Update报文携带，这三处信息分别是：NLRI字段、Next_Hop属性、Aggregator属性。 为实现对多种网络层协议的支持，BGP需要将网络层协议的信息反映到NLRI及Next_Hop。因此MP-BGP引入了两个新的可选非过渡路径属性： MP_REACH_NLRI：Multiprotocol Reachable NLRI，多协议可达NLRI。用于发布可达路由及下一跳信息。 MP_UNREACH_NLRI：Multiprotocol Unreachable NLRI，多协议不可达NLRI。用于撤销不可达路由。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>BGP</tag>
        <tag>路由基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP报文类型]]></title>
    <url>%2F2018%2F01%2F23%2FBGP%E6%8A%A5%E6%96%87%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[BGP报文头部格式BGP报文由BGP报文头和具体报文内容两部分组成。（RFC4271） BGP的运行是通过消息驱动的，共有5种消息类型，这些消息有相同的报文头。这些消息通过TCP协议进行传播（端口号是179）。消息最长为4096字节，最短为19字节（只包含报文头）。 BGP报文头包括三的部分，总长19字节。各个部分的格式和功能如下： 图：BGP报文头部格式 Marker：占16字节，用于检查BGP对等体的同步信息是否完整，以及用于BGP验证的计算。不使用验证时所有比特均为1（十六进制则全“FF”）。 Length：占2个字节（无符号位），BGP消息总长度（包括报文头在内），以字节为单位。长度范围是19～4096。 Type：占1个字节（无符号位），BGP消息的类型。Type有5个可选值，表示BGP报文头后面所接的5类报文（其中，前四种消息是在RFC4271中定义的，而Type5的消息则是在RFC2918中定义的）： | TYPE值 | 报文类型 || —– | —————- || 1 | OPEN || 2 | UPDATE || 3 | NOTIFICATION || 4 | KEEPALIVE || 5 | REFRESH（RFC2918） | BGP报文头部格式抓包示例： 图：BGP报文头部抓包示例 BGP Open报文格式如果BGP报文头中的TYPE为1，则该报文为OPEN报文。报文头后面所接的报文内容如下，OPEN报文用于建立BGP连接： 图：Open报文格式 version：表示协议的版本号，现在BGP的版本号为4。 My autonomous System:发送者自己的AS域号 Hold Time:发送者自己设定的hold time值（单位：秒），用于协商BGP对等体间保持建立连接关系，发送KEEPALIVE或UPDATE等报文的时间间隔。BGP的状态机必须在收到对等体的OPEN报文后，对发出的OPEN报文和收到的OPEN报文两者的hold time时间作比较，选择较小的时间作为协商结果。Hold Time的值可为零（不发KEEPALIVE报文）或大于等于3，我们系统的默认为180。 BGP Identifier：发送者的router id。 Opt Parm Len：表示Optional Parameters（可选参数）的长度。如果此值为0，表示没有可选参数。 Optional Paramters：此值为BGP可选参数列表，每一个可选参数是一个TLV格式的单元(RFC3392)。 Open报文抓包示例： 图：Open报文抓包示例 BGP Update报文格式如果BGP报文头中的TYPE为2，则该报文为UPDATE报文。报文头后面所接的报文内容如下（RFC 4271），UPDATE报文用于通告路由。 图：Update报文格式 Unfeasible Routes Length:标明Withdrawn Routes部分的长度。其值为零时，表示没有撤销的路由。 Withdrawn Routes:包含要撤销的路由列表，列表中的每个单元包含1字节的Length域和可变长度的Prefix域。 Total Path Attribute Length：标明Path Attributes部分的长度。其值为零时，表示没有路由及其路由属性要通告。 Path Attributes：含要更新的路由属性列表，按其类型号从小到大的顺序排序，填写更新的路由的所有属性。每一个属性单元包括属性类型，属性长度，属性值三部分。其编码采用TLV格式。 图：BGP TLV格式 其中，Attr.TYPE占2个字节（无符号位），包括1字节的Flags（无符号位）和1字节的Type Code（无符号位）。 图:TLV-Type结构 Attr.Flags：占1个字节（8个bit），表示属性的标记，其每个bit位的意义如下显示： O: Optional bit, 属性的可选性。决定属性是否为必携带属性。带可选属性（optional）设为1，公认属性（well-known）设为零。 T: Transitive bit 属性的可传递性。对于可选属性，是可传递的设为1，非可传递的设为0。对于公认属性必须设为1。 P: Partial bit 属性的局部性。对于可传递的可选属性是局部的设为1，是完全的设为零。对于非可传递的的可选属性和公认属性，必须设为零。 E: Extended Length bit 决定该属性的长度的字段（即Attr. Length）是否需要扩展。不需要扩展则设为零，Attr. Length占1个字节；需要扩展则设为1，Attr. Length占2个字节。 U: Unused bits 低4位没有使用，发送时必须全部设为零，并且在接收时被忽略。 Attr.Type Code：占1个字节（无符号位），表示属性的类型号。 Attr.Value：**根据不同属性的类型填写不同内容。 Network Layer Reachability Information（NLRI）：含要更新的地址前缀列表，每一个地址前缀单元由一个LV二元组（prefix length, the prefix of the reachable route）组成，其编码填写方法与Withdrawn Routes的填写方法相同。 BGP Update报文抓包示例： 图：Update报文抓包示例 BGP Notification报文格式如果BGP报文头中的TYPE为3，则该报文为NOTIFICATION报文。报文头后面所接的报文内容如下（RFC 4271），NOTIFICATION报文用于处理BGP进程中的各种错误。 图：Notification报文格式 Error code：占1个字节（无符号位），定义错误的类型，非特定的错误类型用零表示。 Error subcode：占1个字节（无符号位），指定错误细节编号，非特定的错误细节编号用零表示。 Data：指定错误数据内容。 Notification报文抓包示例： 图：Notification报文抓包示例 BGP Keepalive报文格式如果BGP报文头中的TYPE为4，则该报文为KEEPALIVE报文。KEEPALIVE报文用于保持BGP连接。 KEEPALIVE报文只有BGP报文头，没有具体内容，故其报文长度应固定为19个字节。 Keepalive报文抓包示例： 图：Keepalive报文抓包示例 BGP Refresh报文格式如果BGP报文头中的TYPE为5，则该报文为REFRESH报文。报文头后面所接的报文内容如下（RFC 2918），REFRESH报文用于动态的请求BGP路由发布者重新发布UPDATE报文，进行路由更新。 图：Refresh报文格式 Field字段 Length长度 Description描述 AFI 2字节（无符号位） 表示地址族id，与UPDATE报文中的定义相同。 Res. 1字节（无符号位） 所有为应全为零，在接收报文时，此位被忽略。 SAFI 1字节（无符号位） 与UPDATE报文中的定义相同 Refresh报文抓包示例： 图：Refresh报文抓包示例]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>BGP</tag>
        <tag>路由基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP学习笔记]]></title>
    <url>%2F2018%2F01%2F10%2FBGP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[BGP的特征： BGP是外部路由协议，用来在AS之间传递路由信息。 是一种增强的距离矢量路由协议（AS_PATH）。 可靠的路由更新机制（TCP）（目的端口为179，源端口随机生成） 丰富的Metric度量方法（12条选路原则）。 从设计上避免了环路的发生 为路由附带属性信息。 支持CIDR（无类别域间选路）。 丰富的路由过滤和路由策略（router-policy）。 无需周期性的更新，只存在触发更新，并且值更新部分路由。 周期性（60s）的发送KeepAlive报文检测TCP的连通性。 BGP报文种类： Open：负责和对等体建立邻接关系。 KeepAlive：该消息在对等体之间周期性地发送，用以维护TCP的连接。（60s） Update：该消息被用来在BGP对等体之间传递路由信息。（通告和撤销路由） Notification：当BGP Speacker检测到错误的时候，就发送给消息给对等体。 Router-refresh：用来通知对等体自己支持路由刷新能力。 BGP邻居：BGP的邻居关系： BGP邻居关系建立在TCP连接的基础之上。 可以通过IGP或静态路由来提供TCP连接的可达性。 注：BGP的邻居是通过单播的方式建立的，所以首先需要在BGP进程下手动配置邻接地址。BGP没有自动发现邻居的机制，只能手动建立。 BGP中影响邻居建立的条件： 停留在Idle状态。 没有到达Peer的路由条目。 EBGP多跳。（不去发送TCP的建立连接报文） 停留在Connect或者Active状态。 源地址错误。（查看对端的IP地址是否是本地指定的邻居地址） TCP的认证。（TCP MD5） 有到达peer的路由，但是路由错误。 过滤了TCP的报文。 注：在华为中如果是通过默认路由的方式到达邻居，那么该邻居通告的所有路由都为无效路由。 关于BGP AS Number：默认使用连个字节的AS number，可以扩展到四个字节。AS Number需要进行申请。 1- 64511//公有的AS Number范围。 64512~65535 //私有的AS Number范围。 BGP状态机： 图：BGP状态机 Idle：BGP连接的第一个状态。在空闲状态，BGP在等待一个启动事件。启动事件出现以后，BGP初始化资源，复位连接重试计时器（Connect-Reitry）,发起第一条TCP连接，同时转入Connect（连接）状态。 Connet：在此状态，BGP发起第一个TCP连接，如果连接失败，则进入到active状态。如果TCP连接成功，就转入OpenSent状态，如果TCP连接失败，就转入Active状态。 Active：在此状态，BGP总是在试图建立TCP连接，如果连接重试计时器（Connect-Retry）超时，就退回到Connect状态，如果TCP连接成功，就转入OpenSent状态，如果TCP连接失败，就继续保持在Active状态，并继续发起TCP连接。 OpenSent：在此状态，TCP连接已经建立，BGP也已经发送了第一个Open报文，剩下的工作，BGP就在等待其对等体发送Open报文，并对收到的Open报文进行正确性检测，如果有错误，系统就会发送一个条出错的通知消息并回退到Idle状态。如果没有错误，BGP就开始放KeepAlive报文，并复位KeepAlive计时器，开始计时。同时转入OpenConfirm状态。 OpenConfirm：在此状态，BGP等待一个KeepAlive报文，同时复位保持计时器，如果收到一个KeepAlive报文，就转入Established阶段，BGP邻居的关系就建立起来了。 Established：在此状态，BGP邻居关系已经建立，这时，BGP将和它的邻居们交换Update报文，同时复位保持计时器。 另外，在除Idle状态以外的其他五个状态出现任何ERROR的时候，BGP状态机就会回退到Idle状态。在BGP对等体建立的过程中，通常可见的三个状态是：Idle，Active，Established。 Idle状态下，BGP拒绝任何进入的连接请求，是BGP的初始状态。 BGP路由通告原则： 连接建立时，BGP Speaker只把本身用的最优路由通告给对等体。 多条路径时，BGP Speraker只选择最优的路由放入路由表。 BGP Speraker从EBGP获得路由会向它所有的BGP对等体通告（包括EBGP和IBGP）。 通告给EBGP时，下一跳为自己。（注：如果通告路由的EBGP邻居需要接收的的EBGP邻居在同一网段，则通告时不修改下一跳。） 通告给IBGP时，不更改下一跳。防止次优路径。 BGP Speraker从IBGP获得的路由不会通告给其他的IBGP邻居。 IBGP的水平分割原理：从一个IBGP邻居收到的路由条目不会再通告给其他IBGP邻居。 如果想让所有的IBGP邻居都能收到路由，有三种解决方案： 全互联（每两台设备之间都建立IBGP邻居）。 RP（路由反射器）。 联盟 BGP与IGP同步。BGP不将从IBGP对等体获得的路由通告给它的EBGP对等体，除非该路由信息也能通过IBGP过得。 所有厂商同步功能默认关闭。华为不支持开启，思科可以开启。 BGP路由信息处理： 图：BGP路由信息处理 BGP路由信息处理： 当从对等体接收到更新数据包时，路由器会把这些更新数据包存储到路由选择信息库(Routing Information Base, RIB)中，并指明是来自哪个对等体的(Adj-RIB-In)。这些更新数据包被输入策略引擎过滤后，路由器将会执行路径选择算法，来为每一条前缀确定最佳路径。 得出的最佳路径被存储到本地BGP RIB (Loc-RIB)中，然后被提交给本地IP路由选择表(IP-RIB)，以用作安装考虑。 除了从对等体接收来的最佳路径外，Loc-RIB也会包含当前路由器注入的(被称为本地发起的路由)，并被选择为最佳路径的BGP前缀。Loc-RIB中的内容在被通告给其他对等体之前，必须通过输出策略引擎。只有那些成功通过输出策略引擎的路由，才会被安装到输出RIB (Adj-RIB-Out)中。 BGP路径属性（12条）：BGP作为一个策略工具，主要作用是实现AS间的路由信息传递。BGP就是结合丰富的路径属性，很好的控制路由信息的传递，从而实现路径的选择。 BGP属性分类（四类）： 公认必遵（Well-known mandatory）公认强制 所有BGP路由器都可以识别，且必须存在于Update消息中。如果缺少这种属性，路由信息就会出错。 origin as_path next hop 公认任意（Well-known discretionary）公认非强制 所有BGP路由器都可以识别，但不要求必须存在于Update消息中，可以根据具体情况来决定是否添加到Update消息中。 Local-Preference Atomic-Aggregate（as-set)原子聚合//标识汇总路由 MP Reach NLRI 可选过渡（Optional transitive） BGP的路由器可以选择是否在Update消息中携带这种路由属性。接收的路由器如果不识别这种属性，可以转发个邻居路由器，邻居路由器可能会识别并使用到这种属性。 Aggreagator//聚合者，标识聚合路由的来源AS和聚合者。通告汇总设备的Router-ID。 Community Extended-Communities 可选非过渡（Optional non-transitive） BGP路由器可以选择是否在Update消息中携带这种属性。在整个路由发布的路径上，如果部分路由器不能识别该属性，可能会导致该属性无法发挥效用。因此接收的路由器如果不识别这种属性，将丢弃这种属性，不必在转发给邻居路由器。 MED（cost） Originator-ID//标识路由的来源设备 Cluster-List//防止路由的反射回路 OeiginOrigin属性用来定义路径信息的来源，标记一条路由是怎么成为BGP路由的。它有以下3种类型： IGP：具有最高的优先级。通过路由始发AS的IGP得到的路由信息，比如通过network命令注入到BGP路由表的路由，其Origin属性为IGP。 EGP：优先级次之。通过EGP得到的路由信息，其Origin属性为EGP。 Incomplete：优先级最低。通过其他方式学习到的路由信息。比如BGP通过import-route命令引入的路由，其Origin属性为Incomplete。 AS_PathAS_Path属性按矢量顺序记录了某条路由从本地到目的地址所要经过的所有AS编号。当BGP路由器从EBGP对等体接收路由时，如果发现AS_Path列表中有本AS号，则不接收该路由，从而避免了AS间的路由环路。 当BGP Speaker本地通告一条路由时： 当BGP Speaker将这条路由通告到其他AS时，便会将本地AS号添加在AS_Path列表中，并通过Update消息通告给邻居路由器。 当BGP Speaker将这条路由通告到本地AS时，便会在Update消息中创建一个空的AS_Path列表。 当BGP Speaker传播从其他BGP Speaker的Update消息中学习到的路由时： 当BGP Speaker将这条路由通告到其他AS时，便会把本地AS编号添加在AS_Path列表的最前面（最左面）。收到此路由的BGP路由器根据AS_Path属性就可以知道去目的地址所要经过的AS。离本地AS最近的相邻AS号排在前面，其他AS号按顺序依次排列。 当BGP Speaker将这条路由通告到本地AS时，不会改变这条路由相关的AS_Path属性。 AS-path属性的类型： AS-Set ：由一系列AS号无序的组成，包含在Update消息中。 AS-sequence：由一系列AS号顺序的组成，包含在update消息中。 AS-confed-sequence:在本地联盟内由一系列ad号按顺序地组成，包含在Update消息中，只能在本地联盟内传递。 AS-confed-set：在本地联盟中由一系列AS号无序的组成，包含在Update消息中。只能在本地联盟内传递。 Next_HopNext_Hop属性记录了路由的下一跳信息。BGP的下一跳属性和IGP的有所不同，不一定就是邻居设备的IP地址。通常情况下，Next_Hop属性遵循下面的规则： BGP Speaker将本地始发路由发布给IBGP对等体时，会把该路由信息的下一跳属性设置为本地与对端建立BGP邻居关系的接口地址。 BGP Speaker在向EBGP对等体发布某条路由时，会把该路由信息的下一跳属性设置为本地与对端建立BGP邻居关系的接口地址。 BGP Speaker在向IBGP对等体发布从EBGP对等体学来的路由时，并不改变该路由信息的下一跳属性。 Local_Pref 该属性仅在IBGP对等体之间有效，不通告给其他AS。它表明路由器的BGP优先级。 该属性用于判断流量离开AS时的最佳路由。当BGP路由器通过不同的IBGP对等体得到目的地址相同但下一跳不同的多条路由时，将优先选择Local_Pref属性值较高的路由。 MEDMED属性用于判断流量进入AS时的最佳路由，当一个运行BGP的设备通过不同的EBGP对等体得到目的地址相同但下一跳不同的多条路由时，在其它条件相同的情况下，将优先选择MED 值较小者作为最佳路由。 MED属性仅在相邻两个AS之间传递，收到此属性的AS一方不会再将其通告给任何其他第三方AS。MED属性可以手动配置，如果路由没有配置MED属性，BGP选路时将该路由的MED值按缺省值0来处理。 团体属性团体属性是一组有相同特征的目的地址的集合。团体属性用一组以4字节为单位的列表来表示，设备中团体属性的格式是aa:nn或团体号。 aa:nn：aa和nn的取值范围都是0～65535，管理员可根据实际情况设置具体数值。通常aa表示自治系统AS编号，nn是管理员定义的团体属性标识。例如，来自AS100的一条路由，管理员定义的团体属性标识是1，则该路由的团体属性格式是100:1。 团体号：团体号是0～4294967295的整数。RFC1997中定义，0（0x00000000）～65535（0x0000FFFF）和4294901760（0xFFFF0000）~4294967295（0xFFFFFFFF）是预留的。 团体属性用来简化路由策略的应用和降低维护管理的难度，利用团体可以使多个AS中的一组BGP设备共享相同的策略。团体是一个路由属性，在BGP对等体之间传播，且不受AS的限制。BGP设备在将带有团体属性的路由发布给其它对等体之前，可以先改变此路由原有的团体属性。 公认团体属性 Internet：缺省情况下，所有的路由都属于Internet团体。具有此属性的路由可以被通告给所有的BGP对等体。 No_Advertise：具有此属性的路由在收到后，不能被通告给任何其他的BGP对等体。 No_Export：具有此属性的路由在收到后，不能被发布到本地AS之外。如果使用了联盟，则不能被发布到联盟之外，但可以发布给联盟中的其他子AS。 No_Export_Subconfed：具有此属性的路由在收到后，不能被发布到本地AS之外，也不能发布到联盟中的其他子AS。 BGP选路规则：当到达同一目的地存在多条路由时，BGP依照如下策略顺序进行路由选择： 如果此路由的下一跳不可达，忽略此路由。 优选协议首选值（PrefVal）最高的路由。 优选本地优先级（Local_Pref）最高的路由。 优选本地生成的路由。 优选AS路径最短的路由。 比较Origin属性，依稀选Origin类型为IGP、EGP、Incomplete的路由。 优选MED值最小的路由。 优选从EBGP邻居学来的路由（EBGP路由优先级高于IBGP路由） 优选到下一跳IGP Metric较小的路由。 优选Cluster_List最短的路由。 优选Router ID最小的路由器发布的路由。 比较对等体的IP address，优选从具有较小IP地址的对等体学来的路由。 BGP路由汇总：自动汇总：开启BGP自动汇总后，只能针对重分发的进BGP的外部路由做自动汇总，并且只汇总成主类路由。 手动汇总：手动汇总优先于自动汇总。 detail-suppressed //抑制明细路由。 suppress-policy //指定抑制哪些明细路由。 origin-policy //配置起源策略，针对哪些类型的路由做汇总，可以匹配属性。 as-set //用于汇总路由基础明细路由的AS-Path属性，防止环路问题。 注：如果汇总的明细路由来自不同AS，则汇总路由继承的明细路由AS—path属性标识为无序。 如果明细路由来自同一个as，则汇总继承的明细路由AS-Path为有序。 attribute-poliy //为汇总路由配置属性。 BGP路由表中的”s”标记表示该路由条目被抑制，并且此路由不能通告给邻居。 汇总路由的属性继承：在华为中如果手工汇总并且不携带“detail-suppressed”参数，汇总路由会继承明细路由的community和origin属性。 community属性：将明细路由中所有community属性汇总，作为汇总路由的community属性。 origin属性：继承明细路由中起源最低的属性。 在华为中如果手工汇总并且携带“detail-suppressed”参数，抑制明细路由的同时会追加Atomic-aggregate属性，该属性标识汇总路由属性丢失。如果Atomic-aggregate属性被设置，则不会继承明细路由的community 属性。 BGP路由过滤： 理由前缀列表实现路由过滤。 peer 13.1.1.1 ip-prefix bgp import 利用filter-policy实现路由过滤 peer 13.1.1.1 filter-policy 2000 import as-path-filter过滤路由 ip as-path-filter as deny 1000 ip as-path-filter as permit .* peer 13.1.1.1 as-path-filter import 正则表达式： 正则表达式知识BGP过滤的一种方法。 正则表达式是按照一定的规则来匹配字符串的公式。基于这些字符串对BGP的as-path属性做出判断（接收或拒绝）。实际上可以认为他是一个as-path的acl。 正则表达式可以定义为多个permit或deny语句。语句与语句之间的关系是或 的关系。 正则表达式字符： 符号 说明 ^ 匹配一个字符串的开始。如^200表是只匹配as-path的第一个值为200. $ 匹配一个子符串的结束。如200$表示只匹配as-path的最后一个值为200. . 匹配任何单个字符，包括空格。 匹配前面的一个字符或者一个序列，可以一次或者多次出现。 _ 匹配一个符号。如逗号，括号，空格符号等。 * 匹配前面的一个字符或者一个序列，可以零次或多次出现。 匹配变化的AS或者一个独立的匹配，通常和“ \ ”一起使用 \ 逻辑或 [ ] 匹配一个范围内得as，通常和“ - ” 一起使用。 - 连接符。 BGP反射器：路由反射器的反射原则（非非不传）： 从EBGP邻居收到的EBGP路由可以反射给客户端、非客户端和其他的EBGP邻居。 从IBGP非客户端邻居收到的IBGP路由可以反射给客户端和其他的EBGP邻居，不能反射给非客户端。 从IBGP客户端邻居收到的IBGP路由可以反射给客户单、非客户端和其他EBGP邻居。 对等体之间的关系： Client只需维护与RR之间的IBGP会话。 RR与RR之间需建立IBGP的全互联。 Non-Client和Non-Client之间需建立IBGP全互联。 RR与Non-Client之间需建立IBGP全互联。 Cluster List：只有经过RR反射的路由才会携带Cluster_list和起源ID属性。 cluster-list属性的目的是为了防止在RR之间反射的路由环路，如果RR收到的路由条目中携带cluster-list属性，并且在列表中包含自己的cluster-id，则丢弃路由。如果不包含则接收并继续反射路由，同时追加自己的cluster-id。 Originator ID： Originator id属性用于防止在反射器和客户端/非客户端之间产生环路。 Originator-id属性长4字节，可选非过渡属性，属性类型为9，是又路由反射器RR产生的，携带了本地AS内部路由发起者的Router ID。 当一条路由第一次被RR反射的时候，RR讲Originator-ID属性加入到这条路由，标识这条路由的始发路由器。如果一条路由中已经存在了Originator-id属性，则RR将不会创建新的Originator-id。 当其他BGP speaker接收到这条路由时，将比较收到的Originator-id和本地的router-id，如果两个id相同，bgp speaker会忽略掉这条路由，不做处理。 BGP联盟： 在联盟AS间传递联盟EBGP路由时不改变下一跳。 如果在联盟AS之间通过loopback口建立联盟EBGP邻居，同样需要指定EBGP多跳，默认TTL为1. ():表示联盟内有序的AS。 []:表示联盟内无序的AS。 //华为才会有，思科是大括号 {}:表示联盟外无序的AS。 正则表达式中下划线可以配置小括号，大括号，不能匹配中括号。 BGP中如何下发默认路由： 针对peer通告默认。 本地创建默认路由后network进BGP。 本地创建默认路由后import进BGP。 default-route imported //配置引入默认路由 BGP命令行：配置BGP只通告活动路由：active-route-advertise 配置IP RIB中过滤BGP路由：bgp-rib-only 这两条命令互斥。 as-path limit 1 //配置允许as-path的数量。默认255. 可配置1-2000. 4字节的AS号： 定义了一种新的Open能力码用于进行BGP连接的能力协商。 2中新的可选过渡属性，AS4-path和AS4-aggregator属性。 定义了AS-Trans（保留值为23456）用于衔接2字节的AS和4字节的AS。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>BGP</tag>
        <tag>路由基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ISIS报文类型]]></title>
    <url>%2F2018%2F01%2F08%2FISIS%E6%8A%A5%E6%96%87%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[ISIS的报文类型IS-IS报文有以下几种类型：HELLO PDU（Protocol Data Unit）、LSP和SNP。 Hello PDU Hello报文用于建立和维持邻居关系，也称为IIH（IS-to-IS Hello PDUs）。其中，广播网中的Level-1 IS-IS使用Level-1 LAN IIH；广播网中的Level-2 IS-IS使用Level-2 LAN IIH；非广播网络中则使用P2P IIH。它们的报文格式有所不同。P2P IIH中相对于LAN IIH来说，多了一个表示本地链路ID的Local Circuit ID字段，缺少了表示广播网中DIS的优先级的Priority字段以及表示DIS和伪节点System ID的LAN ID字段。 LSP 链路状态报文LSP（Link State PDUs）用于交换链路状态信息。LSP分为两种：Level-1 LSP和Level-2 LSP。Level-1 LSP由Level-1 IS-IS传送，Level-2 LSP由Level-2 IS-IS传送，Level-1-2 IS-IS则可传送以上两种LSP。 LSP报文中主要字段的解释如下： ATT字段：当Level-1-2 IS-IS在Level-1区域内传送Level-1 LSP时，如果Level-1 LSP中设置了ATT位，则表示该区域中的Level-1 IS-IS可以通过此Level-1-2 IS-IS通往外部区域。 OL（LSDB Overload）字段：过载标志位。 设置了过载标志位的LSP虽然还会在网络中扩散，但是在计算通过过载路由器的路由时不会被采用。即对路由器设置过载位后，其它路由器在进行SPF计算时不会使用这台路由器做转发，只计算该节点上的直连路由。 IS Type字段：用来指明生成此LSP的IS-IS类型是Level-1还是Level-2 IS-IS（01表示Level-1，11表示Level-2）。 SNP 序列号报文SNP（Sequence Number PDUs）通过描述全部或部分数据库中的LSP来同步各LSDB（Link-State DataBase），从而维护LSDB的完整与同步。 SNP包括全序列号报文CSNP（Complete SNP）和部分序列号报文PSNP（Partial SNP），进一步又可分为Level-1 CSNP、Level-2 CSNP、Level-1 PSNP和Level-2 PSNP。 CSNP包括LSDB中所有LSP的摘要信息，从而可以在相邻路由器间保持LSDB的同步。在广播网络上，CSNP由DIS定期发送（缺省的发送周期为10秒）；在点到点链路上，CSNP只在第一次建立邻接关系时发送。 PSNP只列举最近收到的一个或多个LSP的序号，它能够一次对多个LSP进行确认，当发现LSDB不同步时，也用PSNP来请求邻居发送新的LSP。 IS-IS报文中的变长字段部分是多个TLV（Type-Length-Value）三元组。TLV也称为CLV（Code-Length-Value）。 常见的TLV： TLV Type 名称 所应用的PDU类型 1 Area Addresses IIH、LSP 2 IS Neighbors（LSP） LSP 4 Partition Designated Level2 IS L2 LSP 6 IS Neighbors（MAC Address） LAN IIH 7 IS Neighbors（SNPA Address） LAN IIH 8 Padding IIH 9 LSP Entries SNP 10 Authentication Information IIH、LSP、SNP 128 IP Internal Reachability Information LSP 129 Protocols Supported IIH、LSP 130 IP External Reachability Information L2 LSP 131 Inter-Domain Routing Protocol Information L2 LSP 132 IP Interface Address IIH、LSP IS-IS报文通用格式##ISIS报文通用格式： IS-IS报文是直接封装在数据链路层的帧结构中的。PDU可以分为两个部分，报文头和变长字段部分。其中头部又可分为通用头部和专用头部。对于所有PDU来说，通用报头都是相同的，但专用报头根据PDU类型不同而有所差别。 IS-IS的PDU有4种类型：Hello报文，LSP，CSNP，PSNP。 图：IS-IS通用报文格式 Intradomain Routing Protocol Discriminator：域内路由选择协议鉴别符，设置为0x83。 Length Indicator：PDU头部的长度（包括通用头部和专用头部），以字节为单位。 Version/Protocol ID Extension：版本/协议标识扩展，设置为1（0x01）。 ID Length：NSAP地址或NET中System ID区域的长度。值为0时，表示System ID区域的长度为6字节。值为255时，表示System ID区域为空（即长度为0）。 R（Reserved）：保留，设置为0。 PDU Type：PDU的类型。IS-IS PDU共有9种类型，详细信息请参考下表。 Version：设置为1（0x01）。 Maximum Area Address：支持的最大区域个数。设置为1～254的整数，表示该IS-IS进程实际所允许的最大区域地址数；设置为0，表示该IS-IS进程最大只支持3个区域地址数。 PDU类型对应关系： 类型值 PDU类型 简称 15 Level-1 LAN IS-IS Hello PDU L1 LAN IIH 16 Level-2 LAN IS-IS Hello PDU L2 LAN IIH 17 Point-to-Point IS-IS Hello PDU P2P IIH 18 Level-1 Link State PDU L1 LSP 20 Level-2 Link State PDU L2 LSP 24 Level-1 Complete Sequence Numbers PDU L1 CSNP 25 Level-2 Complete Sequence Numbers PDU L2 CSNP 26 Level-1 Partial Sequence Numbers PDU L1 PSNP 27 Level-2 Partial Sequence Numbers PDU L2 PSNP 抓包示例： 图：IS-IS通用报文抓包示例 IS-IS Hello报文Hello报文用于建立和维持邻居关系，也称为IIH（IS-to-IS Hello PDUs）。其中，广播网中的Level-1路由器使用Level-1LAN IIH；广播网中的Level-2路由器使用Level-2 LAN IIH；非广播网络中则使用P2P IIH。它们的报文格式有所不同。 Hello报文格式： 图：广播网中 IIH报文格式 主要字段的解释如下： Reserved/Circuit Type：高位的6比特保留，值为0。低位的2比特表示路由器的类型（01表示L1，10表示L2，11表示L1/L2）。 Source ID：发出Hello报文的路由器的System ID。 Holding Time：保持时间。在此时间内如果没有收到邻居发来的Hello报文，则中止已建立的邻居关系。 PDU Length：PDU的总长度，单位是字节。 Priority：选举DIS的优先级，取值范围为0～127。数值越大，优先级越高。 LAN ID：包括DIS的System ID和一字节的伪节点ID。 图：P2P中IIH报文格式 从图中可以看出，P2P IIH中的多数字段与LAN IIH相同。不同的是没有Priority和LAN ID字段，而多了一个Local CircuitID字段，表示本地链路ID。 IIH 抓包示例： 图：LAN网中IIH报文抓包示例 图：P2P中IIH报文抓包示例 IS-IS LSP报文格式链路状态报文LSP（Link State PDUs）用于交换链路状态信息。LSP分为两种：Level–1 LSP和Level–2 LSP。Level–1 LSP由Level-1路由器传送，Level–2 LSP由Level-2路由器传送，Level-1-2路由器则可传送以上两种LSP。 两类LSP有相同的报文格式。 LSP报文格式： 图：ISIS LSP报文格式 主要字段的解释如下： PDU Length：PDU的总长度，以字节为单位。 Remaining Lifetime：LSP的生存时间，以秒为单位。 LSP ID：由三部分组成，System ID、伪节点ID（一字节）和LSP分片后的编号（一字节）。 Sequency Number：LSP的序列号。 Checksum：LSP的校验和。 P（Partition Repair）：仅与L2 LSP有关，表示路由器是否支持自动修复区域分割。 ATT（Attachment）：由Level-1-2路由器产生，用来指明始发路由器是否与其它区域相连。虽然此标志位也存在于Level-1和Level-2的LSP中，但实际上此字段只和Level-1-2路由器始发的L1 LSP有关。此字段有4bit，用来表明相连的区域所使用的度量方式。 从右至左这4位依次表示如下所示： 第4位：缺省度量； 第5位：时延度量； 第6位：代价度量； 第7位：差错度量。 OL（LSDB Overload）：过载标志位。设置了过载标志位的LSP虽然还会在网络中扩散，但是在计算通过超载路由器的路由时不会被采用。即，对路由器设置过载位后，其它路由器在进行SPF计算时不会考虑这台路由器。当路由器内存不足时，系统自动在发送的LSP报文中设置过载标志位。 IS Type：生成LSP的路由器的类型。用来指明是Level-1还是Level-2路由器（01表示Level-1，11表示Level-2）。 LSP报文抓包示例： 图：LSP报文抓包示例 IS-IS SNP报文格式时序报文SNP（Sequence Number PDUs）通过描述全部或部分数据库中的LSP来同步各LSDB（Link-State DataBase），从而维护LSDB。 SNP包括CSNP（Complete SNP，全时序报文）和PSNP（Partial SNP，部分时序报文），进一步又可分为L1 CSNP、L2 CSNP、L1 PSNP和L2 PSNP。 CSNP包括LSDB中所有LSP的摘要信息，从而可以在相邻路由器间保持LSDB的同步。在广播网络上，CSNP由DIS定期发送（缺省的发送周期为10秒）；在点到点链路上，CSNP只在第一次建立邻接关系时发送。 SNP报文格式： 图：CSNP报文类型 主要字段的解释如下： Source ID：发出SNP报文的路由器的System ID。 Start LSP ID：CSNP报文中第一个LSP的ID值。 End LSP ID：CSNP报文中最后一个LSP的ID值。 PSNP只列举最近收到的一个或多个LSP的序号，它能够一次对多个LSP进行确认，当发现LSDB不同步时，也用PSNP来请求邻居发送新的LSP。 图：PSNP报文格式 SNP报文抓包示例： 图：CSNP报文抓包示例 图：PSNP报文抓包示例]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>ISIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ISIS命令行配置]]></title>
    <url>%2F2018%2F01%2F08%2FISIS%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[IS-IS配置：ISIS认证：接口认证： 如果配置了send-only则表示仅对发送的Hello封装认证信息，而不检查收到的Hello报文是否通过了认证。在本端不需要进行认证检查且对端认证通过时，才可以建立起邻居关系。 如果没有配置send-only，此时应保证同一网络所有接口的相同级别的认证密码一致。 区域认证或路由器域认证： 对发送的LSP和SNP都封装认证信息，并检查收到的LSP和SNP是否通过认证，丢弃没有通过认证的报文。该情况下不配置参数snp-packet或all-send-only。 对发送的LSP封装认证信息并检查收到的LSP，对发送的SNP不封装认证信息，也不检查收到的SNP。该情况下需要配置参数snp-packet authentication-avoid。 对发送的LSP和SNP都封装认证信息，只检查收到的LSP，不检查收到的SNP。该情况下需要配置参数snp-packet send-only。 对发送的LSP和SNP都封装认证信息，不检查收到的LSP和SNP。该情况下需要配置参数all-send-only。 配置optional checksum：在网络运行期间，IS-IS路由器可能会收到恶意报文的攻击，或者IS-IS报文被篡改，可能导致网络的重要信息被窃取，给网络造成重大损失。optional checksum特性是指在IS-IS路由器发送的CSNP、PSNP及Hello报文中，封装optional checksum TLV，对端在收到封装后的报文后，首先检查其携带的TLV是否正确，如果不正确，则拒绝接收，从而保证网络的安全性。 optional-checksum enable //使能IS-IS进程的optional checksum功能。 如果IS-IS接口或者区域已经配置了MD5认证或者含有生效MD5认证的Keychain认证，则IS-IS路由器发送Hello和SNP报文时不携带checksum TLV，只校验接收到的报文。 IS-IS的选路：123preference 15//配置IS-IS路由的优先级。 //缺省情况下，IS-IS协议的优先级为15。配置preference的值越小，优先级越高。 ISIS接口开销：IS-IS有三种方式来确定接口的开销，按照优先级由高到低分别是： 接口开销：为单个接口设置开销。 全局开销：为所有接口设置开销。 自动计算开销：根据接口带宽自动计算开销。 如果没有为IS-IS接口配置任何开销值，IS-IS接口的默认开销为10，开销类型是narrow。 auto-cost enable： //使能自动计算接口的开销值。 IS-IS接口开销和带宽对应关系表： | 开销值 | 接口带宽范围 || —- | ———————— || 60 | 接口带宽≤10Mbit/s || 50 | 10Mbit/s&lt;接口带宽≤100Mbit/s || 40 | 100Mbit/s&lt;接口带宽≤155Mbit/s || 30 | 155Mbit/s&lt;接口带宽≤622Mbit/s || 20 | 622Mbit/s&lt;接口带宽≤2.5Gbit/s || 10 | 2.5Gbit/s&lt;接口带宽 | 配置ISIS对等价路由的处理方式：当IS-IS网络中有多条冗余链路时，可能会出现多条等价路由，此时可以采取两种方式： 配置负载分担。流量会被均匀的分配到每条链路上。 该方式可以提高网络中链路的利用率及减少某些链路负担过重造成阻塞发生的情况。但是由于对流量转发具有一定的随机性，因此可能不利于对业务流量的管理。 配置等价路由优先级。针对等价路由中的每一条路由，明确指定其优先级，优先级高的路由将被优选，优先级低的路由可以作为备用链路。 该方式可以在不修改原有配置的基础上，指定某条路由被优选，便于业务的管理，同时提高网络的可靠性。 1234567[isis] maximum load-balancing 8//配置在负载分担方式下的等价路由的最大数量。 //配置ISIS等价路由的优先级：[isis] nexthop ip-address weight value//配置等价路由的优先级//缺省情况下，不设置IS-IS等价路由的优先级。value值越小，表示优先级越高。 配置IS-IS路由渗透：12[isis] import-route isis level-2 into level-1 //将Level-2区域的路由渗透到本地Level-1区域。 控制Level-1设备是否生成缺省路由：IS-IS协议规定，如果IS-IS Level-1-2设备根据链路状态数据库判断到通过Level-2区域比Level-1区域能够到达更多的区域，该设备会在所发布的Level-1 LSP内将ATT比特位置位。对于收到ATT比特位置位的LSP报文的Level-1设备，会生成一条目的地为发送该LSP的Level-1-2设备的缺省路由。 以上是协议的默认原则，在实际应用中，可以根据需要对ATT比特位进行手动配置以更好地为网络服务。 1234[isis] attached-bit advertise &#123; always | never&#125;//设置Level-1-2设备发布的LSP报文中ATT比特位的置位情况。[isis] attached-bit avoid-learning //设置即使收到Level-1 LSP报文的ATT比特位置位，Level-1设备也不生成缺省路由。 always参数用来设置ATT比特位永远置位，收到该LSP的Level-1设备会生成缺省路由。 never参数用来设置ATT比特位永远不置位，可以避免Level-1设备生成缺省路由，减小路由表的规模。 控制IS-IS的路由信息的交互配置IS-IS发布缺省路由：在具有外部路由的边界设备上配置IS-IS发布缺省路由可以使该设备在IS-IS路由域内发布一条0.0.0.0/0的缺省路由。在执行此配置后，IS-IS域内的其他设备在转发流量时，将所有去往外部路由域的流量首先转发到该设备，然后通过该设备去往外部路由域。 配置静态缺省路由虽然也可以实现该功能，但是当现网中有大量设备时，配置工作量巨大且不利于管理。 此外，采用IS-IS发布缺省路由的方式更加灵活。例如，如果存在多个边界设备，那么可以通过配置路由策略，使某台边界设备在满足条件时才发布缺省路由，从而避免造成路由黑洞。 12[isis] default-route-advertise [ always | match default | route-policy route-policy-name ] [ cost cost | tag tag | [ level-1 | level-1-2 | level-2 ] ] * [ avoid-learning ]，//配置IS-IS发布缺省路由。 参数 参数说明 取值 always 指定设备无条件的发布缺省路由，且发布的缺省路由中将自己作为下一跳。 - match default 如果在路由表中存在其他路由协议或其它IS-IS进程生成的缺省路由，则在LSP中发布该缺省路由。 - route-policy route-policy-name 指定路由策略名称。当该边界设备的路由表中存在满足路由策略的外部路由时，才向IS-IS域发布缺省路由，避免由于链路故障等原因造成该设备已经不存在某些重要的外部路由时，仍然发布缺省路由从而造成路由黑洞。此处的路由策略不影响IS-IS引入外部路由。 字符串形式，区分大小写，不支持空格，长度范围是1～40。当输入的字符串两端使用双引号时，可在字符串中输入空格。 cost cost 指定缺省路由的开销值。 整数形式。取值范围根据cost-style而定：当cost-style为narrow、narrow-compatible或compatible时，取值范围是0～63；当cost-style为wide或wide-compatible时，取值范围是0～4261412864。 tag tag 指定发布的缺省路由的标记值。只有当IS-IS的开销类型为wide、wide-compatible或compatible时，发布的LSP中才会携带tag值。 整数形式，取值范围为1～4294967295。 level-1 指定发布的缺省路由级别为Level-1。如果不指定级别，则默认为生成Level-2级别的缺省路由。 - level-2 指定发布的缺省路由级别为Level-2。如果不指定级别，则默认为生成Level-2级别的缺省路由。 - level-1-2 指定发布的缺省路由级别为Level-1-2。如果不指定级别，则默认为生成Level-2级别的缺省路由。 - avoid-learning 避免IS-IS进程学到其他路由协议或其它IS-IS进程生成的缺省路由并添加到路由表。如果路由表中已存在学到的缺省路由为活跃状态，则将此路由置为不活跃状态。 - 配置路由聚合：12summary ip-address mask [ avoid-feedback | generate_null0_route | tag tag | [ level-1 | level-1-2 | level-2 ] ] *//配置聚合路由 参数 参数说明 取值 ip-address 指定要生成聚合路由的IP地址。 点分十进制形式。 mask 指定生成的聚合路由的IP地址的掩码。 点分十进制形式。 avoid-feedback 表示避免通过路由计算学习到聚合路由。 - generate_null0_route 表示为防止路由循环而生成Null 0路由。 - tag tag 表示为发布的路由分配管理标签号。 整数形式，取值范围是1～4294967295。 level-1 表示只对引入到Level-1区域的路由进行聚合。如果没有指定Level级别，缺省为Level-2。 - level-1-2 表示对向Level-1区域以及Level-2区域引入的路由都进行聚合。如果没有指定Level级别，缺省为Level-2。 - level-2 表示只对引入到Level-2区域的路由进行聚合。如果没有指定Level级别，缺省为Level-2。 - 控制IS-IS路由的收敛：配置Hello报文属性：12isis timer hello hello-interval [ level-1 | level-2 ]//指定IS-IS接口发送Hello报文的间隔时间。 参数 参数说明 取值 hello-interval 指定发送Hello报文的间隔时间。 整数类型，取值范围是3～255，单位是秒。缺省值是10秒。 level-1 指定Level-1级别Hello报文的发送间隔。如果没有指定级别，则默认级别为Level-1和Level-2。 - level-2 指定Level-2级别Hello报文的发送间隔。如果没有指定级别，则默认级别为Level-1和Level-2。说明： 参数level-1和level-2仅在广播接口上是可配置的。因为在广播链路上，level-1和level-2的Hello报文会分别发送，其间隔时间也要分别设置。在点到点链路上只有一种Hello报文，所以不需要使用参数level-1和level-2。 - 12isis timer holding-multiplier number [ level-1 | level-2 ] //配置Hello报文的发送间隔时间的倍数，以达到修改IS-IS的邻居保持时间的目的。 参数 参数说明 取值 number 指定邻居保持时间为Hello报文的发送间隔时间的倍数。 整数形式，取值范围是3～1000。缺省值为3。 level-1 指定Level-1邻居的邻居保持时间。如果没有指定级别，则默认为Level-1和Level-2邻居指定邻居保持时间。 - level-2 指定Level-2邻居的邻居保持时间。如果没有指定级别，则默认为Level-1和Level-2邻居指定邻居保持时间。 - 配置LSP报文属性：LSP报文用于交换链路状态信息。通过配置LSP的基本属性，可以控制LSP报文的大小及最大有效时间。还可以通过使能LSP快速扩散，以及减小接口发送LSP报文的最小时间间隔和LSP的刷新周期可以加快LSP报文的扩散速度，可以使得网络快速收敛。但是如果网络变化比较频繁，又会过度占用CPU资源。此时可以通过配置LSP生成的智能定时器，既可以快速响应突发事件，加快网络的收敛速度，又可以在网络变化频繁时自动延长智能定时器的间隔时间，避免过度占用CPU资源。 配置的参数 作用 应用场景 配置LSP的大小 控制生成和接收LSP的大小。 当链路状态信息变大时，可以增大生成LSP的报文长度，使得每个LSP可以携带更多的信息。 配置LSP的最大有效时间 控制LSP的最大有效时间，保证在未收到更新的LSP之前旧LSP的有效性。 路由器生成系统LSP时，会在LSP中填写此LSP的最大有效时间。当此LSP被其它路由器接收后，它的有效时间会随着时间的变化不断减小。如果路由器一直没有收到更新的LSP，而此LSP的有效时间已减少到0，LSP再保持60秒，若还未收到新的LSP，那么此LSP将被从LSDB中删除。 配置LSP的刷新周期 控制LSP的泛洪定时刷新，保持LSBD的同步。 IS-IS网络主要通过LSP的泛洪实现链路状态的同步。泛洪即一个路由器向相邻路由器发送自己的LSP后，相邻路由器再将同样的LSP报文传送到除发送该LSP的路由器外的其它邻居，并这样逐级将LSP传送到整个层次内的一种方式。通过这种方式，整个层次内的每一个路由器就都可以拥有相同的LSP信息，并保持LSDB的同步。 配置接口发送LSP的最小时间间隔 控制LSP刷新时单个LSP之间的发送间隔。 减小发送LSP的最小时间间隔可以加快LSP的扩散速度。 配置LSP生成的智能定时器 智能控制LSP生成的频率，平衡提高收敛速度与减轻系统负荷之间的关系。 在运行IS-IS的网络中，当本地路由信息发生变化时，路由器需要产生新的LSP来通告这些变化。当本地路由信息的变化比较频繁时，立即生成新的LSP会占用大量的系统资源。为了加快网络的收敛速度，同时又不影响系统性能，通过配置LSP生成的智能定时器，该定时器可以根据路由信息的变化频率自动调整延迟时间。 配置LSP快速扩散 控制接口每次扩散LSP的数量，以便加快IS-IS网络的收敛速度。 当IS-IS收到其它路由器发来的LSP时，如果此LSP比本地LSDB中相应的LSP要新，则更新LSDB中的LSP，并用一个定时器定期将LSDB内已更新的LSP扩散出去。LSP快速扩散特性改进了这种方式，配置此特性的设备收到一个或多个比较新的LSP时，在路由计算之前，先将小于指定数目的LSP扩散出去，加快LSDB的同步过程。 配置点到点链路上的LSP重传时间间隔 控制LSP的重传间隔，保证点到点网络中LSDB的同步。 配置LSP的大小：123[isis] lsp-length &#123; originate | receive &#125; max-size//配置当前IS-IS路由器生成LSP报文的长度以及接收LSP报文的长度。//缺省情况下，IS-IS路由器生成的LSP报文和接收的LSP报文长度均为1497字节。 参数 参数说明 取值 originate 指定配置生成LSP报文的最大长度。 - receive 指定配置接收LSP报文的最大长度。 - max-size 指定LSP报文的最大长度。配置max-size参数时需注意，生成的LSP报文的max-size必须小于等于接收的LSP报文的max-size。 整数类型，取值范围是512～16384，单位是字节。缺省值是1497。说明： 由于目前接口支持的MTU最大值是9600字节，因此，为了实现两端的正常通信，LSP的报文最大长度允许的最大取值为9600–3=9597字节。 配置LSP的最大有效时间：123timer lsp-max-age age-time//配置当前IS-IS进程生成的LSP的最大有效时间。//缺省情况下，LSP的最大有效时间为1200秒。 配置LSP的刷新周期：123timer lsp-refresh refresh-time//配置LSP的刷新周期。//缺省情况下，LSP刷新周期的缺省值为900秒。 配置接口发送LSP的最小时间间隔：123isis timer lsp-throttle throttle-interval [ count count ]//来配置IS-IS接口发送LSP报文的最小间隔时间和此时间内发送的最大的报文数。//缺省情况下，接口上发送LSP报文的最小间隔时间是50毫秒，每次发送LSP报文的最大数目是10。 配置LSP生成的智能定时器：12timer lsp-generation max-interval [ init-interval [ incr-interval ] ] [ level-1 | level-2 ]//来配置LSP生成智能定时器。 参数 参数说明 取值 max-interval 指定产生LSP（这些LSP具有相同的LSP ID）的最大延迟时间。 整数类型，取值范围是1～120，单位是秒，缺省值为2。 init-interval 指定初次触发产生LSP的延迟时间。 整数类型，取值范围是1～60000，单位是毫秒。缺省情况下不使用这个延迟时间。 incr-interval 指定两次产生具有相同的LSP ID的LSP之间的递增延迟时间。 整数类型，取值范围是1～60000，单位是毫秒。缺省情况下不使用这个延迟时间。 level-1 指定产生Level-1 LSP的延迟时间。如果没有指定Level，则同时配置产生Level-1和Level-2 LSP的延迟时间。 - level-2 指定产生Level-2 LSP的延迟时间。如果没有指定Level，则同时配置产生Level-1和Level-2 LSP的延迟时间。 - 初次产生同一LSP（或者LSP分片）的延迟时间为init-interval；第二次产生同一LSP（或者LSP分片）的延迟时间为incr-interval。随后，每变化一次，延迟时间都增大为前一次的两倍，直到max-interval。稳定在max-interval三次或者IS-IS进程被重启，延迟时间又降回到init-interval。 在不使用incr-interval的情况下，初次产生同一LSP（或者LSP分片）仍然使用init-interval作为延迟时间，随后都是使用max-interval作为延迟时间。同样，稳定在max-interval三次或者IS-IS进程被重启，延迟时间又降回到init-interval。 在只使用max-interval的情况下，智能定时器退化为一般的一次性触发定时器。 配置LSP快速扩散：12flash-flood [ lsp-count | max-timer-interval interval | [ level-1 | level-2 ] ] *//使能LSP快速扩散特性，以便加快IS-IS网络的收敛速度。 参数 参数说明 取值 lsp-count 指定每个接口一次扩散LSP的最大数量。 整数形式，取值范围是1～15。缺省值是5。 max-timer-interval interval 指定LSP扩散的最大间隔时间。 整数形式，取值范围是10～50000，单位是毫秒。缺省值是10毫秒。 level-1 表示在Level-1中使能此特性。如果命令中没有指定级别，则缺省同时在Level-1和Level-2中使能此功能。 - level-2 表示在Level-2中使能此特性。如果命令中没有指定级别，则缺省同时在Level-1和Level-2中使能此功能。 - 配置点到点链路上LSP重传的时间间隔：1234567isis circuit-type p2p [ strict-snpa-check ]//将IS-IS广播网接口的网络类型模拟为P2P类型。//指定IS-IS对LSP和SNP报文的SNPA进行检查。 isis timer lsp-retransmit retransmit-interval//配置点到点链路上LSP报文的重传间隔时间。//缺省情况下，点到点链路上LSP报文的重传间隔时间为5秒。 配置CSNP报文属性：全序列号报文CSNP（Complete Sequence NumberPDUs）包括LSDB中所有LSP的摘要信息，可以保证相邻设备间LSDB的同步。在广播网链路和点到点链路中，运行机制略有不同： 在广播网链路上，CSNP由DIS设备周期性的发送。当邻居发现LSDB不同步时，发送PSNP报文来请求缺失的LSP报文。 在点到点链路上，CSNP只在第一次建立邻接关系时发送。 123isis timer csnp csnp-interval [ level-1 | level-2 ]//指定在广播网络上发送CSNP报文的间隔时间。//缺省情况下，在广播网络上发送CSNP报文的间隔时间是10秒。 调整SPF的计算时间：当网络变化比较频繁时，IS-IS会频繁的进行SPF计算。频繁的SPF计算会消耗系统大量的CPU资源，从而影响其他业务的运行。 配置智能定时器的优势在于当刚开始进行SPF计算时，两次计算的间隔时间较小，保证IS-IS路由的收敛速度。之后随着整个IS-IS网络的拓扑趋于稳定时，就可以适当的延长两次SPF计算的间隔时间，从而减少不必要的资源消耗。 1234567891011121314timer spf max-interval [ init-interval [ incr-interval ] ]//配置SPF路由计算的延迟时间。 //缺省情况下，SPF路由计算的最大延迟时间为5秒。 suppress-flapping route-calculate timer delay-interval [ threshold threshold-value ] //设置路由震荡时收到LSP后启动路由计算的抑制时间。 //缺省情况下，路由震荡情况下收到LSP后启动路由计算的抑制时间为10秒。 timer purge-zero-lsp route-calculate-delay delay-interval//设置收到Purge LSP报文后启动路由计算的抑制时间。//缺省情况下，收到Purge LSP报文后启动路由计算的抑制时间为10秒。spf-slice-size duration-time//配置IS-IS每次路由计算的最大持续时间。 参数 参数说明 取值 delay-interval 指定收到LSP后启动路由计算的抑制时间。 整数形式，取值范围是1～600，单位是秒。 threshold threshold-value 指定进入抑制状态的阈值。即路由震荡threshold-value次之后进入抑制状态。 整数形式，取值范围是3～100，单位是次。缺省情况下，LSP进入计算抑制的阈值默认为30次。 配置ISIS路由按优先级收敛：设备支持通过配置IS-IS路由的收敛优先级，可以使某些重要路由在网络拓扑发生变化时优先收敛。 123prefix-priority [ level-1 | level-2 ] &#123; critical | high | medium &#125; &#123; ip-prefix prefix-name | 配置IS-IS路由的收敛优先级。tag tag-value &#125;//配置IS-IS路由的收敛优先级。//缺省情况下，IS-IS主机路由和缺省路由的收敛优先级为medium，其他IS-IS路由的收敛优先级为low。 参数 参数说明 取值 level-1 指定Level-1级别的IS-IS路由的收敛优先级。 - level-2 指定Level-2级别的IS-IS路由的收敛优先级。 - critical 指定IS-IS路由的收敛优先级为critical。 - high 指定IS-IS路由的收敛优先级为high。 - medium 指定IS-IS路由的收敛优先级为medium。 - ip-prefix prefix-name 指定过滤路由的IP地址前缀名，为符合指定IP地址前缀的IS-IS路由配置收敛优先级。 字符串形式，区分大小写，不支持空格，长度范围是1～169。 tag tag-value 指定过滤路由的tag值，为带有指定tag值的IS-IS路由配置收敛优先级。如果使用tag值来过滤需配置收敛优先级的IPv4路由，要求发送报文的IS-IS的cost-style类型不是narrow且IS-IS路由必须带有tag值。 整数类型，取值范围是1～4294967295。 配置LSP分片扩展：通过配置LSP分片扩展，使运行IS-IS的设备生成多个LSP分片来发布信息，以便携带更多的IS-IS信息。 12345lsp-fragments-extend [ [ level-1 | level-2 | level-1-2 ] | [ mode-1 | mode-2 ] ] *//使能IS-IS路由器的LSP分片扩展功能。virtual-system virtual-system-id//配置IS-IS进程的虚拟系统ID。没有该ID，将不会生成扩展LSP。一个IS-IS进程最多可配置50个虚拟系统ID。 数 参数说明 取值 level-1 指定在Level-1级别使能分片扩展。 - level-2 指定在Level-2级别使能分片扩展。 - level-1-2 指定在Level-1-2级别使能分片扩展。 - mode-1 该模式可以兼容以前老版本不支持LSP分片扩展特性的情况。 - mode-2 该模式要求所有路由器都支持LSP分片扩展特性。说明： 缺省情况下，使用mode-1和level-1-2两个参数。 在NBMA网络中配置Mesh Group：通过在NBMA网络中配置Mesh Group，可以避免因LSP的重复扩散而造成的带宽浪费。 12isis mesh-group &#123; mesh-group-number | mesh-blocked &#125;//将IS-IS接口加入指定的mesh-group。 参数 参数说明 取值 mesh-group-number 指定mesh-group的组号。 整数形式，取值范围是1～4294967295。 mesh-blocked 设置该参数后，接口将被阻塞，不再向其它接口扩散收到的LSP。 配置过载位：12set-overload [ on-startup [ timeout1 | start-from-nbr system-id [ timeout1 [ timeout2 ] ] | wait-for-bgp [ timeout1 ] ] [ send-sa-bit [ timeout3 ] ] ] [ allow &#123; interlevel | external &#125;* ]//配置非伪节点LSP的过载标志位。 数 参数说明 取值 on-startup 表示路由器重启或者出现故障时，过载标志位在配置的时间内将保持被置位状态。 - timeout1 指定系统启动后维持过载标志位的时间。 取值范围是5～86400，单位是秒，缺省值是600秒。 start-from-nbr system-id 表示根据system ID指定的邻居的状态，配置系统保持过载标志位时长。 格式为XXXX.XXXX.XXXX。 timeout1 [ timeout2 ] 指定与邻居状态相关的过载标志位置位的时间。 如果指定的邻居在timeout2超时前没有正常Up，则系统过载标志位维持时间为timeout2。timeout2的取值范围是5～86400，单位是秒，缺省值为1200秒（20分钟）。如果指定的邻居在timeout2超时前正常Up，系统过载标志位将继续维持timeout1时长。timeout1的取值范围是5～86400，单位是秒，缺省值是600秒（10分钟）。 wait-for-bgp 表示根据BGP收敛的状态，设置系统保持过载标志位时长。 - send-sa-bit 设备重启后发送的Hello报文中携带SA Bit。 - timeout3 指定设备重启后发送的Hello报文中携带SA Bit的时间。 整数形式，取值范围是5～120，单位是秒。缺省值是30秒。 allow 表示允许发布地址前缀。缺省情况下，当系统进入过载状态时不允许发布地址前缀。 - interlevel 表示当配置allow时，允许发布从不同层次IS-IS学来的IP地址前缀。 - external 表示当配置allow时，允许发布从其它协议学来的IP地址前缀。 - #ISIS 其他常见配置命令： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667adjacency-strict-check enable//用来使能IS-IS的邻居严格检查功能circuit-cost &#123; cost | maximum &#125; [ level-1 | level-2 ]//配置进行SPF计算时所有IS-IS接口的链路开销值。circuit default-tag //配置指定IS-IS进程下所有接口的管理标记值。cost-style &#123; narrow | wide | wide-compatible | &#123; compatible | narrow-compatible &#125; [ relax-spf-limit ] &#125;//设置IS-IS设备接收和发送路由的开销类型。display default-parameter isis//查看IS-IS的缺省配置信息。display isis cost interface//查看接口的开销值及其具体来源。display isis error //查看接口或进程收到的错误LSP报文和Hello报文的统计信息。display isis graceful-restart status//查看IS-IS GR的状态信息。display isis last-peer-change//查看IS-IS的邻居变化信息。display isis migp-routing//显示IS-IS的MIGP（Multicast IGP）路由信息。display isis name-table//查看本地和远端IS-IS设备主机名到系统ID的映射关系表。display isis process-id peer [ verbose ] //查看IS-IS的邻居信息。display isis purge packet//查看IS-IS收到携带POI TLV的Purge LSP报文统计信息。display isis spf-log//查看IS-IS的SPF计算日志信息。display isis spf-tree//查看SPF树的拓扑信息。graceful-restart//使能IS-IS进程的GR功能。graceful-restart no-impact-holdtime//配置IS-IS邻居的Holdtime不受GR影响。graceful-restart interval interval-value//配置IS-IS GR过程中T3定时器的时间。//缺省情况下，GR T3定时器为300秒。graceful-restart t2-interval//缺省情况下，GR T2定时器为60秒。isis circuit-level [ level-1 | level-1-2 | level-2 ] //配置Level-1-2路由器的接口链路类型。isis dis-name//为DIS配置名称。isis dis-priority//指定挑选对应级别DIS时IS-IS接口的优先级。isis padding-hello//来配置IS-IS接口发送带有填充字段的标准Hello报文。isis small-hello//配置IS-IS接口发送不带有填充字段的Hello报文。isis peer-ip-ignore//配置对接收的Hello报文不作IP地址检查。isis ppp-negotiation &#123; 2-way | 3-way [ only ] &#125;//来指定在建立邻接关系时采用的PPP协商类型。isis silent [ advertise-zero-cost ]//配置IS-IS接口为抑制状态，即抑制该接口接收和发送IS-IS报文，但此接口所在网段的路由可以被发布出去。isis suppress-flapping peer//设置指定接口的IS-IS邻居震荡抑制的检测参数。isis suppress-flapping peer hold-down//设置Hold-down邻居震荡抑制模式和抑制持续时间。isis tag-value//配置IS-IS接口的管理标记值。lsp-fragments-extend//使能IS-IS路由器的LSP分片扩展功能。reset isis all//重启IS-IS进程。reset isis peer//重置与特定IS-IS的邻居关系。 IS-IS配置示例IS-IS综合实验示例：实验拓扑如下： 图：IS-IS综合实验拓扑图 实验要求：公司A网络如实验拓扑所示，请根据如下需求对网络进行部署： R1所属区域ID为49.0001，R2、R3、R4和R5所属区域ID为49.0002，R6所属区域ID为49.0006，各个设备的System ID为0000.0000.000X； 根据拓扑通告相应设备上的接口，R6的E1/0/0运行IS-IS协议，但是不会将任何IS-IS报文发往E1/0/0所连接网段，另外IS-IS区域需要学习到E1/0/0直连网段的地址； R1为Level-2层级设备，R2和R3为Level-1-2层级设备，R4和R5为接口级别的Level-1层级设备，R6为接口的Level-2层级设备； 由于使用System ID标识设备不便于网络维护，请通过合适命令以使用设备编号（设备编号即为R1，R2，R3等）进行标识； R4与R5之间不能出现DIS，并建立可靠的邻居关系； IS-IS可以自动计算Cost； 选择合适的认证模式对区域49.0002的LSP和SNP进行验证，验证密码HUAWEI，认证类型为MD5； 为了进一步提升R4和R5之间带宽的利用率，需要禁止R4与R5相互发送Hello使用填充字段； R4将直连网段4.0.X.0/24引入IS-IS且不需要聚合；R1将直连网段1.0.X.0/24引入IS-IS，并进行最优聚合，请使用最少命令； R2与R3禁止将4.0.0.0/24和4.0.2.0/24发布进区域49.0001，请使用ACL，禁用Route-policy；保证R4和R5能够学习到汇总之后网段1.0.X.0/24，禁用Route-policy； R6禁止将R1产生的汇总路由加入到路由表；但是当R1存在汇总之后网段1.0.X.0/24的路由信息时，需发布缺省路由。 配置文件：AR1：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[AR1]display current-configuration # sysname AR1#acl number 2000 rule 10 permit source 1.0.0.0 0.0.252.255 acl number 2001 rule 5 permit source 1.0.0.0 0.0.255.255 #isis 1 is-level level-2 cost-style wide auto-cost enable network-entity 49.0001.0000.0000.0001.00 is-name R1 import-route direct route-policy D2I default-route-advertise route-policy Default summary 1.0.0.0 255.255.252.0 avoid-feedback generate_null0_route#interface Serial4/0/0 link-protocol ppp ip address 12.1.1.1 255.255.255.0 isis enable 1#interface Serial4/0/1 link-protocol ppp ip address 13.1.1.1 255.255.255.0 isis enable 1#interface GigabitEthernet0/0/0 ip address 16.1.1.1 255.255.255.0 isis enable 1#interface LoopBack0 ip address 10.1.1.1 255.255.255.255 isis enable 1#interface LoopBack1 ip address 1.0.0.1 255.255.255.0 #interface LoopBack2 ip address 1.0.1.1 255.255.255.0 #interface LoopBack3 ip address 1.0.2.1 255.255.255.0 #interface LoopBack4 ip address 1.0.3.1 255.255.255.0 #route-policy D2I permit node 10 if-match acl 2000 #route-policy Default permit node 10 if-match acl 2001 #return AR2：1234567891011121314151617181920212223242526272829303132333435[AR2]dis current-configuration # sysname AR2#acl number 2000 rule 5 deny source 4.0.0.0 0.0.0.255 rule 10 deny source 4.0.2.0 0.0.0.255 rule 15 permit #isis 1 cost-style wide auto-cost enable //自动开销 network-entity 49.0002.0000.0000.0002.00 is-name R2 filter-policy 2000 import import-route isis level-2 into level-1 //路由渗透 area-authentication-mode md5 plain HUAWEI#interface Serial4/0/0 link-protocol ppp ip address 12.1.1.2 255.255.255.0 isis enable 1#interface Serial4/0/1 link-protocol ppp ip address 24.1.1.2 255.255.255.0 isis enable 1#interface LoopBack0 ip address 10.2.2.2 255.255.255.255 isis enable 1#return AR3：123456789101112131415161718192021222324252627282930313233&lt;AR3&gt;dis current-configuration # sysname AR3#acl number 2000 rule 5 deny source 4.0.0.0 0.0.0.255 rule 10 deny source 4.0.2.0 0.0.0.255 rule 15 permit #isis 1 cost-style wide auto-cost enable network-entity 49.0002.0000.0000.0002.00 is-name R3 filter-policy 2000 import import-route isis level-2 into level-1 area-authentication-mode md5 plain HUAWEI#interface Serial4/0/0 link-protocol ppp ip address 13.1.1.3 255.255.255.0 isis enable 1#interface Serial4/0/1 link-protocol ppp ip address 35.1.1.3 255.255.255.0 isis enable 1#interface LoopBack0 ip address 10.3.3.3 255.255.255.255 isis enable 1#return AR4;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[AR4]DIS current-configuration ]# sysname AR4#acl number 2000 rule 10 permit source 4.0.0.0 0.0.3.255 #isis 1 is-level level-1 cost-style wide auto-cost enable network-entity 49.0002.0000.0000.0004.00 is-name R4 import-route direct level-1 route-policy D2I area-authentication-mode md5 plain HUAWEI#interface Serial4/0/0 link-protocol ppp ip address 24.1.1.4 255.255.255.0 isis enable 1 isis circuit-level level-1#interface Serial4/0/1 link-protocol ppp#interface GigabitEthernet0/0/0 ip address 45.1.1.4 255.255.255.0 isis enable 1 isis circuit-type p2p isis circuit-level level-1 isis ppp-negotiation 3-way only isis small-hello #interface LoopBack0 ip address 10.4.4.4 255.255.255.255 isis enable 1 isis circuit-level level-1#interface LoopBack1 ip address 4.0.0.1 255.255.255.0 #interface LoopBack2 ip address 4.0.1.1 255.255.255.0 #interface LoopBack3 ip address 4.0.2.1 255.255.255.0 #interface LoopBack4 ip address 4.0.3.1 255.255.255.0 #route-policy D2I permit node 10 if-match acl 2000 #return AR5:1234567891011121314151617181920212223242526272829303132333435&lt;AR5&gt;dis current-configuration # sysname AR5#isis 1 is-level level-1 cost-style wide auto-cost enable network-entity 49.0002.0000.0000.0005.00 is-name R5 area-authentication-mode md5 plain HUAWEI#interface Serial4/0/0 link-protocol ppp ip address 35.1.1.5 255.255.255.0 isis enable 1 isis circuit-level level-1#interface Serial4/0/1 link-protocol ppp#interface GigabitEthernet0/0/0 ip address 45.1.1.5 255.255.255.0 isis enable 1 isis circuit-type p2p isis circuit-level level-1 isis ppp-negotiation 3-way only isis small-hello #interface LoopBack0 ip address 10.5.5.5 255.255.255.255 isis enable 1 isis circuit-level level-1#return AR6:1234567891011121314151617181920212223242526272829303132&lt;AR6&gt;dis current-configuration # sysname AR6#acl number 2000 rule 5 deny source 1.0.0.0 0.0.255.255 rule 10 permit #isis 1 cost-style wide auto-cost enable network-entity 49.0006.0000.0000.0006.00 is-name R6 filter-policy 2000 import #interface GigabitEthernet0/0/0 ip address 16.1.1.6 255.255.255.0 isis enable 1 isis circuit-level level-2#interface GigabitEthernet0/0/1 ip address 6.0.0.1 255.255.255.0 isis enable 1 isis silent isis circuit-level level-2#interface LoopBack0 ip address 10.6.6.6 255.255.255.255 isis enable 1 isis circuit-level level-2#return 配置结果： 图：AR1的路由表 图：AR6的路由表 图：AR4的ISIS的相关信息]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>ISIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ISIS基础知识]]></title>
    <url>%2F2018%2F01%2F08%2FISIS%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[ISIS简介中间系统到中间系统IS-IS（Intermediate System to Intermediate System）属于内部网关协议IGP（Interior Gateway Protocol），用于自治系统内部。IS-IS也是一种链路状态协议，使用最短路径优先SPF（Shortest Path First）算法进行路由计算。 目的：IS-IS是国际标准化组织ISO（the International Organization for Standardization）为它的无连接网络协议CLNP（ConnectionLess Network Protocol）设计的一种动态路由协议。 随着TCP/IP协议的流行，为了提供对IP路由的支持，IETF（Internet Engineering Task Force ）在RFC1195中对IS-IS进行了扩充和修改，使它能够同时应用在TCP/IP和OSI（Open System Interconnection）环境中，称为集成IS-IS（Integrated IS-IS或Dual IS-IS）。 IS-IS原理描述ISIS基本概念：IS-IS的拓扑结构：为了支持大规模的路由网络，IS-IS在自治系统内采用骨干区域与非骨干区域两级的分层结构。一般来说，将Level-1路由器部署在非骨干区域，Level-2路由器和Level-1-2路由器部署在骨干区域。每一个非骨干区域都通过Level-1-2路由器与骨干区域相连。 OSPF与ISIS的拓扑不同点： 在IS-IS中，每个路由器都只属于一个区域；而在OSPF中，一个路由器的不同接口可以属于不同的区域。 在IS-IS中，单个区域没有骨干与非骨干区域的概念；而在OSPF中，Area0被定义为骨干区域。 在IS-IS中，Level-1和Level-2级别的路由都采用SPF算法，分别生成最短路径树SPT（Shortest Path Tree）；而在OSPF中，只有在同一个区域内才使用SPF算法，区域之间的路由需要通过骨干区域来转发。 IS-IS路由器的分类： Level-1路由器 Level-1路由器负责区域内的路由，它只与属于同一区域的Level-1和Level-1-2路由器形成邻居关系，属于不同区域的Level-1路由器不能形成邻居关系。Level-1路由器只负责维护Level-1的链路状态数据库LSDB（Link State Database），该LSDB包含本区域的路由信息，到本区域外的报文转发给最近的Level-1-2路由器。 Level-2路由器 Level-2路由器负责区域间的路由，它可以与同一或者不同区域的Level-2路由器或者其它区域的Level-1-2路由器形成邻居关系。Level-2路由器维护一个Level-2的LSDB，该LSDB包含区域间的路由信息。 所有Level-2级别（即形成Level-2邻居关系）的路由器组成路由域的骨干网，负责在不同区域间通信。路由域中Level-2级别的路由器必须是物理连续的，以保证骨干网的连续性。只有Level-2级别的路由器才能直接与区域外的路由器交换数据报文或路由信息。 Level-1-2路由器 同时属于Level-1和Level-2的路由器称为Level-1-2路由器，它可以与同一区域的Level-1和Level-1-2路由器形成Level-1邻居关系，也可以与其他区域的Level-2和Level-1-2路由器形成Level-2的邻居关系。Level-1路由器必须通过Level-1-2路由器才能连接至其他区域。 Level-1-2路由器维护两个LSDB，Level-1的LSDB用于区域内路由，Level-2的LSDB用于区域间路由。 IS-IS的网络类型：IS-IS只支持两种类型的网络，根据物理链路不同可分为： 广播链路：如Ethernet、Token-Ring等。 点到点链路：如PPP、HDLC等。 对于NBMA（Non-Broadcast Multi-Access）网络，如ATM，需对其配置子接口，并注意子接口类型应配置为P2P。 IS-IS不能在点到多点链路P2MP（Point to MultiPoint）上运行。 DIS和伪节点：在广播网络中，IS-IS需要在所有的路由器中选举一个路由器作为DIS（Designated Intermediate System）。DIS用来创建和更新伪节点（Pseudonodes），并负责生成伪节点的链路状态协议数据单元LSP（Link state Protocol Data Unit），用来描述这个网络上有哪些网络设备。 伪节点是用来模拟广播网络的一个虚拟节点，并非真实的路由器。在IS-IS中，伪节点用DIS的System ID和一个字节的Circuit ID（非0值）标识。 Level-1和Level-2的DIS是分别选举的，用户可以为不同级别的DIS选举设置不同的优先级。DIS优先级数值最大的被选为DIS。如果优先级数值最大的路由器有多台，则其中MAC地址最大的路由器会被选中。不同级别的DIS可以是同一台路由器，也可以是不同的路由器。 IS-IS协议中DIS与OSPF协议中DR（Designated Router）的区别： 在IS-IS广播网中，优先级为0的路由器也参与DIS的选举，而在OSPF中优先级为0的路由器则不参与DR的选举。 在IS-IS广播网中，当有新的路由器加入，并符合成为DIS的条件时，这个路由器会被选中成为新的DIS，原有的伪节点被删除。此更改会引起一组新的LSP泛洪。而在OSPF中，当一台新路由器加入后，即使它的DR优先级值最大，也不会立即成为该网段中的DR。 在IS-IS广播网中，同一网段上的同一级别的路由器之间都会形成邻接关系，包括所有的非DIS路由器之间也会形成邻接关系。而在OSPF中，路由器只与DR和BDR建立邻接关系。 IS-IS广播网上所有的路由器之间都形成邻接关系，但LSDB的同步仍然依靠DIS来保证。 IS-IS的地址结构：网络服务访问点NSAP（Network Service Access Point）是OSI协议中用于定位资源的地址。NSAP的地址结构如下图所示，它由IDP（Initial Domain Part）和DSP（Domain Specific Part）组成。IDP和DSP的长度都是可变的，NSAP总厂最多是20个字节，最少8个字节。 图：ISIS协议的地址结构示意图 IDP相当于IP地址中的主网络号。它是由ISO规定，并由AFI（Authority and Format Identifier）与IDI（Initial Domain Identifier）两部分组成。AFI表示地址分配机构和地址格式，IDI用来标识域。 DSP相当于IP地址中的子网号和主机地址。它由High Order DSP、System ID和SEL三个部分组成。High Order DSP用来分割区域，System ID用来区分主机，SEL（NSAP Selector）用来指示服务类型。 Area Address IDP和DSP中的High Order DSP一起，既能够标识路由域，也能够标识路由域中的区域，因此，它们一起被称为区域地址（Area Address），相当于OSPF中的区域编号。同一Level-1区域内的所有路由器必须具有相同的区域地址，Level-2区域内的路由器可以具有不同的区域地址。 一般情况下，一个路由器只需要配置一个区域地址，且同一区域中所有节点的区域地址都要相同。为了支持区域的平滑合并、分割及转换，在设备的实现中，一个IS-IS进程下最多可配置3个区域地址。 System ID System ID用来在区域内唯一标识主机或路由器。在设备的实现中，它的长度固定为48bit（6字节）。 将IP地址168.10.1.1的每个十进制数都扩展为3位，不足3位的在前面补0，得到168.010.001.001。 将扩展后的地址分为3部分，每部分由4位数字组成，得到1680.1000.1001。重新组合的1680.1000.1001就是System ID。 实际System ID的指定可以有不同的方法，但要保证能够唯一标识主机或路由器。 SEL SEL的作用类似IP中的“协议标识符”，不同的传输协议对应不同的SEL。在IP上SEL均为00。 网络实体名称NET（Network Entity Title）指的是设备本身的网络层信息，可以看作是一类特殊的NSAP（SEL＝00）。NET的长度与NSAP的相同，最多为20个字节，最少为8个字节。在路由器上配置IS-IS时，只需要考虑NET即可，NSAP可不必去关注。 例如有NET为：ab.cdef.1234.5678.9abc.00，则其中Area Address为ab.cdef，System ID为1234.5678.9abc，SEL为00。 IS-IS基本原理：IS-IS是一种链路状态路由协议，每一台路由器都会生成一个LSP，它包含了该路由器所有使能IS-IS协议接口的链路状态信息。通过跟相邻设备建立IS-IS邻接关系，互相更新本地设备的LSDB，可以使得LSDB与整个IS-IS网络的其他设备的LSDB实现同步。然后根据LSDB运用SPF算法计算出IS-IS路由。如果此IS-IS路由是到目的地址的最优路由，则此路由会下发到IP路由表中，并指导报文的转发。 IS-IS邻居关系的建立：两台运行IS-IS的路由器在交互协议报文实现路由功能之前必须首先建立邻居关系。在不同类型的网络上，IS-IS的邻居建立方式并不相同。 广播链路邻居关系的建立：下图以Level-2路由器为例，描述了广播链路中建立邻接的过程。Level-1路由器之间建立邻居与此相同。 图：广播链路邻居关系的建立过程 RouterA广播发送Level-2 LAN IIH，此报文中无邻居标识。 RouterB收到此报文后，将自己和RouterA的邻居状态标识为Initial。然后，RouterB再向RouterA回复Level-2 LAN IIH，此报文中标识RouterA为RouterB的邻居。 RouterA收到此报文后，将自己与RouterB的邻居状态标识为Up。然后RouterA再向RouterB发送一个标识RouterB为RouterA邻居的Level-2 LAN IIH。 RouterB收到此报文后，将自己与RouterA的邻居状态标识为Up。这样，两个路由器成功建立了邻居关系。 因为是广播网络，需要选举DIS，所以在邻居关系建立后，路由器会等待两个Hello报文间隔，再进行DIS的选举。Hello报文中包含Priority字段，Priority值最大的将被选举为该广播网的DIS。若优先级相同，接口MAC地址较大的被选举为DIS。 P2P链路邻居关系的建立：在P2P链路上，邻居关系的建立不同于广播链路。分为两次握手机制和三次握手机制。 两次握手机制 只要路由器收到对端发来的Hello报文，就单方面宣布邻居为Up状态，建立邻居关系。 三次握手机制 此方式通过三次发送P2P的IS-IS Hello PDU最终建立起邻居关系，类似广播邻居关系的建立。 两次握手机制存在明显的缺陷。当路由器间存在两条及以上的链路时，如果某条链路上到达对端的单向状态为Down，而另一条链路同方向的状态为Up，路由器之间还是能建立起邻接关系。SPF在计算时会使用状态为UP的链路上的参数，这就导致没有检测到故障的路由器在转发报文时仍然试图通过状态为Down的链路。三次握手机制解决了上述不可靠点到点链路中存在的问题。这种方式下，路由器只有在知道邻居路由器也接收到它的报文时，才宣布邻居路由器处于Up状态，从而建立邻居关系。 IS-IS按如下原则建立邻居关系： 只有同一层次的相邻路由器才有可能成为邻居。 对于Level-1路由器来说，区域号必须一致。 链路两端IS-IS接口的网络类型必须一致。 链路两端IS-IS接口的地址必须处于同一网段。 由于IS-IS是直接运行在数据链路层上的协议，并且最早设计是给CLNP使用的，IS-IS邻居关系的形成与IP地址无关。但在实际的实现中，由于只在IP上运行IS-IS，所以是要检查对方的IP地址的。如果接口配置了从IP，那么只要双方有某个IP（主IP或者从IP）在同一网段，就能建立邻居，不一定要主IP相同。 当链路两端IS-IS接口的地址不在同一网段时，如果配置接口对接收的Hello报文不作IP地址检查，也可以建立邻居关系。对于P2P接口，可以配置接口忽略IP地址检查；对于以太网接口，需要将以太网接口模拟成P2P接口，然后才可以配置接口忽略IP地址检查。 IS-IS的LSP交互过程：LSP产生的原因：IS-IS路由域内的所有路由器都会产生LSP，以下事件会触发一个新的LSP： 邻居Up或Down IS-IS相关接口Up或Down 引入的IP路由发生变化 区域间的IP路由发生变化 接口被赋了新的metric值 周期性更新 收到邻居新的LSP的处理过程: 将接收的新的LSP合入到自己的LSDB数据库中，并标记为flooding。 发送新的LSP到除了收到该LSP的接口之外的接口。 邻居再扩散到其他邻居。 LSP的”泛洪”:LSP报文的“泛洪”（flooding）是指当一个路由器向相邻路由器通告自己的LSP后，相邻路由器再将同样的LSP报文传送到除发送该LSP的路由器外的其它邻居，并这样逐级将LSP传送到整个层次内所有路由器的一种方式。通过这种“泛洪”，整个层次内的每一个路由器就都可以拥有相同的LSP信息，并保持LSDB的同步。 每一个LSP都拥有一个标识自己的4字节的序列号。在路由器启动时所发送的第一个LSP报文中的序列号为1，以后当需要生成新的LSP时，新LSP的序列号在前一个LSP序列号的基础上加1。更高的序列号意味着更新的LSP。 广播链路中新加入路由器与DIS同步LSDB数据库的过程： 图：广播链路数据库更新过程 如上图所示，新加入的路由器RouterC首先发送Hello报文，与该广播域中的路由器建立邻居关系。 建立邻居关系之后，RouterC等待LSP刷新定时器超时，然后将自己的LSP发往组播地址（Level-1：01-80-C2-00-00-14；Level-2：01-80-C2-00-00-15）。这样网络上所有的邻居都将收到该LSP。 该网段中的DIS会把收到RouterC的LSP加入到LSDB中，并等待CSNP报文定时器超时并发送CSNP报文，进行该网络内的LSDB同步。 RouterC收到DIS发来的CSNP报文，对比自己的LSDB数据库，然后向DIS发送PSNP报文请求自己没有的LSP。 DIS收到该PSNP报文请求后向RouterC发送对应的LSP进行LSDB的同步。 在上述过程中DIS的LSDB更新过程如下： DIS接收到LSP，在数据库中搜索对应的记录。若没有该LSP，则将其加入数据库，并广播新数据库内容。 若收到的LSP序列号大于本地LSP的序列号，就替换为新报文，并广播新数据库内容；若收到的LSP序列号小本地LSP的序列号，就向入端接口发送本地LSP报文。 若收到的LSP和本地LSP的序列号相等，则比较Remaining Lifetime。若收到的LSP报文的Remaining Lifetime为0，则将本地的报文替换为新报文，并广播新数据库内容；若收到的LSP报文的Remaining Lifetime不为0而本地LSP报文的Remaining Lifetime为0，就向入端接口发送本地LSP报文。 若两个序列号和Remaining Lifetime都相等，则比较Checksum。若收到的LSP的Checksum大于本地LSP的Checksum，就替换为新报文，并广播新数据库内容；若收到的LSP的Checksum小于本地LSP的Checksum，就向入端接口发送本地LSP报文。 若两个序列号、Remaining Lifetime和Checksum都相等，则不转发该报文。 P2P链路上LSDB数据库同步过程： 图：P2P链路数据库更新过程 RouterA先与RouterB建立邻居关系。 建立邻居关系之后，RouterA与RouterB会先发送CSNP给对端设备。如果对端的LSDB与CSNP没有同步，则发送PSNP请求索取相应的LSP。 如上图所示假定RouterB向RouterA索取相应的LSP。RouterA发送RouterB请求的LSP的同时启动LSP重传定时器，并等待RouterB发送的PSNP作为收到LSP的确认。 如果在接口LSP重传定时器超时后，RouterA还没有收到RouterB发送的PSNP报文作为应答，则重新发送该LSP直至收到PSNP报文。 在P2P链路上PSNP有两种作用： 作为Ack应答以确认收到的LSP。 用来请求所需的LSP。 在P2P链路中设备的LSDB更新过程如下： 若收到的LSP比本地的序列号更小，则直接给对方发送本地的LSP，然后等待对方给自己一个PSNP报文作为确认；若收到的LSP比本地的序列号更大，则将这个新的LSP存入自己的LSDB，再通过一个PSNP报文来确认收到此LSP，最后再将这个新LSP发送给除了发送该LSP的邻居以外的邻居。 若收到的LSP序列号和本地相同，则比较Remaining Lifetime，若收到的LSP报文的Remaining Lifetime为0，则将收到的LSP存入LSDB中并发送PSNP报文来确认收到此LSP，然后将该LSP发送给除了发送该LSP的邻居以外的邻居；若收到的LSP报文的Remaining Lifetime不为0而本地LSP报文的Remaining Lifetime为0，则直接给对方发送本地的LSP，然后等待对方给自己一个PSNP报文作为确认。 若收到的LSP和本地LSP的序列号相同且Remaining Lifetime都不为0，则比较Checksum，若收到LSP的Checksum大于本地LSP的Checksum，则将收到的LSP存入LSDB中并发送PSNP报文来确认收到此LSP，然后将该LSP发送给除了发送该LSP的邻居以外的邻居；若收到LSP的Checksum小于本地LSP的Checksum，则直接给对方发送本地的LSP，然后等待对方给自己一个PSNP报文作为确认。 若收到的LSP和本地LSP的序列号、Remaining Lifetime和Checksum都相同，则不转发该报文。 #ISIS高级特性 IS-IS认证：IS-IS认证是基于网络安全性的要求而实现的一种认证手段，通过在IS-IS报文中增加认证字段对报文进行认证。当本地路由器接收到远端路由器发送过来的IS-IS报文，如果发现认证密码不匹配，则将收到的报文进行丢弃，达到自我保护的目的。 认证的分类：根据报文的种类，认证可以分为以下三类： 接口认证：是指使能IS-IS协议的接口以指定方式和密码对Level-1和Level-2的Hello报文进行认证。 区域认证：是指运行IS-IS的区域以指定方式和密码对Level-1的SNP和LSP报文进行认证。 路由域认证：是指运行IS-IS的路由域以指定方式和密码对Level-2的SNP和LSP报文进行认证。 对于接口认证，有以下两种设置： 发送带认证TLV的认证报文，本地对收到的报文也进行认证检查。 发送带认证TLV的认证报文，但是本地对收到的报文不进行认证检查。 对于区域和路由域认证，可以设置为SNP和LSP分开认证。 本地发送的LSP报文和SNP报文都携带认证TLV，对收到的LSP报文和SNP报文都进行认证检查。 本地发送的LSP报文携带认证TLV，对收到的LSP报文进行认证检查；发送的SNP报文携带认证TLV，但不对收到的SNP报文进行检查。 本地发送的LSP报文携带认证TLV，对收到的LSP报文进行认证检查；发送的SNP报文不携带认证TLV，也不对收到的SNP报文进行认证检查。 本地发送的LSP报文和SNP报文都携带认证TLV，对收到的LSP报文和SNP报文都不进行认证检查。 根据报文的认证方式，可以分为以下三类： 明文认证：一种简单的认证方式，将配置的密码直接加入报文中，这种认证方式安全性不够。 MD5认证：通过将配置的密码进行MD5算法之后再加入报文中，这样提高了密码的安全性。 Keychian认证：通过配置随时间变化的密码链表来进一步提升网络的安全性。 认证信息的携带形式：IS-IS通过TLV的形式携带认证信息，认证TLV的类型为10，具体格式如下： Type：ISO定义认证报文的类型值为10，长度为1字节。 Length：指定认证TLV值的长度，长度1字节。 Value：指定认证的具体内容，其中包括了认证的类型和认证的密码，长度为1～254字节。 其中认证的类型为1字节，具体定义如下： 0：保留的类型 1：明文认证 54：MD5认证 255：路由域私有认证方式 ISIS路由渗透：通常情况下，Level-1区域内的路由通过Level-1路由器进行管理。所有的Level-2和Level-1-2路由器构成一个连续的骨干区域。Level-1区域必须且只能与骨干区域相连，不同的Level-1区域之间并不相连。 Level-1-2路由器将学习到的Level-1路由信息装进Level-2 LSP，再泛洪LSP给其他Level-2和Level-1-2路由器。因此，Level-1-2和Level-2路由器知道整个IS-IS路由域的路由信息。但是，为了有效减小路由表的规模，在缺省情况下，Level-1-2路由器并不将自己知道的其他Level-1区域以及骨干区域的路由信息通报给它所在的Level-1区域。这样，Level-1路由器将不了解本区域以外的路由信息，可能导致与本区域之外的目的地址通信时无法选择最佳的路由。 为解决上述问题，IS-IS提供了路由渗透功能。通过在Level-1-2路由器上定义ACL（Access Control List）、路由策略、Tag标记等方式，将符合条件的路由筛选出来，实现将其他Level-1区域和骨干区域的部分路由信息通报给自己所在的Level-1区域。 ISIS Overload：IS-IS OverLoad使用IS-IS过载标记位来标识过载状态。IS-IS过载标志位是指IS-IS LSP报文中的OL字段。对设备设置过载标志位后，其它设备在进行SPF计算时不会使用这台设备做转发，只计算该设备上的直连路由。 当系统因为各种原因无法保存新的LSP，以致无法维持正常的LSDB同步时，该系统计算出的路由信息将出现错误。在这种情况下，系统就可以自动进入过载状态，即通过该设备到达的路由不计算，但该设备的直连路由不会被忽略。 除了设备异常可导致自动进入过载状态，也可以通过手动配置使系统进入过载状态。当网络中的某些IS-IS设备需要升级或维护时，需要暂时将该设备从网络中隔离。此时可以给该设备设置过载标志位，这样就可以避免其他设备通过该节点来转发流量。 ISIS网络收敛：为了提高IS-IS网络的收敛，有快速收敛和按优先级收敛两种方式。快速收敛侧重于从路由的计算角度加快收敛速度；按优先级收敛侧重于从路由优先级角度提高网络性能。 快速收敛：IS-IS快速收敛是为了提高路由的收敛速度而做的扩展特性。它包括以下几个功能： 增量最短路径优先算法I-SPF（Incremental SPF）：是指当网络拓扑改变的时候，只对受影响的节点进行路由计算，而不是对全部节点重新进行路由计算，从而加快了路由的计算。 在ISO10589中定义使用SPF算法进行路由计算。当网络拓扑中有一个节点发生变化时，这种算法需要重新计算网络中的所有节点，计算时间长，占用过多的CPU资源，影响整个网络的收敛速度。 I-SPF改进了这个算法，除了第一次计算时需要计算全部节点外，每次只计算受到影响的节点，而最后生成的最短路径树SPT与原来的算法所计算的结果相同，大大降低了CPU的占用率，提高了网络收敛速度。 部分路由计算PRC（Partial Route Calculation）：是指当网络上路由发生变化的时候，只对发生变化的路由进行重新计算。 PRC的原理与I-SPF相同，都是只对发生变化的路由进行重新计算。不同的是，PRC不需要计算节点路径，而是根据I-SPF算出来的SPT来更新路由。 在路由计算中，叶子代表路由，节点则代表路由器。如果I-SPF计算后的SPT改变，PRC会只处理那个变化的节点上的所有叶子；如果经过I-SPF计算后的SPT并没有变化，则PRC只处理变化的叶子信息。比如一个节点使能一个IS-IS接口，则整个网络拓扑的SPT是不变的，这时PRC只更新这个节点的接口路由，从而节省CPU占用率。 PRC和I-SPF配合使用可以将网络的收敛性能进一步提高，它是原始SPF算法的改进，已经代替了原有的算法。 智能定时器：在进行SPF计算和产生LSP的时候用到的一种智能定时器。该定时器首次超时时间是一个固定的时间。如果在定时器超时前，又有触发定时器的事件发生，则该定时器下一次的超时时间会增加。 改进了路由算法后，如果触发路由计算的时间间隔较长，同样会影响网络的收敛速度。使用毫秒级定时器可以缩短这个间隔时间，但如果网络变化比较频繁，又会造成过度占用CPU资源。SPF智能定时器既可以对少量的外界突发事件进行快速响应，又可以避免过度的占用CPU。通常情况下，一个正常运行的IS-IS网络是稳定的，发生大量的网络变动的几率很小，IS-IS不会频繁的进行路由计算，所以第一次触发的时间可以设置的非常短（毫秒级）。如果拓扑变化比较频繁，智能定时器会随着计算次数的增加，间隔时间也会逐渐延长，从而避免占用大量的CPU资源。 与SPF智能定时器类似的还有LSP生成智能定时器。在IS-IS协议中，当LSP生成定时器到期时，系统会根据当前拓扑重新生成一个自己的LSP。原有的实现机制是采用间隔时间固定的定时器，这样就不能同时满足快速收敛和低CPU占用率的需要。为此将LSP生成定时器也设计成智能定时器，使其可以对于突发事件（如接口Up/Down）快速响应，加快网络的收敛速度。同时，当网络变化频繁时，智能定时器的间隔时间会自动延长，避免过度占用CPU资源。 LSP快速扩散：此特性可以加快LSP的扩散速度。 正常情况下，当IS-IS收到其它路由器发来的LSP时，如果此LSP比本地LSDB中相应的LSP要新，则更新LSDB中的LSP，并用一个定时器定期将LSDB内已更新的LSP扩散出去。 LSP快速扩散特性改进了这种方式，使能了此特性的设备收到一个或多个较新的LSP时，在路由计算之前，先将小于指定数目的LSP扩散出去，加快LSDB的同步过程。这种方式在很大程度上可以提高整个网络的收敛速度。 按优先级收敛：IS-IS按优先级收敛是指在大量路由情况下，能够让某些特定的路由（例如匹配指定IP前缀的路由）优先收敛的一种技术。因此用户可以把和关键业务相关的路由配置成相对较高的优先级，使这些路由更快的收敛，从而使关键的业务收到的影响减小。通过对不同的路由配置不同的收敛优先级，达到重要的路由先收敛的目的，提高网络的可靠性。 ISIS管理标记：管理标记特性允许在IS-IS域中通过管理标记对IP地址前缀进行控制，可以达到简化管理。其用途包括控制不同级别和不同区域间的路由引入，以及在同一路由器上运行的IS-IS多实例。 管理标记值与某些属性相关联。当cost-sytle为wide、wide-compatible或compatible时，如果发布可达的IP地址前缀具有该属性，IS-IS会将管理标记加入到该前缀的IP可达信息TLV中。这样，管理标记就会随着前缀发布到整个路由域。 ISIS Wide Metric：在早期的ISO10589中，使能IS-IS协议的接口下最大只能配置值为63的开销值，此时认为IS-IS开销类型为narrow。但是在大型网络设计中，较小的度量范围不能满足实际需求。所以在RFC3784中规定，使能IS-IS协议的接口开销值可以扩展到16777215，IS-IS路由开销值可以达到4261412864，此时IS-IS的开销类型为wide。 narrow类型下使用的TLV： 128号TLV（IP Internal Reachability TLV）：用来携带路由域内的IS-IS路由信息。 130号TLV（IP External Reachability TLV）：用来携带路由域外的IS-IS路由信息。 2号TLV(IS Neighbors TLV)：用来携带邻居信息。 wide类型下使用的TLV： 135号TLV(Extended IP Reachability TLV)：用来替换原有的IP reachability TLV，携带IS-IS路由信息，它扩展了路由开销值的范围，并可以携带sub TLV。 22号TLV（IS Extended Neighbors TLV）：用来携带邻居信息。 不同开销类型接收和发送ISIS信息的类型详细列表： 开销类型 接收 发送 narrow narrow narrow narrow-compatible narrow&amp;wide narrow compatible narrow&amp;wide narrow&amp;wide wide-compatible narrow&amp;wide wide wide wide wide 当配置开销类型为compatible的时候，会按照narrow类型和wide类型分别发送一份信息。 wide类型下的IS-IS和narrow类型下的IS-IS不可实现互通。如果需要互通，就必须设置成一致的开销类型，让网络上所有路由器都可以接收其他路由器发的所有报文。 ISIS LSP分片扩展：当IS-IS要发布的链路状态协议数据报文PDU（Protocol Data Unit）中的信息量太大时，IS-IS路由器将会生成多个LSP分片，用来携带更多的IS-IS信息。 IS-IS LSP分片由LSP ID中的LSP Number字段进行标识，这个字段的长度是1字节。因此，一个IS-IS进程最多可产生256个LSP分片，携带的信息量有限。在RFC3786中规定，IS-IS可以配置虚拟的SystemID ，并生成虚拟IS-IS的LSP报文来携带路由等信息。 基本概念： 初始系统（Originating System）：初始系统是实际运行IS-IS协议的路由器。允许一个单独的IS-IS进程像多个虚拟路由器一样发布LSP，而“Originating System”指的是那个“真正”的IS-IS进程。 系统ID（Normal System-ID）：初始系统的系统ID。 虚拟系统（Virtual System）：由附加系统ID标识的系统，用来生成扩展LSP分片。这些分片在其LSP ID中携带附加系统ID。 附加系统ID（Additional System-ID）：虚拟系统的系统ID，由网络管理器统一分配。每个附加系统ID都允许生成256个扩展的LSP分片。 24号TLV（IS Alias ID TLV）：用来表示初始系统与虚拟系统的关系。 工作原理：在IS-IS中，每个系统ID都标识一个系统，每个系统都最多可生成256个LSP分片。通过增加附加系统ID，可以最多配置50个虚拟系统，从而使得IS-IS进程最多可生成13056个LSP分片。 使能分片扩展功能之后，如果存在由于报文装满而丢失的信息，系统会提醒重启IS-IS。重启之后，初始系统会尽最大能力装载路由信息，装不下的信息将放入虚拟系统的LSP中发送出去，并通过24号TLV来告知其他路由器此虚拟系统和自己的关系。 工作模式：IS-IS路由器可以在两种模式下运行LSP分片扩展特性： 模式一： 应用场景： 用于网络中的部分路由器不支持LSP分片扩展特性的情况。 工作原理： 虚拟系统参与路由SPF计算，初始系统发布的LSP中携带了到每个虚拟系统的链路信息。类似地，虚拟系统发布的LSP也包含到初始系统的链路信息。这样，在网络中虚拟系统看起来与初始系统相连的真实路由器是一样的。这种方式是为了兼容不支持分片扩展的老版本所做的一个过渡模式。在老版本中，IS-IS无法识别IS Alias IDTLV，所以虚拟系统的LSP必须表现的像一个普通IS-IS发出的报文。 注意事项： 虚拟系统的LSP中包含和原LSP中相同的区域地址和过载标志位。如果还有其它特性的TLV，也必须保持一致。虚拟系统所携带的邻居信息指向初始系统，metric为最大值减1；初始系统所携带的邻居信息指向虚拟系统，metric必须为0。这样就保证了其它路由器在进行路由计算的时候，虚拟系统一定会成为初始系统的下游节点。 模式二： 应用场景： 用于网络中所有路由器都支持LSP分片扩展特性的情况。 工作原理： 虚拟系统不参与路由SPF计算，网络中所有路由器都知道虚拟系统生成的LSP实际属于初始系统。在该模式下工作的IS-IS，可以识别IS Alias ID TLV的内容，并作为计算树和路由的依据。 注：无论在哪种方式下，初始系统和虚拟系统的LSP零分片中，都必须包含IS Alias ID TLV来表示初始系统是谁。 ISIS主机名映射：IS-IS主机名映射机制为运行IS-IS协议的设备提供了一种从主机名到System ID映射的服务，它包括动态主机名映射和静态主机名映射。动态主机名映射的优先级高于静态主机名映射。当两者同时存在时，由动态主机名代替静态主机名。 在没有使能主机名交换特性的运行IS-IS协议的设备上，查看IS-IS邻居和链路状态数据库等信息时，IS-IS域中的各设备都是用由12位十六进制数组成的System ID来表示的，例如：aaaa.eeee.1234。这种表示方法比较繁琐，而且易用性不好。主机名交换机制就是为了方便对IS-IS网络的维护和管理而引入的。 显示IS-IS邻居时，将IS-IS邻居的System ID替换为主机名。如果该邻居为DIS，则DIS的System ID也替换为该邻居的主机名。 显示IS-IS链路状态数据库中的LSP时，将LSP ID中的System ID替换为发布该LSP的设备的主机名。 显示IS-IS链路状态数据库的详细信息时，对于使能了动态主机名交换的设备发送的LSP报文会增加显示Host Name字段，而此字段显示内容中的System ID也将替换为发送此LSP的设备的动态主机名。 动态主机名映射：在使能了动态主机名映射的设备上，IS-IS动态主机名的信息在LSP中以137号TLV（Dynamic Hostname TLV）的形式发布给其他IS-IS设备。在其他设备上使用IS-IS相关显示命令查看IS-IS信息时，本地设备的System ID将被设置的主机名所代替，这样更直观，也更容易记忆。 动态主机名的TLV是可选的，它可以存在于LSP中的任何位置。其中TLV的value值不能为空。设备在发送LSP的时候可以决定是否携带该TLV，接收端的设备也可以决定是否忽略该TLV，或者提取该TLV的内容放在自己的映射表中。 静态主机映射：静态主机名映射是指在本地设备上对其他运行IS-IS协议的设备设置主机名与System ID的映射。静态主机名映射仅在本地设备生效，并不会通过LSP报文发送出去。 IS-IS扩展知识ISIS GR：IS-IS GR（Graceful Restart）是一种支持GR能力的高可靠性技术，可以实现数据的不间断转发。 设备发生主备倒换后，由于没有保存任何重启前的邻居信息，因此一开始发送的Hello报文中不包含邻居列表。此时邻居设备收到后，执行两次握手机制邻居关系检查，发现在重启设备的Hello报文的邻居列表中没有自己，这样邻居关系将会断掉。同时，邻居设备通过生成新的LSP报文，将拓扑变化的信息泛洪给区域内的其它设备。区域内的其他设备会基于新的链路状态数据库进行路由计算，从而造成路由中断或者路由环路。 IETF针对这种情况为IS-IS制定了GR规范（RFC3847），对保留FIB表和不保留FIB表的协议重启都进行了处理，避免协议重启带来的路由震荡和流量转发中断的现象。 基本概念：IS-IS GR过程由GR-Restarter和GR-Helper配合完成。 GR-Restarter：具备GR能力，且要进行GR的设备。 GR-Helper：具备GR能力，辅助GR设备完成GR功能的设备。GR-Restarter一定具有GR-Helper的能力。 为了实现GR，IS-IS引入211号TLV（Restart TLV）和T1、T2、T3三个定时器。 Restart TLV：Restart TLV是包含在IIH（IS-to-IS Hello PDUs）报文中的扩展部分。支持IS-IS GR能力的设备的所有IIH报文都包含Restart TLV。Restart TLV中携带了协议重启的一些参数。其报文格式如下图所示： 图：Restart TLV格式 报文字段解释如下： 字段名 长度 含义 Type 1字节 TLV的类型。值为211表示是Restart TLV。 Length 1字节 TLV值的长度。 RR 1比特 重启请求位（Restart Request）。设备发送的RR置位的Hello报文用于通告邻居自己发生Restarting/Starting，请求邻居保留当前的IS-IS邻接关系并返回CSNP报文。 RA 1比特 重启应答位（Restart Acknowledgement）。设备发送的RA置位的Hello报文用于通告邻居确认收到了RR置位的报文。 SA 1比特 抑制发布邻接关系位（Suppress adjacency advertisement）。用于发生Starting的设备请求邻居抑制与自己相关的邻居关系的广播，以避免路由黑洞。 Remaining Time 2字节 邻居保持邻接关系不重置的时间。长度是2字节，单位是秒。当RA置位时，这个值是必需的。 定时器：IS-IS的GR能力扩展中，引入了三个定时器，分别是T1、T2和T3。 T1定时器：如果GR Restarter已发送RR置位的IIH报文，但直到T1定时器超时还没有收到GR Helper的包含Restart TLV且RA置位的IIH报文的确认消息时，会重置T1定时器并继续发送包含Restart TLV的IIH报文。当收到确认报文或者T1定时器已超时3次时，取消T1定时器。T1定时器缺省设置为3秒。 使能了IS-IS GR特性的进程，在每个接口都会维护一个T1定时器。在Level-1-2路由器上，广播网接口为每个Level维护一个T1定时器。 T2定时器：GR Restarter从重启开始到本Level所有设备LSDB完成同步的时间。T2定时器是系统等待各层LSDB同步的最长时间，一般情况下为60秒。 Level-1和Level-2的LSDB各维护一个T2定时器。 T3定时器：GR Restarter成功完成GR所允许的最大时间。T3定时器的初始值为65535秒，但在收到邻居回应的RA置位的IIH报文后，取值会变为各个IIH报文的Remaining time字段值中的最小者。T3定时器超时表示GR失败。 整个系统维护一个T3定时器。 会话机制：为了以示区别，主备倒换和重启IS-IS进程触发的GR过程称为Restarting，FIB表保持不变。设备重启触发的GR过程称为Starting，进行FIB表更新。 下面分Restarting和Starting两种情况说明IS-IS GR的详细过程。 ISIS Restarting的过程： 图：IS-IS Restarting过程 GR Restarter进行协议重启后，GR Restarter进行如下操作： 启动T1、T2和T3定时器。 从所有接口发送包含Restart TLV的IIH报文，其中RR置位，RA和SA位清除。 GR Helper收到IIH报文以后，进行如下操作： GR Helper维持邻居关系，刷新当前的Holdtime。 回送一个包含Restart TLV的IIH报文（RR清除，RA置位，Remaining time是从现在到Holdtime超时的时间间隔）。 发送CSNP报文和所有LSP报文给GR Restarter。 在点到点链路上，邻居必须发送CSNP。 在广播链路上，是DIS的邻居才发送CSNP报文，如果重启的是DIS，则在LAN中的其它设备中选举一个临时的DIS。 如果邻居设备不具备GR Helper能力，就忽略Restart TLV，按正常的IS-IS过程处理，重置和GR Restarter的邻接关系。 GR Restarter接收到邻居的IIH回应报文（RR清除、RA置位），做如下处理： 把T3的当前值和报文中Remaining time比较，取其中较小者作为T3的值。 在接口收到确认报文和CSNP报文之后，取消该接口的T1定时器。 如果该接口没有收到确认报文和CSNP报文，T1会不停地重置，重发含Restart TLV的IIH报文。如果T1超时次数超过阈值，GR Restarter强制取消T1定时器，启动正常的IS-IS处理流程。 当GR Restarter所有接口上的T1定时器都取消，CSNP列表清空并且收集全所有的LSP报文后，可以认为和所有的邻居都完成了同步，取消T2定时器。 T2定时器被取消，表示本Level的LSDB已经同步。 如果是单Level系统，则直接触发SPF计算。 如果是Level-1-2系统，此时判断另一个Level的T2定时器是否也取消。如果两个Level的T2定时器都被取消，那么触发SPF计算，否则等待另一个Level的T2定时器超时。 各层的T2定时器都取消后，GR Restarter取消T3定时器，更新FIB表。GR Restarter可以重新生成各层的LSP并泛洪，在同步过程中收到的自己重启前生成的LSP此时也可以被删除。 至此，GR Restarter的IS-IS Restarting过程结束。 ISIS Starting过程：对于Starting设备，因为没有保留FIB表项，所以一方面希望在Starting之前和自己的邻接关系为“Up”的邻居重置和自己的邻接关系，同时希望邻居能在一段时间内抑制和自己的邻接关系的发布。其处理过程和Restarting不同，具体如下图所示： 图：IS-IS Starting过程 为每层LSDB的同步启动T2定时器。 从各个接口发送携带Restart TLV的IIH报文，其中RR位清除，SA位置位。 RR位清除表示是Starting完成。 SA位置位则表示希望邻居在收到SA位清除的IIH报文之前，一直抑制和自己的邻接关系的发布。 邻居收到携带Restart TLV的IIH报文，根据设备是否支持GR，进行如下处理。 支持GR 重新初始化邻接关系。 在发送的LSP中取消和GR Restarter邻接关系的描述，进行SPF计算时也不考虑和GR Restarter相连的链路，直到收到SA位清除的IIH为止。 不支持GR 邻居忽略Restart TLV，重置和GR Restarter之间的邻接关系。 回应一个不含Restart TLV的IIH报文，转入正常的IS-IS处理流程。这时不会抑制和GR Restarter的邻接关系的发布。在点到点链路上，还会发送一个CSNP报文。 邻接关系重新初始化之后，在每个接口上GR Restarter都和邻居重建邻接关系。当有一个邻接关系到达Up状态后，GR Restarter为该接口启动T1定时器。 在T1定时器超时之后，GR Restarter发送RR置位、SA置位的IIH报文。 邻居收到RR置位和SA置位的IIH报文后，发送一个RR清除、RA置位的IIH报文作为确认报文，并发送CSNP报文。 GR Restarter收到邻居的IIH确认报文和CSNP报文以后，取消T1定时器。 如果没有收到IIH报文或者CSNP报文，就不停重置T1定时器，重发RR置位、SA置位的IIH报文。如果T1超时次数超过阈值，GR Restarter强制取消T1定时器，进入正常的IS-IS处理流程完成LSDB同步。 GR Restarter收到Helper端的CSNP以后，开始同步LSDB。 本Level的LSDB同步完成后，GR Restarter取消T2定时器。 所有的T2定时器都取消以后，启动SPF计算，重新生成LSP，并泛洪。 至此，GR Restarter的IS-IS Starting过程完成。 IS-IS NSR（不间断路由）:在网络高速发展的今天，用户对数据、视频、语音等应用的需求日渐增多，运营商对IP网络的可靠性也提出了更高的需求。当网络中某个节点发生故障，或者维护过程中人为进行的主备倒换，都可能导致设备无法组建路由信息，导致流量丢失甚至网络瘫痪。部署NSR（Non-Stop Routing）能够解决上述问题，给用户的关键业务提供不间断转发的高可靠性保障。 IS-IS NSR特性通过IS-IS实时数据的主备间高度同步来保证主备倒换后备板能够快速接管原主控板的业务，使邻居不感知本设备故障。在主备倒换后，新主用主控板利用这些实时数据可以迅速地恢复协议，使邻居设备对主备倒换不感知。IS-IS NSR主要通过备份以下数据来实现： 配置数据：用户完成的所有配置，包括邻居信息，定时器参数信息及进程下的配置信息等。 动态数据：包括接口参数及状态、邻居、LSDB等信息。 IS-IS与BFD（双向转发检测）联动：通常情况下，IS-IS设定发送Hello报文的时间间隔为10秒，一般将宣告邻居Down掉的时间（即邻居的保持时间）配置为Hello报文间隔的3倍。若在相邻路由器失效时间内没有收到邻居发来的Hello报文，将会删除邻居。由此可见路由器能感知到邻居故障的时间最小为秒级。这样可能会出现在高速的网络环境中大量报文丢失的问题。 双向转发检测BFD（Bidirectional Forwarding Detection）能够提供轻负荷、快速（毫秒级）的通道故障检测，解决了IS-IS现有检测机制的不足的问题。使用BFD并不是代替IS-IS协议本身的Hello机制，而是配合IS-IS协议更快的发现邻接方面出现的故障，并及时通知IS-IS重新计算相关路由以便正确指导报文的转发。 IS-IS与BFD联动的实现方式 工作原理 区别 IS-IS与静态BFD联动 通过命令行手工配置BFD会话参数，包括了配置本地标识符和远端标识符等，然后手工下发BFD会话建立请求。 静态BFD的优点是可以人为控制，部署比较灵活，为了节省内存，同时又保证关键链路的可靠性，可以在某些指定链路部署BFD，而其他链路不部署。静态BFD的缺点在于建立和删除BFD会话时都需要手工触发，配置时缺乏灵活性。而且有可能造成人为的配置错误。例如，如果配置了错误的本地标识符或者远端标识符时，BFD会话将不能正常工作。 IS-IS与动态BFD联动 通过IS-IS动态创建BFD的会话，不再依靠手工配置。当BFD检测到故障的时候，通过路由管理通知IS-IS。IS-IS进行相应邻居Down处理，快速发布变化的LSP信息和进行增量路由计算，从而实现路由的快速收敛。 动态BFD比静态BFD更具有灵活性。动态BFD由路由协议动态触发BFD会话建立，避免了人为控制可能导致的配置错误，且配置比较简单，适用在全网需要配置BFD的情况。 IS-IS Auto FRR（快速重路由）：随着网络的不断发展，VoIP和在线视频等业务对实时性的要求越来越高，而IS-IS故障恢复需要经历“故障感知、LSP更新、LSP泛洪、路由计算和下发FIB”这几个过程才能让流量切换到新的链路上，因此故障恢复的时间远远超过了50ms（即用户感知流量中断的时间），不能满足此类网络业务的实时性要求。 IS-IS Auto FRR（Fast reroute）遵循RFC 5286（Basic Specification for IP Fast Reroute Loop-Free Alternates）协议，可为流量提供链路和节点的保护。IS-IS Auto FRR能够保证转发系统快速地响应这种故障事件并采取措施，尽快让业务流恢复正常。 通常情况下，通过将BFD会话与IS-IS Auto FRR进行绑定，可以使故障恢复时间降低到50ms以内。当BFD检测到接口链路故障后，BFD会话状态会变为Down并触发接口进行快速重路由，将流量从故障链路切换到备份链路上，从而达到流量保护的目的。 工作原理：IS-IS Auto FRR利用LFA（Loop-Free Alternates）算法预先计算好备份链路，并与主链路一起加入转发表。当网络出现故障时，IS-IS Auto FRR可以在控制平面路由收敛前将流量快速切换到备份链路上，保证流量不中断，从而达到保护流量的目的，因此极大的提高了IS-IS网络的可靠性。 LFA计算备份链路的基本思路是：以可提供备份链路的邻居为根节点，利用SPF算法计算出到目的节点的最短距离。然后，按照RFC5286规定计算出无环的备份链路。 IS-IS Auto FRR支持对需要加入IP路由表的备份路由进行过滤，通过过滤策略的备份路由才会加入到IP路由表，因此，用户可以更灵活的控制加入IP路由表的IS-IS备份路由。 IS-IS TE（流量工程）：传统的路由器选择最短的路径作为主路由，不考虑带宽等因素。这样，即使某条路径发生拥塞，也不会将流量切换到其他的路径上。MPLS TE（Multiprotocol Label Routering Traffic Engineering）解决网络拥塞问题有自己的优势。通过MPLS TE，用户可以精确地控制流量流经的路径，从而可以避开拥塞的节点。同时，MPLS TE在建立隧道的过程中，可以预留资源，保证服务质量。 为了保证服务的连续性，MPLS TE还引入路由备份和快速重路由的机制，可以在链路出现问题时及时进行切换。通过MPLS TE技术，服务提供商能够充分利用现有的网络资源，提供多样化的服务。同时可以优化网络资源，进行科学的网络管理。 MPLS TE为了实现上述目的，需要了解整个网络中所有路由器的TE配置信息，但是MPLS TE缺乏这样一个机制：每个路由器在整个网络中泛洪各自的TE信息，并完成整网TE信息的同步。这个机制恰恰是IS-IS路由协议的一个基本特性，MPLS TE需要借助IS-IS完成TE信息的发布和同步。 IS-IS TE是IS-IS为了支持MPLS TE而做的扩展，它遵循RFC5305和RFC4205中关于IS-IS部分扩展的规定，通过在IS-IS LSP报文中定义新的TLV的方式，携带该路由器MPLS TE的配置信息，通过LSP的泛洪同步，实现MPLS TE信息的泛洪和同步。IS-IS TE把所有LSP中携带的TE信息提取出来，传递给MPLS的CSPF（Constraint Shortest Path First）模块，用来计算隧道路径。IS-IS TE在MPLS TE的流程中扮演着“搬运工”的角色，IS-IS TE和MPLS TE、CSPF的关系可以用下图来概括： 图：MPLS TE、CSPF和IS-IS TE关系图 IS-IS TE新增TLV：IS-IS TE为了在LSP中携带TE信息，在RFC5305中新定义了如下四种TLV： Extended IS reachability TLV 此TLV用来替换IS reachability TLV，并采用sub TLV的形式扩展了原来的TLV格式。sub TLV在TLV中的实现方式与TLV在LSP中的实现方式相同。这些sub TLV用来携带配置在物理接口下的TE信息。 Traffic Engineering router ID TLV 此TLV type为134，包含了四字节的Router ID，在目前实现中就是MPLS LSR-ID。对于MPLS TE来说，Router ID用来唯一的标识一台路由器，它必须要和路由器一一对应。 Extended IP reachability TLV 此TLV用来替换IP reachability TLV，用来携带路由信息。扩展了路由开销值的范围（四个字节），并可以携带sub TLV。 Shared Risk Link Group TLV 此TLV type为138，用来携带共享风险链路组信息。每个共享链路信息为四字节的正整数值，该TLV可以携带多个共享链路信息。 Extended IS reachability TLV 已经定义的Sub TLV： | 名称 | 类型 | 长度（Byte） | 值 || ———————————- | —- | ——– | ———– || Administrative Group | 3 | 4 | 管理组 || IPv4 Interface Address | 6 | 4 | 本端IPv4接口地址 || IPv4 Neighbour Address | 8 | 4 | 邻居的IPv4接口地址 || Maximum Link Bandwidth | 9 | 4 | 最大链路带宽 || Maximum Reserved Link Bandwidth | 10 | 4 | 最大预留链路带宽 || Unreserved Bandwidth | 11 | 32 | 未预留带宽 || Traffic Engineering Default Metric | 18 | 3 | 流量工程缺省开销值 || Bandwidth Constraints sub-TLV | 22 | 36 | 带宽约束TLV | IS-IS TE工作流程：IS-IS TE主要有两个流程： 响应MPLS TE的配置消息流程 只有使能了MPLS TE，IS-IS TE特性才能运行。 根据MPLS TE的配置，更新IS-IS LSP报文中的TE信息。 将MPLS TE的配置传递给CSPF模块。 处理LSP中TE信息的流程 提取收到的IS-IS LSP报文中的TE信息，传递给CSPF模块。 IS-IS TE的典型应用是协助MPLS TE建立TE隧道。 IS-IS多实例和多进程：对于支持VPN（Virtual Private Network）的设备，IS-IS多实例是指在同一台路由器上，可以配置多个VPN实例与多个IS-IS进程相关联。IS-IS多进程指在同一个VPN下（或者同在公网下）可以创建多个IS-IS进程，每个进程之间互不影响，彼此独立。不同进程之间的路由交互相当于不同路由协议之间的路由交互。 每个IS-IS进程都可以绑定一个指定的VPN实例，其典型应用就是在VPN场景中PE和CE之间运行IS-IS协议，同时VPN骨干网上的IGP也采用IS-IS。那么，在PE上这两个IS-IS进程互不影响。 IS-IS多进程共用同一个RM路由表。而IS-IS多实例使用VPN中的RM路由表，并且每个VPN都有自己单独的RM路由表。 IS-IS多进程允许为一个指定的IS-IS进程关联一组接口，从而保证该进程进行的所有协议操作都仅限于这一组接口。这样，就可以实现一台路由器有多个IS-IS协议进程，每个进程负责唯一的一组接口。 IS-IS进程在创建时可以选择绑定一个VPN实例，于是这个IS-IS进程就与此VPN实例相关联，并且只接收和处理此VPN实例内的事件。当VPN实例删除时，IS-IS进程也会跟着被删除。 IS-IS邻居震荡抑制：IS-IS邻居震荡抑制功能是一种震荡抑制方式，通过延迟邻居建立或调整链路开销为最大值的方法达到抑制震荡的目的。 产生原因：如果承载IS-IS业务的接口状态在Up和Down之间切换，就会引起邻居状态的频繁震荡。此时，IS-IS会快速发送Hello报文重新建立邻居，同步数据库LSDB，触发路由计算，会造成大量报文交互，影响现有邻居的稳定性，对IS-IS业务造成较大影响，同时也会影响依赖IS-IS的其他业务（如：LDP、BGP）的正常运行。为了解决这个问题，IS-IS实现了邻居震荡抑制功能，即在邻居频繁震荡时，启动震荡抑制，实现邻居延迟建立，或实现业务流量延迟经过频繁震荡的链路，达到抑制震荡的目的。 相关概念： flapping_event：震荡事件，接口上最后一次邻居状态由Up切换为Init或Down，称之为flapping_event。flapping_event作为震荡源输入，用来触发震荡检测机制启动工作。 flapping_count：当前震荡次数。 detect-interval：震荡检测间隔，用于判断是否触发一次有效震荡事件。 threshold：震荡抑制阈值，有效震荡事件触发累计超过该值时，进入震荡抑制阶段。 resume-interval：恢复间隔，连续两次有效震荡事件超过该值时，退出震荡抑制阶段。 实现原理：震荡检测 IS-IS接口启动一个flapping_count计数器，相邻两次flapping_event产生时间的间隔在detect-interval之内，记为一次有效震荡事件。flapping_count计数加1，当flapping_count计数大于threshold时，系统判定震荡发生，需要进入震荡抑制阶段。进入震荡抑制阶段后，flapping_count清0。在flapping_count大于threshold之前，如果两次flapping_event的间隔大于resume-interval，则flapping_count清0。邻居震荡抑制从最后一次邻居状态变为Init或Down开始计时。 用户可以通过命令行配置detect-interval，threshold，resume-interval三个震荡检测的关键参数。 震荡抑制 震荡抑制分为Hold-down和Hold-max-cost两种模式： Hold-down模式：针对邻居建立过程中的频繁泛洪和拓扑变化的问题，在一段时间内禁止该邻居重新建立，避免频繁的数据库同步和大量的报文交互。 Hold-max-cost模式：针对用户业务流量频繁切换的问题，在一段时间内将链路开销值设置为最大值Max-cost（IS-IS Wide模式的Max-cost=16777214，IS-IS Narrow模式的Max-cost=63），避免用户的业务流量经过频繁震荡的链路。 Hold-down模式和Hold-max-cost模式可以叠加使用，同时生效时，先进入Hold-down模式，待Hold-down模式退出后，再进入Hold-max-cost模式。 缺省情况下，IS-IS使能Hold-max-cost模式，用户可以通过命令行修改震荡抑制方案和震荡抑制周期。 接口进入震荡抑制阶段后，接口下的全部邻居都会进入震荡抑制阶段。 退出震荡抑制 退出震荡抑制有以下几种方式： 抑制定时器超时。 复位IS-IS进程。 用户通过命令行强制退出震荡抑制状态。 通过连续发送三个携带特殊信息的Hello报文（Padding TLV携带一个特殊的Sub TLV=251），通知对端设备强制退出震荡抑制状态。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>ISIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ISIS学习笔记]]></title>
    <url>%2F2018%2F01%2F05%2FISIS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[关于System ID： 一个中间系统（路由器）至少有一个NET（最多可有254个），默认最多3个。 同一AREA中间系统必须有相同的area ID（level-2， level-2）。 每个中间系统在一个area中必须有一个唯一的System ID。 一个域中的两个Level-2中的系统不同有相同的System ID。 NSA至少为8个字节，最多20个字节。 对于IP应用程序而言，1字节定义的AFI（标识二进制DSP语法的地址域），最少2字节定义实际区域信息，6字节定义系统ID和1字节的NSEL，故SNAP地址最少为10字节。 IS-IS整体拓扑：为了支持大规模的路由网络，IS-IS在自治系统内采用骨干区域与非骨干区域两级分层结构。一般来说，将level-1路由器部署在非骨干区域，level-2路由器和Level-1-2路由器部署在骨干区域。每一个非骨干区域都通过level-1-2路由器与骨干区域相连。 IS-IS中选举DIS是为了减少LSP在网络中的通告次数，避免带宽浪费。 ISIS中DIS的特点： ISIS中只有DIS而没有备份的DIS。同时DIS可以被抢占。原因是ISIS中所有的路由器之间都可以建立邻接关系。并且DIS设备的hello报文是每隔10/3秒发送次，在华为中是3秒发送一次，holdtime时间是9秒，可以更快的发送DIS故障，重新选举DIS。非DIS设备每隔10s发送一次IIH，holdtime为30s。 Level-1和Level-2分开选举DIS。 如何选举DIS？ 比较优先级，优先级越大越优。默认优先级为64，在ISIS中如果将优先级设置为0，同样可以参加选举。 如果优先级一样，需要比较MAC地址，MAC地址越大越优。 影响ISIS邻居建立的条件？ 区域ID不一致。（只会影响level-1） 网络类型不一致。 运行级别不一致。（注：在华为中如果系统级别和接口电路级别不同，以系统级别为准。） 修改接口级别主要用在以下两种场景： 只向该网段发送和接收L1或者L2的报文。 只将该接口的路由宣告进L1或L2。 （系统级别包含接口级别） level-1 和 level-2 无法建立。 levle-1和level-1 （需保证区域ID一致） level-1 和level-1-2 （需保证区域ID一致） level-2 和level-2 （level-2的邻居建立不会检查区域ID） level-2 和level-1-2 (level-2的邻居建立不会检查区域ID) level-1-2 和level-1-2 。（可以建立level-1的关系，但需保证区域ID一致。可以建立level-2的关系，不检测区域ID） 接口认证不一致。 注：在ISIS中如果收到报文中携带本地不识别的TLV，可以忽略并透传给其他邻居。 接口认证：会影响邻接的建立。 区域认证：不会影响邻接的建立，但会影响L1区域的SNP和LSP报文的接收。 域的认证：不会影响邻接的建立，但会影响L2区域的SNP和LSP报文的接收。 MTU不一致。（ISIS中存在隐式的MTU检测机制通过IIH报文） 广播网：1497：在广播网中发送的所有的IIH报文都会按出接口的MTU值进行填充。 点到点:1500：在点到点网络中建立邻接关系之前发送的IIH报文长度会按出接口的MTU值进行填充。建立邻接关系以后不填充，发送正常的IIH报文。 配置： interface gi0/0/0 mtu 1100 \接口下修改MTU为1100 isis 1 is-level level-2 cost-style wide lsp-length originate 1097\修改后同时需修改进程下的LSP的长度，长度要小于等于计算后的MTU值。 在接口在可通过配置isis small-hello，可以建立邻接关系。通过这种方式关闭MTU隐是检测。 system-id长度不一致。（默认是6个字节） max area数量不一致。（默认是3个） system id冲突（只限于直连设备） 多拓扑。（接口下既可以支持IPv6，也可以支持IPv4 ）（思科中会有影响，华为默认会在TlV中携带多拓扑信息，不影响。） IP地址不在同一个网段（ISIS在广播网中是开启源检查的，并且不能关闭。P2P也是默认开启，但是 可以关闭） ISIS支持的网络类型：只支持广播和点到点，不支持非广播，如果想支持非广播，需要改为点到点。 ISIS具体的报文： Hello PDU （IIH）用于建立和维护邻居关系 level-1 Lan IIH（01-80-C2-00-00-14） level-2 Lan IIH （01-80-C2-00-00-15） P2P IIH LSP PDU用于交换链路状态信息 Level-1 LSP Levle-2 LSP SNP PDU用于维护LSDB的完整与同步，且为摘要信息 CSNP： Level-1 CSNP Levle-2 CSNP CSNP： Level-1 CSNP Levle-2 CSNP ​ 广播网中邻接建立过程：在广播网中采用的是可靠的邻接建立过程，如果在接收的IIH报文中看到了自己接口的MAC地址，说明邻接已经收到并确认了自己发送的IIH报文。那么本地维护邻居的状态变为UP状态。 在广播网中通过IS邻居TLV携带邻居接口MAC地址的方式保证邻居建立的可靠性。 在点到点网络中邻接建立的过程：（2Way和3way的过程）2Way是属于两次握手，没有可靠性保证。只要收到邻接发送的IIH报文，并检测通过，维护邻居的状态为UP状态。 3Way是属于三次握手，在点到点网络中使用3way的方式保证邻接建立的可靠性。新增一种TLV，点到点邻居状态TLV。 点到点邻居状态TLV中包含四个参数： state：本地当前维护邻居的状态。 本地接口扩展电路ID（4B） 邻居的System ID 邻接接口的扩展电路ID(4b) 注：在华为中默认是3way的建立过程。 扩展电路ID:4B. ISIS LSP交互过程广播网中LSP的交互过程： 所有设备之间建立邻接关系。 向组播地址通告自己的LSP，Level-1的组播地址01-80-C2-00-00-14,level-2的组播地址：01-80-C2-00-00-15。 由DIS收集LSP，并每隔10s发送一次CSNP，在CSNP报文中通告DIS设备中LSDB中所有LSP的摘要信息（LSP头部信息）。 其他设备收到DIS发送的CNSP报文后，需要查看在CNSP报文中是否包含自己的LSP，如果包含说明DIS收到了自己发送的LSP。如果没有需要重传。同时，还需要将CSNP中的摘要信息和本地的LSDB做对比，查看本地去缺少哪些LSP，后续通过PSNP报文向DIS请求自己缺少的LSP。 DIS收到PSNP报文后回复PSNP报文中请求的LSP。 注：上述过程中所有的报文都是以组播方式交互。 如何在广播网中保证LSP报文交互的可靠性：通过DIS每隔10s发送一次CSNP报文。 点到点中LSP的交互过程： 首先建立邻接关系。 开始互相发送CSNP，在CSNP报文中包含本地LSBD中所有LSP的摘要信息。 收到邻居发送的CSNP报文，需要将CSNP报文中的LSP摘要信息和自己的LSDB做对比，查看缺少的LSP，并通过PSNP报文请求缺少的LSP。 收到PSNP请求后，回复LSP报文。 收到LSP报文后回复PSNP确认接收到的LSP。 注：在点到点网络中PSNP报文有两个作用，请求和确认。 在OSPF中收到LSA后，先给邻居发送LSA，后进行SPF计算。 在ISIS中收到LSP后，小进行SPF计算，后给邻居发送LSP。 SSN/SRM标志：发送序列号/发送路由管理 都是基于发送、接收LSP的接口设置。用于LSP完整性、可靠性的保证。 P2P链路： SSN标志：用于P2P链路接收方，在收到一个LSP时设置，在完成PSNP确认时清除。 SRM标志：用于P2P链路发送方，在发送一个LSP时设置，在收到其PSNP确认时清除。 广播网链路： SSN标志：用于广播网链路数据库同步过程中，请求完整的LSP。 SRM标志：用于广播网链路发送方，在发送一个LSP时设置，但在LSP传送出去后被立即清除，因为广播链路不需要PSNP确认。 LSP的老化处理：ISIS的LSP最大老化时间为1200s（20分钟），通告间隔时间为900s（15分钟）。在ISIS中LSP是通过剩余老化时间来维护的（倒计时），如果LSP的剩余老化时间为0，说明该LSP需要被清除。如果LSP的剩余老化时间为0，需要再等待60s（零老化时间）后将LSP删除。 在ISIS中如何判断LSP的新旧： 需要比较序列号。序列号越大越新。 如果序列号一样，比较看LSP的剩余老化时间是否为0,。如为0，LSP为最新。 如果LSP的剩余老化时间不为0，则认为一致。 华为的比较方法： 若收到的LSP比本地的序列号更小，则直接给对方发送本地的LSP，然后等待对方给自己一个PSNP报文作为确认。若收到的LSP比本地的序列号大更大，则将这个新的LSP存入自己的LSDB，再通过一个PSNP报文来确认收到此LSP，最后再将这个新的LSP发送个除了发送该LSP的邻居以外的邻居。 若收到的LSP序列号和本地相同，则比较Remaining Lifetime，若收到LSP的剩余老化时间小于本地LSP的剩余老化时间，则将收到的LSP存入LSDB中并发送PSNP报文来确认收到此LSP，然后将该LSP发送给LSP的邻居以外的邻居。若收到LSP的剩余老化时间大于本地的。则直接发送给对方本地的LSP，然后等待对方给自己一个PSNP报文作为确认。 若收到的LSP和本地LSP的序列号和Remaining Lifetime都相同，则比较Checksum，若收到LSP的Checksum大于本地LSP的Checksum，则将收到的LSP存入LSDB中并发送PSNP报文俩确认收到此LSP。然后将该LSP发送给LSP的邻居以外的邻居。若收到LSP的Checksum小于本地LSP的Checksum，则直接发送给对方本地的LSP，然后等待对方给自己一个PSNP报文作为确认。 若收到的LSP和本地LSP的序列号，Remaining Lifetime和Checksum都相同，则不转发该报文。 ISIS LSDB是由几部分组成的？ 图：ISIS LSDB 0000.0000.000 是system id。 00是伪节点ID部分。如果位00表示是标准的LSP，标准的LSP每台ISIS路由器都会通告，如果为非0值，说明是伪节点的LSP，伪节点LSP只有DIS才会通告。（* 部分表示是本地产生的LSP。） -00是LSP的分片部分。标准分片：默认最多可以分256片（00-255）。00是首部分片，在00片中包含所有协议的TLV头部，而其他分片只有通告数据。如果接收过程中00片丢失，那么后续的分片都会被丢弃。 ATT:区域边界标识位 P：分段区域修复位（用于虚链路，但是各厂商均不支持。该比特位只有在L2 LSP才会被置位） OL：overload过载位：如果邻居通告的LSP中OL位置位，那么需要通告该邻居到达的目的路由，都不会再该邻居做计算。但是该邻居通告的直连路由，还可以做计算（需要经过该邻居转发的路由不再做计算，但是该邻居始发的路由还可以做计算）。 OL位的设置有两种方式： 自动设置：内存不足。 协议联动（ISIS over BGP）。 手动设置。（用于流量的割接） 路由渗透：Level1-2路由器手动将Level 2层级路由渗透到level 1层，可以避免level 1路由器路由次优路由。 在ISIS中Level-1区域的设备需要通过默认路由访问骨干区域，并且默认路由不是由Level1/2的设备通告的，而是由Level-1区域中的设备自动生成的。 Level-1区域的设备什么情况下会生成一条默认路由？ 收到的Level-1的LSP中ATT位置位，就需要生成该设备的默认路由。 如果区域中存在多条Level-1的LSP中ATT位置位，则生成一条离自己最近的设备的默认路由。 只有Level1-2的设备才会通告ATT位置1的Level1的LSP。 什么情况下Level1-2的设备才会通告一条ATT置位的Level1的LSP？ Level1/2的设备在骨干区域（level2）中存在活动的邻接关系。 骨干区域的区域ID不能和Level1/2的区域ID一样。 ISIS的度量值类型：窄度量： 通过一个字节的长度，表示度量值。在这一个字节中，前两个比特位用于标志位。后面的六个bit表示度量值。 第一bit：up、dowm比特位，如果为0，代表Up，如果为1，代表down。主要目的是用于防环。如果收到的路由条目中down比特位置位，该路由不能被通告会level2的区域。 第二个bit ：标识路由类型。（internal/external），如果为0，表示内部路由（internal），如果为1，表示外部路由（external）。 窄度量中同时还划分了四种度量值，分别为： 默认度量。（目前只有这个在使用） 延迟度量。 差错度量。 开销度量。 窄度量中接口下可以配置的最大度量值为63，转发路径上度量值之和最大为1024.如果在窄度量的环境中收到的路由条目的度量值大于1024，则该路由不选路。 ISIS中度量值的配置方式： 默认值为10. 手动设置。 宽度量（4B）：宽度量：接口COST = （bandwidth-reference/接口带宽）* 10； 窄度量：根据接口带宽范围有固定的cost值。 想要支持IPv6的话必须使用宽度量。 22TLV（3B）扩展的IS可达性 135TLV（4B）扩展的IP可达性 注：如果设备两端的度量类型不一致，无法计算路由。 什么场景下需要用到wide metric(宽度量)？ 支持IPv6 携带Tag 支持MPLS-TE cost值范围不够用 ISIS的认证方式： 接口认证： 只对Level-1和level-2的Hello报文进行认证。 区域认证（area）： 对Level-1的SNP和LSP报文进行认证。 路由域认证（domain）： 对Level-2的SNP和LSP报文进行认证。 认证方式： 明文认证 MD5 在负载是影响选路的配置weight： nexthope命令用来设置等价路由的优先级。 在IS-IS根据SPF算法算出等价路由后，再根据weight的权重从这些等价路由中选择下一跳，值越小越优。 nexthop ip-address weight value value值范围：1-254。缺省值255.]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>ISIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一元多项式的表示及相加]]></title>
    <url>%2F2018%2F01%2F02%2F%E4%B8%80%E5%85%83%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%8F%8A%E7%9B%B8%E5%8A%A0%2F</url>
    <content type="text"><![CDATA[一元多项式的表示及相加设计目的与要求题目与设计要求我们设计的程序为一元多项式的表示及相加，这是使用C++语言写成。我们使用计算机处理的对象之间通常存在着的是一种最简单的线性关系，这类数学模型可称为线性的数据结构。而数据存储结构有两种：顺序存储结构和链式存储结构。线性表是最常用且最简单的一种数据结构。所以我们做的是———–一元多项式的表示及相加，其过程其实是对线性标的操作。实验结构和链接存储结构上的运算以及熟练运用掌握的线性表的操作，实现一元n次多项式的目的是掌握线性表的基本操作，插入、删除、查找，以及线性表合并等运算在顺序存储的加法运算。学习实现一元n次多项式的加法是符号多项式的操作，是表处理的典型用例，需要注意的是：顺序存储结构指的是用数组方法，使用数组方法实现时，在插入和删除的方面，数组不如链表灵活，方法复杂，删除其中一个需要将其后的数组元素改变位置，使其数组保持原有的顺序结构，在查找方面较链表简单，只需要知道其下标就可以知道。链接存储结构指的是用链表方法,值得注意的是，删除和插入较为灵活，不需要变动大多数元素，但是查找过程相对于数组这种顺序存储结构来说较为复杂，耗时巨大。在这里我们在一元多项式的表示与相加实验中，采用的是链式存储结构。 我们程序的任务是： 实现一元多项式：Rn(x)=Pn(x)+Qn(x) 本程序涉及的知识点1If语句 switch语句 for循坏 do…while循坏 指针 结构体 函数的套用 线性表的操作 线性表链式存储结构 对内存空间的开辟与释放 功能设计总体设计我们需要实现的功能是一元多项式的表示及相加。但在实现一元多项式的过程中，主要是通过对链表的操作来完成的。所以，这里还实现的对链式线性表的基本操作。例如，插入、删除、查找等。对于一元多项式，需要实现一元多项式的创建，同时可以打印出一元多项式，可以对两个多项式进行加法运算。 详细设计（1）项目工程文件规划： 在这个项目中，我设计使用三个头文件，和一个cpp源文件。以下为各个文件的主要作用： Base.h： 这个头文件中主要用来存放一些项目需要的头文件和公用的常量和类型。并且一元多项式的存储结构也放在这里。 LinkList.h： 这个头文件为链表头文件，其中主要包含了链式线性表的存储结构和链式线性表的各函数具体实现代码。在这个头文件中实现的方法有：InitList(); MakeNode(); FreeNode();InsFirst(); GetHead(); SetCurElem(); LocateElemP(); NextPos(); GetCurElem(); DelFirst();ListEmpty(); Append(); ListTraverse(); Polynomial.h： 这个头文件是一元多项式头文件，其中主要包含了一元多项式的基本操作的各种方法的实现代码。在这个头文件中实现的方法有：CreatPolyn(); DestroyPolyn(); PolynLength(); PrintPolyn(); AddPolyn(); Main.cpp: 这是一个cpp源文件，也是程序测试文件。它的功能主要是对一元多项式方法的测试，检测所需功能是否完成。 （2）程序存储结构的设计： 链表存储结构： 12345678910//----------链表的存储结构表示------------typedef struct LNode&#123;//节点类型 ElemType data;//这里表示了每一项，其指数和系数 struct LNode *next;&#125;*Link,*Position;typedef struct&#123;//链表类型 Link head, tail;//分别指向线性链表中的头结点和最后一个结点 int len;//指示线性链表中数据元素的个数&#125;LinkList;//每一项组成一个列表 一元多项式存储结构： 123456//---------------一元多项式存储结构表示-----------typedef struct&#123;//项的表示，多项式的项作为LinkList的数据元素 float coef;//系数 int expn;//指数&#125;term, ElemType;//两个类型：term用于本ADT，ElemType为LinkList的数据对象名typedef LinkList polynomial; 一元多项式其实就是通过链式线性表来存放。通过对线性表的操作进而实现对一元多项式的操作。 程序主要方法的实现创建多项式的实现：这是一元多项式程序中主要一个方法，通过它来创建一元多项式。在这个函数中首先会要求传入需要创建几项多项式。然后会通过循环输入每项的系数和指数来生成多项式。其实也就是生成一个按指数升序的链表，以方便后面做一元多项式的加法运算。 在创建一元多项式中，考虑到了用户输入数据的多种情况：每种情况都做了相应的输入策略，每次在插入一个数据项时，首先都会查找是否存在该指数项。如果不存在，然后判断系数是否为0.如果为0，不添加，进行下一次循环。如果不为0，则正常添加一个节点。这个结点是在升序链表中找到适合的位置进入插入，而不是随便添加结点。如果在添加查找该指数时，发现该指数项已经存在，则在原来该指数项的系数上添加上该系数。如果添加后系数等于0.则删除该结点。不为0，则正常进入下一次循环，添加其他数据项。 以下为此函数具体实现代码： 12345678910111213141516171819202122232425262728void CreatPolyn(polynomial &amp;p,int m)&#123; //输入m项的系数和指数，建立表示一元多项式的有序链表P InitList(&amp;p);//初始化-多项式链表 Link h = GetHead(p);//设置头结点的数据元素 ElemType e;//头结点设置 Position q,s; e.coef = 0.0; e.expn = -1; SetCurElem(h, e);//设置头结点的元素 for (int i = 1; i &lt;= m; ++i)//依次输入m个非零项 &#123; cout &lt;&lt; "第"&lt;&lt;i&lt;&lt;"项的系数:"; cin &gt;&gt; e.coef; cout &lt;&lt; "第" &lt;&lt; i &lt;&lt; "项的指数:"; cin &gt;&gt; e.expn; if (!LocateElemP(p, e,&amp;q, cmp))//当前链表中不存在该指数项 &#123; if (e.coef != 0)//不等于才插入 if (MakeNode(&amp;s, e)) InsFirst(&amp;p,q,s);//生成结点并插入链表 &#125; else//当前链表中存在该指数项,增加其系数 &#123; q-&gt;data.coef = q-&gt;data.coef + e.coef; //如果合起来等于0，则删除掉 if (q-&gt;data.coef == 0) Remove_Polyn(&amp;p, q);//删除掉当前节点 &#125; &#125;&#125;//CreatPolyn 一元多项式相加的具体实现：在一元多项式相加的函数中。首先会要求传入两个已经创建好的一元多项式PA，PB，然后进行相加，实现PA=PA+PB的功能。 程序执行过程：只有在Pa和Pb都不为空的时候程序才会进行循环，因为一元多项式以链式线性表以指数升序存储。所以每次进入循环都会首先比较Pa和Pb中的需要比较的qa和qb中指数的大小。如果qa的指数小，则会ha和qa指针都后移，继续比较。如果qa和qb的指数相等，则会把qa和qb的系数进行相加并赋值给qa的系数。从而实现相同指数的系数相加，加完后将qb所指结点删除，同时qa后qb指针都后移。如果qa的指数比qb大，则把qb所在的结点链接到qa的前面。qb指针继续后移。进行循环。这是就这个加法的具体实现过程。在最后，如果qa已经为空，而qb不为空，则把qb剩下的结点都直接链接在PA的最后。释放hb的头结点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051void AddPolyn(polynomial &amp;Pa, polynomial &amp;Pb)&#123; //多项式加法:Pa = Pa+Pb,利用两个多项式的结点构成“和多项式” Position ha, hb, qa, qb; term a, b; ha = GetHead(Pa); hb = GetHead(Pb);//ha和hb分别指向Pa和Pb的头结点 qa = NextPos(ha); qb = NextPos(hb);//qa和qb分别指向Pa和Pb中的当前结点 //此时qa和qb都是指向多项式第一项 while (qa &amp;&amp; qb)//qa和qb非空 &#123; a = GetCurElem(qa); b = GetCurElem(qb); // a和b为两表中当前比较元素 float sum; switch (cmp(a, b))//比较两者的指数值 &#123; case -1://多项式中PA中的结点的指数小 ha = qa; qa = NextPos(ha); break; case 0://两者指数值相等 sum = a.coef + b.coef; if (sum != 0) &#123; //修改pa指向的该结点的系数值 qa-&gt;data.coef = sum; //下一个 ha = qa; &#125; else &#123; //删除结点 DelFirst(&amp;Pa, ha, &amp;qa); FreeNode(&amp;qa); &#125; DelFirst(&amp;Pb, hb, &amp;qb);//也删除掉qb的结点 FreeNode(&amp;qb);//释放qb的空间 //都往后移动一位 qb = NextPos(hb); qa = NextPos(ha); break; case 1://多项式PB中的当前结点指数值小 DelFirst(&amp;Pb, hb, &amp;qb);//把当前结点从PB中删除，并用qb指向当前结点用以插入 InsFirst(&amp;Pa, ha, qb);//插入在ha前 qb = NextPos(hb); qa = NextPos(ha); break; &#125;//switch &#125;//while if (!ListEmpty(Pb)) Append(&amp;Pa, qb);//连接Pb中剩余结点 FreeNode(&amp;hb);//释放Pb的头结点&#125;//AddPolyn 打印多项式的具体实现:在这个函数，主要调用了ListTraverse()，即对链表进行遍历。通过循环，输出每个结点的数据。循环的次数为一元多项式这个链表的项数。每次输出数据时，调用visit(()函数，在visit函数中，我对输入的各种可能系数和指数进行了情况输出。如果系数为1，则不输出系数。如果系数和指数为负数，则会输出括号，在括号内输出负数。如果指数为1，则不输出指数。如果指数为0，则该项为常数，只输出系数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152void PrintPolyn(polynomialp)&#123; //打印出一元多项式 ListTraverse(p, visit);&#125;Status ListTraverse(LinkList L, void(*visit)(ElemType))&#123; // 依次对L的每个数据元素调用函数visit()。一旦visit()失败，则操作失败 Link p = L.head-&gt;next; int j; for (j = 1; j &lt;= L.len; j++) &#123; visit(p-&gt;data); p = p-&gt;next; &#125; cout &lt;&lt; "\b "; //退格，每次输出多项式后删掉的最后输出的"+" if (L.len == 0) cout &lt;&lt; "0"; return OK;&#125;//ListTraversevoid visit(ElemType e)&#123; if (e.coef &gt; 0 &amp;&amp; e.coef != 1 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; e.coef &lt;&lt; "x+"; else if (e.expn &gt; 0) cout &lt;&lt; e.coef &lt;&lt; "x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; e.coef &lt;&lt; "x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.coef &lt; 0 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; "(" &lt;&lt;e.coef &lt;&lt; ")x+"; else if (e.expn &gt; 0) cout &lt;&lt; "(" &lt;&lt; e.coef &lt;&lt; ")x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; "(" &lt;&lt; e.coef &lt;&lt; ")x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.coef == 1 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; "x+"; else if (e.expn &gt; 0) cout &lt;&lt; "x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; "x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.expn == 0 &amp;&amp; e.coef != 0) cout &lt;&lt; e.coef&lt;&lt;"+"; else cout &lt;&lt; "";//考虑用户输入可能有系数为0的情况&#125;//visit 程序测试结果这里对程序使用了三组数据进行测试： 第一组测试：第一组测试数据为指数和系数都是正整数的情况。例：PA=3+4x+3x^2 +4x^4; PB=4+6x^2 +3x^4 +3x^5;求PA=PA+PB。如下图4.1: 图4.1：第一组测试结果 第二组测试：第二组测试数据为指系数和指数中都有负数的情况。有负数时，会在负数上加上括号来显示。例：PA=-5x^(-2) +4-3x^2 +4x^3; PB=3x^(-3) +3x^2 -4x^3; 求PA=PA+PB；测试结果如下图4.2： 图4.2：第二组测试结果 第三组测试：第三组测试数据为：系数中存在0的情况，和指数中存在1的情况。系数中存在0，在程序执行过程中会自动删除该项。指数为1的时候，该多项式不会显示指数项。例：PA=4+0x^3 +4x^4 -3x^5; PB=3+x^1 +3x^3 +4x^5; 求PA=PA+PB；测试结果如下图4.3： 图4.3：第三组测试结果 总结：在做这个程序过程中，我遇到过很多问题，比如有时候调试可以通过，然而程序却不能正确执行，总会出错。这种情况只能去仔细检查对应代码的逻辑是否有错误。把可能出现的情况去修改，然后慢慢去调试。通过这样的反复调试，我感觉对线性链表的知识理解更加深刻。同时，对写代码也有了很多练习，写的代码更规范，更简洁。在这个实验过程中，也与我的小组队员进行了多次讨论，让我们懂得了团队合作的重要性。通过小组讨论，使我对一些模糊不清的地方了解透彻，同时小组其他成员也都理解了相应的知识。最后，通过这个实验，使我对链式线性表可以很熟练的去运用。同时，对一元多项式的简单操作也有了清晰的认识。只有经常进行编程练习，我们的编程能力才能得到有效提高。 全部代码：base.h123456789101112131415161718192021//base.h//----常用的头文件--------#include &lt;iostream&gt;using namespace std;#include &lt;malloc.h&gt;//-----公用的常量和类型----------#define OK 1#define ERROR 0#define OVERFLOW -2#define TRUE 1#define FALSE 0typedef int Status;//---------一元多项式存储结构表示----------typedef struct&#123;//项的表示，多项式的项作为LinkList的数据元素 float coef;//系数 int expn;//指数&#125;term, ElemType;//两个类型：term用于本ADT，ElemType为LinkList的数据对象名 LinkList.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186//LinkList.h//链式表的基本函数实现//----------链表的存储结构表示------------typedef struct LNode&#123;//节点类型 ElemType data;//这里表示了每一项，其指数和系数 struct LNode *next;&#125;*Link,*Position;typedef struct&#123;//链表类型 Link head, tail;//分别指向线性链表中的头结点和最后一个结点 int len;//指示线性链表中数据元素的个数&#125;LinkList;//每一项组成一个列表//----------链表函数的具体实现代码-----------Status InitList(LinkList *L)&#123; // 构造一个空的线性链表 Link p; p = (Link)malloc(sizeof(LNode)); // 生成头结点 if (p) &#123; p-&gt;next = NULL; (*L).head = (*L).tail = p; (*L).len = 0; return OK; &#125; else return ERROR;//内存分配不够&#125;//InitListStatus MakeNode(Link *p, ElemType e)&#123; // 分配由p指向的值为e的结点，并返回OK；若分配失败。则返回ERROR *p = (Link)malloc(sizeof(LNode)); if (!*p) return ERROR; (*p)-&gt;data = e; return OK;&#125;//MakeNodevoid FreeNode(Link *p)&#123; // 释放p所指结点 free(*p); *p = NULL;&#125;//FreeNodeStatus InsFirst(LinkList *L, Link h, Link s)&#123; // h指向L的一个结点，把h当做头结点，将s所指结点插入在第一个结点之前 s-&gt;next = h-&gt;next; h-&gt;next = s; if (h == (*L).tail) // h指向尾结点 (*L).tail = h-&gt;next; // 修改尾指针 (*L).len++; return OK;&#125;//InsFirstPosition GetHead(LinkList L)&#123; // 返回线性链表L中头结点的位置 return L.head;&#125;//GetHeadStatus SetCurElem(Link p, ElemType e)&#123; // 已知p指向线性链表中的一个结点，用e更新p所指结点中数据元素的值 p-&gt;data = e; return OK;&#125;//SetCurElemStatus LocateElemP(LinkList L, ElemType e, Position *q, int(*compare)(ElemType, ElemType))&#123; // 若升序链表L中存在与e满足判定函数compare()取值为0的元素，则q指示L中 // 第一个值为e的结点的位置，并返回TRUE；否则q指示第一个与e满足判定函数 // compare()取值&gt;0的元素的前驱的位置。并返回FALSE。（用于一元多项式） Link p = L.head, pp; do &#123; pp = p; p = p-&gt;next; &#125; while (p &amp;&amp; (compare(p-&gt;data, e)&lt;0)); // 没到表尾且p-&gt;data.expn&lt;e.expn if (!p || compare(p-&gt;data, e)&gt;0) // 到表尾或compare(p-&gt;data,e)&gt;0 &#123; *q = pp; return FALSE; &#125; else // 找到 &#123;// 没到表尾且p-&gt;data.expn=e.expn *q = p; return TRUE; &#125;&#125;//LocateElemPPosition NextPos(Link p)&#123; // 已知p指向线性链表L中的一个结点，返回p所指结点的直接后继的位置 // 若无后继，则返回NULL return p-&gt;next;&#125;//NextPosElemType GetCurElem(Link p)&#123; // 已知p指向线性链表中的一个结点，返回p所指结点中数据元素的值 return p-&gt;data;&#125;//GetCurElemStatus DelFirst(LinkList *L, Link h, Link *q)&#123; // 形参增加L,因为需修改L // h指向L的一个结点，把h当做头结点，删除链表中的第一个结点并以q返回。 // 若链表为空(h指向尾结点)，q=NULL，返回FALSE *q = h-&gt;next; if (*q) // 链表非空 &#123; h-&gt;next = (*q)-&gt;next; if (!h-&gt;next) // 删除尾结点 (*L).tail = h; // 修改尾指针 (*L).len--; return OK; &#125; else return FALSE; // 链表空&#125;//DelFirstStatus ListEmpty(LinkList L)&#123; // 若线性链表L为空表，则返回TRUE，否则返回FALSE if (L.len) return FALSE; else return TRUE;&#125;//ListEmptyStatus Append(LinkList *L, Link s)&#123; // 将指针s(s-&gt;data为第一个数据元素)所指(彼此以指针相链,以NULL结尾)的 // 一串结点链接在线性链表L的最后一个结点之后,并改变链表L的尾指针指向新 // 的尾结点 int i = 1; (*L).tail-&gt;next = s; while (s-&gt;next) &#123; s = s-&gt;next; i++; &#125; (*L).tail = s; (*L).len += i; return OK;&#125;//AppendStatus ListTraverse(LinkList L, void(*visit)(ElemType))&#123; // 依次对L的每个数据元素调用函数visit()。一旦visit()失败，则操作失败 Link p = L.head-&gt;next; int j; for (j = 1; j &lt;= L.len; j++) &#123; visit(p-&gt;data); p = p-&gt;next; &#125; cout &lt;&lt; "\b "; //退格，每次输出多项式后删掉的最后输出的"+" if (L.len == 0) cout &lt;&lt; "0"; return OK;&#125;//ListTraversevoid visit(ElemType e)&#123; if (e.coef &gt; 0 &amp;&amp; e.coef != 1 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; e.coef &lt;&lt; "x+"; else if (e.expn &gt; 0) cout &lt;&lt; e.coef &lt;&lt; "x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; e.coef &lt;&lt; "x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.coef &lt; 0 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; "(" &lt;&lt;e.coef &lt;&lt; ")x+"; else if (e.expn &gt; 0) cout &lt;&lt; "(" &lt;&lt; e.coef &lt;&lt; ")x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; "(" &lt;&lt; e.coef &lt;&lt; ")x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.coef == 1 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; "x+"; else if (e.expn &gt; 0) cout &lt;&lt; "x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; "x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.expn == 0 &amp;&amp; e.coef != 0) cout &lt;&lt; e.coef&lt;&lt;"+"; else cout &lt;&lt; "";//考虑用户输入可能有系数为0的情况&#125;//visit Polynomial.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136//Polynomial.h//一元多项式基本操作头文件typedef LinkList polynomial;Status Remove_Polyn(LinkList *L, Link q)&#123; //由于项的指数为0，删除掉已有的项 Link h; h = L-&gt;head; while (h-&gt;next != q) &#123; h = h-&gt;next; &#125; //找到了 if (q == L-&gt;tail) &#123;//删除的如果是表尾，改变表尾 L-&gt;tail = h; &#125; h-&gt;next = q-&gt;next; free(q); L-&gt;len--; return OK;&#125;//Remove_Polynint cmp(term a, term b)&#123;// CreatPolyn()的实参 // 依a的指数值&lt;、=或&gt;b的指数值，分别返回-1、0或+1 if (a.expn == b.expn) return 0; else if(a.expn &gt; b.expn) return 1; else return -1;&#125;//cmpvoid CreatPolyn(polynomial &amp;p,int m)&#123; //输入m项的系数和指数，建立表示一元多项式的有序链表P InitList(&amp;p);//初始化-多项式链表 Link h = GetHead(p);//设置头结点的数据元素 ElemType e;//头结点设置 Position q,s; e.coef = 0.0; e.expn = -1; SetCurElem(h, e);//设置头结点的元素 for (int i = 1; i &lt;= m; ++i)//依次输入m个非零项 &#123; cout &lt;&lt; "第"&lt;&lt;i&lt;&lt;"项的系数:"; cin &gt;&gt; e.coef; cout &lt;&lt; "第" &lt;&lt; i &lt;&lt; "项的指数:"; cin &gt;&gt; e.expn; if (!LocateElemP(p, e,&amp;q, cmp))//当前链表中不存在该指数项 &#123; if (e.coef != 0)//不等于才插入 if (MakeNode(&amp;s, e)) InsFirst(&amp;p,q,s);//生成结点并插入链表 &#125; else//当前链表中存在该指数项,增加其系数 &#123; q-&gt;data.coef = q-&gt;data.coef + e.coef; //如果合起来等于0，则删除掉 if (q-&gt;data.coef == 0) Remove_Polyn(&amp;p, q);//删除掉当前节点 &#125; &#125;&#125;//CreatPolynvoid DestroyPolyn(polynomial &amp;p)&#123; //销毁一元多项式 Link h,s; h = p.head; while(h)&#123; s = h; h = h-&gt;next; FreeNode(&amp;s); &#125; p.head = p.tail = NULL;&#125;//DestroyPolynint PolynLength(polynomial p)&#123; //返回一元多项式的长度 return p.len;&#125;//PolynLengthvoid PrintPolyn(polynomial p)&#123; //打印出一元多项式 ListTraverse(p, visit);&#125;void AddPolyn(polynomial &amp;Pa, polynomial &amp;Pb)&#123; //多项式加法:Pa = Pa+Pb,利用两个多项式的结点构成“和多项式” Position ha, hb, qa, qb; term a, b; ha = GetHead(Pa); hb = GetHead(Pb);//ha和hb分别指向Pa和Pb的头结点 qa = NextPos(ha); qb = NextPos(hb);//qa和qb分别指向Pa和Pb中的当前结点 //此时qa和qb都是指向多项式第一项 while (qa &amp;&amp; qb)//qa和qb非空 &#123; a = GetCurElem(qa); b = GetCurElem(qb); // a和b为两表中当前比较元素 float sum; switch (cmp(a, b))//比较两者的指数值 &#123; case -1://多项式中PA中的结点的指数小 ha = qa; qa = NextPos(ha); break; case 0://两者指数值相等 sum = a.coef + b.coef; if (sum != 0) &#123; //修改pa指向的该结点的系数值 qa-&gt;data.coef = sum; //下一个 ha = qa; &#125; else &#123; //删除结点 DelFirst(&amp;Pa, ha, &amp;qa); FreeNode(&amp;qa); &#125; DelFirst(&amp;Pb, hb, &amp;qb);//也删除掉qb的结点 FreeNode(&amp;qb);//释放qb的空间 //都往后移动一位 qb = NextPos(hb); qa = NextPos(ha); break; case 1://多项式PB中的当前结点指数值小 DelFirst(&amp;Pb, hb, &amp;qb);//把当前结点从PB中删除，并用qb指向当前结点用以插入 InsFirst(&amp;Pa, ha, qb);//插入在ha前 qb = NextPos(hb); qa = NextPos(ha); break; &#125;//switch &#125;//while if (!ListEmpty(Pb)) Append(&amp;Pa, qb);//连接Pb中剩余结点 FreeNode(&amp;hb);//释放Pb的头结点&#125;//AddPolyn Main.cpp1234567891011121314151617181920212223242526272829303132333435363738394041#include "base.h"#include "LinkList.h"#include "Polynomial.h"int main()&#123; cout&lt;&lt;"***************************************************************"&lt;&lt;endl; cout&lt;&lt;"** **"&lt;&lt;endl; cout&lt;&lt;"** 数据结构课程设计 **"&lt;&lt;endl; cout&lt;&lt;"** 课程题目：一元多项式的表示及相加 **"&lt;&lt;endl; cout&lt;&lt;"** 作者：曹世宏 **"&lt;&lt;endl; cout&lt;&lt;"** **"&lt;&lt;endl; cout&lt;&lt;"***************************************************************"&lt;&lt;endl; polynomial A, B; cout &lt;&lt; "请输入第一个多项式的项数为："; int length; //一元多项式项数 cin &gt;&gt; length; CreatPolyn(A, length); //显示A出来 cout &lt;&lt; "PA(x) = "; PrintPolyn(A);//打印一元多项式 cout &lt;&lt; endl; //输入B cout &lt;&lt; "请输入第二个多项式的项数为："; cin &gt;&gt; length; CreatPolyn(B, length); //输出B cout &lt;&lt; "PB(x) = "; PrintPolyn(B); cout &lt;&lt; endl; //假设以上输入成功 //进行相加 AddPolyn(A, B);//一元多项式相加 //这时候A是合并后的结果 cout &lt;&lt; "PA(x)+PB(x) = "; PrintPolyn(A); cout &lt;&lt; endl; cout&lt;&lt;"一元多项式的长度："&lt;&lt;PolynLength(A)&lt;&lt;endl; DestroyPolyn(A); return 0;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络质量分析-NQA]]></title>
    <url>%2F2017%2F12%2F22%2F%E7%BD%91%E7%BB%9C%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90-NQA%2F</url>
    <content type="text"><![CDATA[NQA简介网络质量分析NQA（Network Quality Analysis）是一种实时的网络性能探测和统计技术，可以对响应时间、网络抖动、丢包率等网络信息进行统计。NQA能够实时监视网络QoS，在网络发生故障时进行有效的故障诊断和定位。 目的：为了使网络服务质量可见，使用户能够自行检查网络服务质量是否达到要求，需要采取以下措施： 在设备上提供能够说明网络服务质量的数据。 在网络中部署探针设备能对网络服务质量进行监控。 部署上述措施时，需要在设备侧提供时延、抖动、丢包率等相关统计参数和使用专用的探针设备，增加了设备和资金的投入。 当设备提供NQA时，就不用部署专门的探针设备，可以有效的节约成本。NQA可以实现对网络运行状况的准确测试，输出统计信息。 NQA监测网络上运行的多种协议的性能，使用户能够实时采集到各种网络运行指标，例如：HTTP的总时延、TCP连接时延、DNS解析时延、文件传输速率、FTP连接时延、DNS解析错误率等。 原理描述：构造测试例 NQA测试中，把测试两端称为客户端和服务器端（或者称为源端和目的端），NQA的测试是由客户端（源端）发起。在客户端通过命令行配置测试例或由网管端发送相应测试例操作后，NQA把相应的测试例放入到测试例队列中进行调度。 启动测试例 启动NQA测试例，可以选择立即启动、延迟启动、定时启动。在定时器的时间到达后，则根据测试例的测试类型，构造符合相应协议的报文。但配置的测试报文的大小如果无法满足发送本协议报文的最小尺寸，则按照本协议规定的最小报文尺寸来构造报文发送。 测试例处理 测试例启动后，根据返回的报文，可以对相关协议的运行状态提供数据信息。发送报文时的系统时间作为测试报文的发送时间，给报文打上时间戳，再发送给服务器端。服务器端接收报文后，返回给客户端相应的回应信息，客户端在接收到报文时，再一次读取系统时间，给报文打上时间戳。根据报文的发送和接收时间，计算出报文的往返时间。 测试机制：DHCP测试：NQA的DHCP测试以UDP报文为承载，模拟DHCP Client在指定的接口上发起DHCP请求，根据是否申请到地址，确定接口所在的网络中是否有DHCP Server服务以及测试申请到地址的时间。 DHCP测试过程如下： 源端（RouterA）从需要获得地址的接口，向接口所在网段广播查询DHCP Server的Discovery报文。 DHCP Server（RouterB）收到报文后，向源端回送Offer报文，报文中包含了DHCP Server的IP地址。 源端向接口所在网段广播要求获取IP地址的Request报文，报文中包含了DHCP Server的IP地址信息。 DHCP Server收到报文后，向源端回送ACK报文，报文中包含了DHCP Server分配给相应接口的IP地址。 源端收到数据包后通过计算源端接收报文的时间和源端最初发送Discovery报文的时间的差，计算出从DHCP服务器获取IP地址的时间。 DHCP测试只是借用操作接口发送DHCP报文，申请到地址后立即释放DHCP租约，不会为接口真正申请地址，因此不会占用DHCP Server的地址资源。进行DHCP测试的操作接口必须处于Up状态。 DHCP测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 DNS测试：NQA的DNS测试以UDP报文为承载，通过模拟DNS Client向指定的DNS服务器发送域名解析请求，根据域名解析是否成功及域名解析需要的时间，来判断DNS服务器是否可用，及域名解析速度。 dns测试过程如下： 客户端（RouterA）向DNS Server发送要求解析给定的DNS名称的Query报文。 DNS Server收到报文后，通过解析构造Response报文，然后再把这个数据包发回到客户端。 客户端收到数据包后通过计算客户端接收报文的时间和客户端发送报文的时间的差，计算出DNS域名解析时间。从而清晰的反映出网络DNS协议的性能状况。 DNS测试只是模拟域名解析的过程，不会保存要解析的域名与IP地址的对应关系。 DNS测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 FTP测试：NQA的FTP测试以TCP报文为承载，用于检测是否可以与指定的FTP服务器建立连接，以及从FTP服务器下载指定文件或向FTP服务器上载指定文件的速度。 FRP测试提供两个阶段的响应速度： 控制连接时间：客户端（RouterA）与FTP Server通过TCP“三次握手”建立控制连接的时间以及通过控制连接交互信令的时间。 数据连接时间：客户端（RouterA）通过数据连接从FTP服务器下载指定文件或向FTP服务器上载指定文件的时间。 通过FTP测试，从客户端接收到的信息中可以计算出： 最小控制连接时间、最大控制连接时间及平均控制连接时间。 最小数据连接时间、最大数据连接时间及平均数据连接时间。 FTP测试支持文件下载和文件上载操作。文件下载操作并不会把文件放到本地的文件系统，只是计算下载该文件所需要的时间，取得数据后随即自动释放占用的内存；文件上载操作并不是将本地文件放到服务器上，而是上传固定大小及内容的文件（文件名由用户配置，数据为系统内部指定的固定数据；如果配置的文件名和服务器上已有的文件重名，则覆盖原来的文件），测试完成后该文件并不被删除。因此，FTP测试与本地文件系统无关。 FTP测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 HTTP测试：NQA的HTTP测试主要是测试客户端是否可以与指定的HTTP服务器建立连接，从而判断该设备是否提供了HTTP服务以及建立连接的时间。 NQA的HTTP测试提供三分阶段的响应速度： DNS解析时间：客户端（RouterA）发送DNS报文给DNS服务器，DNS服务器将HTTP服务器域名解析为IP地址，DNS解析报文返回到客户端所花费的总时间。 TCP建立连接时间：客户端（RouterA）与HTTP服务器通过TCP“三次握手”建立连接所用的时间。 交易时间：客户端（RouterA）发送Get或Post报文给HTTP服务器，响应报文到达HTTP服务器的时间。 通过HTTP测试，从客户端接收到的信息中可以计算出： 最小DNS查询时间、最大DNS查询时间及DNS查询时间总和。 最小TCP连接建立时间、最大TCP连接建立时间及TCP连接建立时间总和。 最小HTTP交易时间、最大HTTP交易时间及HTTP交易时间总和。 HTTP测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 ICPM Jitter测试：ICMP Jitter测试是以ICMP报文为承载，通过记录在报文中的时间戳信息来统计时延、抖动、丢包的一种测试方法。Jitter（抖动时间）是指相邻两个报文的接收时间间隔减去这两个报文的发送时间间隔。 ICMP Jitter测试的过程如下： 源端（RouterA）以一定的时间间隔向目的端（RouterB）发送数据包。 目的端（RouterB）每收到一个数据包，就给它打上时间戳，然后再把这个数据包发回到源端（RouterA）。 源端（RouterA）收到数据包后通过计算目的端（RouterB）接收数据包时间间隔和源端（RouterA）发送数据包的时间间隔之差，计算出抖动时间。 从源端接收到的信息中计算出： 数据包从源端到目的端和从目的端到源端的最大抖动时间、最小抖动时间及平均抖动时间。 从目的端到源端或从源端到目的端的最大单向延时。 ICMP Jitter测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 ICMP测试：NQA的ICMP测试例用于检测源端到目的端的路由是否可达。ICMP测试提供类似于命令行下的Ping命令功能，但输出信息更为丰富： 默认情况下能够保存最近5次的测试结果。 结果中能够显示平均时延、丢包率，最后一个报文正确接收的时间等信息。 ICMP测试过程如下： 源端（RouterA）向目的端（RouterB）发送构造的ICMP Echo Request报文。 目的端（RouterB）收到报文后，直接回应ICMP Echo Reply报文给源端（RouterA）。 源端收到报文后，通过计算源端接收时间和源端发送时间之差，计算出源端到目的端的通信时间，从而清晰的反应出网络性能及网络畅通情况。 ICMP测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 LSP Ping测试：NQA的LSP Ping测试例用于检测两种类型（LDP，TE）的LSP路径是否可达。 LSP ping测试的过程如下： 源端（PE-A）首先构造MPLS Echo Request报文，在IP头填入127.0.0.0/8网段的地址作为IP的目的地，根据配置对端LSR ID查找相应的LSP（对于TE的LSP，可以指定从Tunnel接口发送，从而找到相应的CR-LSP），按指定的LSP进行MPLS域内的转发。 目的端（PE-B）Egress侦听3503端口发送MPLS Echo Reply响应报文。 源端通过接收到的响应报文，统计出测试结果，通过计算源端接收时间和源端发送时间之差，计算出源端到目的端的通信时间，从而清晰的反应出MPLS网络链路畅通情况。 LSP Ping测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 LSP Trace测试：NQA的LSP Trace测试用于检测两种类型（LDP，TE）的LSP转发路径，并沿该路径收集各设备的有关的统计信息。 LSP Trace测试的过程如下： 源端（PE-A）首先构造UDP的MPLS Echo Request报文，在IP头填入127.0.0.0/8网段的地址作为IP的目的地，查找相应的LSP（对于TE的LSP，可以指定从Tunnel接口发送，从而找到相应的CR-LSP）。MPLS Echo Request报文应该包含有Downstream MapPing TLV（用来携带LSP在当前节点的下游信息，主要包括下一跳地址、出标签等）。第一次发送的MPLS Echo Request报文的TTL为1。 该报文按指定的LSP进行MPLS域内的转发，到达LSP路径第一跳TTL超时返回MPLS Echo Reply消息。 源端（PE-A）继续以TTL递增的方式发送MPLS Echo Request报文，如此重复，直到整条LSP上的所有LSR都应答后，LSP Trace测试过程完成。 源端收到每跳LSR的应答消息后，统计并打印出从源端到目的端的LSP转发路径和该路径上各设备的有关信息。从而清晰的反映出从源端到目的端的LSP转发路径。 LSP Trace测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 SNMP测试：NQA的SNMP测试用于检测主机与SNMP Agent之间通信的速度，以UDP报文为承载。 SNMP测试过程如下； 源端（RouterA）向SNMP Agent（RouterC）发送要求获取系统时间的请求报文。 SNMP Agent收到报文，查询系统时间并构造回应报文，然后再把这个数据包发回到源端。 源端收到数据包后通过计算源端接收报文的时间和源端发送报文的时间的差，计算出源端与SNMP Agent之间通信的时间。从而清晰的反映出网络SNMP协议的性能状况。 SNMP测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 TCP测试：NQA的TCP测试用于检测主机与TCP Server之间经过三次握手建立TCP连接的速度。 TCP测试的过程如下： RouterA向RouterB发送要求建立连接的TCP SYN报文。 RouterB收到报文，接收请求并向RouterA回应TCP SYN ACK报文。 RouterA报文后，向RouterB回应ACK报文，连接建立。 此后，RouterA通过发送报文和接收报文的时间差，计算出与RouterB之间三次握手建立TCP连接的时间。从而清晰的反映出网络TCP协议的性能状况。 不能太频繁的发起TCP探测，以免占用过多资源，影响到目的设备上的正常服务。 TCP测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 Trace测试：NQA的Trace测试用于检测源端到目的端的转发路径，并沿该路径记录源设备到中间各个设备的时延等信息。Trace测试类似于Tracert命令功能，但输出信息更为丰富。每一跳信息中能够显示平均时延、丢包、最后一个包接收时间等信息。 Trace测试的过程如下： 源端（RouterA）向目的端（RouterD）发送构造的UDP报文，报文中的TTL为1。 第一跳RouterB收到该报文后，判断TTL是否为0，如果为0则丢弃该报文，返回ICMP超时报文。 源端（RouterA）收到该ICMP超时报文后，记录第一跳的IP地址，并重新构造UDP报文，报文中的TTL为2。 报文到达第二跳RouterC后，判断TTL是否为0，如果为0则丢弃该报文，返回ICMP超时报文。 以此类推，最终报文到达目的端（RouterD），返回端口不可达的ICMP报文给源端（RouterA）。 源端收到每跳返回的ICMP报文后，统计并打印出从源端到目的端的转发路径和该路径上各设备的有关信息。从而清晰的反映出从源端到目的端的转发路径。 Trace测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 UDP测试：NQA的UDP测试用于检测源端与目的端（UDP Server）之间通信的速度。 UDP测试的过程如下： 源端（RouterA）向目的端（RouterC）发送构造的UDP报文。 目的端收到报文，直接将报文再回送给源端。 源端收到数据包后通过计算源端接收报文的时间和源端发送报文的时间的差，计算出源端与目的端之间通信的时间。从而清晰的反映出网络UDP协议的性能状况。 UDP测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 UDP Jitter测试：UDP Jitter是以UDP报文为承载，通过记录在报文中的时间戳信息来统计时延、抖动、丢包的一种测试方法。Jitter（抖动时间）是指相邻两个报文的接收时间间隔减去这两个报文的发送时间间隔。 UDP Jitter测试的过程如下： 源端（RouterA）以一定的时间间隔向目的端（RouterB）发送报文。 目的端（RouterB）每收到一个报文，就给它打上时间戳，然后再把这个报文发回到源端（RouterA）。 源端（RouterA）收到报文后通过计算目的端（RouterB）接收报文时间间隔和源端（RouterA）发送报文的时间间隔之差，计算出抖动时间。 从源端接收到的信息中计算出： 报文从源端到目的端和从目的端到源端的最大抖动时间、最小抖动时间及平均抖动时间。 从目的端到源端或从源端到目的端的最大单向延时。 UDP Jitter每次测试最大发包数量可配，是探测数（probe-count）与每次探测发送报文（jitter-packetnum）的乘积。 UDP Jitter测试可以设置单个测试例的连续发包数目，通过这项设置，可以在一段时间内模拟某种数据的真实流量。例如，设置3000个UDP报文以20毫秒的间隔发送，可以在一分钟内模拟G.711流量。 UDP Jitter测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 UDP Jitter（hardware-based）测试：UDP Jitter（hardware-based）是以UDP报文为承载，是对UDP Jitter的补充。可以达到如下目的： 可以减小发包间隔，最小可以达到10ms。 可以增加测试例的并发数。 时延抖动计算更加准确。 从而可以更加真实的反映网络状况和提高设备效率。 UDP Jitter和UDP jitter（hardware-based）的不同点： 比较点 UDP Jitter UDP Jitter(hardware-based) 发包间隔 最小只能达到20ms 最小可以达到10ms 抖动计算 上送主控板打时间戳 接口板打时间戳，更精准 UDP Jitter(hardware-based)测试的结果和历史记录将记录在测试例中，可以通过命令行来查看探测结果和历史记录。 NQA联动机制：联动功能是指NQA提供探测功能，把探测结果通知其他模块，其他模块再根据探测结果进行相应处理的功能。目前实现了与VRRP、静态路由、备份接口、IGMP Proxy、IP地址池、DNS服务器和策略路由的联动。 以静态路由为例： 用户配置了一条静态路由，下一跳为192.168.0.88，如果192.168.0.88可达，该静态路由有效；如果192.168.0.88不可达，则该静态路由无效。通过在NQA和应用模块之间建立联动，可以实现静态路由有效性的实时判断。如果NQA发现192.168.0.88不可达，NQA将通知静态路由模块，静态路由模块可以据此判断该静态路由项无效。 NQA配置命令行：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990adv-factor factor-value//配置NQA Jitter模拟语音测试计算的补偿因子。//缺省情况下，NQA Jitter模拟语音测试计算的补偿因子的值为0。取值范围是0～20。agetime hh:mm:ss//来配置NQA测试例的老化时间。//缺省情况下，老化时间为0，表示测试例永不老化。clear-records//用来清除NQA测试例的统计信息。community read cipher community-name//用来配置用于SNMP测试的团体名。//缺省情况下，系统中SNMP测试的团体名为public。datafill fillstring //配置NQA测试例的填充字符。datasize size//用来配置NQA测试例的报文大小。取值范围是0～8100destination-address//用来配置NQA测试例的目的地址。destination-port//用来配置NQA测试例的目的端口号。display nqa application//查看与业务对应的NQA测试例类型。display nqa-parameter (参数)//用来查看当前测试例的参数配置信息。dns-server ipv4 ip-address//用来配置NQA测试中DNS服务器地址。fail-percent percent//用来配置NQA测试失败百分比。//缺省情况下，测试失败百分比为100%，即只有全部探测失败，本次测试才视为失败。frequency interval//用来配置NQA测试例自动执行测试的时间间隔。//缺省情况下，没有配置自动测试间隔，即只进行一次测试。ftp-filename file-name//用来配置NQA测试FTP测试例的文件名和文件路径。hardware-based enable//用来使能在进行Jitter测试时，采用接口板上的硬件转发引擎进行发包及打时间戳。icmp-jitter-mode &#123; icmp-echo | icmp-timestamp &#125;//用来指定ICMP Jitter测试例测试模式的类型。//缺省情况下，ICMP Jitter测试例测试模式的类型为icmp-timestamp。interval &#123; milliseconds interval | seconds interval &#125;//配置NQA测试例的发送报文的时间间隔。probe-count number//用来配置NQA测试例的一次测试探针数目。//缺省情况下，一次测试探针数目是3。probe-failtimes times//用来配置NQA测试探测失败后发送trap的阈值。即，连续探测失败的次数。//取值范围是1～15。缺省值是1。packet-rewrite-check &#123; alternant-binary | same-binary &#125; //配置NQA报文改写检查功能，通过填充检测报文的方式实现检查。//alternant-binary:指定使用0101和1010交替填充检测报文。//same-binary:指定使用全0和全1交替填充检测报文。records &#123; history number | result number &#125;//配置NQA测试的历史记录和结果记录的最大数目。records history-filter &#123; all | failures &#125;//打开对NQA测试例历史表记录的过滤功能。sendpacket passroute//配置NQA测试例不查找路由表发送报文。send-trap//用来配置Trap消息的发送条件。set-df//设置报文的DF（Don't Fragment）位。即，不允许报文分片。snmp-agent trap enable feature-name nqa//打开NQA模块的告警开关。start//配置NQA测试例的启动方式和结束方式。stop//用来终止当前正在执行的NQA测试例。test-failtimes times//配置在NQA测试失败后发送Trap的阈值。即，连续测试失败的次数。test-type//配置NQA测试例的测试类型。timestamp-unit &#123; millisecond | microsecond &#125; //来设置NQA测试例的时间戳单位。//millisecond:毫秒 microsecond：微秒threshold &#123; owd-ds owd-ds-value | owd-sd owd-sd-value | rtd rtd-value &#125;//设置双向传输延迟、单向传输延迟的阈值。timeout time//配置NQA测试例的一次探测的超时时间。//缺省情况下，除DHCP、FTP测试类型的超时时间为15秒外，其他测试类型的超时时间为3秒。tos value//配置NQA测试报文的服务类型。tracert-hopfailtimes//配置NQA测试中Trace测试例失败的失败跳数。取值范围是1～255。//缺省情况下，一次探测中的失败跳数达到5次就认为此次探测失败。tracert-livetime first-ttl first-ttl max-ttl max-ttl//配置NQA测试Trace测试例的生存时间。//缺省情况下，初始TTL值为1，最大TTL值为30。ttl number//配置NQA测试例测试报文的TTL值。//缺省情况下，TTL值为30。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双向转发检测-BFD]]></title>
    <url>%2F2017%2F12%2F19%2F%E5%8F%8C%E5%90%91%E8%BD%AC%E5%8F%91%E6%A3%80%E6%B5%8B-BFD%2F</url>
    <content type="text"><![CDATA[BFD简介双向转发检测BFD（Bidirectional Forwarding Detection）用于快速检测系统之间的通信故障，并在出现故障时通知上层应用。 为了减小设备故障对业务的影响、提高网络的可靠性，设备需要能够尽快检测到与相邻设备间的通信故障，以便能够及时采取措施，从而保证业务继续进行。 现有的故障检测方法主要包括以下几种: 硬件检测：硬件检测的优点是可以很快发现故障，但并不是所有介质都能提供硬件检测。 慢Hello机制：通常采用路由协议中的Hello报文机制。这种机制检测到故障所需时间为秒级。对于高速数据传输，超过1秒的检测时间将导致大量数据丢失。并且，这种机制依赖于路由协议，在小型三层网络中，如果没有部署路由协议，则无法使用路由协议的Hello报文机制来检测故障。 其他检测机制：不同的协议有时会提供专用的检测机制，但在特性间互联互通时，这样的专用检测机制通常难以应用于多个特性。 BFD提供了一个与介质和协议无关的快速故障检测机制。具有以下优点： 对网络设备间任意类型的双向转发路径提供快速、轻负荷的故障检测。 用单一的机制对任何介质、任何协议层进行实时检测，并支持不同的检测时间与开销。 设备支持的BFD特性：设备支持的BFD特性主要包括：BFD会话建立、BFD检测模式、单跳和多跳检测、静态标识符自协商BFD、单臂回声功能、联动功能和动态改变BFD参数。 BFD会话建立：BFD通过控制报文中的本地标识符（Local Discriminator）和远端标识符（Remote Discriminator）区分不同的会话。按照本地标识符和远端标识符创建方式的差异，设备支持以下BFD会话类型： 手工指定标识符的静态BFD会话 必须手工指定BFD会话的本地标识符和远端标识符。如果本端采用手工指定标识符，则对端也必须手工指定标识符。 标识符自协商的静态BFD会话 如果对端设备采用动态BFD，而本端设备既要与之互通，又要能够实现BFD检测静态路由，必须配置静态标识符自协商BFD，此时无需指定本地标识符和远端标识符。如果本端采用静态标识符自协商，则对端既可以配置静态标识符自协商，也可以配置动态BFD。 协议触发的动态BFD会话 动态分配本端标识符和自学习远端标识符，无需指定本地标识符和远端标识符。 BFD检测模式：设备采用BFD异步检测模式。 各设备间按照协商好的周期发送BFD控制报文，如果某个设备在检测时间内没有收到对端发来的报文，则将BFD会话的状态置为Down。 单跳检测和多跳检测：单跳检测指检测两台三层直连设备间转发链路的连通性。 多跳检测指检测两台三层非直连设备间任意路径的连通性，这些路径可能跨越很多跳，也可能在某些部分重叠。 静态标识符自协商BFD：如果对端设备采用动态BFD，而本端设备既要与之互通，又要能够实现BFD检测静态路由，必须配置静态标识符自协商BFD。 单臂回声功能：在两台直接相连的设备中，其中一台设备支持BFD功能，另一台设备不支持BFD功能。为了能够快速的检测这两台设备之间的故障，可以在支持BFD功能的设备上创建单臂回声功能的BFD会话。支持BFD功能的设备主动发起回声请求功能，不支持BFD功能的设备接收到该报文后直接将其环回，从而实现转发链路的连通性检测功能。 注：单臂回声功能只适用于单跳BFD会话中。 联动功能：在实际组网中，BFD通常会和其他的协议联合使用，服务于上层应用，比如：BFD和OSPF联动。缺省情况下，OSPF发送Hello报文的时间间隔为10秒钟，设备能感知到邻居故障的时间最小也是秒级。在高速的网络环境中，这将导致报文大量丢失。BFD联动OSPF可以更快的发现邻接方面出现的故障，并及时通知OSPF重新计算相关路由以便正确指导报文的转发。 设备支持BFD和OSPF联动、BFD和IS-IS联动、BFD和BGP联动、BFD和静态路由联动、BFD和PIM联动、BFD和EFM联动以及BFD和VRRP联动。 BFD与接口状态联动：当直连链路中间存在传输设备时，与接口本身的链路协议故障检测机制相比，BFD能够更快地检测到链路故障。另外对于Eth-Trunk或VLANIF等逻辑接口来说，链路协议状态是由其成员接口的链路协议状态决定的。 因此，为了将BFD检测结果更快地通告到应用程序，在设备接口管理模块中，为每个接口增加了一个属性，即BFD状态，指的是与该接口绑定的BFD会话的状态，系统根据接口的链路状态、协议状态和BFD状态决定接口的状态，并将结果通告给应用程序。 BFD会话状态与接口状态联动功能是指当BFD会话的状态变化时，直接修改接口的BFD状态。 当BFD会话状态变为Down时，与其绑定的接口的BFD状态变为Down，然后将接口状态通告给接口上的应用。 当BFD会话的状态变为Up时，与其绑定的接口的BFD状态变为Up。 该功能针对绑定出接口且使用缺省组播地址进行检测的单跳BFD会话。 BFD报文格式BFD控制报文封装在UDP报文中传送，对于单跳检测其UDP目的端口号为3784，对于多跳检测其UDP目的端口号为4784或3784。 BFD控制报文根据场景不同封装不同。BFD控制报文包括两部分：强制部分和可选的认证字段。不同的认证类型，认证字段的格式不同。 BFD控制报文强制部分的格式如下： 图：BFD报文格式 字段解释： 字段 长度 含义 Version (Vers) 3 bits BFD协议版本号，目前为1。 Diagnostic (Diag) 5 bits 诊断字，标明本地BFD系统最近一次会话状态发生变化的原因，取值及含义： 0 – No Diagnostic ； 1 – Control Detection Time Expired ；2 – Echo Function Failed ； 3 – Neighbor Signaled Session Down ； 4 – Forwarding Plane Reset； 5 – Path Down； 6 – Concatenated Path Down ； 7 – Administratively Down； 8 – Reverse Concatenated Path Down； 9-31 – Reserved for future use State (Sta) 2 bits BFD本地状态。0 – AdminDown； 1 – Down； 2 – Init； 3 – Up Poll (P) 1 bit 参数发生改变时，发送方在BFD报文中置该标志，接收方必须立即响应该报文。1：表示发送系统请求进行连接确认，或者发送请求参数改变的确认。0：表示发送系统不请求确认。 Final (F) 1 bit 响应P标志置位的回应报文中必须将F标志置位。1：表示发送系统响应一个接收到P比特为1的BFD包。0：表示发送系统不响应一个P比特为1的包。 Control Plane Independent (C) 1 bit 转发/控制分离标志，一旦置位，控制平面的变化不影响BFD检测，如：控制平面为IS-IS，当IS-IS重启/GR时，BFD可以继续监测链路状态。1：表示发送系统的BFD实现不依赖于它的控制平面。即，BFD报文在转发平面传输，即使控制平面失效，BFD仍然能够起作用。0：表示BFD报文在控制平面传输。 Authentication Present (A) 1 bit 认证标识，置1代表会话需要进行验证。 Demand (D) 1 bit 查询请求，置位代表发送方期望采用查询模式对链路进行监测。1：表示发送系统希望工作在查询模式。0：表示发送系统不希望、或不能工作在查询模式。 Multipoint (M) 1 bit 为BFD将来支持点对多点扩展而设的预留位。 Detect Mult 8 bits 检测超时倍数，用于检测方计算检测超时时间。查询模式：采用本地检测倍数。异步模式：采用对端检测倍数。 Length 8 bits 报文长度，单位为字节。 My Discriminator 32 bits BFD会话连接本地标识符。发送系统产生的一个唯一的、非0鉴别值，用来区分一个系统的多个BFD会话。 Your Discriminator 32 bits BFD会话连接远端标识符。从远端系统接收到的鉴别值，这个域直接返回接收到的“My Discriminator”，如果不知道这个值就返回0。 Desired Min TX Interval 32 bits 本地支持的最小BFD报文发送间隔，单位为微秒。 Required Min RX Interval 32 bits 本地支持的最小BFD报文接收间隔，单位为微秒。 Required Min Echo RX Interval 32 bits 本地支持的最小Echo报文接收间隔，单位为微秒（如果本地不支持Echo功能，则设置0）。 BFD报文抓包示例： 图：BFD报文抓包示例 配置BFD配置VLANIF接口BFD单跳检测：在两台交换机之间配置VLANif接口实现三层互通，配置BFD实现链路故障的快速检测。 图：配置VALNIF接口BFD单跳检测 配置文件： 12345678910111213&lt;SW1&gt;dis current-configuration #sysname SW1#interface Vlanif1 //配置VALNIF接口 ip address 12.1.1.1 255.255.255.0#bfd 1 bind peer-ip 12.1.1.2 interface Vlanif1 source-ip 12.1.1.1//创建BFD会话绑定信息 discriminator local 1 //配置BFD会话的本地标识符。 discriminator remote 2 //配置BFD会话的远端标识符。 commit //用来提交BFD会话配置。# 配置BFD多跳检测：AR1和AR3为非直连设备，通过配置静态路由互通。在AR1和RAR3上分别配置BFD会话，实现AR1到AR3间多跳路径的检测。 图：配置BFD多跳检测 配置文件： 123456789101112131415161718192021222324[AR1]dis current-configuration # sysname AR1#interface GigabitEthernet0/0/0 ip address 12.1.1.1 255.255.255.0 #bfd 1 bind peer-ip 23.1.1.3//配置BFD绑定远端IP地址 discriminator local 2 discriminator remote 1 description duotainjiance //配置BFD会话的描述信息。 min-tx-interval 1200 //配置BFD报文的发送间隔。 min-rx-interval 1200//配置BFD报文的接收间隔。 wtr 3//配置BFD会话的等待恢复时间。 缺省情况下，WTR为0，即不等待。 commit //提交BFD配置#ip route-static 23.1.1.0 255.255.255.0 12.1.1.2# BFD会话状态： 图：BFD会话信息 配置BFD单臂回声功能：AR4支持BFD功能，而AR5不支持，所以在AR4上配置BFD单臂回声功能，实现链路故障的快速检测。 图：配置BFD单臂检测功能 配置文件： 1234567interface GigabitEthernet0/0/0 ip address 12.1.1.1 255.255.255.0 #bfd 1 bind peer-ip 12.1.1.2 interface GigabitEthernet0/0/0 one-arm-echo discriminator local 1 commit# 其他常用BFD配置命令行：123456789101112131415161718192021222324252627282930313233bfd bind peer-ip source-ip auto//用来创建静态标识符自协商BFD会话。bfd one-arm-echo//配置单臂回声功能的BFD会话。default-ip-address//配置BFD缺省组播地址。缺省情况下，组播缺省地址为224.0.0.184。delay-up//用来使能延迟BFD会话Up的功能。detect-multiplier//配置BFD会话的本地检测倍数。缺省情况下，BFD会话本地检测倍数为3。discriminator//（鉴别器）//用来配置静态BFD会话的本地标识符和远端标识符。min-echo-rx-interval//配置单臂回声功能的BFD报文的最小接收间隔。multi-hop destination-port &#123; 3784 | 4784 &#125;//用来配置多跳BFD会话的目的端口号。//缺省情况下，使用3784作为多跳BFD会话报文的目的端口号。peer-ip ttl //配置BFD报文的生存时间。/*缺省情况下，不配置BFD报文的生存时间，采用默认值。对于静态配置的BFD会话，单跳BFD报文的生存时间为255，多跳BFD报文的生存时间为254；对于动态建立的BFD会话，单跳BFD报文的生存时间为255，多跳BFD报文的生存时间为253。*/process-interface-status//用来配置当前BFD会话与绑定的接口进行状态联动。snmp-agent bfd trap-interval//用来设置发送Trap消息定时器的时间间隔。//缺省情况下，发送Trap消息定时器的时间间隔是120秒。snmp-agent trap enable feature-name bfd//用来打开BFD模块的告警开关。tos-exp//用来设置BFD报文的优先级。缺省情况下，BFD报文的优先级是7。track bfd session-name//用来把BFD会话加入BFD组。unlimited-negotiate//用来使能组播BFD会话无条件协商功能。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟路由冗余协议(VRRP)]]></title>
    <url>%2F2017%2F12%2F18%2F%E8%99%9A%E6%8B%9F%E8%B7%AF%E7%94%B1%E5%86%97%E4%BD%99%E5%8D%8F%E8%AE%AE-VRRP%2F</url>
    <content type="text"><![CDATA[VRRP简介：定义：虚拟路由冗余协议VRRP（Virtual Router Redundancy Protocol）通过把几台路由设备联合组成一台虚拟的路由设备，将虚拟路由设备的IP地址作为用户的默认网关实现与外部网络通信。当网关设备发生故障时，VRRP机制能够选举新的网关设备承担数据流量，从而保障网络的可靠通信。 ##目的： VRRP能够在不改变组网的情况下，采用将多台路由设备组成一个虚拟路由器，通过配置虚拟路由器的IP地址为默认网关，实现默认网关的备份。当网关设备发生故障时，VRRP机制能够选举新的网关设备承担数据流量，从而保障网络的可靠通信。 收益：在具有多播或广播能力的局域网（如以太网）中，借助VRRP能在网关设备出现故障时仍然提供高可靠的缺省链路，无需修改主机及网关设备的配置信息便可有效避免单一链路发生故障后的网络中断问题。 VRRP原理描述VRRP概述： VRRP路由器（VRRP Router）：运行VRRP协议的设备，它可能属于一个或多个虚拟路由器。 虚拟路由器（Virtual Router）：又称VRRP备份组，由一个Master设备和多个Backup设备组成，被当作一个共享局域网内主机的缺省网关。 Master路由器（Virtual Router Master）：承担转发报文任务的VRRP设备。 Backup路由器（Virtual Router Backup）：一组没有担转发任务的VRRP设备，当Master设备出现故障时，它们将通过竞选成为新的Master设备。 VRID：虚拟路由器的标识。 虚拟IP地址(Virtual IP Address)：虚拟路由器的IP地址，一个虚拟路由器可以有一个或多个IP地址，由用户配置。 IP地址拥有者（IP Address Owner）：如果一个VRRP设备将虚拟路由器IP地址作为真实的接口地址，则该设备被称为IP地址拥有者。如果IP地址拥有者是可用的，通常它将成为Master。 虚拟MAC地址（Virtual MAC Address）：虚拟路由器根据虚拟路由器ID生成的MAC地址。一个虚拟路由器拥有一个虚拟MAC地址，格式为：00-00-5E-00-01-{VRID}(VRRP for IPv4)；00-00-5E-00-02-{VRID}(VRRP for IPv6)。当虚拟路由器回应ARP请求时，使用虚拟MAC地址，而不是接口的真实MAC地址。 VRRP报文：VRRP协议报文用来将Master设备的优先级和状态通告给同一备份组的所有Backup设备。 VRRP协议报文封装在IP报文中，发送到分配给VRRP的IP组播地址。在IP报文头中，源地址为发送报文接口的主IP地址（不是虚拟IP地址），目的地址是224.0.0.18，TTL是255，协议号是112。 VRRP报文的IP头中，TTL必须为255。当VRRP路由器收到TTL不等于255的VRRP协议报文后，必须丢弃。 主IP地址（Primary IP Address）：从接口的真实IP地址中选出来的一个主用IP地址，通常选择配置的第一个IP地址。 目前，VRRP协议包括两个版本：VRRPv2和VRRPv3。VRRPv2仅适用于IPv4网络，VRRPv3适用于IPv4和IPv6两种网络。 基于不同的网络类型，VRRP可以分为VRRP for IPv4和VRRP for IPv6（简称VRRP6）。VRRP for IPv4支持VRRPv2和VRRPv3，而VRRP for IPv6仅支持VRRPv3。 VRRP报文结构： 图：VRRPv2报文结构 图：VRRPv3报文结构 字段解释： 字段 长度 描述 Version 4比特 指VRRP协议版本，VRRPv2此字段为2，VRRPv3此字段为3。 Type 4比特 定义了VRRP报文的类型。本版本的协议仅定义了一个报文类型：1：ADVERTISEMENT 带有未知类型的报文必须被丢弃。 Virtual Rtr ID8 8比特 虚拟路由器标识（VRID）字段标识了此报文所报告状态的虚拟路由器。可配置的范围是1–255。没有缺省值。 Priority 8比特 Priority字段申明了发送此报文的VRRP路由器的优先级。值越高优先级越高。该字段为8位无符号整型。如果VRRP路由器是虚拟路由器地址的IP地址所有者，那么其优先级必须为255。起备用作用的VRRP路由器的优先级必须在1–254之间。缺省的VRRP路由器优先级为100。优先级值0 用于指示当前虚拟路由器的主路由器停止参与VRRP组。主要用于触发备用路由器快速地迁移到主路由器，而不用等待当前主路由器超时。 Count IP Addrs 8比特 在此VRRP通告中包含的IP地址的数量。 Auth Type 8比特 认证类型字段用于标识要用到的认证方法。在一个虚拟路由器组内认证类型是唯一的。认证类型字段是一个8位无符号整型。如果报文携带未知的认证类型或者该认证类型和本地配置的认证方法不匹配，那么该报文必须被丢弃。目前定义的认证方法有：0 : No Authentication 不认证该认证类型表明VRRP协议报文的交换不需要认证。在发送VRRP协议报文时，Authentication Data 字段将被置为0；而在接收协议报文时，Authentication Data 字段被忽略。 1 : Simple Text Password，表示明文认证方式。2: IP Authentication Header，表示MD5认证方式。 Adver Int 8比特 VRRP通告间隔时间，单位为秒。缺省为1秒。这个字段主要用于错误配置路由器时的故障定位和解决。 Checksum 16比特 16位校验和，用于检测VRRP报文中的数据破坏情况。 IP Address 32比特 VRRP备份组的虚拟IPv4地址 或者虚拟IPv6地址 Authentication Data 32比特 VRRP报文的认证字。目前只有明文认证和MD5认证才用到该部分，对于其它认证方式，一律填0。 VRRP报文主要区别： 支持的网络类型不同。VRRPv3适用于IPv4和IPv6两种网络，而VRRPv2仅适用于IPv4网络。 认证功能不同。VRRPv3不支持认证功能，而VRRPv2支持认证功能。 VRRPv2版本保留报文的认证字段，是为了兼容早期版本（RFC2338），VRRP认证并不能提高安全性。 发送通告报文的时间间隔的单位不同。VRRPv3支持的是厘秒级，而VRRPv2支持的是秒级。 VRRP认证： 无认证方式：设备对要发送的VRRP通告报文不进行任何认证处理，收到通告报文的设备也不进行任何认证，认为收到的都是真实的、合法的VRRP报文。 简单字符（Simple）认证方式：发送VRRP通告报文的设备将认证方式和认证字填充到通告报文中，而收到通告报文的设备则会将报文中的认证方式和认证字与本端配置的认证方式和认证字进行匹配。如果相同，则认为接收到的报文是合法的VRRP通告报文；否则认为接收到的报文是一个非法报文，并丢弃这个报文。 MD5认证方式：发送VRRP通告报文的设备利用MD5算法对认证字进行加密，加密后保存在Authentication Data字段中。收到通告报文的设备会对报文中的认证方式和解密后的认证字进行匹配，检查该报文的合法性。 VRRP报文抓包示例： 图：VRRPv2报文抓包示例 图：VRRPv3报文抓包示例 VRRP工作原理：VRRP状态机：VRRP协议中定义了三种状态机：初始状态（Initialize）、活动状态（Master）、备份状态（Backup）。其中，只有处于Master状态的设备才可以转发那些发送到虚拟IP地址的报文。 Initialize： 该状态为VRRP不可用状态，在此状态时设备不会对VRRP报文做任何处理。 通常刚配置VRRP时或设备检测到故障时会进Initialize状态。 收到接口Up的消息后，如果设备的优先级为255，则直接成为Master设备；如果设备的优先级小于255，则会先切换至Backup状态。 Masster：当VRRP设备处于Master状态时，它将会做下列工作： 定时（Advertisement Interval）发送VRRP通告报文。 以虚拟MAC地址响应对虚拟IP地址的ARP请求。 转发目的MAC地址为虚拟MAC地址的IP报文。 如果它是这个虚拟IP地址的拥有者，则接收目的IP地址为这个虚拟IP地址的IP报文。否则，丢弃这个IP报文。 如果收到比自己优先级大的报文，立即成为Backup。 如果收到与自己优先级相等的VRRP报文且本地接口IP地址小于对端接口IP，立即成为Backup。 Backup： 当VRRP设备处于Backup状态时，它将会做下列工作： 接收Master设备发送的VRRP通告报文，判断Master设备的状态是否正常。 对虚拟IP地址的ARP请求，不做响应。 丢弃目的IP地址为虚拟IP地址的IP报文。 如果收到优先级和自己相同或者比自己大的报文，则重置Master_Down_Interval定时器，不进一步比较IP地址。 Master_Down_Interval定时器：Backup设备在该定时器超时后仍未收到通告报文，则会转换为Master状态。计算公式如下：Master_Down_Interval=(3*Advertisement_Interval) + Skew_time。其中，Skew_Time=(256–Priority)/256。 如果收到比自己优先级小的报文且该报文优先级是0时，定时器时间设置为Skew_time（偏移时间），如果该报文优先级不是0，丢弃报文，立刻成为Master。 VRRP的工作过程：VRRP的工作过程如下： VRRP备份组中的设备根据优先级选举出Master。Master设备通过发送免费ARP报文，将虚拟MAC地址通知给与它连接的设备或者主机，从而承担报文转发任务。 Master设备周期性向备份组内所有Backup设备发送VRRP通告报文，以公布其配置信息（优先级等）和工作状况。 如果Master设备出现故障，VRRP备份组中的Backup设备将根据优先级重新选举新的Master。 VRRP备份组状态切换时，Master设备由一台设备切换为另外一台设备，新的Master设备会立即发送携带虚拟路由器的虚拟MAC地址和虚拟IP地址信息的免费ARP报文，刷新与它连接的主机或设备中的MAC表项，从而把用户流量引到新的Master设备上来，整个过程对用户完全透明。 原Master设备故障恢复时，若该设备为IP地址拥有者（优先级为255），将直接切换至Master状态。若该设备优先级小于255，将首先切换至Backup状态，且其优先级恢复为故障前配置的优先级。 Backup设备的优先级高于Master设备时，由Backup设备的工作方式（抢占方式和非抢占方式）决定是否重新选举Master。 抢占模式：在抢占模式下，如果Backup设备的优先级比当前Master设备的优先级高，则主动将自己切换成Master。 非抢占模式：在非抢占模式下，只要Master设备没有出现故障，Backup设备即使随后被配置了更高的优先级也不会成为Master设备。 Master设备的选举。 Master设备状态的通告 Master设备的选举 VRRP根据优先级来确定虚拟路由器中每台设备的角色（Master设备或Backup设备）。优先级越高，则越有可能成为Master设备。 如果VRRP报文中Master设备的优先级高于或等于自己的优先级，则Backup设备保持Backup状态。 如果VRRP报文中Master设备的优先级低于自己的优先级，采用抢占方式的Backup设备将切换至Master状态，采用非抢占方式的Backup设备仍保持Backup状态。 如果多个VRRP设备同时切换到Master状态，通过VRRP通告报文的交互进行协商后，优先级较低的VRRP设备将切换成Backup状态，优先级最高的VRRP设备成为最终的Master设备；优先级相同时，VRRP设备上VRRP备份组所在接口主IP地址较大的成为Master设备。 如果创建的VRRP设备为IP地址拥有者，收到接口Up的消息后，将会直接切换至Master状态。 Master设备状态的通告 当Master设备主动放弃Master地位（如Master设备退出备份组）时，会发送优先级为0的通告报文，用来使Backup设备快速切换成Master设备，而不用等到Master_Down_Interval定时器超时。这个切换的时间称为Skew time，计算方式为：（256－Backup设备的优先级）/256，单位为秒。 当Master设备发生网络故障而不能发送通告报文的时候，Backup设备并不能立即知道其工作状况。等到Master_Down_Interval定时器超时后，才会认为Master设备无法正常工作，从而将状态切换为Master。其中，Master_Down_Interval定时器取值为：3×Advertisement_Interval＋Skew_time，单位为秒。 在性能不稳定的网络中，网络堵塞可能导致Backup设备在Master_Down_Interval期间没有收到Master设备的报文，Backup设备则会主动切换为Master。如果此时原Master设备的报文又到达了，新Master设备将再次切换回Backup。如此则会出现VRRP备份组成员状态频繁切换的现象。为了缓解这种现象，可以配置抢占延时，使得Backup设备在等待了Master_Down_Interval后，再等待抢占延迟时间。如在此期间仍没有收到通告报文，Backup设备才会切换为Master设备。 VRRP负载分担：负载分担是指多个VRRP备份组同时承担业务，VRRP负载分担与VRRP主备备份的基本原理和报文协商过程都是相同的。同样对于每一个VRRP备份组，都包含一个Master设备和若干Backup设备。与主备备份方式不同点在于：负载分担方式需要建立多个VRRP备份组，各备份组的Master设备可以不同；同一台VRRP设备可以加入多个备份组，在不同的备份组中具有不同的优先级。 多网关负载分担：通过创建多个带虚拟IP地址的VRRP备份组，为不同的用户指定不同的VRRP备份组作为网关，实现负载分担。 VRRP笔记：VRRP报文通告是通过组播来通告的，组播地址：224.0.0.18,组播MAC：01-00-5e-00-00-12,VRRP是三层协议，通过IP协议承载，协议号112。同时IP包中的TTL值为255。 VRRP需要通过VRRP报文来选举Master和Backup,只有Master才能装发数据，而backup不装发数据，收到数据帧后丢弃。 如何选举Master和Backup？ 比较优先级，默认情况下优先级为100，最大可以配置的优先级为1-254，优先级越大越优。 255（V-IP = Interface ip），优先级如果为0，说明退出Master（Master离组，例如在Master的接口下删除VRRP配置） 如果优先级一样，IP地址大的一端成为Master。 Master： 可以装发报文。 应答 ARP请求。 通告基于VIP的免费ARP。 master定时通告VRRP报文。 Backup： 如果backup接收到目标mac为虚拟mac地址的数据帧，丢弃不转发。 backup被动接收vrrp报文，不通告。 影响VRRP协商的条件： IP包头中的TTL值必须为255. 版本必须一致。 VRRP报文中的字段必须一致。（Authen date） VRID必须一致。 认证类型和认证必须一致。 VIP（Count ip address）列表必须一致。 VRRP报文通告间隔必须一致（华为Backup会使用master端的通告间隔） checksum必须一致。 VRRP应用VRRP与接口状态联动监视上行接口：VRRP备份组只能感知其所在接口状态的变化，当VRRP设备上行接口或直连链路发生故障时，VRRP无法感知，此时会引起业务流量中断。通过部署VRRP与接口状态联动监视上行接口可以有效地解决上述问题，当Master设备的上行接口或直连链路发生故障时，通过调整自身优先级，触发主备切换，确保流量正常转发。 如果VRRP设备上配置以Increased方式监视一个接口，当被监视的接口状态变成Down后，该VRRP设备的优先级增加指定值。 如果VRRP设备上配置以Reduced方式监视一个接口，当被监视的接口状态变为Down后，该VRRP设备的优先级降低指定值。 VRRP与BFD/NQA/路由联动监视上行链路：VRRP只能感知VRRP备份组之间的故障，而配置VRRP监视上行接口仅能感知Master设备上行接口或直连链路的故障，当Master设备上行非直连链路故障时，VRRP无法感知，此时会导致用户流量丢失。通过部署VRRP与BFD/NQA/路由联动监视上行链路，可以有效地解决上述问题。通过配置BFD/NQA/路由检测Master上行链路的连通状况，当Master设备的上行链路发生故障时，BFD/NQA/路由可以快速检测故障并通知Master设备调整自身优先级，触发主备切换，确保流量正常转发。 VRRP与BFD联动实现快速切换：VRRP备份组通过收发VRRP协议报文进行主备状态的协商，以实现设备的冗余备份功能。当VRRP备份组之间的链路出现故障时，Backup设备需要等待Master_Down_Interval后才能感知故障并切换为Master设备，切换时间通常在3秒以上。在等待切换期间内，业务流量仍会发往Master设备，此时会造成数据丢失。通过部署VRRP与BFD联动功能，可以有效解决上述问题。通过在Master设备和Backup设备之间建立BFD会话并与VRRP备份组进行绑定，快速检测VRRP备份组之间的连通状态，并在出现故障时及时通知VRRP备份组进行主备切换，实现了毫秒级的切换速度，减少了流量丢失。 VRRP支持与静态的BFD会话类型或静态标识符自协商的BFD会话类型的联动。 VRRP配置配置注意事项：在路由器上部署VRRP功能时需注意： 不同备份组之间的虚拟IP地址不能重复，并且必须和接口的IP地址在同一网段。 保证同一备份组的设备上配置相同的备份组号（virtual-router-id）。 不同接口上可以绑定相同virtual-router-id的VRRP备份组。 在设备上同时配置VRRP和静态ARP时，需要注意：当在Dot1q终结子接口、QinQ终结子接口或者VLANIF接口下配置VRRP时，不能将与这些接口相关的静态ARP表项对应的映射IP地址作为VRRP的虚拟地址。否则会生成错误的主机路由，影响设备之间的正常转发。 如果VRRP备份组内各路由器上配置的VRRP协议版本不同，可能导致VRRP报文不能互通。 缺省配置： 参数 缺省值 设备在VRRP备份组中的优先级 100 抢占方式 立即抢占 通告报文发送间隔 1秒 发送免费ARP报文时间间隔 120秒 配置基于IPv4的VRRP基本功能：创建VRRP备份组：12[接口视图] vrrp vrid 1 virtual-ip 192.168.1.1//创建VRRP备份组并给备份组配置虚拟IP地址。 多网关负载分担 实现多网关负载分担，需要重复执行上述“主备备份”的操作步骤，在接口上配置两个或多个VRRP备份组，各备份组之间以备份组号（virtual-router-id）区分。 配置设备在备份组中的优先级：VRRP根据优先级决定设备在备份组中的地位，优先级越高，越可能成为Master设备。通过配置优先级，可以指定Master设备，以承担流量转发业务。 123[接口视图] vrrp vrid 1 priority 100//配置路由器在备份组中的优先级。//缺省情况下，优先级的取值是100。数值越大，优先级越高。 优先级0被系统保留作为特殊用途；优先级值255保留给IP地址拥有者。通过命令可以配置的优先级取值范围是1～254。 IP地址拥有者的优先级固定为255，用户不能手动修改。但是，用户可以通过vrrp vrid virtual-router-id priority priority-value为IP地址拥有者配置一个非255的优先级（该优先级不会取代255，不生效），当VRRP备份组不再是IP地址拥有者时，其优先级为配置的优先级。 优先级取值相同的情况下，同时竞争Master时，备份组所在接口的主IP地址较大的成为Master设备；VRRP备份组中先切换至Master状态的设备为Master设备，其余Backup设备不再进行抢占。 配置VRRP协议的版本：基于IPv4的VRRP支持VRRPv2和VRRPv3两个版本。如果VRRP备份组内各路由器上配置的协议版本不同，可能导致VRRP报文不能互通。 配置了v2版本的备份组：只能发送和接收v2版本的VRRP通告报文。如果接收到v3版本的VRRP通告报文，则将此报文丢弃。 配置了v3版本的备份组：能接收v2或v3版本的VRRP通过报文，发送报文的格式可以选择配置，包括仅发送v2版本报文、仅发送v3版本报文和既发送v2版本报文也发送v3版本报文。使用时可以根据需要进行配置。 123456vrrp version &#123; v2 | v3 &#125;//配置当前设备的VRRP协议版本号。 默认v2。vrrp version-3 send-packet-mode &#123; v2-noly | v3-only | v2v3-both &#125;//配置VRRPv3发送通告报文的模式。//缺省情况下，VRRPv3版本备份组发送通告报文的模式为v3-only。 配置VRRP的时间参数: 功能 应用场景 配置VRRP通告报文的发送间隔 Master设备定时（Advertisement_Interval）向组内的Backup设备发送VRRP通告报文，通告自己工作正常。如果Backup设备在Master_Down_Interval定时器超时后仍未收到VRRP通告报文，则重新选举Master。网络流量过大或设备的定时器差异等因素会导致Backup设备无法及时接收到VRRP报文而发生状态转换，当原Master发送的报文到达新Master时，新Master将再次发生状态切换。通过延长Master设备发送VRRP报文的时间间隔可以解决此类问题。 配置路由器在VRRP备份组中的抢占延时 在不稳定的网络中，可能存在VRRP备份组监测的BFD等状态频繁振荡或Backup设备不能及时收到VRRP通告报文的情况，导致VRRP发生频繁切换而造成网络振荡。通过调整路由器在VRRP备份组中的抢占延时，使Backup设备在指定的时间后再进行抢占，有效避免了VRRP备份组状态的频繁切换。 配置Master设备发送免费ARP报文的超时时间 VRRP备份组中，为了确保下游交换机的MAC表项正确，Master设备会定时发送免费ARP报文，用来刷新下游交换机上的MAC地址表项。说明： 为避免VRRP协议震荡，请不要在VRRP备用设备上把系统MAC或VRRP虚MAC等一些特殊的MAC地址配置成黑洞MAC。 配置VRRP备份组的状态恢复延迟时间 在不稳定的网络中，VRRP备份组监测的BFD或接口等状态频繁振荡会导致VRRP备份组状态频繁切换。通过配置VRRP备份组的状态恢复延迟时间，VRRP备份组在接收到接口或BFD会话的Up事件时不会立刻响应，而是等待配置的状态恢复的延迟时间后，再进行相应的处理，防止因接口或BFD会话的频繁震荡而导致的VRRP状态的频繁切换。 12345678910111213141516171819[接口视图] vrrp vrid 1 timer advertise 1 //置发送VRRP通告报文的时间间隔。 //缺省情况下，发送VRRP通告报文的时间间隔是1秒。 [接口视图] vrrp vrid 1 preempt-mode timer delay 0 //配置备份组中路由器的抢占延迟时间。 //缺省情况下，抢占延迟时间为0，即立即抢占。 vrrp vrid 1 preempt-mode disable //设置备份组中路由器采用非抢占方式。 vrrp gratuitous-arp timeout 120//配置Master发送免费ARP报文的超时时间。 //缺省情况下，Master每隔120秒发送一次免费ARP报文。vrrp gratutious-arp timeout disable//禁止发送免费ARPvrrp recover-deley 0//配置VRRP备份组的状态恢复延迟时间。 //缺省情况下，VRRP备份组状态恢复延迟时间为0秒。 在配置VRRP备份组内各路由器的延迟方式时，建议Backup设备配置为立即抢占，Master设备配置为延时抢占，指定一定的延迟时间。这样配置的目的是为了在网络环境不稳定时，为上下行链路的状态恢复一致性等待一定时间，以免出现双Master设备或由于主备双方频繁抢占导致用户设备学习到错误的Master设备地址。 配置的Master设备发送免费ARP报文超时时间应小于用户侧设备的MAC地址表项老化时间。 配置VRRP报文在Sub-VLAN中的发送方式：当VRRP备份组配置在VLAN聚合时，用户可以通过命令行配置，使VRRP报文在指定的Sub-VLAN中传输，避免VRRP通告报文在所有Sub-VLAN内广播，以节约网络带宽。 12vrrp advertise send-mode &#123; sub-vlan | all&#125;//配置VRRP通告报文在Super-VLAN中的发送方式。 缺省情况下，Master设备向Super-VLAN中状态为Up且VLAN ID最小的Sub-VLAN发送VRRP通告报文。 如果指定参数sub-vlan-id，VRRP通告报文只发送给指定ID的Sub-VLAN。 如果指定参数all，VRRP通告报文发送给本Super-VLAN的所有Sub-VLAN。 配置禁止检测VRRP报文跳数：系统对收到的VRRP通告报文的TTL值进行检测，如果TTL值不等于255，则丢弃这个报文。在不同设备制造商的设备配合使用的组网环境中，检测VRRP报文的TTL值可能导致错误地丢弃合法报文，此时用户可以配置系统不检测VRRP报文的TTL值，以实现不同设备制造商设备之间的互通。 12vrrp un-check ttl//禁止检测VRRP报文的TTL值。 配置VRRP报文的认证方式：VRRPv2支持在通告报文中设定不同的认证方式和认证字。 无认证方式：设备对要发送的VRRP通告报文不进行任何认证处理，收到通告报文的设备也不进行任何认证，认为收到的都是真实的、合法的VRRP报文。 简单字符（Simple）认证方式：发送VRRP通告报文的设备将认证方式和认证字填充到通告报文中，而收到通告报文的设备则会将报文中的认证方式和认证字与本端配置的认证方式和认证字进行匹配。如果相同，则认为接收到的报文是合法的VRRP通告报文；否则认为接收到的报文是一个非法报文，并丢弃这个报文。 MD5认证方式：发送VRRP通告报文的设备利用MD5算法对认证字进行加密，加密后保存在Authentication Data字段中。收到通告报文的设备会对报文中的认证方式和解密后的认证字进行匹配，检查该报文的合法性。 注：目前仅VRRPv2版本支持认证，VRRPv3版本不支持认证。VRRPv2版本保留报文的认证字段，是为了兼容早期版本（RFC2338），VRRP认证并不能提高安全性。 12vrrp vrid 1 authentication-mode &#123; simple &#123;key | plain key | cipher cipher-key&#125; | md5 md5-key&#125;//配置VRRP报文认证方式。 使能虚拟IP地址Ping功能：路由器支持对虚拟IP地址的Ping功能，可用于： 检测备份组中的Master设备是否起作用。 检测是否能通过使用某虚拟IP地址作为默认网关与外部通信。 1234567vrrp virtual-ip ping enable//使能虚拟地址可达性功能。 //缺省情况下，该功能处于使能状态，Master设备响应对本备份组虚拟IP地址的Ping报文。vrrp arp send-mode simple//使能Master设备使用QinQ终结子接口下配置的外层Tag//的VLAN和内层Tag段内的第一个VLAN发送免费ARP报文。 VRRP配置综合实验示例：如下图拓扑，AR1，AR2为内网路由器，配置VRRP虚拟IP实现备份。同时在AR1与AR2之间配置了BFD，使它们之间可以快速检测链路故障。 AR3,4,5为外网路由器。在AR1与AR3上配置了上行接口检测，当上行接口GE1/0/0状态Down时，VRRP备份组能够及时感知并进行主备切换，由AR2接替作为网关继续承担业务转发，以减小接口状态Down对业务传输的影响。 在AR2和上还配置了IP检测，检测到4.4.4.4 的链路是否有故障。 配置VRRP与路由联动监视上行链路。当非直连上行链路Down时，VRRP优先级自动降低，实现主备快速切换。 在AR1和AR2上还配置了负载分担。现在内网流量通过不同网关走不同路由器。 在AR2上配置的检测到4.4.4.4网段的NQA，ICMP直连检测，当传输质量低于百分之八十时，VRRP vrid 2 优先级自动降低，实现主备快速切换。 图：VRRP综合实验拓扑图 配置文件：AR1： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;AR1&gt;dis current-configuration # sysname AR1#vrrp gratuitous-arp timeout 100//配置免费ARP发送时间间隔为100svrrp version v3//VRRP选择版本v3vrrp recover-delay 3//VRRP 恢复延迟3s#bfd#acl number 2000 rule 5 permit source 192.168.1.0 0.0.0.255 rule 10 permit source 192.168.2.0 0.0.0.255 rule 15 deny #interface GigabitEthernet0/0/0 ip address 13.1.1.1 255.255.255.0 nat outbound 2000 //nat ，easy IP，实现内网到外网的地址转换#interface GigabitEthernet0/0/1 ip address 192.168.1.1 255.255.255.0 vrrp vrid 1 virtual-ip 192.168.1.254 vrrp vrid 1 priority 110 vrrp vrid 1 timer advertise 2 vrrp vrid 1 track interface GigabitEthernet0/0/0 reduced 30 vrrp vrid 1 version-3 send-packet-mode v2v3-both vrrp vrid 1 track ip route 4.4.4.4 255.255.255.0 reduced 30 vrrp vrid 1 authentication-mode md5 %$%$[U*W7Y)upJ3N*0#HA_x~~A=8%$%$ //VRRP vrid 1 认证密码 huawei vrrp vrid 2 virtual-ip 192.168.1.253 vrrp vrid 2 version-3 send-packet-mode v2v3-both#bfd 1 bind peer-ip 192.168.1.2 source-ip 192.168.1.1 auto commit#rip 1 version 2 network 13.0.0.0# AR2： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;AR2&gt;display current-configuration # sysname AR2#bfd#acl number 2000 rule 5 permit source 192.168.1.0 0.0.0.255 rule 10 permit source 192.168.2.0 0.0.0.255 rule 15 deny #interface GigabitEthernet0/0/0 ip address 25.1.1.2 255.255.255.0 nat outbound 2000#interface GigabitEthernet0/0/1 ip address 192.168.1.2 255.255.255.0 vrrp vrid 1 virtual-ip 192.168.1.254 vrrp vrid 1 preempt-mode timer delay 3 vrrp vrid 1 authentication-mode md5 %$%$)vYYTI4Nv=@M5_0,Yx^/~BLU%$%$ vrrp vrid 2 virtual-ip 192.168.1.253 vrrp vrid 2 track nqa vrrp test reduced 20#interface GigabitEthernet0/0/2#interface NULL0#bfd 1 bind peer-ip 192.168.1.1 source-ip 192.168.1.2 auto commit#rip 1 version 2 network 25.0.0.0#nqa test-instance vrrp test test-type icmp destination-address ipv4 4.4.4.4 fail-percent 80 frequency 20 probe-count 5 start now# AR3： 123456789101112131415161718&lt;AR3&gt;dis current-configuration # sysname AR3#interface GigabitEthernet0/0/0 ip address 13.1.1.3 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 23.1.1.3 255.255.255.0 #interface GigabitEthernet0/0/2 ip address 34.1.1.3 255.255.255.0 #rip 1 version 2 network 34.0.0.0 network 13.0.0.0# AR4： 12345678910111213141516171819&lt;AR4&gt;dis current-configuration # sysname AR4#interface GigabitEthernet0/0/0 ip address 34.1.1.4 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 45.1.1.4 255.255.255.0 #interface LoopBack0 ip address 4.4.4.4 255.255.255.255 #rip 1 version 2 network 34.0.0.0 network 45.0.0.0 network 4.0.0.0# AR5： 1234567891011121314[AR5]dis current-configuration # sysname AR5#interface GigabitEthernet0/0/0 ip address 45.1.1.5 255.255.255.0 #interface GigabitEthernet0/0/1 ip address 25.1.1.5 255.255.255.128 #rip 1 version 2 network 25.0.0.0 network 45.0.0.0 在AR1上VRRP的信息状态： 图：AR1上的VRRP的信息]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP Snooping]]></title>
    <url>%2F2017%2F12%2F09%2FDHCP-Snooping%2F</url>
    <content type="text"><![CDATA[DHCP Snooping简介DHCP Snooping是DHCP（Dynamic Host Configuration Protocol）的一种安全特性，用于保证DHCP客户端从合法的DHCP服务器获取IP地址，并记录DHCP客户端IP地址与MAC地址等参数的对应关系，防止网络上针对DHCP攻击。 目前DHCP协议（RFC2131）在应用的过程中遇到很多安全方面的问题，网络中存在一些针对DHCP的攻击，如DHCP Server仿冒者攻击、DHCP Server的拒绝服务攻击、仿冒DHCP报文攻击等。 为了保证网络通信业务的安全性，可引入DHCP Snooping技术，在DHCP Client和DHCP Server之间建立一道防火墙，以抵御网络中针对DHCP的各种攻击。 受益： 设备具有防御网络上DHCP攻击的能力，增强了设备的可靠性，保障通信网络的正常运行。 为用户提供更安全的网络环境，更稳定的网络服务。 DHCP Snooping原理描述基本原理：信任功能：DHCP Snooping的信任功能，能够保证客户端从合法的服务器获取IP（Internet Protocol）地址。 网络中如果存在私自架设的DHCP Server仿冒者，则可能导致DHCP客户端获取错误的IP地址和网络配置参数，无法正常通信。DHCP Snooping信任功能可以控制DHCP服务器应答报文的来源，以防止网络中可能存在的DHCP Server仿冒者为DHCP客户端分配IP地址及其他配置信息。 信任接口正常接收DHCP服务器响应的DHCP ACK、DHCP NAK和DHCP Offer报文。 非信任接口在接收到DHCP服务器响应的DHCP ACK、DHCP NAK和DHCP Offer报文后，丢弃该报文。 管理员在部署网络时，一般将与合法DHCP服务器直接或间接连接的接口设置为信任接口，其他接口设置为非信任接口，从而保证DHCP客户端只能从合法的DHCP服务器获取IP地址，私自架设的DHCPServer仿冒者无法为DHCP客户端分配IP地址。 分析功能：开启DHCP Snooping功能后，设备能够通过分析DHCP的报文交互过程，生成DHCP Snooping绑定表，绑定表项包括客户端的MAC地址、获取到的IP地址、与DHCP客户端连接的接口及该接口所属的VLAN（Virtual Local Area Network）等信息。 DHCP Snooping绑定表根据DHCP租期进行老化或根据用户释放IP地址时发出的DHCP Release报文自动删除对应表项。 出于安全性的考虑，管理员需要记录用户上网时所用的IP地址，确认用户申请的IP地址和用户使用的主机的MAC地址的对应关系。在设备通过DHCP Snooping功能生成绑定表后，管理员可以方便的记录DHCP用户申请的IP地址与所用主机的MAC地址之间的对应关系。 由于DHCP Snooping绑定表记录了DHCP客户端IP地址与MAC地址等参数的对应关系，故通过对报文与DHCP Snooping绑定表进行匹配检查，能够有效防范非法用户的攻击。 为了保证设备在生成DHCP Snooping绑定表时能够获取到用户MAC等参数，DHCP Snooping功能需应用于二层网络中的接入设备或第一个DHCP Relay上。 DHCP Snooping支持的Option82功能：概述：在传统的DHCP动态分配IP地址过程中，DHCP Server不能够根据DHCP请求报文感知到用户的具体物理位置，以致同一VLAN的用户得到的IP地址所拥有的权限是完全相同的。由于网络管理者不能对同一VLAN中特定的用户进行有效的控制，即不能够控制客户端对网络资源的访问，这将给网络的安全控制提出了严峻的挑战。 RFC 3046定义了DHCP Relay Agent Information Option（Option 82），该选项记录了DHCP Client的位置信息。DHCP Snooping设备或DHCP Relay通过在DHCP请求报文中添加Option82选项，将DHCP Client的精确物理位置信息传递给DHCP Server，从而使得DHCP Server能够为主机分配合适的IP地址和其他配置信息，实现对客户端的安全控制。 Option82包含两个常用子选项Circuit ID和Remote ID。其中Circuit ID子选项主要用来标识客户端所在的VLAN、接口等信息，Remote ID子选项主要用来标识客户端接入的设备，一般为设备的MAC地址。 设备作为DHCP Relay时，使能或未使能DHCP Snooping功能都可支持Option82选项功能，但若设备在二层网络作为接入设备，则必须使能DHCP Snooping功能方可支持Option82功能。 Option82选项仅记录了DHCP用户的精确物理位置信息并通过DHCP请求报文中将该信息发送给DHCP Server。而如果需要对不同的用户部署不同的地址分配或安全策略，则需DHCP Server支持Option82功能并在其上已配置了IP地址分配或安全策略。 Option82选项携带的用户位置信息与DHCP Snooping绑定表记录的用户参数是两个相互独立的概念，没有任何关联。Option82选项携带的用户位置信息是在DHCP用户申请IP地址时（此时用户还未分配到IP地址），由设备添加到DHCP请求报文中。DHCP Snooping绑定表是在设备收到DHCP Server回应的DHCP Ack报文时（此时已为用户分配了IP地址），设备根据DHCP Ack报文信息自动生成。 实现： Insert方式：当设备收到DHCP请求报文时，若该报文中没有Option82选项，则插入Option82选项；若该报文中含有Option82选项，则判断Option82选项中是否包含remote-id，如果包含，则保持Option82选项不变，如果不包含，则插入remote-id。 Rebuild方式：当设备收到DHCP请求报文时，若该报文中没有Option82选项，则插入Option82选项；若该报文中含有Option82选项，则删除该Option82选项并插入管理员自己在设备上配置的Option82选项。 对于Insert和Rebuild两种方式，当设备接收到DHCP服务器的响应报文时，处理方式一致。 DHCP响应报文中有Option82选项： 如果设备收到的DHCP请求报文中没有Option82选项，则设备将删除DHCP响应报文中的Option82选项，之后转发给DHCP Client。 如果设备收到的DHCP请求报文中有Option82选项，则设备将DHCP响应报文中的Option82选项格式还原为DHCP请求报文中的Option82选项，之后转发给DHCP Client。 DHCP响应报文不含有Option82选项：直接转发。 DHCPv6 Snooping支持的LDRA功能：概述：RFC 6221定义了轻量级DHCPv6中继代理LDRA（Lightweight DHCPv6 Relay Agent），它是一种在DHCPv6交互报文中插入中继代理选项信息以标示用户位置的规范。 类似于DHCPv4网络中使用的Option82选项，在DHCPv6网络中可以使用LDRA获取用户详细的位置信息。LDRA一般部署在靠近用户的接入设备上。 实现：LDRA工作流程与DHCPv6中继工作流程相似。当接收到用户的DHCPv6请求报文时，部署LDRA功能的设备即会构建Relay-Forward报文并在其中封装用户的位置信息（如用户与设备连接的接口信息等）然后转发给DHCPv6 Server，从而使得DHCPv6 Server能够获取到DHCPv6 Client的物理位置信息进而为用户部署诸如IP地址分配、QoS、接入控制等策略。 LDRA工作过程： 图：LDRA工作流程图 DHCPv6客户端向LDRA设备发送DHCPv6报文。 LDRA设备收到客户端的DHCPv6报文后，将其封装在Relay-Forward报文的中继消息选项中，同时将用户的位置信息封装在Relay-Forward报文中的interface-id或remote-id中，之后将Relay-Forward报文发送给DHCPv6服务器。 DHCPv6服务器从Relay-Forward报文中解析出DHCPv6客户端的请求以及用户位置信息，之后根据用户位置信息为DHCPv6客户端选取IPv6地址和其他配置参数，构造应答消息，将应答消息封装在Relay-Reply报文中，并发送给LDRA设备。 LDRA设备从Relay-Reply报文中解析出DHCPv6服务器的应答，转发给DHCPv6客户端。DHCPv6客户端根据应答报文获取到DHCPv6服务器地址，后续从该服务器获取IPv6地址和其他网络配置参数。 DHCPv6 Snooping支持的Option18与Option37功能：Option18与Option37选项功能类似于Option82。Option82用于插入DHCPv4报文中，而对于DHCPv6报文则需插入Option18与Option37选项用于记录DHCPv6 Client的位置信息。 设备必须使能DHCPv6 snooping功能方可支持Option18与Option37选项功能。 DHCP 攻击：DHCP Server仿冒者攻击：攻击原理：由于DHCP Server和DHCP Client之间没有认证机制，所以如果在网络上随意添加一台DHCP服务器，它就可以为客户端分配IP地址以及其他网络参数。如果该DHCP服务器为用户分配错误的IP地址和其他网络参数，将会对网络造成非常大的危害。 解决方法：为了防止DHCP Server仿冒者攻击，可配置设备接口的“信任（Trusted）/非信任（Untrusted）”工作模式。 将与合法DHCP服务器直接或间接连接的接口设置为信任接口，其他接口设置为非信任接口。此后，从“非信（Untrusted）”接口上收到的DHCP回应报文将被直接丢弃，这样可以有效防止DHCP Server仿冒者的攻击。 配置防止DHCP Server仿冒者攻击：在使能DHCP Snooping功能并配置了接口的信任状态之后，设备将能够保证客户端从合法的服务器获取IP地址，这将能够有效的防止DHCP Server仿冒者攻击。但是此时却不能够定位DHCP Server仿冒者的位置，使得网络中仍然存在着安全隐患。 通过配置DHCP Server探测功能，DHCP Snooping设备将会检查并在日志中记录所有DHCP回应报文中携带的DHCP Server地址与接口等信息，此后网络管理员可根据日志来判定网络中是否存在伪DHCP Server进而对网络进行维护。 1dhcp server detect//使能DHCP Server探测功能。 仿冒DHCP报文攻击：攻击原理：已获取到IP地址的合法用户通过向服务器发送DHCP Request或DHCP Release报文用以续租或释放IP地址。如果攻击者冒充合法用户不断向DHCP Server发送DHCP Request报文来续租IP地址，会导致这些到期的IP地址无法正常回收，以致一些合法用户不能获得IP地址；而若攻击者仿冒合法用户的DHCP Release报文发往DHCP Server，将会导致用户异常下线。 解决方法：为了有效的防止仿冒DHCP报文攻击，可利用DHCP Snooping绑定表的功能。设备通过将DHCP Request续租报文和DHCP Release报文与绑定表进行匹配操作能够有效的判别报文是否合法（主要是检查报文中的VLAN、IP、MAC、接口信息是否匹配动态绑定表），若匹配成功则转发该报文，匹配不成功则丢弃。 配置防止仿冒DHCP报文攻击：12dhcp snooping check user-bind enable//使能对DHCP报文进行绑定表匹配检查的功能。 DHCP Server服务拒绝攻击：攻击原理：若设备接口interface1下存在大量攻击者恶意申请IP地址，会导致DHCP Server中IP地址快速耗尽而不能为其他合法用户提供IP地址分配服务。 另一方面，DHCP Server通常仅根据DHCP Request报文中的CHADDR（Client Hardware Address）字段来确认客户端的MAC地址。如果某一攻击者通过不断改变CHADDR字段向DHCP Server申请IP地址，同样将会导致DHCP Server上的地址池被耗尽，从而无法为其他正常用户提供IP地址。 解决方法：为了抑制大量DHCP用户恶意申请IP地址，在使能设备的DHCP Snooping功能后，可配置设备或接口允许接入的最大DHCP用户数，当接入的用户数达到该值时，则不再允许任何用户通过此设备或接口成功申请到IP地址。 而对通过改变DHCP Request报文中的CHADDR字段方式的攻击，可使能设备检测DHCP Request报文帧头MAC与DHCP数据区中CHADDR字段是否一致功能，此后设备将检查上送的DHCP Request报文中的帧头MAC地址是否与CHADDR值相等，相等则转发，否则丢弃。 配置防止DHCP Server服务拒绝攻击:12345678dhcp snooping max-user-number 10// 配置接口允许学习的DHCP Snooping绑定表项的最大个数。 dhcp snooping check mac-address enable//能检测DHCP Request报文帧头MAC与DHCP数据区中CHADDR字段是否一致功能。 dhcp snooping alarm threshold 100//配置全局DHCP Snooping丢弃报文数量的告警阈值。 dhcp snooping alarm mac-address threshold 100//配置帧头MAC地址与DHCP数据区中CHADDR字段不匹配而被丢弃的DHCP报文的告警阈值。 配置命令行： 使能DHCP Snooping功能的顺序是先使能全局下的DHCP Snooping功能，再使能接口或VLAN下的DHCP Snooping功能。 1dhcp snooping enable [ipv4 | ipv6] 为使DHCP客户端能通过合法的DHCP服务器获取IP地址，需将与管理员信任的DHCP服务器直接或间接连接的设备接口设置为信任接口，其他接口设置为非信任接口。从而保证DHCP客户端只能从合法的DHCP服务器获取IP地址，私自架设的DHCP Server仿冒者无法为DHCP客户端分配IP地址。 在连接用户的接口或VLAN下使能DHCP Snooping功能之后，需将连接DHCP服务器的接口配置为“信任”模式，两者同时生效设备即能够生成DHCP Snooping动态绑定表。 12dhcp snooping trusted //配置接口为“信任”接口。 在移动应用场景中，若某一用户由接口A上线后，然后切换到接口B，这时为了让用户能够上线，需要使能DHCP Snooping用户位置迁移功能。 12dhcp snooping user-transfer enable //使能DHCP Snooping用户位置迁移功能。 配置ARP与DHCP Snooping的联动功能 DHCP Snooping设备在收到DHCP用户发出的DHCP Release报文时将会删除该用户对应的绑定表项，但若用户发生了异常下线而无法发出DHCP Release报文时，DHCP Snooping设备将不能够及时的删除该DHCP用户对应的绑定表。 使能ARP与DHCP Snooping的联动功能，如果DHCP Snooping表项中的IP地址对应的ARP表项达到老化时间，则DHCP Snooping设备会对该IP地址进行ARP探测，如果在规定的探测次数内探测不到用户，设备将删除用户对应的ARP表项。之后，设备将会再次按规定的探测次数对该IP地址进行ARP探测，如果最后仍不能够探测到用户，则设备将会删除该用户对应的绑定表项。 只有设备作为DHCP Relay时，才支持ARP与DHCP Snooping的联动功能。 12arp dhcp-Snooping-detect enable //使能ARP与DHCP Snooping的联动功能。 配置丢弃Giaddr字段非0的DHCP报文 DHCP报文中的GIADDR（Gateway Ip Address）字段记录了DHCP报文经过的第一个DHCP Relay的IP地址，当客户端发出DHCP请求时，如果服务器和客户端不在同一个网段，那么第一个DHCP Relay在将DHCP请求报文转发给DHCP服务器时，会把自己的IP地址填入此字段，DHCP服务器会根据此字段来判断出客户端所在的网段地址，从而选择合适的地址池，为客户端分配该网段的IP地址。 在为了保证设备在生成DHCP Snooping绑定表时能够获取到用户MAC等参数，DHCP Snooping功能需应用于二层网络中的接入设备或第一个DHCP Relay上。故DHCP Snooping设备接收到的DHCP报文中GIADDR字段必然为零，若不为零则该报文为非法报文，设备需丢弃此类报文。 12dhcp snooping check dhcp-giaddr enable//使能检测DHCP Request报文中GIADDR字段是否非零的功能。 去使能接口DHCP Snooping功能 若使能了某一VLAN的DHCP Snooping功能，则VLAN内所有的接口均使能了DHCP Snooping功能。此时如果需要去使能一特定接口的DHCP Snooping功能，可使用命令dhcp snooping disable去使能特定接口的DHCPSnooping功能。此后该接口下的用户将能正常上线，但是并不会生成DHCP动态绑定表。 配置DHCP Snooping的攻击防范功能：如下图，在SW1上配置DHCP Snooping的一些功能，防范DHCP的各种攻击. 使能DHCP Snooping功能。 配置接口的信任状态，以保证客户端从合法的服务器获取IP地址。 使能ARP与DHCP Snooping的联动功能，保证DHCP用户在异常下线时实时更新绑定表。 使能对DHCP报文进行绑定表匹配检查的功能，防止仿冒DHCP报文攻击。 配置允许接入的最大用户数以及使能检测DHCP Request报文帧头MAC与DHCP数据区中CHADDR字段是否一致功能，防止DHCP Server服务拒绝攻击。 配置丢弃报文告警和报文限速告警功能。 图：DHCP Snooping攻击防范 配置文件：AR1: 1234567891011&lt;DHCP&gt;display current-configuration sysname DHCP#dhcp enable#dhcp snooping enable#interface GigabitEthernet0/0/0 ip address 192.168.0.1 255.255.255.0 dhcp select interface //开启接口DHCP功能# SW1： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;SW&gt;dis current-configuration #sysname SW#dhcp enable#dhcp snooping enable#arp dhcp-snooping-detect enable //使能ARP与DHCP Snooping的联动功能。#interface GigabitEthernet0/0/1 dhcp snooping trusted //配置上联口为信任端口#interface GigabitEthernet0/0/2 dhcp snooping sticky-mac dhcp snooping enable dhcp snooping check dhcp-giaddr enable //使能检测DHCP报文中GIADDR字段是否非零的功能。 dhcp snooping check dhcp-request enable dhcp snooping alarm dhcp-request enable// 使能DHCP Snooping告警功能。 dhcp snooping alarm dhcp-request threshold 100 //配置DHCP Snooping丢弃报文数量的告警阈值。 dhcp snooping check dhcp-chaddr enable dhcp snooping alarm dhcp-chaddr enable dhcp snooping alarm dhcp-chaddr threshold 100 dhcp snooping check dhcp-rate enable dhcp snooping alarm dhcp-rate enable dhcp snooping alarm dhcp-rate threshold 100 dhcp snooping alarm dhcp-reply enable dhcp snooping alarm dhcp-reply threshold 100 dhcp snooping max-user-number 100 //配置接口允许学习的DHCP Snooping绑定表项的最大个数 dhcp option82 insert enable#interface GigabitEthernet0/0/3 dhcp option82 insert enable //配置在DHCP报文中添加的Option82选项的格式。# SW2,3: 123456789101112#interface GigabitEthernet0/0/1 dhcp snooping trusted dhcp option82 insert enable#interface GigabitEthernet0/0/2 dhcp option82 insert enable dhcp option82 format common#interface GigabitEthernet0/0/3 dhcp option82 rebuild enable# 图：SW1中DHCP Snooping状态]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
        <tag>DHCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP]]></title>
    <url>%2F2017%2F12%2F09%2FDHCP%2F</url>
    <content type="text"><![CDATA[DHCP简介动态主机配置协议DHCP（Dynamic Host Configuration Protocol）是一种用于集中对用户IP地址进行动态管理和配置的技术。 DHCP采用客户端/服务器通信模式，由客户端（DHCP Client）向服务器（DHCP Server）提出配置申请，服务器返回为客户端分配的配置信息（包括IP地址、缺省网关、DNS Server、WINS Server等参数），可以实现IP地址动态分配，以及其他网络参数的集中配置管理。 DHCP的发展：DHCP是在BOOTP（BOOTstrap Protocol）基础上发展而来，但BOOTP运行在相对静态（每台主机都有固定的网络连接）的环境中，管理员为每台主机配置专门的BOOTP参数文件，该文件会在相当长的时间内保持不变。DHCP从以下两方面对BOOTP进行了扩展： DHCP加入了对重新使用的网络地址的动态分配和附加配置选项的功能，可使计算机仅用一个消息就获取它所需要的所有配置信息。 DHCP允许计算机动态地获取IP地址，而不是静态为每台主机指定地址。 DHCP技术实现用户地址和配置信息的动态分配和集中管理，使企业可以动态地为企业用户分配和管理地址，避免繁琐的手工配置，可以快速适应网络的变化。 DHCP原理描述DHCP角色： DHCP客户端：通过DHCP协议请求获取IP地址等网络参数的设备。例如，IP电话、PC、手机、无盘工作站等。 DHCP服务器：负责为DHCP客户端分配网络参数的设备。 （可选）DHCP中继：负责转发DHCP服务器和DHCP客户端之间的DHCP报文，协助DHCP服务器向DHCP客户端动态分配网络参数的设备。 DHCP客户端广播发送请求报文（即目的IP地址为255.255.255.255），位于同一网段内的DHCP服务器能够接收请求报文。如果DHCP客户端和DHCP服务器不在同一个网段，DHCP服务器无法接收来自客户端的请求报文，此时，需要通过DHCP中继来转发DHCP报文。不同于传统的IP报文转发，DHCP中继接收到DHCP请求或应答报文后，会重新修改报文格式并生成一个新的DHCP报文再进行转发。 在企业网络中，如果需要规划较多网段，且网段中的终端都需要通过DHCP自动获取IP地址等网络参数时，可以部署DHCP中继。这样，不同网段的终端可以共用一个DHCP服务器，节省了服务器资源，方便统一管理。 DHCP报文是基于UDP协议传输的。DHCP客户端向DHCP服务器发送报文时采用67端口号，DHCP服务器向DHCP客户端发送报文时采用68端口号。 DHCP服务器给首次接入网络的客户端分配网络参数的工作原理：无中继场景时DHCP客户端首次接入网络的工作原理： 图：无中继场景DHCP客户端首次接入网络的报文交互示意图 发现阶段，即DHCP客户端发现DHCP服务器的阶段。 DHCP客户端发送DHCP DISCOVER报文来发现DHCP服务器。由于DHCP客户端不知道DHCP服务器的IP地址，所以DHCP客户端以广播方式发送DHCP DISCOVER报文（目的IP地址为255.255.255.255），同一网段内所有DHCP服务器或中继都能收到此报文。DHCP DISCOVER报文中携带了客户端的MAC地址（DHCP DISCOVER报文中的chaddr字段）、需要请求的参数列表选项（Option55中填充的内容，标识了客户端需要从服务器获取的网络配置参数）、广播标志位（DHCP DISCOVER报文中的flags字段，表示客户端请求服务器以单播或广播形式发送响应报文）等信息。 DHCP DISCOVER报文中的Option字段定义了网络参数信息，不同Option值代表了不同的参数。例如，Option3表示客户端的网关地址选项（当客户端发送的DHCP DISCOVER报文的Option55中填充了选项值3，就表示客户端希望从服务器获取网关地址）；Option53表示DHCP报文类型（例如，DHCP DISCOVER报文）。Option选项分为知名选项和自定义选项，关于知名选项的含义请参见RFC2132。除了RFC2132里面定义的知名选项，不同厂商可以根据需求自己定义自定义选项，例如，Option43为厂商特定信息选项。 RFC2131中定义了DHCP报文的广播标志字段（flags），当标志字段的最高位为0时，表示客户端希望服务器以单播方式发送DHCP OFFER/DHCP ACK报文；当标志字段的最高位为1时，表示客户端希望服务器以广播方式发送DHCP OFFER/DHCP ACK报文。Huawei AR100&amp;AR120&amp;AR150&amp;AR160&amp;AR200&amp;AR1200&amp;AR2200&amp;AR3200&amp;AR3600系列作为客户端时，此字段为1。 提供阶段，即DHCP服务器提供网络配置信息的阶段。 位于同一网段的DHCP服务器都会接收到DHCP DISCOVER报文，每个DHCP服务器上可能会部署多个地址池，服务器通过地址池来管理可供分配的IP地址等网络参数。服务器接收到DHCP DISCOVER报文后，选择跟接收DHCP DISCOVER报文接口的IP地址处于同一网段的地址池，并且从中选择一个可用的IP地址，然后通过DHCP OFFER报文发送给DHCP客户端。DHCP OFFER报文里面携带了希望分配给指定MAC地址客户端的IP地址（DHCP报文中的yiaddr字段）及其租期等配置参数。 通常，DHCP服务器的地址池中会指定IP地址的租期，如果DHCP客户端发送的DHCP DISCOVER报文中携带了期望租期，服务器会将客户端请求的期望租期与其指定的租期进行比较，选择其中时间较短的租期分配给客户端。 DHCP服务器上已配置的与客户端MAC地址静态绑定的IP地址。 客户端发送的DHCP DISCOVER报文中Option50字段（请求IP地址选项）指定的地址。 DHCP服务器上记录的曾经分配给客户端的IP地址。 按照IP地址从大到小的顺序查询，选择最先找到的可供分配的IP地址。 如果未找到可供分配的IP地址，则依次查询超过租期、处于冲突状态的IP地址，如果找到可用的IP地址，则进行分配；否则，发送DHCP NAK报文作为应答，通知DHCP客户端无法分配IP地址。DHCP客户端需要重新发送DHCP DISCOVER报文来申请IP地址。 为了防止分配出去的IP地址跟网络中其他客户端的IP地址冲突，DHCP服务器在发送DHCP OFFER报文前可以通过发送源地址和目的地址都为预分配出去IP地址的ICMP ECHO REQUEST报文对分配的IP地址进行地址冲突探测。如果在指定的时间内没有收到应答报文，表示网络中没有客户端使用这个IP地址，可以分配给客户端；如果指定时间内收到应答报文，表示网络中已经存在使用此IP地址的客户端，则把此地址列为冲突地址，然后等待重新接收到DHCP DISCOVER报文后按照前面介绍的选择IP地址的优先顺序重新选择可用的IP地址。 此阶段DHCP服务器分配给客户端的IP地址不一定是最终确定使用的IP地址，因为DHCP OFFER报文发送给客户端等待16秒后如果没有收到客户端的响应，此地址就可以继续分配给其他客户端。通过下面的选择阶段和确认阶段后才能最终确定客户端可以使用的IP地址。 选择阶段，即DHCP客户端选择IP地址的阶段。 因为DHCP DISCOVER报文是广播发送的，所以如果同一网段内存在多个DHCP服务器，接收到DHCP DISCOVER报文的服务器都会回应DHCP OFFER报文。如果有多个DHCP服务器向DHCP客户端回应DHCP OFFER报文，则DHCP客户端一般只接收第一个收到的DHCP OFFER报文，然后以广播方式发送DHCP REQUEST报文，该报文中包含客户端想选择的DHCP服务器标识符（即Option54）和客户端IP地址（即Option50，填充了接收的DHCP OFFER报文中yiaddr字段的IP地址）。 以广播方式发送DHCP REQUEST报文，是为了通知所有的DHCP服务器，它将选择某个DHCP服务器提供的IP地址，其他DHCP服务器可以重新将曾经分配给客户端的IP地址分配给其他客户端。 确认阶段，即DHCP服务器确认所分配IP地址的阶段。 当DHCP服务器收到DHCP客户端发送的DHCP REQUEST报文后，DHCP服务器回应DHCP ACK报文，表示DHCP REQUEST报文中请求的IP地址（Opton50填充的）分配给客户端使用。 DHCP客户端收到DHCP ACK报文，会广播发送免费ARP报文，探测本网段是否有其他终端使用服务器分配的IP地址，如果在指定时间内没有收到回应，表示客户端可以使用此地址。如果收到了回应，说明有其他终端使用了此地址，客户端会向服务器发送DECLINE报文，并重新向服务器请求IP地址，同时，服务器会将此地址列为冲突地址。当服务器没有空闲地址可分配时，再选择冲突地址进行分配，尽量减少分配出去的地址冲突。 当DHCP服务器收到DHCP客户端发送的DHCP REQUEST报文后，如果DHCP服务器由于某些原因（例如协商出错或者由于发送REQUEST过慢导致服务器已经把此地址分配给其他客户端）无法分配DHCP REQUEST报文中Opton50填充的IP地址，则发送DHCP NAK报文作为应答，通知DHCP客户端无法分配此IP地址。DHCP客户端需要重新发送DHCP DISCOVER报文来申请新的IP地址。 有中继场景时DHCP客户端首次接入网络的工作原理： 图：有中继场景时DHCP客户端首次接入网络的工作原理 发现阶段 检查DHCP报文中的hops字段，如果大于16，则丢弃DHCP报文；否则，将hops字段加1（表明经过一次DHCP中继），并继续下面的操作。 DHCP报文中的hops字段表示DHCP报文经过的DHCP中继的数目，该字段由客户端或服务器设置为0，每经过一个DHCP中继时，该字段加1。hops字段的作用是限制DHCP报文所经过的DHCP中继的数目。目前，设备最多支持DHCP客户端与服务器之间有存在16个中继。 检查DHCP报文中的giaddr字段。如果是0，将giaddr字段设置为接收DHCP DISCOVER报文的接口IP地址。如果不是0，则不修改该字段，继续下面的操作。 DHCP报文中的giaddr字段标识客户端网关的IP地址。如果服务器和客户端不在同一个网段且中间存在多个DHCP中继，当客户端发出DHCP请求时，第一个DHCP中继会把自己的IP地址填入此字段，后面的DHCP中继不修改此字段内容，DHCP服务器会根据此字段来判断出客户端所在的网段地址，从而为客户端分配该网段的IP地址。 将DHCP报文的目的IP地址改为DHCP服务器或下一跳中继的IP地址，源地址改为中继连接客户端的接口地址，通过路由转发将DHCP报文单播发送到DHCP服务器或下一跳中继。 如果DHCP客户端与DHCP服务器之间存在多个DHCP中继，后面的中继接收到DHCP DISCOVER报文的处理流程同前面所述。 提供阶段 DHCP服务器接收到DHCP DISCOVER报文后，选择与报文中giaddr字段为同一网段的地址池，并为客户端分配IP地址等参数然后向giaddr字段标识的DHCP中继单播发送DHCP OFFER报文。 检查报文中的giaddr字段，如果不是接口的地址，则丢弃该报文；否则，继续下面的操作。 DHCP中继检查报文的广播标志位。如果广播标志位为1，则将DHCP OFFER报文广播发送给DHCP客户端；否则将DHCP OFFER报文单播发送给DHCP客户端。 选择阶段 确认阶段 选择阶段和确认阶段的过程同无中继场景。 DHCP客户端重用曾经使用的地址的工作原理：DHCP客户端非首次接入网络时，可以重用曾经使用过的地址。 图：DHCP客户端重用曾经使用过的IP地址的报文交互过程 客户端广播发送包含前一次分配的IP地址的DHCP REQUEST报文，报文中的Option50（请求的IP地址选项）字段填入曾经使用过的IP地址。 DHCP服务器收到DHCP REQUEST报文后，根据DHCP REQUEST报文中携带的MAC地址来查找有没有相应的租约记录，如果有则返回DHCP ACK报文，通知DHCP客户端可以继续使用这个IP地址。否则，保持沉默，等待客户端重新发送DHCP DISCOVER报文请求新的IP地址。 DHCP客户端更新租期的工作原理：DHCP服务器采用动态分配机制给客户端分配IP地址时，分配出去的IP地址有租期限制。DHCP客户端向服务器申请地址时可以携带期望租期，服务器在分配租期时把客户端期望租期和地址池中租期配置比较，分配其中一个较短的租期给客户端。租期时间到后服务器会收回该IP地址，收回的IP地址可以继续分配给其他客户端使用。这种机制可以提高IP地址的利用率，避免客户端下线后IP地址继续被占用。如果DHCP客户端希望继续使用该地址，需要更新IP地址的租期（如延长IP地址租期）。 当租期达到50%（T1）时，DHCP客户端会自动以单播的方式向DHCP服务器发送DHCP REQUEST报文，请求更新IP地址租期。如果收到DHCP服务器回应的DHCP ACK报文，则租期更新成功（即租期从0开始计算）；如果收到DHCP NAK报文，则重新发送DHCP DISCOVER报文请求新的IP地址。 当租期达到87.5%（T2）时，如果仍未收到DHCP服务器的应答，DHCP客户端会自动以广播的方式向DHCP服务器发送DHCP REQUEST报文，请求更新IP地址租期。如果收到DHCP服务器回应的DHCP ACK报文，则租期更新成功（即租期从0开始计算）；如果收到DHCP NAK报文，则重新发送DHCP DISCOVER报文请求新的IP地址。 如果租期时间到时都没有收到服务器的回应，客户端停止使用此IP地址，重新发送DHCP DISCOVER报文请求新的IP地址。 客户端在租期时间到之前，如果用户不想使用分配的IP地址（例如客户端网络位置需要变更），会触发DHCP客户端向DHCP服务器发送DHCP RELEASE报文，通知DHCP服务器释放IP地址的租期。DHCP服务器会保留这个DHCP客户端的配置信息，将IP地址列为曾经分配过的IP地址中，以便后续重新分配给该客户端或其他客户端。 客户端可以通过发送DHCP INFORM报文向服务器请求更新配置信息。 DHCP报文：DHCP报文类型： DHCP Discover 由客户端来查找可用的服务器。 DHCP offer 服务器用来响应客户端的DHCP Discover报文，并指定相应的配置参数。 DHCP Resquet 由客户端发送给服务器来请求配置参数或者请求配置确认或者续借租期。 DHCP ACK 由服务器到客户端，含有配置参数包括IP地址。 DHCP Decline 当客户端发现地址已经被使用时，用来通知服务器。 DHCP Inform 客户端已经有IP地址时用它来向服务器请求其他的配置参数。 DHCP NAK 由服务器发送给客户端来报名客户端的地址请求不正确或者租期已过期。 DHCP Release 客户端要释放地址时用来通知服务器。 DHCP报文是承载于UDP上的高层协议报文，采用67（DHCP服务器）和68（DHCP客户端）两个端口号。 DHCP的报文格式如下图所示。 DHCP报文格式： 图：DHCP报文格式 报文字段解释： 字段 长度 含义 OP （op code） 1字节 表示报文的类型：1：客户端请求报文2：服务器响应报文 htype （hardware type） 1字节 表示硬件地址的类型。对于以太网，该类型的值为“1”。 hlen （hardware type） 1字节 表示硬件地址的长度，单位是字节。对于以太网，该值为6。 Hops 1字节 表示当前的DHCP报文经过的DHCP中继的数目。该字段由客户端或服务器设置为0，每经过一个DHCP中继时，该字段加1。此字段的作用是限制DHCP报文所经过的DHCP中继数目。 xid 4字节 事务ID，由客户端选择的一个随机数，被服务器和客户端用来在它们之间交流请求和响应，客户端用它对请求和应答进行匹配。该ID由客户端设置并由服务器返回，为32位整数。 secs (seconds) 2字节 由客户端填充，表示从客户端开始获得IP地址或IP地址续借后所使用了的秒数。 flags 2字节 此字段在BOOTP中保留未用，在DHCP中表示标志字段。只有标志字段的最高位才有意义，其余的位均被置为0。最左边的字段被解释为广播响应标志位，内容如下所示：0：客户端请求服务器以单播形式发送响应报文1：客户端请求服务器以广播形式发送响应报文 ciaddr (client ip address) 4字节 表示客户端的IP地址。可以是服务器分配给客户端的IP地址或者客户端已有的IP地址。客户端在初始化状态时没有IP地址，此字段为0.0.0.0。IP地址0.0.0.0仅在采用DHCP方式的系统启动时允许本主机利用它进行临时的通信，不是有效目的地址。 yiaddr (your client ip address) 4字节 表示服务器分配给客户端的IP地址。当服务器进行DHCP响应时，将分配给客户端的IP地址填入此字段。 siaddr (server ip address) 4字节 DHCP客户端获得启动配置信息的服务器的IP地址。 giaddr （gateway ip address） 4字节 该字段表示第一个DHCP中继的IP地址（注意：不是地址池中定义的网关）。当客户端发出DHCP请求时，如果服务器和客户端不在同一个网络中，那么第一个DHCP中继在转发这个DHCP请求报文时会把自己的IP地址填入此字段。服务器会根据此字段来判断出网段地址，从而选择为用户分配地址的地址池。服务器还会根据此地址将响应报文发送给此DHCP中继，再由DHCP中继将此报文转发给客户端。若在到达DHCP服务器前经过了不止一个DHCP中继，那么第一个DHCP中继后的中继不会改变此字段，只是把Hops的数目加1。 chaddr (client hardware address) 16字节 该字段表示客户端的MAC地址，此字段与前面的“Hardware Type”和“Hardware Length”保持一致。当客户端发出DHCP请求时，将自己的硬件地址填入此字段。对于以太网，当“Hardware Type”和“Hardware Length”分别为“1”和“6”时，此字段必须填入6字节的以太网MAC地址。 sname (server host name) 64字节 该字段表示客户端获取配置信息的服务器名字。此字段由DHCP Server填写，是可选的。如果填写，必须是一个以0结尾的字符串。 file (file name) 128字节 该字段表示客户端的启动配置文件名。此字段由DHCP Server填写，是可选的，如果填写，必须是一个以0结尾的字符串。 options 可变 该字段表示DHCP的选项字段，至少为312字节，格式为”代码+长度+数据”。DHCP通过此字段包含了服务器分配给终端的配置信息，如网关IP地址，DNS服务器的IP地址，客户端可以使用IP地址的有效租期等信息。 DHCP报文抓包示例： 图：DHCP报文抓包示例 DHCP Opthion字段选项：DHCP报文中的Options字段可以用来存放普通协议中没有定义的控制信息和参数。如果用户在DHCP服务器端配置了Options字段，DHCP客户端在申请IP地址的时候，会通过服务器端回应的DHCP报文获得Options字段中的配置信息。 Options字段由Type、Length和Value三部分组成。这三部分的表示含义如下所示： 字段 长度 含义 Type 1字节 该字段表示信息类型。 Length 1字节 该字段表示后面信息内容的长度。 Value 其长度为Length字段所指定 该字段表示信息内容。 DHCP Options选项的取值范围为1～255。 Options号 Options作用 1 设置子网掩码选项。 3 设置网关地址选项。 6 设置DNS服务器地址选项。 12 设置DHCP客户端的主机名选项。 15 设置域名后缀选项。 33 设置静态路由选项。该选项中包含一组有分类静态路由（即目的地址的掩码固定为自然掩码，不能划分子网），客户端收到该选项后，将在路由表中添加这些静态路由。如果存在Option121，则忽略该选项。 44 设置NetBios服务器选项。 46 设置NetBios节点类型选项。 50 设置请求IP地址选项。 51 设置IP地址租约时间选项。 52 设置Option附加选项。 53 设置DHCP消息类型。 54 设置服务器标识。 55 设置请求参数列表选项。客户端利用该选项指明需要从服务器获取哪些网络配置参数。该选项内容为客户端请求的参数对应的选项值。 58 设置续约T1时间，一般是租期时间的50%。 59 设置续约T2时间。一般是租期时间的87.5%。 60 设置厂商分类信息选项，用于标识DHCP客户端的类型和配置。 61 设置客户端标识选项。 66 设置TFTP服务器名选项，用来指定为客户端分配的TFTP服务器的域名。 67 设置启动文件名选项，用来指定为客户端分配的启动文件名。 77 设置用户类型标识。 121 设置无分类路由选项。该选项中包含一组无分类静态路由（即目的地址的掩码为任意值，可以通过掩码来划分子网），客户端收到该选项后，将在路由表中添加这些静态路由。 根据Options选项功能的不同，此字段的作用对象也不同。比如Option77用于DHCP客户端，用于识别用户所属的类型，根据Options字段中所携带的用户类型（User Class），DHCP服务器选择适当的地址池为客户端分配IP地址以及相关配置参数。Option77一般在客户端由用户进行配置，而不必在服务器端配置。 自定义DHCP选项：除了RFC2132中规定的字段选项外，还有部分选项内容没有统一规定，例如Option82。 Option82称为中继代理信息选项，该选项记录了DHCP客户端的位置信息。DHCP中继或DHCP Snooping设备接收到DHCP客户端发送给DHCP服务器的请求报文后，在该报文中添加Option82，并转发给DHCP服务器。 管理员可以从Option82中获得DHCP客户端的位置信息，以便定位DHCP客户端，实现对客户端的安全和计费等控制。支持Option82的服务器还可以根据该选项的信息制定IP地址和其他参数的分配策略，提供更加灵活的地址分配方案。 Option82最多可以包含255个子选项。若定义了Option82，则至少要定义一个子选项。目前设备只支持两个子选项：sub-option1（Circuit ID，电路ID子选项）和sub-option2（Remote ID，远程ID子选项）。 由于Option82的内容没有统一规定，不同厂商通常根据需要进行填充。 DHCP的Option82原理： DHCP Relay Agent插入到用户的DHCP报文，DHCP服务器通过识别Option82来执行IP地址分配策略或其他策略。 DHCP服务器的响应报文也带Option82，Relay Agent将Option82剥离后发给用户。 Agent Information Fied中包含多个子选项，每个子选项格式为iSubOpt/Length/Value三元组。 使能Option82功能，可以根据Option82信息建立精确到接口的绑定表。 DHCP服务器如果存在多个地址池，如何判断应该分配哪个地址池的地址？ 如果discovery报文中gateway ip address （relay agent address）被填充地址，则分配该IP地址所在网段的地址。 如果discovery报文中gateway ip address 为空，则分配discovery报文接收端口所在IP网段的地址。 unr：Uer Nerwork Router，用户网络路由。由DHCP服务器通告给客户端的静态路由。 DHCP配置配置为客户端分配IP地址：创建地址池： 基于接口方式的地址池：在DHCP Server与Client相连的接口上配置IP地址，地址池是跟此接口地址所属同一网段的IP地址，且地址池中地址只能分配给此接口下的Client。这种配置方式简单，仅适用于DHCP Server与Client在同一个网段，即不存在中继的场景。例如，设备做DHCP Server仅给一个接口下的Client分配IP地址或者给多个接口下的Client分别分配不同网段的IP地址。 基于全局方式的地址池：在系统视图下创建指定网段的地址池，且地址池中地址可以分配给设备所有接口下的Client。这种配置方式适用于： DHCP Server与Client在不同网段，即存在中继的场景。 DHCP Server与Client在同一网段，且需要给一个接口下的Client分配IP地址或者给多个接口下的Client分别分配IP地址。 DHCP基于接口配置：如下图，AR1为DHCP服务器，接口配置地址为192.168.0.1/24.给接口下所连接的设备主机分配IP地址。 图：DHCP基于接口配置拓扑 配置文件：DHCP服务器配置： 123456789101112131415161718&lt;DHCP&gt;dis current-configuration # sysname DHCP#dhcp enable //使能DHCP功能#interface GigabitEthernet0/0/0 ip address 192.168.0.1 255.255.255.0 dhcp check dhcp-rate enable //使能DHCP报文速率检查功能。 dhcp check dhcp-rate 90 //配置DHCP报文上送到DHCP协议栈的检查速率。 dhcp alarm dhcp-rate enable //使能DHCP报文速率告警功能。 dhcp alarm dhcp-rate threshold 500 //配置DHCP报文速率检查告警阈值。 dhcp select interface //开启接口采用接口地址池的DHCP Server功能。 AR3作为DHCP客户端配置： 123456789101112131415161718&lt;AR2&gt;dis current-configuration sysname AR2#dhcp enable //使能DHCP功能#interface GigabitEthernet0/0/0 dhcp client default-route preference 100 //配置DHCP服务器下发给DHCP客户端的路由表项优先级。 dhcp client gateway-detect period 3600 retransmit 3 timeout 500 //来配置DHCP Client网关探测功能。 dhcp client expected-lease 3600 //配置DHCP Client期望租期功能。 dhcp client class-id huawei//配置设备作为DHCP客户端时，发送DHCP请求报文中的Option60字段。 dhcp client hostname DHCPClient //配置DHCP客户的主机名 ip address dhcp-alloc //配置ip地址获取方式为通过DHCP获取 dhcp client gateway-detect period 3600 retransmit 3 timeout 500 参数 参数说明 取值 period period 指定DHCP Client网关探测周期。 整数形式，取值范围是1～86400。单位是秒。 retransmit retransmit 指定DHCP Client网关探测重传次数。 整数形式，取值范围是1～10。 timeout time 指定DHCP Client网关探测超时时间。 整数形式，取值范围是300～2000。单位是毫秒。 应用场景 此命令应用于DHCP客户端。当DHCP Client成功获取IP地址后，该功能可以使DHCP Client迅速检测正在使用的网关状态，如果网关地址错误或网关设备故障，DHCP Client将向DHCP Server重新发送IP地址请求。 注意事项 DHCP Client网关探测功能适用于双上行链路场景。 dhcp client class-idDHCP服务器需要根据请求报文中的Option60字段内容来区分不同设备，用户可以使用此命令自定义设备作为DHCP客户端时，发送的请求报文中封装的Option60内容。 接口下配置此命令后，设备作为DHCP客户端时，从该接口发送的DHCP请求报文中将使用配置的内容填充Option60字段。 dhcp client client-id该命令用来配置DHCP客户端的标识，该标识将会封装在DHCP请求报文中与服务器进行交互。DHCP客户端在申请IP地址的时候，DHCP服务器会获取请求报文中的DHCP客户端标识信息，DHCP服务器将根据该标识，为DHCP客户端分配IP地址。 DHCP基于全局配置：如下图，路由器AR1为DHCP服务器，为不同VLAN的主机分配不同网段的IP地址，同时，为了节约IP地址，使用了聚合VLAN。 基于全局的配置文件：AR1DHCP服务器的配置文件： 1234567891011121314151617181920212223242526272829303132333435363738&lt;DHCP&gt;dis current-configuration # sysname DHCP#dhcp enable#dhcp snooping enable#ip pool VLAN100 gateway-list 10.0.10.254 network 10.0.10.0 mask 255.255.255.0 excluded-ip-address 10.0.10.1 lease day 1 hour 23 minute 30 dns-list 114.114.114.144 8.8.8.8 domain-name VLAN100#ip pool VLAN200 //配置VLAN200地址池 gateway-list 10.0.20.254 network 10.0.20.0 mask 255.255.255.0 excluded-ip-address 10.0.20.1 dns-list 10.0.20.254 domain-name VLAN200#ip pool VLAN300 gateway-list 10.0.30.1 10.0.30.254 network 10.0.30.0 mask 255.255.255.0 dns-list 10.0.30.254 8.8.8.8 domain-name VLAN300#interface GigabitEthernet0/0/0 ip address 10.0.0.1 255.255.255.0 dhcp select global //开启接口采用全局地址池的DHCP Server功能。#//配置去往DHCP中继不同网段的路由ip route-static 10.0.10.0 255.255.255.0 10.0.0.2ip route-static 10.0.20.0 255.255.255.0 10.0.0.2ip route-static 10.0.30.0 255.255.255.0 10.0.0.2 图：DHCP服务器分配情况 SW1作为DHCP中继的配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273[SW]dis current-configuration #sysname SW#vlan batch 10 to 11 20 to 21 30 to 31 100 200 300 //批量创建VLAN#dhcp enable//使能DHCP功能 #dhcp snooping enable //使能DHCP Snooping功能#//在每个VLAN下都开启DHCP Snooping功能vlan 1 dhcp snooping enablevlan 10 dhcp snooping enablevlan 11 dhcp snooping enablevlan 20 dhcp snooping enablevlan 21 dhcp snooping enablevlan 30 dhcp snooping enablevlan 31 dhcp snooping enablevlan 100 //聚合VLAN aggregate-vlan access-vlan 10 to 11vlan 200 //聚合VLAN aggregate-vlan access-vlan 20 to 21vlan 300 //聚合VLAN aggregate-vlan access-vlan 30 to 31#interface Vlanif1 ip address 10.0.0.2 255.255.255.0 //配置与DHCP服务器直通的路由#interface Vlanif100 ip address 10.0.10.254 255.255.255.0 dhcp select relay //开启DHCP 中继 dhcp relay server-ip 10.0.0.1 //DHCP服务器IP地址#interface Vlanif200 ip address 10.0.20.254 255.255.255.0 dhcp select relay dhcp relay server-ip 10.0.0.1#interface Vlanif300 ip address 10.0.30.254 255.255.255.0 dhcp select relay dhcp relay server-ip 10.0.0.1#interface GigabitEthernet0/0/1 port link-type trunk dhcp snooping trusted //配置接口为信任状态。#interface GigabitEthernet0/0/2 port link-type trunk port trunk allow-pass vlan 10 to 11#interface GigabitEthernet0/0/3 port link-type trunk port trunk allow-pass vlan 20 to 21#interface GigabitEthernet0/0/4 port link-type trunk port trunk allow-pass vlan 30 to 31# 图：DHCP中继情况 SW2配置文件：SW3,4与之类似。 123456789101112131415161718192021222324&lt;SW2&gt;dis current-configuration #sysname SW2#vlan batch 10 to 11#dhcp enable#dhcp snooping enable#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 2 to 4094 dhcp snooping enable dhcp snooping trusted#interface GigabitEthernet0/0/2 port link-type access port default vlan 10#interface GigabitEthernet0/0/3 port link-type access port default vlan 11#]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
        <tag>DHCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MSTP多区域生成树协议]]></title>
    <url>%2F2017%2F11%2F29%2FMSTP%E5%A4%9A%E5%8C%BA%E5%9F%9F%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[MSTP简介多生成树协议MSTP（Multiple Spanning Tree Protocol）是IEEE802.1s中定义的生成树协议，通过生成多个生成树，来解决以太网环路问题。 目的：在以太网中部署MSTP协议后可实现如下功能： 形成多棵无环路的树，解决广播风暴并实现冗余备份。 多棵生成树在VLAN间实现负载均衡，不同VLAN的流量按照不同的路径转发。 MSTP原理描述STP/RSTP的缺陷：RSTP在STP基础上进行了改进，实现了网络拓扑快速收敛。但RSTP和STP还存在同一个缺陷：由于局域网内所有的VLAN共享一棵生成树，因此无法在VLAN间实现数据流量的负载均衡，链路被阻塞后将不承载任何流量，还有可能造成部分VLAN的报文无法转发。 MSTP对STP和RSTP的改进： 为了弥补STP和RSTP的缺陷，IEEE于2002年发布的802.1S标准定义了MSTP。MSTP兼容STP和RSTP，既可以快速收敛，又提供了数据转发的多个冗余路径，在数据转发过程中实现VLAN数据的负载均衡。 MSTP把一个交换网络划分成多个域，每个域内形成多棵生成树，生成树之间彼此独立。每棵生成树叫做一个多生成树实例MSTI（Multiple Spanning Tree Instance），每个域叫做一个MST域（MST Region：Multiple Spanning Tree Region）。 所谓生成树实例就是多个VLAN的一个集合。通过将多个VLAN捆绑到一个实例，可以节省通信开销和资源占用率。MSTP各个实例拓扑的计算相互独立，在这些实例上可以实现负载均衡。可以把多个相同拓扑结构的VLAN映射到一个实例里，这些VLAN在端口上的转发状态取决于端口在对应MSTP实例的状态。 MSTP基本概念： MST域（MST Region） ​ 都启动了MSTP。 具有相同的域名。 具有相同的VLAN到生成树实例映射配置。 具有相同的MSTP修订级别配置。 一个局域网可以存在多个MST域，各MST域之间在物理上直接或间接相连。用户可以通过MSTP配置命令把多台交换设备划分在同一个MST域内。 VLAN映射表： VLAN映射表是MST域的属性，它描述了VLAN和MSTI之间的映射关系。 CST 公共生成树CST（Common Spanning Tree）是连接交换网络内所有MST域的一棵生成树。 如果把每个MST域看作是一个节点，CST就是这些节点通过STP或RSTP协议计算生成的一棵生成树。 IST 内部生成树IST（Internal Spanning Tree）是各MST域内的一棵生成树。 IST是一个特殊的MSTI，MSTI的ID为0，通常称为MSTI0。 IST是CIST在MST域中的一个片段。 SST 运行STP或RSTP的交换设备只能属于一个生成树。 MST域中只有一个交换设备，这个交换设备构成单生成树。 CIST 公共和内部生成树CIST（Common and Internal Spanning Tree）是通过STP或RSTP协议计算生成的，连接一个交换网络内所有交换设备的单生成树。 域根 域根（Regional Root）分为IST域根和MSTI域根。 一个MST域内可以生成多棵生成树，每棵生成树都称为一个MSTI。MSTI域根是每个多生成树实例的树根。 总根 总根是CIST（Common and Internal Spanning Tree）的根桥。 主桥 主桥（Master Bridge）也就是IST Master，它是域内距离总根最近的交换设备。 端口角色 根端口、指定端口、Alternate端口、Backup端口和边缘端口的作用同RSTP协议中定义。 除边缘端口外，其他端口角色都参与MSTP的计算过程。 同一端口在不同的生成树实例中可以担任不同的角色。 端口角色： 端口角色 说明 根端口 在非根桥上，离根桥最近的端口是本交换设备的根端口。根交换设备没有根端口。根端口负责向树根方向转发数据。 指定端口 对一台交换设备而言，它的指定端口是向下游交换设备转发BPDU报文的端口。 Alternate端口 从配置BPDU报文发送角度来看，Alternate端口就是由于学习到其它网桥发送的配置BPDU报文而阻塞的端口。 从用户流量角度来看，Alternate端口提供了从指定桥到根的另一条可切换路径，作为根端口的备份端口。 Backup端口 从配置BPDU报文发送角度来看，Backup端口就是由于学习到自己发送的配置BPDU报文而阻塞的端口。 从用户流量角度来看，Backup端口作为指定端口的备份，提供了另外一条从根节点到叶节点的备份通路。 Master端口 1、 Master端口是MST域和总根相连的所有路径中最短路径上的端口，它是交换设备上连接MST域到总根的端口。 2、 Master端口是域中的报文去往总根的必经之路。 3、 Master端口是特殊域边缘端口，Master端口在CIST上的角色是Root Port，在其它各实例上的角色都是Master端口。 域边缘端口 域边缘端口是指位于MST域的边缘并连接其它MST域或SST的端口。 边缘端口 1、如果指定端口位于整个域的边缘，不再与任何交换设备连接，这种端口叫做边缘端口。2、 边缘端口一般与用户终端设备直接连接。 3、 端口使能MSTP功能后，会默认启用边缘端口自动探测功能，当端口在（2 × Hello Timer + 1）秒的时间内收不到BPDU报文，自动将端口设置为边缘端口，否则设置为非边缘端口。 端口状态：MSTP定义的端口状态与RSTP协议中定义相同。 注：根端口、Master端口、指定端口和域边缘端口支持Forwarding、Learning和Discarding状态，Alternate端口和Backup端口仅支持Discarding状态。 MSPT报文：MSTP使用多生成树桥协议数据单元MST BPDU（Multiple Spanning Tree Bridge Protocol Data Unit）作为生成树计算的依据。MST BPDU报文用来计算生成树的拓扑、维护网络拓扑以及传达拓扑变化记录。 STP中定义的配置BPDU、RSTP中定义的RST BPDU、MSTP中定义的MST BPDU及TCN BPDU差异对比如下： 四种BPDU差异比较： 版本 类型 名称 0 0x00 配置BPDU 0 0x80 TCN BPDU 2 0x02 RST BPDU 3 0x02 MST BPDU MSTP帧格式： 图：MSTP帧格式 无论是域内的MST BPDU还是域间的，前35个字节和RST BPDU相同。 从第36个字节开始是MSTP专有字段。最后的MSTI配置信息字段由若干MSTI配置信息组连缀而成。 MSTP 报文字段解释： 字段 说明 Protocol Identifier 协议标识符。 Protocol Version Identifier 协议版本标识符，STP为0，RSTP为2，MSTP为3。 BPDU Type BPDU类型，MSTP为0x02。0x00：STP的Configuration BPDU0x80：STP的TCN BPDU（Topology Change Notification BPDU）0x02：RST BPDU（Rapid Spanning-Tree BPDU）或者MST BPDU（Multiple Spanning-Tree BPDU） CIST Flags CIST标志字段。 CIST Root Identifier CIST的总根交换机ID。 CIST External Path Cost CIST外部路径开销指从本交换机所属的MST域到CIST根交换机的累计路径开销。CIST外部路径开销根据链路带宽计算。 CIST Regional Root Identifier CIST的域根交换机ID，即IST Master的ID。 如果总根在这个域内，那么域根交换机ID就是总根交换机ID。 CIST Port Identifier 本端口在IST中的指定端口ID。 Message Age BPDU报文的生存期。 Max Age BPDU报文的最大生存期，超时则认为到根交换机的链路故障。 Hello Time Hello定时器，缺省为2秒。 Forward Delay Forward Delay定时器，缺省为15秒。 Version 1 Length Version1 BPDU的长度，值固定为0。 Version 3 Length Version3 BPDU的长度。 MST Configuration Identifier MST配置标识，表示MST域的标签信息，包含4个字段：Configuration Identifier Format Selector：固定为0。Configuration Name：“域名”，32字节长字符串。Revision Level：2字节非负整数。Configuration Digest：利用HMAC-MD5算法将域中VLAN和实例的映射关系加密成16字节的摘要。只有MST Configuration Identifier中的四个字段完全相同的，并且互联的交换机，才属于同一个域。 CIST Internal Root Path Cost CIST内部路径开销指从本端口到IST Master交换机的累计路径开销。CIST内部路径开销根据链路带宽计算。 CIST Bridge Identifier CIST的指定交换机ID。 CIST Remaining Hops BPDU报文在CIST中的剩余跳数。 MSTI Configuration Messages (may be absent) MSTI配置信息。每个MSTI的配置信息占16 bytes，如果有n个MSTI就占用n×16bytes。单个MSTI Configuration Messages的字段说明如下：MSTI Flags：MSTI标志。MSTI Regional Root Identifier：MSTI域根交换机ID。MSTI Internal Root Path Cost：MSTI内部路径开销指从本端口到MSTI域根交换机的累计路径开销。MSTI内部路径开销根据链路带宽计算。MSTI Bridge Priority：本交换机在MSTI中的指定交换机的优先级。MSTI Port Priority：本交换机在MSTI中的指定端口的优先级。MSTI Remaining Hops：BPDU报文在MSTI中的剩余跳数。 MSTP报文抓包示例： 图：MST BPDU包示例 MSTP报文格式可配置：目前MSTP的BPDU报文存在两种格式： dot1s：IEEE802.1s规定的报文格式。 legacy：私有协议报文格式。 如果端口收发报文格式为默认支持dot1s或者legacy，这样就存在一个缺点：需要人工识别对端的BPDU报文格式，然后手工配置命令来决定支持哪种格式。人工识别报文格式比较困难，且一旦配置错误，就有可能导致MSTP计算错误，出现环路。 华为技术有限公司采用的端口收发MSTP报文格式可配置（stp compliance）功能，能够实现对BPDU报文格式的自适应： auto dot1s legacy 这样报文收发不但支持dot1s和legacy格式，还能通过auto方式根据收到的BPDU报文格式自动切换端口支持的BPDU报文格式，使报文格式与对端匹配。在自适应的情况下，端口初始支持dot1s格式，收到报文后，格式则和收到的报文格式保持一致。 每个Hello Time时间内端口最多能发送BPDU的报文数可配置：Hello Time用于生成树协议定时发送配置消息维护生成树的稳定。如果交换设备在一段时间内没有收到BPDU报文，则会由于消息超时而对生成树进行重新计算。 当交换设备成为根交换设备时，该交换设备会按照该设置值为时间间隔发送BPDU报文。非根交换设备采用根交换设备所设置的Hello Time时间值。 华为技术有限公司数据通信设备提供的每个Hello Time时间内端口最多能够发送的BPDU报文个数可配置（Max Transmitted BPDU Number in Hello Time is Configurable）功能，可以设定当前端口在Hello Time时间内配置BPDU的最大发送数目。 用户配置的数值越大，表示每Hello Time时间内发送的报文数越多。适当的设置该值可以限制端口每Hello Time时间内能发送的BPDU数目，防止在网络拓扑动荡时，BPDU占用过多的带宽资源。 MSTP拓扑计算：MSTP可以将整个二层网络划分为多个MST域，各个域之间通过计算生成CST。域内则通过计算生成多棵生成树，每棵生成树都被称为是一个多生成树实例。其中实例0被称为IST，其他的多生成树实例为MSTI。MSTP同STP一样，使用配置消息进行生成树的计算，只是配置消息中携带的是设备上MSTP的配置信息。 优先级向量：MSTI和CIST都是根据优先级向量来计算的，这些优先级向量信息都包含在MST BPDU中。各交换设备互相交换MST BPDU来生成MSTI和CIST。 优先级向量简介 参与CIST计算的优先级向量为： { 根交换设备ID，外部路径开销，域根ID，内部路径开销，指定交换设备ID，指定端口ID，接收端口ID } 参与MSTI计算的优先级向量为： { 域根ID，内部路径开销，指定交换设备ID，指定端口ID，接收端口ID } 括号中的向量的优先级从左到右依次递减。 向量说明： 向量名 说明 根交换设备ID 根交换设备ID用于选择CIST中的根交换设备。根交换设备ID = Priority(16bits) + MAC(48bits)。其中Priority为MSTI0的优先级。 外部路径开销（ERPC） 从CIST的域根到达总根的路径开销。MST域内所有交换设备上保存的外部路径开销相同。若CIST根交换设备在域中，则域内所有交换设备上保存的外部路径开销为0。 域根ID 域根ID用于选择MSTI中的域根。域根ID = Priority(16bits) + MAC(48bits)。其中Priority为MSTI0的优先级。 内部路径开销（IRPC） 本桥到达域根的路径开销。域边缘端口保存的内部路径开销大于非域边缘端口保存的内部路径开销。 指定交换设备ID CIST或MSTI实例的指定交换设备是本桥通往域根的最邻近的上游桥。如果本桥就是总根或域根，则指定交换设备为自己。 指定端口ID 指定交换设备上同本设备上根端口相连的端口。Port ID = Priority(4位) + 端口号（12位）。端口优先级必须是16的整数倍。 接收端口ID 接收到BPDU报文的端口。Port ID = Priority(4位) + 端口号（12位）。端口优先级必须是16的整数倍。 比较原则 同一向量比较，值最小的向量具有最高优先级。 优先级向量比较原则如下。 首先，比较根交换设备ID。 如果根交换设备ID相同，再比较外部路径开销。 如果外部路径开销相同，再比较域根ID。 如果域根ID仍然相同，再比较内部路径开销。 如果内部路径仍然相同，再比较指定交换设备ID。 如果指定交换设备ID仍然相同，再比较指定端口ID。 如果指定端口ID还相同，再比较接收端口ID。 如果端口接收到的BPDU内包含的配置消息优于端口上保存的配置消息，则端口上原来保存的配置消息被新收到的配置消息替代。端口同时更新交换设备保存的全局配置消息。反之，新收到的BPDU被丢弃。 CIST中端口角色的选举：1、比价CIST的总根ID，越小越优。2、比较CIST到达总根的ERPC，越小越优。3、比较CIST域根的BID，越小越优。4、比较CIST到达域根的IPRC，越小越优。5、比较CIST中BPDU报文发送者的BID，越小越优。6、比较CIST中BPDU报文发送者的PID，越小越优。7、比较CIST中BPDU报文接收者的PID，越小越优。 CIST的计算：经过比较配置消息后，在整个网络中选择一个优先级最高的交换设备作为CIST的树根。在每个MST域内MSTP通过计算生成IST；同时MSTP将每个MST域作为单台交换设备对待，通过计算在MST域间生成CST。CST和IST构成了整个交换设备网络的CIST。 MSTI的计算：在MST域内，MSTP根据VLAN和生成树实例的映射关系，针对不同的VLAN生成不同的生成树实例。每棵生成树独立进行计算，计算过程与STP计算生成树的过程类似。 MSTI的特点： 每个MSTI独立计算自己的生成树，互不干扰。 每个MSTI的生成树计算方法与STP基本相同。 每个MSTI的生成树可以有不同的根，不同的拓扑。 每个MSTI在自己的生成树内发送BPDU。 每个MSTI的拓扑通过命令配置决定。 每个端口在不同MSTI上的生成树参数可以不同。 每个端口在不同MSTI上的角色、状态可以不同。 在MST域内，沿着其对应的MSTI转发。 在MST域间，沿着CST转发。 MSTP对拓扑变化的处理：MSTP拓扑变化处理与RSTP拓扑变化处理过程类似。 在RSTP中检测拓扑是否发生变化只有一个标准：一个非边缘端口迁移到Forwarding状态。 为本交换设备的所有非边缘指定端口启动一个TC While Timer，该计时器值是Hello Time的两倍。 在这个时间内，清空所有端口上学习到的MAC地址。 同时，由非边缘端口向外发送RST BPDU，其中TC置位。一旦TC While Timer超时，则停止发送RST BPDU。 其他交换设备接收到RST BPDU后，清空所有端口学习到MAC地址，除了收到RST BPDU的端口。然后也为自己所有的非边缘指定端口和根端口启动TC While Timer，重复上述过程。 如此，网络中就会产生RST BPDU的泛洪。 MSTP快速收敛机制：MSTP支持普通方式和增强方式两种P/A（Proposal/Agreement）机制： 普通方式 MSTP支持普通方式的P/A机制实现与RSTP支持的P/A机制实现相同。 增强方式 图：增加方式的P/A机制 在MSTP中，P/A机制工作过程如下： 上游设备发送Proposal报文，请求进行快速迁移。下游设备接收到后，把与上游设备相连的端口设置为根端口，并阻塞所有非边缘端口。 上游设备继续发送Agreement报文。下游设备接收到后，根端口转为Forwarding状态。 下游设备回应Agreement报文。上游设备接收到后，把与下游设备相连的端口设置为指定端口，指定端口进入Forwarding状态。 缺省情况下，华为数据通信设备使用增强的快速迁移机制。如果华为数据通信设备和其他制造商的设备进行互通，而其他制造商的设备P/A机制使用普通的快速迁移机制，此时，可在华为数据通信设备上通过设置P/A机制为普通的快速迁移机制，从而实现华为数据通信设备和其他制造商的设备进行互通。 MSTP多进程：MSTP多进程是基于MSTP协议的增强性技术。此技术可将二层交换设备上的端口绑定到不同的进程中，并以进程为单位进行MSTP协议计算，不在同一个进程内的端口不参与此进程中的MSTP协议计算，从而实现各个进程内的生成树计算相互独立，互不影响。 MSTP多进程机制并不只限于MSTP协议，RSTP和STP协议同样适用。 优势：通过部署MSTP多进程可实现如下： 极大地提升了在不同组网条件下生成树协议的可部署性。 为了保证运行不同类型生成树协议的网络可靠运行，可将不同类型的生成树协议划分到不同的进程中，不同进程对应的网络进行独立的生成树协议计算。 增强了组网的可靠性，对于大量的二层接入设备，可减少单台设备故障对整个网络的冲击。 通过进程隔离不同的拓扑计算，即某台设备故障只影响其所在的进程对应的拓扑，不会影响其他进程拓扑计算。 网络扩容时，可减少网络管理者维护量，从而提升了用户运维管理的方便性。 当网络扩容时，只需要划分新的进程与原有网络对接，不需要调整原有网络的MSTP进程配置。如果是某个进程中进行了设备扩容，此时也只需要针对扩容的进程进行修改，而不需要调整其他进程中的配置。 实现二层端口分割管理 每个MSTP进程可以管理设备上的部分端口，即设备的二层端口资源被多个MSTP进程分割管理，每个MSTP进程上均可运行标准的MSTP。 ​ MSTP配置配置MSTP基本功能：配置MSTP的工作模式：1stp mode mstp //配置交换设备的MSTP模式 因为STP和MSTP不能互相识别报文，而MSTP和RSTP可以互相识别报文，所以若工作在MSTP工作模式下，交换设备会设置所有和运行STP的交换设备直接相连的端口工作在STP模式下，其他端口工作在MSTP模式下，实现运行不同生成树协议的设备之间的互通。 配置MST域并激活：当两台交换设备的以下配置都相同时，这两台交换设备属于同一个MST域。 MST域的域名。 多生成树实例和VLAN的映射关系。 MST域的修订级别。 12345678stp region-configuration //进入MST域视图region-name name //配置MST域的域名instance 1 vlan 2 to 3 //配置多生成树的实例与VLAN映射关系vlan-mapping modulo modulo //配置多生成树实例和VLAN按照缺省算法自动分配映射关系。缺省情况下，MST域内所有的VLAN都映射到生成树实例0。revision-level level //配置MST域的MSTP修订级别//缺省情况下，MST域的MSTP修订级别为0。//MSTP是标准协议，各厂商设备的MSTP修订级别一般都默认为0。如果某厂商的设备不为0，为保持MST域内计算，在部署MSTP时，需要将各设备的MSTP修订级别修改为一致。active region-configuration //激活MST域的配置 配置根桥和备份根桥：12stp instance 0 root primary //配置当前设备为根桥设备。 stp instance 0 root secondary//配置当前交换设备为备份根桥设备。 配置交换设备在指定实例中的优先级；12stp instance 0 priority 32768 //配置交换设备在指定生成树实例中的优先级。 配置端口在指定生成树实例中的路径开销：123456stp pathcost-standard &#123; dot1d-1998 | dot1t | legacy &#125;//配置端口路径开销计算方法。 缺省情况下，路径开销的计算方法为IEEE 802.1t（dot1t）标准方法。//同一网络内所有交换设备的端口路径开销应使用相同的计算方法。stp instacne 0 cost cost //设置当前端口在指定生成树实例中的路径开销值。 配置端口路径开销计算方法为legacy时，参数cost取值范围是1～200000。 配置端口路径开销计算方法为dot1d-1998时，参数cost取值范围是1～65535。 配置端口路径开销计算方法为dot1t时，参数cost取值范围是1～200000000。 配置端口在指定生成树实例中的优先级：12stp instance 0 port priority 128 //配置端口在指定生成树实例中的优先级。 缺省情况下，端口的优先级数值为128。 优先级数值的取值范围是0～240，步长为16。 配置端口收发MSTP下一的报文格式：MSTP协议报文存在两种格式，一种为dot1s，即IEEE802.1s规定的报文格式，另一种为legacy，是一种私有报文格式。 配置时，可以指定报文的格式，也可以配置MSTP协议报文格式自适应的功能，即根据收到的MSTP协议报文格式自动切换端口支持的MSTP协议报文格式，使报文格式与对端匹配。 stp compliance { auto | dot1s legacy } 配置端口协议报文格式。 stp config-digest-snoop //使能端口上配置摘要监听功能。 MSTP配置举例：如下图，按要求配置各个区域。防止出现环路。 配置文件：SW1：SW2和3与SW1类似。 12345678910111213141516171819202122232425&lt;SW1&gt;dis current-configuration #sysname SW1#vlan batch 2 to 20#stp instance 0 root primarystp instance 1 root primarystp instance 2 root secondary#stp region-configuration region-name HCNA revision-level 1 instance 1 vlan 1 to 10 instance 2 vlan 11 to 20 active region-configuration#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 2 to 20#interface GigabitEthernet0/0/2 port link-type trunk port trunk allow-pass vlan 2 to 20# SW4：SW5和6配置和SW4配置类似： 12345678910111213141516171819202122232425262728&lt;SW4&gt;dis current-configuration #sysname SW4#vlan batch 2 to 20#stp instance 1 root primarystp instance 2 root secondary#stp region-configuration region-name HCNP revision-level 2 instance 1 vlan 1 to 10 instance 2 vlan 11 to 20 active region-configuration#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 2 to 20#interface GigabitEthernet0/0/2 port link-type trunk port trunk allow-pass vlan 2 to 20#interface GigabitEthernet0/0/3 port link-type trunk port trunk allow-pass vlan 2 to 20# SW7：8,9的配置和7的配置类似： 123456789101112131415161718192021222324252627[SW7]dis current-configuration #sysname SW7#vlan batch 2 to 20#stp instance 1 root primarystp instance 2 root secondary#stp region-configuration region-name HCIE instance 1 vlan 1 to 10 instance 2 vlan 11 to 20 active region-configuration#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 2 to 20#interface GigabitEthernet0/0/2 port link-type trunk port trunk allow-pass vlan 2 to 20#interface GigabitEthernet0/0/3 port link-type trunk port trunk allow-pass vlan 2 to 20# 查看MSTP状态： 图：SW4各端口在不同示例下的状态]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
        <tag>STP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSTP快速生成树协议]]></title>
    <url>%2F2017%2F11%2F29%2FRSTP%E5%BF%AB%E9%80%9F%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[RSTP简介RSTP概述：快速生成树协议RSTP（Rapid Spanning Tree Protocol）在STP基础上实现了快速收敛，并增加了边缘端口的概念及保护功能。 RSTP的端口角色：RSTP在STP基础上新增加了2种端口角色：、Backup端口和边缘端口。通过端口角色的增补，简化了生成树协议的理解及部署。 Backup端口：由于学习到自己发送的配置BPDU报文而阻塞的端口，指定端口的备份，提供了另外一条从根节点到叶节点的备份通路。 边缘端口：如果端口位于整个交换区域边缘，不与任何交换设备连接，这种端口叫做边缘端口。边缘端口一般与用户终端设备直接连接。 图：RSTP 端口角色示意图 边缘端口的特点： 边缘端口会节省30S的延时，端口UP后会立即进入转发状态。 边缘端口的UP/DOWN不会触发拓扑改变。 边缘端口收的TC置为的配置BPDU报文不会将MAC地址的老化时间设置为15s。 边缘端口如果收到配置的BPDU报文会马上变为一个普通端‘’口，进行STP的收敛 边缘端口也会发送配置BPDU报文。 PA协商不会阻塞边缘端口。 RSTP的端口状态：RSTP的端口状态在STP的基础上进行了改进。由原来的五种缩减为三种。 端口状态 说明 Forwarding（转发） 在这种状态下，端口既转发用户流量又处理BPDU报文。 Learning（学习） 这是一种过渡状态。在Learning下，交换设备会根据收到的用户流量，构建MAC地址表，但不转发用户流量，所以叫做学习状态。Learning状态的端口处理BPDU报文，不转发用户流量。 Discarding(丢弃) Discarding状态的端口只接收BPDU报文。 注： MSTP端口状态与RSTP端口状态相同。 华为公司数据通信设备缺省情况处于MSTP模式，当从MSTP模式切换到STP模式，运行STP协议的设备上端口支持的端口状态仍然保持和MSTP支持的端口状态一样，支持的状态仅包括Forwarding、Learning和Discarding RSTP报文:RSTP报文格式：在BPDU的格式上，除了保证和STP格式基本一致之外，RSTP作了一些小的变化。一个是在Type字段，配置BPDU类型不再是0而是2，版本号也变成了2。所以运行STP的交换机收到该类BPDU时会丢弃。 另一个变化是在Flag字段，把原来保留的中间6位使用起来。这样改变了的配置BPDU叫做RST BPDU。 RSTP Flag字段格式： Bit7：TCA Bit6：Agreement Bit5：Forwarding Bit4：Learning Bit3和Bit2：端口角色 00：未知 01：根端口 10：Alternate / Backup 11：指定端口 Bit1：Proposal Bit0：TC RSTP报文抓包示例： 图：RSTP报文抓包示例 RSTP快速收敛机制：P/A协商：针对运行STP设备从初始化到完全收敛至少需要30s的问题，RSTP采用P/A（Proposal/agreement）协商机制。 特点：由于有来回确认机制和同步变量机制，就无需依靠计时器来保障无环。可以让交换机的互联接口快速进入转发模式。 P/A协商的硬件条件：只能应用在点到点的链路上（全双工的端口），如果是半双工端口会识别为共享（share）链路，在共享链路上不能使用P/A协商。 P/A协商的过程： SW1向SW2发送p置位的BPDU包。 同步变量（阻塞除边缘端口以外的其他端口，防止出现环路）。 SW2向SW1发送A置位的BPDU包。 SW1收到A置位的BPDU包后，端口立即进入Forwarding状态。（一般都是秒级） P/A协商的详细过程： 图：P/A协商的详细过程 什么情况下RSTP报文中需要将Proposal位置位？一个指定端口进入discarding或者learning状态，需要将proposal位置位。 RSTP中收敛时间的优化： P/A协商：可以让交换机的RP和DP的互联接口快速进入转发状态。 直连故障：AP口变为RP并快速进入转发状态，不需要30s延时。 次优场景：AP口收到次优的RST BPDU包后会马上变为DP口，并向该端口发送最优的RST BPDU包。 非直连链路故障：连续丢失3个RST BPDU包，端口角色就需切换，最长时间为6s。 RSTP中TC置位的RST BPDU包所有桥设备都可以发送，连续发送4s（TC while时间）。 在RSTP中什么情况下才会发送TC BPDU包？ 指定端口进入到转发状态。 MAC地址表的清除： TC发送者：清除除了边缘端口以为的其它端口的MAC地址绑定条目。 TC接受者：清除除了TC报文接口端口和边缘端口以外的其它端口的MAC地址绑定条目。 在RSTP中非根桥也会每隔hello timer 主动发送RsT BPDU报文，不是由根桥来发。 在RSTP中DP口shutdown后BP口的角色会马上变为DP口，并经过30s的转发延时进入到转发状态。 RSTP保护功能： 保护功能 场景 配置影响 BPDU（Bridge Protocol Data Unit）保护 边缘端口在收到BPDU以后端口状态将变为非边缘端口，此时就会造成生成树的重新计算，如果攻击者伪造配置消息恶意攻击交换设备，就会引起网络震荡。 交换设备上启动了BPDU保护功能后，如果边缘端口收到RST BPDU，边缘端口将被error-down，但是边缘端口属性不变，同时通知网管系统。被error-down的边缘端口只能由网络管理员手动恢复。如果用户需要被error-down的边缘端口可自动恢复，可通过配置使能端口自动恢复功能，并可设置延迟时间。 防TC-BPDU报文攻击保护 交换设备在接收到拓扑变化报文后，会执行MAC地址表项和ARP表项的删除操作，如果频繁操作则会对CPU的冲击很大。 启用防TC-BPDU报文攻击功能后，在单位时间内，交换设备处理拓扑变化报文的次数可配置。如果在单位时间内，交换设备在收到拓扑变化报文数量大于配置的阈值，那么设备只会处理阈值指定的次数。对于其他超出阈值的拓扑变化报文，定时器到期后设备只对其统一处理一次。这样可以避免频繁的删除MAC地址表项和ARP表项，从而达到保护设备的目的。 Root保护 由于维护人员的错误配置或网络中的恶意攻击，根桥收到优先级更高的BPDU，会失去根桥的地位，重新进行生成树的计算，并且由于拓扑结构的变化，可能造成高速流量迁移到低速链路上，引起网络拥塞。 对于启用Root保护功能的指定端口，其端口角色只能保持为指定端口。一旦启用Root保护功能的指定端口收到优先级更高的RST BPDU时，端口状态将进入Discarding状态，不再转发报文。在经过一段时间（通常为两倍的Forward Delay），如果端口一直没有再收到优先级较高的RST BPDU，端口会自动恢复到正常的Forwarding状态。 环路保护 当出现链路拥塞或者单向链路故障，根端口和Alternate端口会老化。根端口老化，会导致系统重新选择根端口（而这有可能是错误的），Alternate端口老化，将迁移到Forwarding状态，这样会产生环路。 在启动了环路保护功能后，如果根端口或Alternate端口长时间收不到来自上游设备的BPDU报文时，则向网管发出通知信息（此时根端口会进入Discarding状态，角色切换为指定端口），而Alternate端口则会一直保持在阻塞状态（角色也会切换为指定端口），不转发报文，从而不会在网络中形成环路。直到链路不再拥塞或单向链路故障恢复，端口重新收到BPDU报文进行协商，并恢复到链路拥塞或者单向链路故障前的角色和状态。 stp root-protection //需要在所有的指定端口开启根保护，如果开启后的端口收到比根桥更优的BPDU报文，端口状态会变为Discarding状态。 如果连续MAX age的时间内从该端口都没有收到更优的BPDU报文，端口会自动恢复为Forwarding状态。。 防止根被抢占。 stp loop-protection //用于RP和AP端口。接收BPDU报文的端口。防止单向链路故障造成的环路。 TC-protection //设置TC报文的响应次数。如果接收TC的数量大于阀值范围内得TC次数，超出部分只执行1次。 BPDU-protection //配置BPDU保护 RSTP配置命令:基础配置同STP配置命令行。 1234567891011121314151617181920212223242526272829303132333435[接口视图] stp point-to-point &#123; auto | force-false | force-true&#125;//配置指定端口的链路类型。 缺省情况下，指定端口自动识别是否与点对点链路相连，点对点链路支持快速收敛。//如果当前以太网端口工作在全双工模式，则当前端口相连的链路是点到点链路，选择参数force-true实现快速收敛。//如果当前以太网端口工作在半双工模式，可通过执行命令stp point-to-point force-true强制链路类型为点对点链路，实现快速收敛。[接口视图] stp transmit-limit packet-number//配置端口在单位时间内BPDU的最大发送数目。缺省情况下，端口每秒BPDU的最大发送数目为6。//如果设备的所有端口都需要配置每秒发送BPDU的最大数目。可以在系统视图下通过执行该命令实现。stp mckeck //执行MCheck操作。用来对端口执行从STP模式自动迁移回原来的RSTP/MSTP模式的操作。stp edged-port default//配置当前设备上的所有端口为边缘端口。 stp bpdu-filter enable//配置当前端口为BPDU filter端口。stp bpdu-protection //配置交换设备边缘端口的BPDU保护功能stp tc-Protection //使能交换设备对TC类型BPDU报文的保护功能。 stp tc-Protection threshold 1//配置设备处理阈值指定数量的拓扑变化报文所需的时间。 stp tc-Protection threshold 1//配置交换设备在收到TC类型BPDU报文后，单位时间内，处理TC类型BPDU报文并立即刷新转发表项的阈值。 //缺省情况下，设备在指定时间内处理拓扑变化报文的最大数量是1。stp root-protection //配置交换设备的Root保护功能。//当端口的角色是指定端口时，配置的Root保护功能才生效。//配置了根保护的端口，不可以配置环路保护。stp loop-protection //配置交换设备根端口或Alternate端口的环路保护功能。 注意： 在全局模式下配置边缘端口和BPDU报文过滤功能后，设备上所有的端口不会主动发送BPDU报文，且均不会主动与对端设备直连端口协商，所有端口均处于转发状态。这将可能导致网络成环，引起广播风暴，请用户慎用。 在端口模式下配置边缘端口和BPDU报文过滤功能后，端口将不处理、不发送BPDU报文。该端口将无法成功与对端设备直连端口协商STP协议状态，请慎用。 如果用户希望被error-down的边缘端口可自动恢复，可通过配置使能端口自动恢复功能，并设置延迟时间，即在系统视图下执行命令error-down auto-recovery cause bpdu-protection interval interval-value，使能端口自动恢复为Up的功能，并设置端口自动恢复为Up的延时时间。使被关闭的端口经过延时时间后能够自动恢复。 当端口的角色是指定端口时，配置的Root保护功能才生效。 配置了根保护的端口，不可以配置环路保护。 配置设备支持和其他厂商设备互通的参数：为了实现华为公司的数据通信设备与其他厂商设备互通，需要根据其他厂商设备的P/A机制选择端口的快速迁移方式。 Proposal/Agreement机制，目前交换设备的端口支持以下两种方式： 增强方式：当前端口在计算同步标志位时计算根端口。 上游设备发送Proposal报文，请求进行快速迁移，下游设备接收到后，把与上游设备相连的端口设置为根端口，并阻塞所有非边缘端口。 上游设备继续发送Agreement报文，下游设备接收到后，根端口转为Forwarding状态。 下游设备回应Agreement报文，上游设备接收到后，把与下游设备相连的端口设置为指定端口，指定端口进入Forwarding状态。 普通方式：当前端口在计算同步标志位时忽略根端口。 上游设备发送Proposal报文，请求进行快速迁移，下游设备接收到后，把与上游设备相连的端口设置为根端口，并阻塞所有非边缘端口，根端口转为Forwarding状态。 下游设备回应Agreement报文，上游设备接收到后，把与下游设备相连的端口设置为指定端口，指定端口进入Forwarding状态。 在运行生成树的通信网络中，如果华为公司的数据通信设备与其他厂商设备混合组网，可能会因为与其他厂商设备的Proposal/Agreement机制不同可能导致互通失败。需要根据其他厂商设备的Proposal/Agreement机制，选择端口使用增强的快速迁移机制还是普通的快速迁移机制。 配置命令： 123[接口视图] stp no-agreement-check//配置端口使用普通的快速迁移方式。 //缺省情况下，端口使用增强的快速迁移机制。 RSTP配置举例：如下图，SW1配置为根桥，并且配置了根保护功能。SW2配置为备份根桥，连接PC的端口配置为边缘端口。SW3连接PC的端口配置为边缘端口，并配置BPDU过滤。 图：RSTP配置拓扑 SW1配置文件： 1234567891011121314[SW1]dis current-configuration #sysname SW1#stp mode rstpstp instance 0 root primarystp tc-protection#interface GigabitEthernet0/0/1 stp root-protection //配置根保护#interface GigabitEthernet0/0/2 stp root-protection# SW2配置文件： 123456789101112131415161718192021[SW2]dis current-configuration #sysname SW2#stp mode rstpstp instance 0 root secondarystp bpdu-protection //配置BPDU保护error-down auto-recovery cause bpdu-protection interval 30//配置因为BPDU保护导致端口Down后自动恢复功能#interface GigabitEthernet0/0/1 stp no-agreement-check //配置普通P/A协商 stp transmit-limit 5 //配置端口在单位时间内BPDU的最大发送数目为5 stp instance 0 port priority 32 //配置端口优先级 stp instance 0 cost 100 //配置端口开销值为100#interface GigabitEthernet0/0/2#interface GigabitEthernet0/0/3 stp edged-port enable //配置边缘端口# SW3配置文件： 1234567891011121314151617[SW3]dis current-configuration #sysname SW3#stp mode rstpstp tc-protection threshold 5 #interface GigabitEthernet0/0/1#interface GigabitEthernet0/0/2 stp bpdu-filter enable //配置BPDU过滤#interface GigabitEthernet0/0/3#interface GigabitEthernet0/0/4 stp loop-protection //配置环路保护#]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
        <tag>STP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STP生成树协议]]></title>
    <url>%2F2017%2F11%2F29%2FSTP%E7%94%9F%E6%88%90%E6%A0%91%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[STP简介STP概述：生成树协议STP（Spanning Tree Protocol）将环形网络修剪成为一个无环的树型网络，避免报文在环形网络中的增生和无限循环。 在一个复杂的网络环境中，难免会出现环路。由于冗余备份的需要，网络设计者都倾向于在设备之间部署多条物理链路，其中一条作主用链路，其他链路作备份，这样都有可能会导致环路产生。 环路会产生广播风暴，最终导致整个网络资源被耗尽，网络瘫痪不可用。环路还会引起MAC地址表震荡导致MAC地址表项被破坏。 为了破除环路，可以采用数据链路层协议STP，运行该协议的设备通过彼此交互信息发现网络中的环路，并有选择的对某个端口进行阻塞，最终将环形网络结构修剪成无环路的树形网络结构，从而防止报文在环形网络中不断循环，避免设备由于重复接收相同的报文造成处理能力下降。 STP相关概念： 根桥 树形网络结构必须有树根，于是STP/RSTP引入了根桥（Root Bridge）概念。 对于一个STP/RSTP网络，根桥有且只有一个，它是整个网络的逻辑中心，但不一定是物理中心。但是根据网络拓扑的变化，根桥可能改变。 BID（Bridge ID）：桥ID IEEE 802.1d标准中规定BID是由2字节的桥优先级（Bridge Priority）与桥MAC地址构成，即BID（8字节） = 桥优先级（2字节） + 桥MAC（6字节）。 在STP网络中，桥ID最小的设备会被选举为根桥。在华为公司的设备上，桥优先级支持手工配置。 PID（Port ID）：端口ID PID由两部分构成的，即PID（16位） = 端口优先级（4位） + 端口号（12位）。 PID只在某些情况下对选择指定端口有作用，即在选择指定端口时，两个端口的根路径开销和发送交换设备BID都相同的情况下，比较端口的PID，PID小者为指定端口。 路径开销（RPC） 路径开销是STP/RSTP协议用于选择链路的参考值。STP/RSTP协议通过计算路径开销，选择较为“强壮”的链路，阻塞多余的链路，将网络修剪成无环路的树形网络结构。根设备的端口的路径开销都为0。 在一个STP/RSTP网络中，某端口到根桥累计的路径开销就是所经过的各个桥上的各端口的开销。 PC（port cost） PC的计算需要依据端口带宽来计算。 端口角色： 根端口（RP）： 即去往根桥路径最近的端口。根端口负责向根桥方向转发数据，根端口同时还负责接收上游设备的BPDU报文和用户流量转发。根端口的选择标准是依据根路径开销判定。在一台设备上所有使能STP的端口中，根路径开销最小者，就是根端口。在一个运行STP/RSTP协议的设备上根端口有且只有一个，而且根桥上没有根端口。 指定端口（DR）： 对一台交换设备而言，它的指定端口是向下游交换设备转发BPDU报文的端口。根桥的所有端口都是指定端口。在环网的每一网段都会选举出一个指定端口，在一个网段上拥有指定端口的交换设备被称作该网段的指定桥。 替代端口（AP）： 由于学习到其它设备发送的配置BPDU报文而阻塞的端口，作为根端口的备份端口，提供了从指定桥到根的另一条可切换路径。 端口状态： 端口状态 目的 说明 Forwarding（转发） 端口既转发用户流量也处理BPDU报文。 只有根端口或指定端口才能进入Forwarding状态。 设备会根据收到的用户流量构建MAC地址表，但不转发用户流量。 过渡状态，增加Learning状态防止临时环路。（15s） Listening（监听） 确定端口角色，将选举出根桥、根端口和指定端口。 过渡状态。（15s） Blocking（阻塞） 端口紧紧接收并处理BPDU报文，不转发用户流量 阻塞端口的最终状态。 Disabled（禁用） 端口既不处理BPDU报文，也不转发用户流量。 端口状态为Down。 三种定时器： 定时器类型 说明 Hello Time Hello Timer定时器时间的大小控制配置BPDU发送间隔。 Forward Delay Timer Forward Delay Timer定时器时间的大小控制端口在Listening和Learning状态的持续时间。 Max Age Max Age定时器时间的大小控制存储配置BPDU的超时时间，超时认为根桥连接失败。 STP报文STP报文格式： 图：STP报文格式 报文字段解释： 字段内容 说明 Protocol Identifier 协议ID＝“0” Protocol Version Identifier 协议版本标识符，STP为0，RSTP为2，MSTP为3。 BPDU Type BPDU类型，MSTP为0x02。0x00：STP的Configuration BPDU0x80：STP的TCN BPDU（Topology Change Notification BPDU）0x02：RST BPDU（Rapid Spanning-Tree BPDU）或者MST BPDU（Multiple Spanning-Tree BPDU） Flags 对于“标记域”（Flags），第一个bit（左边、高位bit）表示“TCA（拓扑改变响应）”，最后一个bit（右边、低位bit）表示“TC（拓扑改变）”。 Root Identifier 网桥ID都是8个字节——前两个字节是网桥优先级，后6个字节是网桥MAC地址。 Root Path Cost 根路径开销，本端口累计到根桥的开销。 Bridge Identifier 发送者BID，本交换机的BID。 Port Identifier 发送端口PID，发送该BPDU的端口ID。 Message Age 该BPDU的消息年龄。 Max Age 消息老化年龄。 Hello Time 发送两个相邻BPDU间的时间间隔。 Forward Delay 控制Listening和Learning状态的持续时间。 STP报文抓包示例： 图：STP报文抓包示例 STP笔记STP原理：找到冗余的一端，然后阻塞端口，避免环路。 STP版本： IEEE 802.1D STP IEEE802.1W RSTP IEEE802.1S（华为） MSTP STP的选举过程： 在一个交换网络中选举一个根桥，根桥是设备的概念。 根桥选举后，交换网络中的其他设备都是非根桥，每个根桥还需选取一个到达根桥最短路径的端口称为根端口。 注：非根桥只能有一个根端口。 每条链路上，还需选举一个指定端口，默认情况下根桥的所有端口都是指定端口。 既不是根端口，也不是指定端口的其他端口需要被阻塞，不能转发数据帧。 根桥的选举： 通过比较BID选举，优选BID小的。BID由优先级+MAC地址组成。 首先比较优先级，优先级越小越优。 如果优先级一样，比较MAC地址，MAC地址越小越优。 分端口的选举： 比较RID，优选小的。 比较到达根桥的RPC（Root Path Cost），越小越优。 比较BPDU包发送者的BID，越小越优。 比较BPDU包发送者的PID，越小越优。 比较BPDU包接收者的PID，越小越优。 BPDU报文的两种类型： 配置BPDU 包含了桥ID，路径开销，端口ID等参数。 TCN BPDU 指下游交换机感知到拓扑发生变化时向上游交换机发送的拓扑变化通知。用以快速刷新MAC地址表。 STP故障： 根桥故障 非根桥会在BPDU老化之后，开始根桥的重新选举。 直连链路故障 交换机检测到直连链路故障后，会将预备端口转换为根端口。 预备端口会在30s后恢复到转发状态。 间接链路故障 间接链路故障进入到转发状态需要50s（MAX age + Forwarding delay * 2）。 拓扑改变导致MAC地址表错误 MAC地址默认老化时间为300s，这段时间内无法转发数据。 STP用于拓扑改变的报文： TCN BPDU报文：拓扑改变通知。 TCN BPDU报文只能由非根桥发出，通告给根桥。 TCA BPDU报文：用于确认接收到的TCN PBDU报文。 TC BPDU报文：只能由根桥发起，连续发送35s（MAX age + Forwarding delay）。 非根桥收到TC BPDU报文后会将MAC地址的老化时间设置为15s，加速老化。 STP拓扑改变： 如果非根桥上发生拓扑变化，向根桥发送TCN BPDU包，通告根桥拓扑已改变。 上联的非根桥从指定端口收到TCN BPDU包后，会向发送者回复TCA flag位置位的配置BPDU包，同时继续向根桥发送TCN BPDU包。 根桥收到TCN BPDU包后，向发送者回复TCA Flag位置位的配置BPDU包，同时向所有指定端口发送TC Flag位置位的配置BPDU包。TC置位的配置BPDU包会连续发送35s，同时将自己的MAC aging 设置为15s。 其他非根桥收到TC置位的配置BPDU包后，将自己的MAC地址的老化时间设置为15s，加速老化。 STP触发拓扑改变条件： 一个端口从forwarding状态过渡到disable或blocking状态。 一个非根桥如果从指定端口接收到TCN BPDU包，需要向根桥装发TCN BPDU包。 一个端口进入转发状态，并且本地已存在一个指端端口。 STP配置命令行12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758stp mode &#123; stp | rstp | mstp&#125;//配置交换机的STP工作模式，默认情况下，交换设备运行MSTP模式，MSTP模式兼容STP和RSTP模式。stp root primary//配置当前设备为根桥设备。缺省情况下，交换设备不作为任何生成树的根桥。配置后该设备优先级BID值自动为0，并且不能更改设备优先级。stp root secondary//配置当前交换机设备为备份根桥设备。缺省情况下，交换设备不作为任何生成树的备份根桥。配置后该设备优先级BID值为4096，并且不能更改设备优先级。stp priority 32768//配置交换设备在系统中的优先级。缺省情况下，交换设备的优先级取值是32768。 配置时，优先级必须为4096的倍数。 stp pathcost-standard &#123; dot1d-1998 | dot1t | legacy &#125;//配置端口路径开销计算方法。缺省情况下，路径开销值的计算方法为IEEE 802.1t（dot1t）标准方法。[接口视图]stp cost 100//设置当前端口的路径开销值。//使用华为计算方法时参数cost取值范围是1～200000。//使用IEEE 802.1d标准方法时取值范围是1～65535。//使用IEEE 802.1t标准方法时取值范围是1～200000000。[接口视图] stp port priority 128//配置端口的优先级。缺省情况下，交换设备端口的优先级取值是128。stp enable //使能交换设备的STP功能。缺省情况下，设备的STP/RSTP功能处于启用状态。 stp converge &#123; fast | normal&#125;//配置端口的收敛方式//根据对ARP表项的处理方式不同，STP/RSTP的收敛方式分为fast和normal两种：//fast：ARP表将需要更新的表项直接删除。//normal：ARP表中需要更新的表项快速老化。//交换设备将ARP表中这些表项的剩余存活时间置为0，对这些表项进行老化处理。如果配置的ARP老化探测次数大于零，则ARP对这些表项进行老化探测。//建议选择normal收敛方式。若选择fast方式，频繁的ARP表项删除可能会导致设备CPU占用率高达100%，报文处理超时导致网络震荡。stp bridge-diameter 5//配置网络直径。缺省情况下，网络直径为7。 stp timer-factor factor//配置未收到上游的BPDU就重新开始生成树计算的超时时间。 缺省情况下，设备未收到上游的BPDU就重新开始生成树计算的超时时间是Hello Timer的9倍。stp timer forward-delay 1500//配置设备的Forward Delay时间。 缺省情况下，设备的Forward Delay时间是1500厘秒（15秒）。stp timer hello 200//配置设备的Hello Time时间。 缺省情况下，设备的Hello Time时间是200厘秒（2秒）。 stp timer mac-age 2000//配置设备的Max Age时间。缺省情况下，设备的Max Age时间是2000厘秒（20秒）。max bandwidth-affected-linknumber 8//配置影响带宽的最大连接数。 缺省情况下，影响链路聚合带宽的最大连接数是8。 reset stp error packet statistics //清除生成树协议的错误报文计数。display stp toplogy-change//查看STP/RSTP拓扑变化相关的统计信息 STP配置举例如下图，需将SW1配置为根桥，SW2配置为备份根桥。通过在三天交换机中配置STP，对某个端口进行阻塞，防止网络出环。 图：STP配置拓扑 SW1配置文件： 1234567[SW1]dis current-configuration #sysname SW1#stp mode stpstp instance 0 root primary# SW2配置文件： 1234567[SW2]dis current-configuration #sysname SW2#stp mode stpstp instance 0 root secondary# 查看SW3的GI0/0/2端口STP状态： 图：SW3的gi0/0/2的STP状态]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
        <tag>STP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的基本操作]]></title>
    <url>%2F2017%2F11%2F24%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[二叉树：二叉树是树的特殊一种，具有如下特点：1、每个结点最多有两颗子树，结点的度最大为2。2、左子树和右子树是有顺序的，次序不能颠倒。3、即使某结点只有一个子树，也要区分左右子树。 满二叉树：在一棵二叉树中，如果所有分支结点都有左孩子和右孩子结点，并且叶子结点都集中在二叉树的最下层，这样的树叫做满二叉树 完全二叉树：若二叉树中最多只有最下面两层的结点的度数可以小于2，并且最下面一层的叶子结点都是依次排列在该层最左边的位置上，则称为完全二叉树 区别：满二叉树是完全二叉树的特例，因为满二叉树已经满了，而完全并不代表满。所以形态你也应该想象出来了吧，满指的是出了叶子节点外每个节点都有两个孩子，而完全的含义则是最后一层没有满。 二叉树的五个重要性质： 在二叉树的第i层上最多有2 i-1 个节点 。（i&gt;=1） 二叉树中如果深度为k,那么最多有2k-1个节点。(k&gt;=1） n0=n2+1 n0表示度数为0的节点 n2表示度数为2的节点 在完全二叉树中，具有n个节点的完全二叉树的深度为[log2n]+1，其中[log2n]+1是向下取整。 若对含 n 个结点的完全二叉树从上到下且从左至右进行 1 至 n 的编号，则对完全二叉树中任意一个编号为 i 的结点： 若 i=1，则该结点是二叉树的根，无双亲, 否则，编号为 [i/2] 的结点为其双亲结点; 若 2i&gt;n，则该结点无左孩子， 否则，编号为 2i 的结点为其左孩子结点； 2i+1&gt;n，则该结点无右孩子结点， 否则，编号为2i+1 的结点为其右孩子结点。 二叉树的基本操作：base.h12345678910111213141516171819//base.h//-----公用的常量和类型----------#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;malloc.h&gt;using namespace std;//函数结果状态码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define OVERFLOW -2typedef int Status;typedef char TElemType; biTree.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131//biTree.h//-----二叉树的基本函数实现------//---------二叉树的链式存储表示------typedef struct BiTNode&#123; //二叉树链表节点 TElemType date; //数据域 struct BiTNode *lchild, *rchild; //左右孩子指针&#125;BiTNode, *BiTree;//-----基本操作的函数原型说明------------//构造空二叉树Status InitBiTree(BiTree &amp;T)&#123; if(!(T = (BiTNode *)malloc(sizeof(BiTNode))))//开辟节点空间 exit(OVERFLOW); T == NULL; return OK;&#125;//按先序次序输入二叉树中节点的值（一个字符），@字符表示空树//构造二叉链表表示的二叉树TStatus CreateBiTree(BiTree &amp;T)&#123; char ch; cin&gt;&gt;ch; //输入字符 if(ch == '@') //判断输入的是否为@ T = NULL; //如果是@，T为空树 else&#123; if(!(T = (BiTNode *)malloc(sizeof(BiTNode))))//开辟节点空间 exit(OVERFLOW); T-&gt;date = ch; //生成根节点 CreateBiTree(T-&gt;lchild); //构造左子树 CreateBiTree(T-&gt;rchild); //构造右子树 &#125; return OK;&#125;//CreateBitree//销毁二叉树Status DestroyBiTree(BiTree &amp;T)&#123; if(T)&#123; DestroyBiTree(T-&gt;lchild); DestroyBiTree(T-&gt;rchild); free(T); T = NULL; &#125; return OK;&#125;//DestroyBiTree//判空Status BiTreeEmpty(BiTree T)&#123; if(T) return FALSE; else return TRUE;&#125;//BiTreeEmpty//递归求树的深度int BiTreeDepth(BiTree T)&#123; int ldepth; //用来存放左子树的深度 int rdepth; //右子树的深度 if(!T) //树空 return 0; ldepth = BiTreeDepth(T-&gt;lchild); //求左子树的深度 rdepth = BiTreeDepth(T-&gt;rchild); //求右子树的深度 return (ldepth &gt; rdepth) ? (ldepth+1):(rdepth+1);&#125;//BiTreeDepth//递归求叶子的个数int BiTreeLeafCount(BiTree T)&#123; if(T == NULL) return 0; if(T-&gt;lchild == NULL &amp;&amp; T-&gt;rchild == NULL) return 1; return BiTreeLeafCount(T-&gt;lchild) + BiTreeLeafCount(T-&gt;rchild);&#125;//BiTreeLeafCount//求二叉树中节点个数int NodeCount(BiTree T)&#123; if(T == NULL) return 0; return NodeCount(T-&gt;lchild) + NodeCount(T-&gt;rchild) + 1;&#125;//NodeCount//求二叉树第K层的节点个数int GetLevelNums(BiTree T, int k)&#123; if(T==NULL || k==0) return 0; if(k == 1) return 1; //左右子树k-1层节点数的和 return GetLevelNums(T-&gt;lchild, k-1) + GetLevelNums(T-&gt;rchild, k-1);&#125;//GetLevelNums//先序遍历二叉树Status PreOrderTraverse(BiTree T)&#123; if(T)&#123; //判T是否为空树 cout&lt;&lt;T-&gt;date&lt;&lt;" "; //输出T节点的数据 if(PreOrderTraverse(T-&gt;lchild)); //递归遍历左子树 if(PreOrderTraverse(T-&gt;rchild)); //递归遍历右子树 return ERROR; &#125;else&#123; return OK; &#125;&#125;//PreOrderTraverse//中序遍历二叉树Status InOrderTraverse(BiTree T)&#123; if(T)&#123; if(PreOrderTraverse(T-&gt;lchild)); cout&lt;&lt;T-&gt;date&lt;&lt;" "; if(PreOrderTraverse(T-&gt;rchild)); return ERROR; &#125;else&#123; return OK; &#125;&#125;//InOrderTraverse//后序遍历二叉树Status PostOrderTraverse(BiTree T)&#123; if(T)&#123; if(PreOrderTraverse(T-&gt;lchild)); if(PreOrderTraverse(T-&gt;rchild)); cout&lt;&lt;T-&gt;date&lt;&lt;" "; return ERROR; &#125;else&#123; return OK; &#125;&#125;//PostOrderTraverse main.cpp1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include "base.h"#include "biTree.h"#include "stack.h" //非递归中序遍历二叉树Status InOrderTraverse_Stack(BiTree T)&#123; PLinkStack S; //定义一个栈S BiTree p = T; //定义一个二叉树节点p = T； InitStack_L(&amp;S); //初始化栈S while( p || !StackEmpty_L(S))&#123; //结束条件为二叉树P空且栈S空 if(p)&#123; //判二叉树p是否为空 Push_L(S, p); //根指针进栈遍历左子树 p = p-&gt;lchild; //遍历左子树 &#125;else&#123; Pop_L(S, p); //根指针退栈 cout&lt;&lt;p-&gt;date&lt;&lt;" "; //访问根节点的数据 p = p-&gt;rchild; //遍历右子树 &#125;//else &#125;//while return OK;&#125;//InOrderTraverse_Stackint main()&#123; BiTree T; cout&lt;&lt;"先序创建二叉树，请按先序输入二叉树各节点的值：（@字符表示空格）"&lt;&lt;endl; CreateBiTree(T); cout&lt;&lt;"判空："; if(BiTreeEmpty(T)) cout&lt;&lt;"二叉树为空！"&lt;&lt;endl; else cout&lt;&lt;"二叉树不为空！"&lt;&lt;endl; cout&lt;&lt;"先序遍历二叉树："; PreOrderTraverse(T); cout&lt;&lt;endl; cout&lt;&lt;"中序遍历二叉树："; InOrderTraverse(T); cout&lt;&lt;endl; cout&lt;&lt;"后序遍历二叉树："; PostOrderTraverse(T); cout&lt;&lt;endl; cout&lt;&lt;"非递归中序遍历："; InOrderTraverse_Stack(T); cout&lt;&lt;endl; cout&lt;&lt;"二叉树的深度："&lt;&lt;BiTreeDepth(T)&lt;&lt;endl; cout&lt;&lt;"二叉树的叶子数："&lt;&lt;BiTreeLeafCount(T)&lt;&lt;endl; cout&lt;&lt;"二叉树的节点数："&lt;&lt;NodeCount(T)&lt;&lt;endl; cout&lt;&lt;"第2层的节点数："&lt;&lt;GetLevelNums(T, 2)&lt;&lt;endl; cout&lt;&lt;"初始化二叉树："&lt;&lt;endl; InitBiTree(T); cout&lt;&lt;"销毁二叉树："&lt;&lt;endl; return OK;&#125; 二叉树程序测试结果： 图：二叉树程序测试图]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链路聚合Eth-Trunk]]></title>
    <url>%2F2017%2F11%2F21%2F%E9%93%BE%E8%B7%AF%E8%81%9A%E5%90%88Eth-Trunk%2F</url>
    <content type="text"><![CDATA[链路聚合简介以太网链路聚合Eth-Trunk简称链路聚合，它通过将多条以太网物理链路捆绑在一起成为一条逻辑链路，从而实现增加链路带宽的目的。同时，这些捆绑在一起的链路通过相互间的动态备份，可以有效地提高链路的可靠性。 目的：随着网络规模不断扩大，用户对骨干链路的带宽和可靠性提出越来越高的要求。在传统技术中，常用更换高速率的接口板或更换支持高速率接口板的设备的方式来增加带宽，但这种方案需要付出高额的费用，而且不够灵活。 采用链路聚合技术可以在不进行硬件升级的条件下，通过将多个物理接口捆绑为一个逻辑接口，达到增加链路带宽的目的。在实现增大带宽目的的同时，链路聚合采用备份链路的机制，可以有效的提高设备之间链路的可靠性。 链路聚合主要有以下三个优势： 增加带宽 链路聚合接口的最大带宽可以达到各成员接口带宽之和。 提高可靠性 当某条活动链路出现故障时，流量可以切换到其他可用的成员链路上，从而提高链路聚合接口的可靠性。 负载分担 在一个链路聚合组内，可以实现在各成员活动链路上的负载分担。 原理描述基本概念：如在两个设备之间通过三条以太网物理链路相连，将这三条链路捆绑在一起，就成为了一条逻辑链路。这条逻辑链路的最大带宽等于原先三条以太网物理链路的带宽总和，从而达到了增加链路带宽的目的；同时，这三条以太网物理链路相互备份，有效地提高了链路的可靠性。 链路聚合的一些基本概念: 链路聚合组和链路聚合接口 链路聚合组LAG（Link Aggregation Group）是指将若干条以太链路捆绑在一起所形成的逻辑链路。 每个聚合组唯一对应着一个逻辑接口，这个逻辑接口称之为链路聚合接口或Eth-Trunk接口。链路聚合接口可以作为普通的以太网接口来使用，与普通以太网接口的差别在于：转发的时候链路聚合组需要从成员接口中选择一个或多个接口来进行数据转发。 成员接口和成员链路 组成Eth-Trunk接口的各个物理接口称为成员接口。成员接口对应的链路称为成员链路。 活动接口和非活动接口、活动链路和非活动链路 链路聚合组的成员接口存在活动接口和非活动接口两种。转发数据的接口称为活动接口，不转发数据的接口称为非活动接口。 活动接口对应的链路称为活动链路，非活动接口对应的链路称为非活动链路。 活动接口数上限阈值 设置活动接口数上限阈值的目的是在保证带宽的情况下提高网络的可靠性。当前活动链路数目达到上限阈值时，再向Eth-Trunk中添加成员接口，不会增加Eth-Trunk活动接口的数目，超过上限阈值的链路状态将被置为Down，作为备份链路。 例如，有8条无故障链路在一个Eth-Trunk内，每条链路都能提供1G的带宽，现在最多需要5G的带宽，那么上限阈值就可以设为5或者更大的值。其他的链路就自动进入备份状态以提高网络的可靠性。 注：手工负载分担模式链路聚合不支持活动接口数上限阈值的配置。 活动接口数下限阈值 设置活动接口数下限阈值是为了保证最小带宽，当前活动链路数目小于下限阈值时，Eth-Trunk接口的状态转为Down。 例如，每条物理链路能提供1G的带宽，现在最小需要2G的带宽，那么活动接口数下限阈值必须要大于等于2。 链路聚合模式 链路聚合模式分为手工模式和LACP模式两种 两种链路聚合模式比较： 维度 手工模式 LACP模式 定义 Eth-Trunk的建立、成员接口的加入由手工配置，没有链路聚合控制协议的参与。 Eth-Trunk的建立是基于LACP协议的，LACP为交换数据的设备提供一种标准的协商方式，以供系统根据自身配置自动形成聚合链路并启动聚合链路收发数据。聚合链路形成以后，负责维护链路状态。在聚合条件发生变化时，自动调整或解散链路聚合。 设备是否需要支持LACP协议 不需要 需要 数据转发 一般情况下，所有链路都是活动链路。所有活动链路均参与数据转发。如果某条活动链路故障，链路聚合组自动在剩余的活动链路中分担流量。 一般情况下，部分链路是活动链路。所有活动链路均参与数据转发。如果某条活动链路故障，链路聚合组自动在非活动链路中选择一条链路作为活动链路，参与数据转发的链路数目不变。 是否支持跨设备的链路聚合 不支持 支持 检测故障 只能检测到同一聚合组内的成员链路有断路等有限故障，但是无法检测到链路故障、链路错连等故障。 不仅能够检测到同一聚合组内的成员链路有断路等有限故障，还可以检测到链路故障、链路错连等故障。 设备支持的链路聚合方式: 同一设备：是指链路聚合时，同一聚合组的成员接口分布在同一设备。 堆叠设备：是指在堆叠场景下，成员接口分部在堆叠的各个成员设备上。 跨设备：是指E-Trunk基于LACP（单台设备链路聚合的标准）进行了扩展，能够实现多台设备间的链路聚合。 手工模式链路聚合：根据是否启用链路聚合控制协议LACP，链路聚合分为手工模式和LACP模式。 手工模式下，Eth-Trunk的建立、成员接口的加入由手工配置，没有链路聚合控制协议LACP的参与。当需要在两个直连设备之间提供一个较大的链路带宽而设备又不支持LACP协议时，可以使用手工模式。手工模式可以实现增加带宽、提高可靠性和负载分担的目的。 LACP模式链路聚合：作为链路聚合技术，手工负载分担模式Eth-Trunk可以完成多个物理接口聚合成一个Eth-Trunk口来提高带宽，同时能够检测到同一聚合组内的成员链路有断路等有限故障，但是无法检测到链路层故障、链路错连等故障。 为了提高Eth-Trunk的容错性，并且能提供备份功能，保证成员链路的高可靠性，出现了链路聚合控制协议LACP（Link Aggregation Control Protocol），LACP模式就是采用LACP的一种链路聚合模式。 LACP为交换数据的设备提供一种标准的协商方式，以供设备根据自身配置自动形成聚合链路并启动聚合链路收发数据。聚合链路形成以后，LACP负责维护链路状态，在聚合条件发生变化时，自动调整或解散链路聚合。 基本概念： 系统LACP优先级 系统LACP优先级是为了区分两端设备优先级的高低而配置的参数。LACP模式下，两端设备所选择的活动接口必须保持一致，否则链路聚合组就无法建立。此时可以使其中一端具有更高的优先级，另一端根据高优先级的一端来选择活动接口即可。系统LACP优先级值越小优先级越高。 接口LACP优先级 接口LACP优先级是为了区别同一个Eth-Trunk中的不同接口被选为活动接口的优先程度，优先级高的接口将优先被选为活动接口。接口LACP优先级值越小，优先级越高。 成员接口间M:N备份 LACP模式链路聚合由LACP确定聚合组中的活动和非活动链路，又称为M:N模式，即M条活动链路与N条备份链路的模式。这种模式提供了更高的链路可靠性，并且可以在M条链路中实现不同方式的负载均衡。 LACP模式实现原理：基于IEEE802.3ad标准的LACP是一种实现链路动态聚合与解聚合的协议。LACP通过链路聚合控制协议数据单元LACPDU（Link Aggregation Control Protocol Data Unit）与对端交互信息。 在LACP模式的Eth-Trunk中加入成员接口后，这些接口将通过发送LACPDU向对端通告自己的系统优先级、MAC地址、接口优先级、接口号和操作Key等信息。对端接收到这些信息后，将这些信息与自身接口所保存的信息比较，用以选择能够聚合的接口，双方对哪些接口能够成为活动接口达成一致，确定活动链路。 LACPDU报文： 图：LACPDU报文格式 报文字段说明： 字段 长度 说明 Destination Address 6字节 目的MAC地址，是一个组播地址（01-80-C2-00-00-02） Source Address 6字节 源MAC地址，发送端口的MAC地址 Length/Type 2字节 协议类型：0x8809 Subtype 1字节 报文子类型：0x01，说明是LACP报文 Version Number 1字节 协议版本号：0x01 TLV_type 1字节 0x00代表Terminator字段0x01代表Actor字段0x02代表Partner字段0x03代表Collector字段 Actor_Information_Length 1字节 actor信息字段长度，为20字节 Actor_Port 2字节 端口号，根据算法生成，由接口所在的槽位号、子卡号和端口号决定 Actor_State 1字节 本端状态信息：LACP_Activity：代表链路所在的聚合组参与LACP协商的方式。主动的LACP被编码为1，主动方式下会主动发送LACPDU报文给对方，被动方式不会主动发送协商报文，除非收到协商报文才会参与。LACP_Timeout：代表链路接收LACPDU报文的周期，有两种，快周期1s和慢周期30s，超时时间为周期的3倍。短超时被编码为1，长超时被编码为0。Aggregation：标识该链路能否被聚合组聚合。如果编码为0，该链路被认为是独立的，不能被聚合，即，这个链路只能作为一个个体链路运行。Synchronization：代表该链路是否已被分配到一个正确的链路聚合组，如果该链路已经关联了一个兼容的聚合器，那么该链路聚合组的识别与系统ID和被发送的运行Key信息是一致的。编码为0，代表链路当前不在正确的聚合里。Collecting：帧的收集使能位，假如编码为1，表示在这个链路上进来的帧的收集是明确使能的；即收集当前被使能，并且不期望在没有管理变化或接收协议信息变化的情况下被禁止。其它情况下这个值编码为0。Distributing：帧的分配使能位，假如编码为0，意味着在这个链路上的外出帧的分配被明确禁止，并且不期望在没有管理变化或接收协议信息变化的情况下被使能。其它情况下这个值编码为1。Default：诊断调试时使用，编码为1，代表接收到的对端的信息是管理配置的。假如编码为0，正在使用的运行伙伴信息在接收到的LACPDU里。该值不被正常LACP协议使用，仅用于诊断协议问题。Expired：诊断调试时使用，编码为1，代表本端的接收机是处于EXPIRED超时状态；假如编码为0，本端接收状态机处于正常状态。该值不被正常LACP协议使用，仅用于诊断协议问题。 Actor_System_Priority 2字节 本端系统优先级，可以设置，默认情况下为32768 Actor_System 6字节 系统ID，本端系统的MAC地址 Actor_key 2字节 端口KEY值，系统根据端口的配置生成，是端口能否成为聚合组中的一员的关 键因素，影响Key值得因素有trunk ID、接口的速率和双工模式 Actor_Port_Priority 2字节 接口优先级，可以配置，默认为0x8000 Reserved 3字节 保留字段，可用于功能调试以及扩展 Partner_Information_Length 1字节 Partner信息字段长度。Partner字段代表了链路接口接收到对端的系统信息、接口信息和状态信息，与actor字段含义一致。在协商最开始未收到对端信息时，partner字段填充0，接收到对端信息后会把收到的对端信息补充到partner字段当中。 Partner_Port 2字节 对端端口号 Partner_State 2字节 对端状态信息 Partner_System_Priority 2字节 对端系统优先级 Partner_System 6字节 对端系统ID，对端系统的MAC地址 Partner_key 2字节 对端端口KEY值 Partner_Port_Priority 2字节 对端接口优先级 Reserved 2字节 保留字段 Collector_Information_Length 1字节 Collector信息字段长度：0x10 CollectorMaxDelay 2字节 最大延时：默认情况下为0xffff Reserved 12字节 保留字段 Terminator_Length 1字节 Terminator信息字段长度：0x00 Reserved 50字节 保留字段，全置0 FCS 4字节 用于帧内后续字节差错的循环冗余检验（也称为FCS或帧检验序列）。 抓包示例： 图：LACP报文抓包示例 LACP模式Eth-Trunk建立过程如下： 两端互相发送LACPDU报文。 如下图所示，在DeviceA和DeviceB上创建Eth-Trunk并配置为LACP模式，然后向Eth-Trunk中手工加入成员接口。此时成员接口上便启用了LACP协议，两端互发LACPDU报文。 确定主动端和活动链路。 如下图所示，两端设备均会收到对端发来的LACPDU报文。以DeviceB为例，当DeviceB收到DeviceA发送的报文时，DeviceB会查看并记录对端信息，然后比较系统优先级字段，如果DeviceA的系统优先级高于本端的系统优先级，则确定DeviceA为LACP主动端。如果DeviceA和DeviceB的系统优先级相同，比较两端设备的MAC地址，确定MAC地址小的一端为LACP主动端。 选出主动端后，两端都会以主动端的接口优先级来选择活动接口，两端设备选择了一致的活动接口，活动链路组便可以建立起来，从这些活动链路中以负载分担的方式转发数据。 LACP抢占： 使能LACP抢占功能后，聚合组会始终保持高优先级的接口作为活动接口的状态。 图：抢占功能演示 以下两种情况需要使能LAXP的抢占功能： Port1接口出现故障而后又恢复了正常。当接口Port1出现故障时被Port3所取代，如果在Eth-Trunk接口下未使能LACP抢占功能，则故障恢复时Port1将处于备份状态；如果使能了LACP抢占功能，当Port1故障恢复时，由于接口优先级比Port3高，将重新成为活动接口，Port3再次成为备份接口。 如果希望Port3接口替换Port1、Port2中的一个接口成为活动接口，可以使能了LACP抢占功能，并配置Port3的接口LACP优先级较高。如果没有使能LACP抢占功能，即使将备份接口的优先级调整为高于当前活动接口的优先级，系统也不会进行重新选择活动接口的过程，不切换活动接口。 LACP抢占延时：抢占延时是LACP抢占发生时，处于备用状态的链路将会等待一段时间后再切换到转发状态。配置抢占延时是为了避免由于某些链路状态频繁变化而导致Eth-Trunk数据传输不稳定的情况。 活动链路与非活动链路的切换：LACP模式链路聚合组两端设备中任何一端检测到以下事件，都会触发聚合组的链路切换： 链路Down事件。 以太网OAM检测到链路失效。 LACP协议发现链路故障。 接口不可用。 在使能了LACP抢占功能的前提下，更改备份接口的优先级高于当前活动接口的优先级。 当满足上述切换条件其中之一时，按照如下步骤进行切换： 关闭故障链路。 从N条备份链路中选择优先级最高的链路接替活动链路中的故障链路。 优先级最高的备份链路转为活动状态并转发数据，完成切换。 链路聚合负载分担方式：背景：数据流是指一组具有某个或某些相同属性的数据包。这些属性有源MAC地址、目的MAC地址、源IP地址、目的IP地址、TCP/UDP的源端口号、TCP/UDP的目的端口号等。 对于负载分担，可以分为逐包的负载分担和逐流的负载分担。 逐包的负载分担 在使用Eth-Trunk转发数据时，由于聚合组两端设备之间有多条物理链路，就会产生同一数据流的第一个数据帧在一条物理链路上传输，而第二个数据帧在另外一条物理链路上传输的情况。这样一来同一数据流的第二个数据帧就有可能比第一个数据帧先到达对端设备，从而产生接收数据包乱序的情况。 逐流的负载分担 这种机制把数据帧中的地址通过HASH算法生成HASH-KEY值，然后根据这个数值在Eth-Trunk转发表中寻找对应的出接口，不同的MAC或IP地址HASH得出的HASH-KEY值不同，从而出接口也就不同，这样既保证了同一数据流的帧在同一条物理链路转发，又实现了流量在聚合组内各物理链路上的负载分担。逐流负载分担能保证包的顺序，但不能保证带宽利用率。 注：目前AR系列路由器仅支持逐流的负载分担。 转发原理：Eth-Trunk位于MAC与LLC子层之间，属于数据链路层。 Eth-Trunk模块内部维护一张转发表，这张表由以下两项组成。 HASH-KEY值 HASH-KEY值是根据数据包的MAC地址或IP地址等，经HASH算法计算得出。 接口号 Eth-Trunk转发表表项分布和设备每个Eth-Trunk支持加入的成员接口数量相关，不同的HASH-KEY值对应不同的出接口。 Eth-Trunk模块根据转发表转发数据帧的过程如下： Eth-Trunk模块从MAC子层接收到一个数据帧后，根据负载分担方式提取数据帧的源MAC地址/IP地址或目的MAC地址/IP地址。 根据HASH算法进行计算，得到HASH-KEY值。 Eth-Trunk模块根据HASH-KEY值在转发表中查找对应的接口，把数据帧从该接口发送出去。 负载分担方式：为了避免数据包乱序情况的发生，Eth-Trunk采用逐流负载分担的机制，其中如何转发数据则由于选择不同的负载分担方式而有所差别。 负载分担的方式主要包括以下几种，用户可以根据具体应用选择不同的负载分担方式。 根据报文的源MAC地址进行负载分担 根据报文的目的MAC地址进行负载分担 根据报文的源IP地址进行负载分担 根据报文的目的IP地址进行负载分担 根据报文的源MAC地址和目的MAC地址进行负载分担 根据报文的源IP地址和目的IP地址进行负载分担 配置负载分担方式时，请注意： 负载分担方式只在流量的出接口上生效，如果发现各入接口的流量不均衡，请修改上行出接口的负载分担方式。 尽量将数据流通过负载分担在所有活动链路上传输，避免数据流仅在一条链路上传输，造成流量拥堵，影响业务正常运行。 例如，数据报文的目的MAC和IP地址只有一个，则应选择根据报文的源MAC和IP地址进行负载分担，如果选择根据报文的目的MAC和IP地址进行负载分担则会造成流量只在一条链路上传输，造成流量拥堵。 配置注意事项：链路聚合前： 成员接口不能配置某些业务，例如成员接口不能修改接口类型、不能配置静态MAC地址。 Eth-Trunk接口不能嵌套，即Eth-Trunk接口的成员接口不能是Eth-Trunk接口。 一个Eth-Trunk接口中的成员接口必须是以太网类型和速率相同的接口。 以太网类型和速率不同的接口不能加入同一个Eth-Trunk接口，如GE接口和FE接口不能加入同一个Eth-Trunk接口，GE电接口和GE光接口不能加入同一个Eth-Trunk接口。 如果本端设备接口加入了Eth-Trunk，与该接口直连的对端接口也必须加入Eth-Trunk，两端才能正常通信。 两台设备对接时需要保证两端设备上链路聚合的模式一致。 链路聚合后： 一个以太网接口只能加入到一个Eth-Trunk接口，如果需要加入其它Eth-Trunk接口，必须先退出原来的Eth-Trunk接口。 当成员接口加入Eth-Trunk后，学习MAC地址或ARP地址时是按照Eth-Trunk来学习的，而不是按照成员接口来学习。 删除聚合组时需要先删除聚合组中的成员接口。 缺省配置： 参数 缺省值 链路聚合模式 手工负载分担模式 活动接口数上限阈值 8 活动接口数下限阈值 1 系统LACP优先级 32768 接口LACP优先级 32768 LACP抢占 去使能 LACP抢占等待时间 30s 接收LACP报文超时时间 90s 链路聚合配置命令行配置手工负载分担模式：如下图，交换机1和2都有VLAN10,20.通过在两个交换机之间配置链路聚合提高链路带宽，以及增加一定的可靠性。 图:配置手工负载模式 配置命令行：两个交换机配置相同 12345678910111213141516171819[SW1]dis current-configuration #sysname SW1#vlan batch 10 20#interface Eth-Trunk1 port link-type trunk port trunk allow-pass vlan 10 20#interface GigabitEthernet0/0/1 eth-trunk 1 //加入Eth-trunk接口#interface GigabitEthernet0/0/2 eth-trunk 1 //加入Eth-trunk接口#interface GigabitEthernet0/0/3 eth-trunk 1 //加入Eth-trunk接口# 执行：display eth-trunk 1，查看配置结果： 图：手工负载模式配置情况 配置LACP模式链路聚合：如下图，在两台设备上配置LACP模式链路聚合组，提高两设备之间的带宽与可靠性，具体要求如下： 两条活动链路具有负载分担的能力。 两设备间的链路具有一条冗余备份链路，当活动链路出现故障链路时，备份链路替代故障链路，保持数据传输的可靠性。 图：LACP模式 配置命令行：123456789101112131415161718192021222324252627282930313233343536373839404142[SW3]dis current-configuration #sysname SW3#lacp priority 100//配置系统LACP优先级#interface Eth-Trunk1//创建eth-trunk接口 mode lacp-static//配置链路聚合模式为LACP模式 least active-linknumber 2//配置链路聚合活动接口数下限阈值 max bandwidth-affected-linknumber 3//配置带宽计算的端口数量 load-balance dst-ip//配置负载分担方式 lacp timeout fast//配置当前接口接收LACP协议报文的超时时间 lacp preempt enable//使能当前Eth-Trunk接口的LACP抢占功能 max active-linknumber 2//配置链路聚合活动接口数上限阈值 lacp preempt delay 20//配置当前Eth-Trunk接口的LACP抢占等待时间//配置为fast，对端发送LACP报文的周期为1秒。//配置为slow，对端发送LACP报文的周期为30秒。//LACP协议报文的超时时间为LACP报文发送周期的3倍 lacp selected speed//更改LACP模式Eth-Trunk依据接口速率来选择活动接口#interface GigabitEthernet0/0/1 eth-trunk 1 //加入Eth-trunk接口 lacp priority 100//配置当前接口的LACP优先级#interface GigabitEthernet0/0/2 eth-trunk 1#interface GigabitEthernet0/0/3 eth-trunk 1# 配置结果： 图：：LACP配置结果 其他常用命令：1234567891011121314151617181920trunkport interface gi 0/0/1 to 0/0/3 //将多个接口同时加上eth-turnk接口中display eth-trunk [ trunk-id [ interface interface-type interface-number | verbose ] ]//查看Eth-Trunk接口的配置信息 display lacp statistics eth-trunk 1//查看LACP模式下LACP报文收发统计信息 display interface eth-trunk 1 //查看eth-trunk接口的状态信息 display trunkmembership eth-trunk 1 //查看eth-trunk的成员接口信息 reset lacp statistics eth-trunk 1//清除LACP收发报文的统计信息 reset lacp error packet statistics//清除LACP错误报文的统计信息]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QinQ基础知识]]></title>
    <url>%2F2017%2F11%2F19%2FQinQ%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[QinQ简介定义：QinQ（802.1Q-in-802.1Q）技术是一项扩展VLAN空间的技术，通过在802.1Q标签报文的基础上再增加一层802.1Q的Tag来达到扩展VLAN空间的功能，可以使私网VLAN透传公网。由于在骨干网中传递的报文有两层802.1Q Tag（一层公网Tag，一层私网Tag），即802.1Q-in-802.1Q，所以称之为QinQ协议。 ##目的： 随着以太网技术在网络中的大量部署，利用802.1Q VLAN对用户进行隔离和标识受到很大限制。因为IEEE802.1Q中定义的VLAN Tag域只有12个比特，仅能表示4096个VLAN，无法满足以太网中标识大量用户的需求，于是QinQ技术应运而生。 QinQ是通过在原有的802.1Q报文的基础上增加一层802.1Q标签来实现的，使得VLAN数量增加到4094×4094，扩展了VLAN空间。 随着以太网的发展以及精细化运作的要求，QinQ的双层标签又有了进一步的使用场景。它的内外层标签可以代表不同的信息，如内层标签代表用户，外层标签代表业务。另外，QinQ报文带着两层Tag穿越公网时，内层Tag透明传送，也是一种简单、实用的VPN技术。因此它又可以作为核心MPLS VPN在以太网VPN的延伸，最终形成端到端的VPN技术。 优点： 扩展VLAN，对用户进行隔离和标识不再受到限制。 QinQ内外层标签可以代表不同的信息，如内层标签代表用户，外层标签代表业务，更利于业务的部署。 QinQ封装、终结的方式很丰富，帮助运营商实现业务精细化运营。 解决日益紧缺的公网VLAN ID 资源问题 用户可以规划自己的私网VLNA ID 提供一种较为简单的二层VPN解决方案 使用户网络具有较高的独立性 原理描述基本原理：QinQ是指在802.1Q VLAN的基础上增加一层802.1Q VLAN标签，从而拓展VLAN的使用空间。在公网的传输过程中，设备只根据外层VLAN Tag转发报文，并根据报文的外层VLAN Tag进行MAC地址学习，而用户的私网VLAN Tag将被当作报文的数据部分进行传输。 QinQ报文：QinQ报文有固定的格式，就是在802.1Q的标签之上再打一层802.1Q标签，QinQ报文比802.1Q报文多四个字节。 图；QinQ帧格式 字段解释： 字段 长度 含义 Destination address 6字节 目的MAC地址。 Source address 6字节 源MAC地址。 Type 2字节 长度为2字节，表示帧类型。取值为0x8100时表示802.1Q Tag帧。如果不支持802.1Q的设备收到这样的帧，会将其丢弃。对于内层VLAN tag，该值设置为0x8100；对于外层VLAN tag，有下列几种类型0x8100：思科路由器使用0x88A8：Extreme Networks switches使用0x9100：Juniper路由器使用0x9200：Several路由器使用 PRI 3比特 Priority，长度为3比特，表示帧的优先级，取值范围为0～7，值越大优先级越高。用于当交换机阻塞时，优先发送优先级高的数据包。 CFI 1比特 CFI (Canonical Format Indicator)，长度为1比特，表示MAC地址是否是经典格式。CFI为0说明是经典格式，CFI为1表示为非经典格式。用于区分以太网帧、FDDI（Fiber Distributed Digital Interface）帧和令牌环网帧。在以太网中，CFI的值为0。 VID 12比特 LAN ID，长度为12比特，表示该帧所属的VLAN。在VRP中，可配置的VLAN ID取值范围为1～4094。 Length/Type 2字节 指后续数据的字节长度，但不包括CRC检验码。 Data 42~1500字节 负载（可能包含填充位）。 CRC 4字节 用于帧内后续字节差错的循环冗余检验（也称为FCS或帧检验序列）。 报文示例： 图：QinQ抓包示例 QinQ封装：QinQ封装是指如何把单层Q报文转换成双层Q报文。 根据不同的封装数据，QinQ可以分为几种不同类型，包括基本QinQ和灵活QinQ两大类。其中基本QinQ是指基于接口的QinQ，灵活QinQ包括基于VLAN ID的QinQ和基于802.1p优先级的QinQ，具体如下： 基于接口的QinQ封装 基于接口的封装是指进入一个接口的所有流量全部封装一个相同的外层VLAN Tag，封装方式不够灵活，用户业务区分不够细致，这种封装方式也称作基本QinQ。 基于VLAN ID的QinQ封装（灵活QinQ） 基于VLAN ID的QinQ封装可以对不同的数据流选择是否封装外层Tag、封装何种外层Tag，因此这种封装方式也称作灵活QinQ。 例如：当同一用户的不同业务使用不同的VLAN ID时，可以根据VLAN ID区间进行分流。假设PC上网的VLAN ID范围是101～200；IPTV的VLAN ID范围是201～300；VoIP的VLAN ID范围是301～400。根据VLAN ID范围，对PC上网业务封装上外层Tag 100，对IPTV封装上外层Tag 300，对VoIP封装上外层Tag 500。 基于802.1p优先级的QinQ封装（基于流的灵活QinQ） 基于802.1p优先级的QinQ封装可以对不同优先级的数据流选择是否封装外层Tag、封装何种外层Tag，因此这种封装方式也称作灵活QinQ。 例如：当同一用户的不同业务使用不同的优先级，如语音、视频、数据等。可以根据优先级为这些业务建立不同的数据传输通道，方便对业务进行区分。 QinQ的实现方式：QinQ的实现方式可分为以下两种： 基本QinQ 如果收到的是带有VLAN Tag的报文，该报文就成为带双Tag的报文。 如果收到的是不带VLAN Tag的报文，该报文就成为带有本端口缺省VLAN Tag的报文。 灵活QinQ 为具有不同内层VLAN ID的报文添加不同的外层VLAN Tag。 根据报文内层VLAN的802.1p优先级标记外层VLAN的802.1p优先级和添加不同的外层VLAN Tag。 通过使用灵活QinQ技术，在能够隔离运营商网络和用户网络的同时，又能够提供丰富的业务特性和更加灵活的组网能力。 QinQ/Dot1q终结子接口：终结主要是指设备对报文的单层或者双层Tag进行识别，然后根据后续的转发行为对单层或者双层Tag进行剥离或继续传送。 终结一般在路由子接口上执行，即：终结子接口。 QinQ技术在和MPLS/IP核心网连接时，根据不同的情况，会用到不同的终结方法。 如果路由子接口是对报文的单层Tag终结，那么该子接口称为Dot1q终结子接口。 如果路由子接口是对报文的双层Tag终结，那么该子接口称为QinQ终结子接口。 注意： Dot1q终结子接口和QinQ终结子接口不支持透传不带VLAN的报文，收到不带VLAN的报文会直接丢弃。 基本QinQ：基本QinQ，是基于接口方式实现的。开启接口的基本QinQ功能后，当该接口接收到报文，设备会为该报文打上配置的外层Tag。如果接收到的是已经带有VLAN Tag的报文，则为其加上外层VLAN Tag；如果接收到的是不带VLAN Tag的报文，则先为其加上内层VLAN Tag，再加上外层Tag。 灵活QinQ： 基于VLAN ID的灵活QinQ：为具有不同内层VLAN ID的报文添加不同的外层VLAN Tag。 基于802.1p优先级的灵活QinQ：根据报文的原有内层VLAN的802.1p优先级添加不同的外层VLAN Tag。 灵活QinQ功能是对基本QinQ功能的扩展，它比基本QinQ的功能更灵活。二者之间的主要区别是： 基本QinQ：对进入二层QinQ接口的所有帧都加上相同的外层Tag。 灵活QinQ：对进入二层QinQ接口的帧，可以根据不同的内层Tag而加上不同的外层Tag，对于用户VLAN的划分更加细致。 TPID（Tag Protocol Identifier）：标签协议标识TPID（Tag Protocol Identifier）是VLAN Tag中的一个字段，表示VLAN Tag的协议类型，IEEE 802.1Q协议规定该字段的取值为0x8100。 IEEE802.1Q协议定义的以太网帧的VLAN Tag。802.1Q Tag位于SA（Source Address）和Length/Type之间。通过检查对应的TPID值，设备可确定收到的帧承载的是运营商VLAN标记还是用户VLAN标记。接收到帧之后，设备将配置的TPID值与帧中TPID字段的值进行比较。如果二者匹配，则该帧承载的是对应的VLAN标记。例如，如果帧承载TPID值为0x8100的VLAN标记，而用户网络VLAN标记的TPID值配置为0x8200，设备将认为该帧没有用户VLAN标记。也就是说，设备认为该帧是Untagged报文。 另外，不同运营商的系统可能将QinQ帧外层VLAN标记的TPID设置为不同值。为实现与这些系统的兼容性，可以修改TPID值，使QinQ帧发送到公网时，承载与特定运营商相同的TPID值，从而实现与该运营商设备之间的互操作性。以太网帧的TPID与不带VLAN标记的帧的协议类型字段位置相同。为避免在网络中转发和处理数据包时出现问题，不可将TPID值设置为下表中的任意值： 协议类型及对应值描述表： 协议类型 对应值 ARP 0x0806 RARP 0x8035 IP 0x0800 IPv6 0x86DD PPPoE 0x8863/0x8864 MPLS 0x8847/0x8848 IPX/SPX 0x8137 LACP 0x8809 802.1x 0x888E HGMP 0x88A7 设备保留 0xFFFD/0xFFFE/0xFFFF QinQ配置配置基本QinQ(二层)：如下图，通过配置基本QinQ，实现客户网络在运营商网络中的传输。 图：基本QinQ配置拓扑 配置文件：LSW1和LSW4配置相同： 123456789101112131415161718&lt;SW1&gt;dis current-configuration #sysname SW1#vlan batch 10 20#interface GigabitEthernet0/0/1 port link-type access port default vlan 10#interface GigabitEthernet0/0/2 port link-type access port default vlan 20#interface GigabitEthernet0/0/3 port link-type trunk port trunk allow-pass vlan 10 20# LSW3和LSW4配置相同： 1234567891011121314[SW2]dis current-configuration #sysname SW2#vlan batch 100#interface GigabitEthernet0/0/1 port link-type dot1q-tunnel //使能二层QinQ功能 port default vlan 100 //划分接口到VLAN100#interface GigabitEthernet0/0/2 port link-type trunk port trunk allow-pass vlan 100# 配置灵活QinQ（二层）：拓扑如上，LSW1和LSW4配置同上。 LSW2和LSW3配置如下： 1234567891011121314151617181920[SW2]dis current-configuration #sysname SW2#vlan batch 100 200#interface GigabitEthernet0/0/1qinq vlan-translation enable//开启QinQ的VLAN转换功能port hybrid untagged vlan 100 200//定义接口出方向剥离VLAN100和VLAN200的标签port vlan-stacking vlan 10 stack-vlan 100//接口收到来自VLAN10的数据帧后叠加一层VLAN100的外层标签port vlan-stacking vlan 20 stack-vlan 200//接口收到来自VLAN20的数据帧后叠加一层VLAN200的外层标签#interface GigabitEthernet0/0/2 port link-type trunk port trunk allow-pass vlan 100 200# 注： 灵活QinQ只能用在hybrid接口，trunk口无法实现。 qing protocol 9100 \只会修改针对内层VLAN TAG的以太类型的改写，用于不同厂商的设备互通。华为默认为8100，可配置范围为0x0600~0xFFFF。 基本QinQ可配置多层，而灵活QinQ只能配置两层，想要配多层，第三层开始得结合配置基本QinQ。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>VLAN</tag>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[端口镜像]]></title>
    <url>%2F2017%2F11%2F16%2F%E7%AB%AF%E5%8F%A3%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[镜像简介：镜像是指将经过指定端口（源端口或者镜像端口）的报文复制一份到另一个指定端口（目的端口或者观察端口）。 目的：在网络运营与维护的过程中，为了便于业务监测和故障定位，网络管理员时常要获取设备上的业务报文进行分析。 镜像可以在不影响设备对报文进行正常处理的情况下，将镜像端口的报文复制一份到观察端口。网络管理员通过网络监控设备就可以分析从观察端口复制过来的报文，判断网络中运行的业务是否正常。 原理描述：基本概念：###镜像端口和观察端口： 镜像端口：是指被监控的端口，镜像端口收发的报文将被复制一份到与监控设备相连的端口。 观察端口：是指连接监控设备的端口，用于将镜像端口复制过来的报文发送给监控设备。 一般观察端口专门用于镜像流量的转发，因此不建议在上面配置其他业务，防止镜像流量与其他业务流量在观察端口上同时转发会互相影响。 在设备上应用镜像功能时，如果镜像过多，会占用较多的设备内部转发带宽，可能影响其他业务转发。另外，如果镜像端口与观察端口的带宽不一致，比如，镜像端口的带宽是1000Mbit/s，观察端口的带宽是100Mbit/s，则有可能导致观察端口因带宽不足而不能及时转发全部的镜像报文，发生丢包情况。 镜像方向：镜像方向是指将镜像端口指定方向的报文复制到观察端口，包括： 入方向：将镜像端口接收的报文复制到观察端口上。 出方向：将镜像端口发送的报文复制到观察端口上。 双向：将镜像端口接收和发送的报文都复制到观察端口上。 端口镜像：端口镜像是指设备复制从镜像端口流经的报文，并将此报文传送到指定的观察端口进行分析和监控。端口镜像根据监控设备在网络中位置的不同，分为本地端口镜像和远程端口镜像。 本地端口镜像：本地端口镜像是指观察端口与监控设备直接相连，此时观察端口被称为本地观察端口。 远程端口镜像：远程端口镜像是指观察端口与监控设备通过中间网络传输镜像报文，此时观察端口被称为远程观察端口。 二层远程端口镜像是指远程观察端口与监控设备通过一个二层网络相连。如下图所示，二层远程端口镜像中镜像报文的具体转发过程如下。 图：二层远程端口镜像示意图 镜像端口将流经的原始报文复制到远程观察端口。 远程观察端口收到镜像端口复制过来的镜像报文，在原来的VLAN标签（VLAN10）外层再添加一层VLAN标签（VLAN20），以便将镜像报文向中间二层网络转发。值得注意的是，这一步不需要通过端口加入VLAN来完成，是直接通过配置远程观察端口来实现的。 SwitchC在接收到远程观察端口发来的镜像报文后，就将镜像报文向监控设备转发。为了实现这一步，需要将中间二层设备（SwitchC）与远程观察端口、监控设备相连的端口加入VLAN20，保证tchB、SwitchC与监控设备间能够二层通信。 流镜像：流镜像是指在设备上配置一定的规则，将符合规则的特定业务流复制到观察端口进行分析和监控。 VLAN镜像：VLAN镜像是指将指定VLAN内所有活动接口的报文镜像到观察端口。用户可以对某个VLAN或者某些VLAN内的报文进行监控。 目前，华为S系列盒式交换机在应用VLAN镜像时，仅支持将VLAN内活动接口入方向的报文镜像到观察端口。 同端口镜像类似，根据监控设备在网络中位置的不同，VLAN镜像也可以分为本地VLAN镜像和远程VLAN镜像。值得注意的是，远程VLAN镜像中，主机所在VLAN和用于转发镜像报文的中间二层网络的VLAN不能相同。 MAC镜像:MAC镜像是指将VLAN内匹配指定源或者目的MAC地址的报文镜像到观察端口。MAC地址镜像提供了一种更加精确的镜像方式，用户可以对网络中特定设备的报文进行监控。 目前，华为S系列盒式交换机在应用MAC镜像时，仅支持将VLAN内活动接口入方向匹配指定源或者目的MAC地址的报文镜像到观察端口。 端口镜像配置命令：123456789101112131415observer-port [observer-port-index] interface-type interface-number [untag-packet]//配置单个本地观察端口observer-port [ observe-port-index ] interface-range &#123; interface-type interface-number [ to interface-type interface-number ] &#125; &amp;&lt;1-n&gt; [ untag-packet ]//批量配置本地观察端口 observer-port observe-port-index interface-range &#123; add | delete &#125; interface-type interface-number//向配置好的本地观察端口组添加或者删除本地观察端口。port-mirroring to observe-port observe-port-index &#123; both | inbound | outboud &#125;//将镜像端口绑定到观察端口display observe-port //查看观察端口的配置信息 diaplay port-mirroring //查看镜像功能的配置信息 注意： 一般观察端口专门用于镜像流量的转发，因此不建议在上面配置其他业务，防止镜像流量与其他业务流量在观察端口上同时转发会互相影响。 inbound：将镜像端口入方向绑定到观察端口，即将镜像端口接收的报文复制到观察端口上。 outbound：将镜像端口出方向绑定到观察端口，即将镜像端口发送的报文复制到观察端口上。 both：将镜像端口双方向绑定到观察端口，将镜像端口收、发的报文都复制到观察端口上。 在1：N镜像中，如果镜像端口某一方向绑定的是通过批量方式配置的多个观察端口，则该方向不能再绑定到其他的观察端口。 以太网端口和Eth-trunk端口都可以配置为镜像端口。如果将Eth-trunk端口配置为镜像端口，就不能再将其对应的成员端口配置为观察端口。 observe-port-index指观察端口的索引，必须与配置的观察端口的索引相同。 本地端口镜像配置：如下图,Gi0/0/02为观察端口，其他三个端口为镜像端口。 图：本地端口镜像 配置命令： 123456789101112131415161718[SW]dis current-configuration #sysname SW#observe-port 1 interface GigabitEthernet0/0/1 //观察端口#interface GigabitEthernet0/0/3 port-mirroring to observe-port 1 inbound port-mirroring to observe-port 1 outbound#interface GigabitEthernet0/0/4 port-mirroring to observe-port 1 inbound port-mirroring to observe-port 1 outbound#interface GigabitEthernet0/0/5 port-mirroring to observe-port 1 inbound port-mirroring to observe-port 1 outbound# 远程端口镜像：如下图,PC8为监控器，通过两台交换机实现对PC6,7出入流量的监控。 图：远程端口镜像 配置命令： 12345678910111213141516171819&lt;SW2&gt;dis current-configuration #sysname SW2#observe-port 1 interface GigabitEthernet0/0/3 vlan 10 //配置远程观察端口所属VLAN10#interface GigabitEthernet0/0/1 port-mirroring to observe-port 1 inbound port-mirroring to observe-port 1 outbound#interface GigabitEthernet0/0/2 port-mirroring to observe-port 1 inbound port-mirroring to observe-port 1 outbound#interface GigabitEthernet0/0/3 port link-type trunk port trunk allow-pass vlan 10# 1234567891011121314&lt;SW3&gt;display current-configuration #sysname SW3#vlan batch 10#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 10#interface GigabitEthernet0/0/2 port link-type access port default vlan 10# 流镜像配置示例：如下图，AR4设备监控源从源10.0.12.0地址的出去的流量。 图：流镜像 配置命令： 123456789101112131415161718192021222324252627282930313233343536&lt;AR2&gt;dis current-configuration # sysname AR2# observe-port interface GigabitEthernet0/0/1#acl number 2000 rule 5 permit source 10.1.12.0 0.0.0.255 #traffic classifier c1 operator or if-match acl 2000#traffic behavior b1 mirror to observe-port #traffic policy p1 classifier c1 behavior b1#interface GigabitEthernet0/0/0 ip address 10.1.12.2 255.255.255.0 mirror to observe-port inbound#interface GigabitEthernet0/0/1 ip address 10.1.24.2 255.255.255.0 traffic-policy p1 inbound traffic-policy p1 outbound#interface GigabitEthernet0/0/2 ip address 10.1.23.2 255.255.255.0 #ospf 1 area 0.0.0.0 network 10.1.12.0 0.0.0.255 network 10.1.23.0 0.0.0.255 network 10.1.24.0 0.0.0.255 #]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[端口安全和端口隔离]]></title>
    <url>%2F2017%2F11%2F16%2F%E7%AB%AF%E5%8F%A3%E5%AE%89%E5%85%A8%E5%92%8C%E7%AB%AF%E5%8F%A3%E9%9A%94%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[端口安全简介：端口安全（Port Security）通过将接口学习到的动态MAC地址转换为安全MAC地址（包括安全动态MAC和Sticky MAC），阻止除安全MAC和静态MAC之外的主机通过本接口和设备通信，从而增强设备的安全性。 原理描述：安全MAC地址分类： 类型 定义 特点 安全动态MAC地址 使能端口安全而未使能Sticky MAC功能时转换的MAC地址。 设备重启后表项会丢失，需要重新学习。缺省情况下不会被老化，只有在配置安全MAC的老化时间后才可以被老化。 Sticky MAC地址 使能端口安全后又同时使能Sticky MAC功能后转换到的MAC地址。 不会被老化，手动保存配置后重启设备不会丢失。 未使能端口安全功能时，设备的MAC地址表项可通过动态学习或静态配置。当某个接口使能端口安全功能后，该接口上之前学习到的动态MAC地址表项会被删除，之后学习到的MAC地址将变为安全动态MAC地址，此时该接口仅允许匹配安全MAC地址或静态MAC地址的报文通过。若接着使能Sticky MAC功能，安全动态MAC地址表项将转化为Sticky MAC表项，之后学习到的MAC地址也变为Sticky MAC地址。直到安全MAC地址数量达到限制，将不再学习MAC地址，并对接口或报文采取配置的保护动作。 超过安全MAC地址限制后得的动作：接口上安全MAC地址数达到限制后，如果收到源MAC地址不存在的报文，端口安全则认为有非法用户攻击，就会根据配置的动作对接口做保护处理。缺省情况下，保护动作是丢弃该报文并上报告警。 动作 实现说明 restrict 丢弃源MAC地址不存在的报文并上报警。推荐使用该动作。 注：设备收到非法MAC地址的报文时，每30s至少警告1次，至多警告2次。 protect 只丢弃源MAC地址不存在的报文，不上告报警。 shutdown 接口状态被置为error-down，并上报告警。 注：默认情况下，接口关闭后不会自动回复，只能由管理员手动恢复。 应用场景：端口安全经常使用在以下两种场景： 应用在接入层设备，通过配置端口安全可以防止仿冒用户从其他端口攻击。 应用在汇聚层设备，通过配置端口安全可以控制接入用户的数量。 接入层使用时注意： 如果接入用户变动比较频繁，可以通过端口安全把动态MAC地址转换为安全动态MAC地址。这样可以在用户变动时，及时清除绑定的MAC地址表项。 如果接入用户变动较少，可以通过端口安全把动态MAC地址转换为Sticky MAC地址。这样在保存配置重启后，绑定的MAC地址表项不会丢失。 配置命令：1234567891011121314151617prot-security enable //使能端口安全功能port-security max-mac-num 5//配置端口安全动态MAC学习的数量 display mac-address security //查看安全动态MAC表项 port-security mac-address sticky//使能接口Sticky MAC功能port-security protect-action &#123;protect | restrict | shutdown&#125;//配置端口安全保护动作port-security aging-time//配置端口安全MAC地址老化时间 端口隔离： 端口隔离的方法和应用场景 端口隔离的方法 应用场景 配置接口单向隔离 接入同一个设备不同接口的多台主机，若某台主机存在安全隐患，往其他主机发送大量的广播报文，可以通过配置接口间的单向隔离来实现其他主机对该主机报文的隔离。同一端口隔离组的接口之间互相隔离，不同端口隔离组的接口之间不隔离。为了实现不同端口隔离组的接口之间的隔离，可以通过配置接口之间的单向隔离来实现。 配置端口隔离组 为了实现接口之间的二层隔离，可以将不同的接口加入不同的VLAN，但这样会浪费有限的VLAN资源。采用端口隔离特性，可以实现同一VLAN内接口之间的隔离。用户只需要将接口加入到隔离组中，就可以实现隔离组内接口之间二层数据的隔离。端口隔离功能为用户提供了更安全、更灵活的组网方案。 端口隔离配置：1234port-isolate mode &#123; l2 | all&#125;//配置端口隔离模式，缺省情况下，端口隔离模式为二层隔离三层互通port-isolate enable//使能端口隔离功能。 端口安全和端口隔离配置：端口安全配置：如下图，给三台交换机三个端口都配置了端口安全，同时为了禁止三台PC通信，配置了端口隔离。 图：端口安全 配置命令：1234567891011121314151617181920212223242526272829303132[SW]dis current-configuration #sysname SW#port-isolate mode all//配置端口隔离模式为二层三层都隔离#interface GigabitEthernet0/0/1 port-security enable//使能端口安全 port-security protect-action shutdown //配置端口安全保护动作为 shutdown port-security max-mac-num 3 //配置端口最大MAC地址数量为3个 port-security mac-address sticky //配置MAC地址模式为 sticky port-isolate enable group 1 //端口隔离组1#interface GigabitEthernet0/0/2 port-security enable port-security protect-action shutdown port-security max-mac-num 3 port-security mac-address sticky port-isolate enable group 1# interface GigabitEthernet0/0/3 port-security enable port-security protect-action shutdown port-security max-mac-num 3 port-security mac-address sticky port-isolate enable group 1# 注：配置多个端口时，可以先配置一个端口组，将需要配置的端口添加进端口组，然后就可同时配置多个端口。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLAN-Mapping]]></title>
    <url>%2F2017%2F11%2F16%2FVLAN-Mapping%2F</url>
    <content type="text"><![CDATA[VLAN-Mapping简介：定义：VLAN Mapping通过修改报文携带的VLAN Tag来实现不同VLAN的相互映射。 目的：在某些场景中，两个VLAN相同的二层用户网络通过骨干网络互联，为了实现用户之间的二层互通，以及二层协议（例如MSTP等）的统一部署，需要实现两个用户网络的无缝连接，此时就需要骨干网可以传输来自用户网络的带有VLAN Tag的二层报文。而在通常情况下，骨干网的VLAN规划和用户网络的VLAN规划是不一致的，所以在骨干网中无法直接传输用户网络的带有VLAN Tag的二层报文。 解决这个问题的方法有两个，其中一个是通过QinQ或者VPLS等二层隧道技术，将用户带有VLAN Tag的二层报文封装在骨干网报文中进行传输，可以实现用户带有VLAN Tag的二层报文的透传。但是这种方法一方面需要增加额外的报文开销（增加一层封装），另外一方面，二层隧道技术可能会对某些二层协议报文的透传支持不是非常完善。另外一种方法就是通过VLAN Mapping技术，一侧用户网络的带有VLAN Tag的二层报文进入骨干网后，骨干网边缘设备将用户网络的VLAN（C-VLAN）修改为骨干网中可以识别和承载的VLAN（S-VLAN），传输到另一侧之后，边缘设备再将S-VLAN修改为C-VLAN。这样就可以很好的实现两个用户网络二层无缝连接。 在另一种场景中，如果由于规划的差异，导致两个直接相连的二层网络中部署的VLAN ID不一致。但是用户又希望可以把两个网络作为单个二层网络进行统一管理，例如用户二层互通和二层协议的统一部署。此时也可以在连接两个网络的交换机上部署VLAN Mapping功能，实现两个网络之间不同VLAN ID的映射，达到二层互通和统一管理的目的。 原理描述：​ 路由器收到带Tag的数据报文后，根据配置的VLAN Mapping方式，决定替换外层Tag中的VLAN ID或优先级；然后进入MAC地址学习阶段，根据源MAC地址+映射后的VLAN ID刷新MAC地址表项；根据目的MAC+映射后VLAN ID查找MAC地址表项，如果没有找到，则在VLAN ID对应的VLAN内广播，否则从表项对应的接口转发。 实现方式：设备支持基于VLAN ID和802.1p优先级实现VLAN Mapping。 基于VLAN ID 当部署VLAN Mapping功能设备上的接口收到带有单层VLAN Tag的报文时，将单层报文所携带的VLAN ID替换为新的VLAN ID。 当部署VLAN Mapping功能设备上的接口收到带有两层VLAN Tag的报文时，将两层报文携带的外层Tag替换为新的VLAN Tag，内层Tag作为数据透传。 基于802.1p优先级 当部署VLAN Mapping功能设备上的接口收到带有单层VLAN Tag的报文时，将单层报文所携带的802.1p优先级替换为新的802.1p优先级。 当部署VLAN Mapping功能设备上的接口收到带有两层VLAN Tag的报文时，将两层报文所携带的外层802.1p优先级替换为新的802.1p优先级。 配置基于VLAN ID的VLAN-Mapping：需求：如下图所示，客户有两个区，配置有VLNA 10 20，现在需要通过运营商网络进行传递。运营商网络中也有自己的VLAN，所以通过VLAN-Mapping映射，以实现客户两端的通信。 图：基于VLAN ID配置VLAN-Mapping拓扑 配置命令：LSW1和LSW4配置: 12345678910111213#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 10 20#interface GigabitEthernet0/0/2 port link-type access port default vlan 10#interface GigabitEthernet0/0/3 port link-type access port default vlan 20# LSW2和LSW3配置： 1234567891011121314#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 100 200#interface GigabitEthernet0/0/2 qinq vlan-translation enable //开启vlan转换功能 port link-type trunk port trunk allow-pass vlan 100 200 port vlan-mapping vlan 10 map-vlan 100 //配置VLAN10映射为VLAN100 port vlan-mapping vlan 20 map-vlan 200# 注意： 一个接口下接收到的帧携带的VLAN Tag的VLAN ID和映射后的VLAN Tag的VLAN ID不能相同。 映射后的外层VLAN必须存在，且接口必须以Tagged方式加入映射前后的VLAN。 VLAN Stacking和VLAN Mapping功能可以同时生效，但是同时配置的多个CE的VLAN ID不能重复，映射前后的VLAN Tag的VLAN ID也不能与之重复。PE的VLAN ID配置要求也一样。 二层以太网接口上只支持基于VLAN ID的VLAN Mapping功能，不支持基于802.1p或者VLAN ID+802.1p优先级的VLAN Mapping功能。 接口下可以配置多条该命令，所有接口下一共可以配置最多128条VLAN Mapping。 LSW2的gi0/0/2收到LSW1的数据后，先把VLNA10.20映射为100后才会检查接口是否允许该VLAN通过。 运营商与客户的VLAN ID一比一映射否则在运营商出口都会被映射为第一条VLAN ID 多对一情景下的情况：如下图，客户这边有多个属于不同VLAN的主机，运营商那边有一台服务器。PC5处于VLAN2，PC6处于VLAN3，在LSW5进行了VLAN-Mapping ，将VLAN2,3映射为VLAN300。LSW6可以接收VLAN300的数据，所以PC7可以收到数据。但是在通信过程中，只能客户机先主动访问服务器，在SW5中留下MAC-VLAN地址表后，以后服务器才可访问客户机，否则服务器不能直接访问客户机。 图：多对一的情景 在多对一这种场景下，只能客户机这边先主动访问服务器，才会在SW5中留下MAC-VLAN地址表，以后服务器才能访问客户机，否则服务器不能直接访问客户机]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>VLAN</tag>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MUX VLAN]]></title>
    <url>%2F2017%2F11%2F14%2FMUX-VLAN%2F</url>
    <content type="text"><![CDATA[MUX VLAN简介：产生背景：MUX VLAN（Multiplex VLAN）提供了一种通过VLAN进行网络资源控制的机制。 例如，在企业网络中，企业员工和企业客户可以访问企业的服务器。对于企业来说，希望企业内部员工之间可以互相交流，而企业客户之间是隔离的，不能够互相访问。 为了实现所有用户都可访问企业服务器，可通过配置VLAN间通信实现。如果企业规模很大，拥有大量的用户，那么就要为不能互相访问的用户都分配VLAN，这不但需要耗费大量的VLAN ID，还增加了网络管理者的工作量同时也增加了维护量。 通过MUX VLAN提供的二层流量隔离的机制可以实现企业内部员工之间互相交流，而企业客户之间是隔离的。 基本概念： MUX VLAN分为主VLAN和从VLAN，从VLAN又分为隔离型从VLAN和互通型从VLAN。 主VLAN（Principal VLAN）：Principal port可以和MUX VLAN内的所有接口进行通信。 隔离型从VLAN（Separate VLAN）：Separate port只能和Principal port进行通信，和其他类型的接口实现完全隔离。每个隔离型从VLAN必须绑定一个主VLAN。 互通型从VLAN（Group VLAN）：Group port可以和Principal port进行通信，在同一组内的接口也可互相通信，但不能和其他组接口或Separate port通信。每个互通型从VLAN必须绑定一个主VLAN。 配置MUX VLAN:配置注意事项： 如果指定VLAN已经用于主VLAN或从VLAN，那么该VLAN不能再用于创建VLANIF接口，或者在VLAN Mapping、VLAN Stacking、Super-VLAN、Sub-VLAN的配置中使用。 禁止接口MAC地址学习功能或限制接口MAC地址学习数量会影响MUX VLAN功能的正常使用。 不能在同一接口上配置MUX VLAN和接口安全功能。 不能在同一接口上配置MUX VLAN和MAC认证功能。 不能在同一接口上配置MUX VLAN和802.1x认证功能。 当同时配置DHCP Snooping和MUX VLAN时，如果DHCP Server在MUX VLAN的从VLAN侧，而DHCP Client在主VLAN侧，则会导致DHCP Client不能正常获取IP地址。因此请将DHCP Server配置在主VLAN侧。 接口使能MUX VLAN功能后，该接口不可再配置VLAN Mapping、VLAN Stacking。 配置MUX VLAN：拓扑：PC1,2为组VLAN，组内成员可以实现互通，同时可以与主VLAN互通，而与隔离VLAN不能互通。 PC3为主VLAN成员，可以与所用组VLAN和隔离VLAN内所有成员通信。 PC6,7属于隔离VLAN组，隔离VLAN内成员不能互相通信，只能与主VLAN内成员通信。 图：MUX VLAN拓扑图 配置命令：123456789101112131415161718192021222324252627282930313233343536&lt;SW&gt;dis current-configuration #sysname SW#vlan batch 10 20 30#vlan 10 mux-vlan //配置vlan10位 MUX valn subordinate separate 30 //配置隔离型从VLAN subordinate group 20 //配置互通型从VLAN#interface GigabitEthernet0/0/1 port link-type access port default vlan 20 port mux-vlan enable //使能接口的MUX VLAN功能。#interface GigabitEthernet0/0/2 port link-type access port default vlan 20 port mux-vlan enable#interface GigabitEthernet0/0/3 port link-type access port default vlan 30 port mux-vlan enable#interface GigabitEthernet0/0/4 port link-type access port default vlan 10 port mux-vlan enable#interface GigabitEthernet0/0/5 port link-type access port default vlan 30 port mux-vlan enable# 配置跨设备MUX VLAN示列：在企业网络中，企业希望某些部门之间的员工是互相隔离的，某些部门之间的员工是可以互相访问的，并且所有部门的员工都可以访问公司的某些服务器。 为了解决上述问题，可在设备上部署MUX VLAN功能。将企业服务器划分在主VLAN内，需要互相访问的部门员工划分在互通型从VLAN内，需要互相隔离的部门员工划分在隔离型从VLAN内，即可解决上述问题，且不会耗费大量的VLAN ID。 拓扑需求：如下图所示，PC1,2和PC5,6是连接在不同交换机上的主机，属于同一个VLAN3，VLAN3为组VALN。 PC3,4 和PC 7,8是连接在不同交换机上的主机，属于同一个VLAN4，VLAN4为隔离VALN。 PC9为交换机SW1上的一台服务器A，PC10为交换机SW2上的一台服务器B。PC9，10同属于VLAN2，VLAN2为主VLAN。 图： 跨设备MUX VLNA通信 配置命令行： SW1和SW2配置完全相同。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;SW1&gt;dis current-configuration #sysname SW1#vlan batch 2 to 4#vlan 2 mux-vlan subordinate separate 4 subordinate group 3#interface GigabitEthernet0/0/1 port link-type access port default vlan 3 port mux-vlan enable#interface GigabitEthernet0/0/2 port link-type access port default vlan 3 port mux-vlan enable#interface GigabitEthernet0/0/3 port link-type access port default vlan 4 port mux-vlan enable#interface GigabitEthernet0/0/4 port link-type access port default vlan 4 port mux-vlan enable#interface GigabitEthernet0/0/5 port link-type access port default vlan 2 port mux-vlan enable#interface GigabitEthernet0/0/6 port link-type trunk port trunk allow-pass vlan 2 to 4#]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>VLAN</tag>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLAN聚合]]></title>
    <url>%2F2017%2F11%2F14%2FVLAN%E8%81%9A%E5%90%88%2F</url>
    <content type="text"><![CDATA[VLAN聚合简介：VLAN聚合（VLAN Aggregation，也称Super VLAN）指在一个物理网络内，用多个VLAN（称为Sub-VLAN）隔离广播域，并将这些Sub-VLAN聚合成一个逻辑的VLAN（称为Super-VLAN），这些Sub-VLAN使用同一个IP子网和缺省网关。 通过引入Super-VLAN和Sub-VLAN的概念，使每个Sub-VLAN对应一个广播域，并让多个Sub-VLAN和一个Super-VLAN关联，只给Super-VLAN分配一个IP子网，所有Sub-VLAN都使用Super-VLAN的IP子网和缺省网关进行三层通信。 这样，多个Sub-VLAN共享一个网关地址，节约了子网号、子网定向广播地址、子网缺省网关地址，且各Sub-VLAN间的界线也不再是从前的子网界线了，它们可以根据各自主机的需求数目在Super-VLAN对应子网内灵活的划分地址范围，从而即保证了各个Sub-VLAN作为一个独立广播域实现广播隔离，又节省了IP地址资源，提高了编址的灵活性。 原理描述：VLAN聚合通过定义Super-VLAN和Sub-VLAN，使Sub-VLAN只包含物理接口，负责保留各自独立的广播域；Super-VLAN不包含物理接口，只用来建立三层VLANIF接口。然后再通过建立Super-VLAN和Sub-VLAN间的映射关系，把三层VLANIF接口和物理接口两部分有机的结合起来，实现所有Sub-VLAN共用一个网关与外部网络通信，并用ARP Proxy实现Sub-VLAN间的三层通信，从而在实现普通VLAN的隔离广播域的同时，达到节省IP地址的目的。 Sub-VLAN：只包含物理接口，不能建立三层VLANIF接口，用于隔离广播域。每个Sub-VLAN内的主机与外部的三层通信是靠Super-VLAN的三层VLANIF接口来实现的。 Super-VLAN：只建立三层VLANIF接口，不包含物理接口，与子网网关对应。与普通VLAN不同的是，它的VLANIF接口的Up不依赖于自身物理接口的Up，而是只要它所含Sub-VLAN中存在Up的物理接口就Up。 一个Super-VLAN可以包含一个或多个Sub-VLAN。Sub-VLAN不再占用一个独立的子网网段。在同一个Super-VLAN中，无论主机属于哪一个Sub-VLAN，它的IP地址都在Super-VLAN对应的子网网段内。 这样，Sub-VLAN间共用同一个网关，既减少了一部分子网号、子网缺省网关地址和子网定向广播地址的消耗，又实现了不同广播域使用同一子网网段地址的目的，消除了子网差异，增加了编址的灵活性，减少了闲置地址浪费。 Sub-VLAN之间的通信：VLAN聚合在实现不同VLAN共用同一子网网段地址的同时，也给Sub-VLAN间的三层转发带来了问题。普通VLAN中，不同VLAN内的主机可以通过各自不同的网关进行三层互通。但是Super-VLAN中，所有Sub-VLAN内的主机使用的是同一个网段的地址，共用同一个网关地址，主机只会做二层转发，而不会送网关进行三层转发。即实际上，不同Sub-VLAN的主机在二层是相互隔离的，这就造成了Sub-VLAN间无法通信的问题。 解决这一问题的方法就是使用Proxy ARP。 示列：如下图所示，假设Sub-VLAN2内的主机Host_1与Sub-VLAN3内的主机Host_2要通信，在Super-VLAN10的VLANIF接口上启用ProxyARP。 图：Proxy ARP实现不同Sub-VLAN间的三层通信组网图 Host_1与Host_2的通信过程如下（假设Host_1的ARP表中无Host_2的对应表项）： Host_1将Host_2的IP地址（10.1.1.12）和自己所在网段10.1.1.0/24进行比较，发现Host_2和自己在同一个子网，但是Host_1的ARP表中无Host_2的对应表项。 Host_1发送ARP广播报文，请求Host_2的MAC地址，目的IP为10.1.1.12。 网关Router收到Host_1的ARP请求，由于网关上使能Sub-VLAN间的Proxy ARP，开始使用报文中的目的IP地址在路由表中查找，发现匹配了一条路由，下一跳为直连网段（VLANIF10的10.1.1.0/24），VLANIF10对应Super-VLAN10，则向Super-VLAN10的所有Sub-VLAN接口发送一个ARP广播，请求Host_2的MAC地址。 Host_2收到网关发送的ARP广播后，对此请求进行ARP应答。 网关收到Host_2的应答后，就把自己的MAC地址回应给Host_1。 Host_1之后要发给Host_2的报文都先发送给网关，由网关做三层转发。 Host_2发送报文给Host_1的过程和上述的Host_1发送报文给Host_2的过程类似，不再赘述。 Sub_VLAN与其他网络的三层通信：以所示组网为例，介绍Sub-VLAN内主机与其他网络内的主机间通信过程。 如下图，用户主机与服务器处于不同的网段中，Router_1上配置了Sub-VLAN2、Sub-VLAN3、Super-VLAN4和VLAN10，Router_2上配置了VLAN10和VLAN20。 图：Sub-VLAN与其他网络的三层通信组网图 假设Sub-VLAN2下的主机Host_1想访问与Router_2相连的Server，报文转发流程如下（假设Router_1上已配置了去往10.1.2.0/24网段的路由，Router_2上已配置了去往10.1.1.0/24网段的路由，但两设备没有任何三层转发表项）： Host_1将Server的IP地址（10.1.2.2）和自己所在网段10.1.1.0/24进行比较，发现和自己不在同一个子网，发送ARP请求给自己的网关，请求网关的MAC地址，目的MAC为全F，目的IP为10.1.1.1。 Router_1收到该请求报文后，查找Sub-VLAN和Super-VLAN的对应关系，知道应该回应Super-VLAN4对应的VLANIF4的MAC地址，并知道从Sub-VLAN2的接口回应给Host_1。 Host_1学习到网关的MAC地址后，开始发送目的MAC为Super-VLAN4对应的VLANIF4的MAC地址、目的IP为10.1.2.2的报文。 Router_1收到该报文后，根据Sub-VLAN和Super-VLAN的对应关系以及目的MAC判断进行三层转发，查三层转发表项没有找到匹配项，上送CPU查找路由表，得到下一跳地址为10.1.10.2，出接口为VLANIF10，并通过ARP表项和MAC表项确定出接口，把报文发送给Router_2。 Router_2根据正常的三层转发流程把报文发送给Server。 Server收到Host_1的报文后给Host_1回应，回应报文的目的IP为10.1.1.2，目的MAC为Router_2上VLANIF20接口的MAC地址，回应报文的转发流程如下： Server给Host_1的回应报文按照正常的三层转发流程到达Router_1。到达Router_1时，报文的目的MAC地址为Router_1上VLANIF10接口的MAC地址。 Router_1收到该报文后根据目的MAC地址判断进行三层转发，查三层转发表项没有找到匹配项，上送CPU，CPU查路由表，发现目的IP为10.1.1.2对应的出接口为VLANIF4，查找Sub-VLAN和Super-VLAN的对应关系，并通过ARP表项和MAC表项，知道报文应该从Sub-VLAN2的接口发送给Host_1。 回应报文到达Host_1。 Sub-VLAN与其他设备的二层通信：如下图所示组网为例，介绍Sub-VLAN内主机与其他设备的二层通信情况。Router_1上配置了Sub-VLAN2、Sub-VLAN3和Super-VLAN4，_Router_1的_IF_1和IF_2配置为Access接口，IF_3接口配置为Trunk接口，并允许VLAN2和VLAN3通过；Router_2连接Router_1的接口配置为Trunk接口，并允许VLAN2和VLAN3通过。 图：Sub-VLAN与其他设备的二层通信组网图 从Host_1进入Router_1的报文会被打上VLAN2的Tag。在Router_1中这个Tag不会因为VLAN2是VLAN4的Sub-VLAN而变为VLAN4的Tag。该报文从Router_1的Trunk接口IF_3出去时，依然是携带VLAN2的Tag。 也就是说，Router_1本身不会发出VLAN4的报文。就算其他设备有VLAN4的报文发送到该设备上，这些报文也会因为Router_1上没有VLAN4对应的物理接口而被丢弃。因为Router_1的IF_3接口上根本就不允许Super-VLAN4通过。对于其他设备而言，有效的VLAN只有Sub-VLAN2和Sub-VLAN3，所有的报文都是在这些VLAN中交互的。 这样，Router_1上虽然配置了VLAN聚合，但与其他设备的二层通信，不会涉及到Super-VLAN，与正常的二层通信流程一样。 配置Super-VALN:配置注意事项： VLAN1不能配置为Super-VLAN。 配置某VLAN为Super-VLAN后，该VLAN类型改变为super，不允许任何物理接口加入该VLAN。 流策略只有在Super-vlan的所有Sub-vlan下配置才能生效，在Super-vlan下配置不生效。 配置某个VLAN为子接口的终结VLAN后，该VLAN不能再配置为Super-VLAN或Sub-VLAN。 Super-VLAN对应的VLANIF接口配置IP地址后Proxy ARP才能生效。 配置聚合VLAN：拓扑：PC1,2 属于VLAN10 ，PC3,4属于VLAN20，通过聚合VLAN100，实现共用网关IP地址，开启VLAN间ARP代理，实现VLAN间通信。 图：VLAN聚合配置拓扑 配置参数：1234567891011121314151617181920212223242526272829303132[SW]dis current-configuration #sysname SW#vlan batch 10 20 100 //批量创建VLAN#vlan 100 aggregate-vlan//创建聚合VLAN access-vlan 10 20//将valn10 20 添加进聚合和VLAN#interface Vlanif100 ip address 10.0.100.254 255.255.255.0 arp-proxy inter-sub-vlan-proxy enable //开启VLAN间ARP代理，实现VLAN间通信#interface GigabitEthernet0/0/1 port link-type access port default vlan 10#interface GigabitEthernet0/0/2 port link-type access port default vlan 10#interface GigabitEthernet0/0/3 port link-type access port default vlan 20#interface GigabitEthernet0/0/4 port link-type access port default vlan 20#]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>VLAN</tag>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLAN命令行配置]]></title>
    <url>%2F2017%2F11%2F05%2FVLAN%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[VLNA配置任务概览各配置任务间的逻辑关系： VLAN配置任务概览： 配置任务 描述 划分VLAN 创建并划分VLAN，将没有二层互通需求的用户进行隔离，可增强网络的安全性、减少广播流量，同时也减少了广播风暴的产生。 配置通过VLANIF实现VLAN间互访 划分VLAN后，不同VLAN的用户不能直接互通。不同VLAN的用户如果有互通需求，可通过配置VLANIF接口实现VLAN间的三层互通。 配置通过流策略实现VLAN内隔离 划分VLAN后，同一VLAN的用户可以直接互通，同一VLAN的部分用户间如果需要隔离，可通过配置MQC实现VLAN内的二层隔离。 配置同流策略实现VLNA内互访控制 配置通过VLANIF实现VLAN间互访后，不同VLAN的用户可以三层互通，不同VLAN的部分用户如果需要单向访问或者需要隔离，可通过配置流策略实现。 配置管理VLAN 如果用户要通过网管集中管理设备，则要在划分VLAN后，配置管理VLAN。 VLAN缺省配置： 参数 缺省值 Hybrid 缺省VLAN VLAN1 接口加入的VLAN 接口以Untagged方式加入VLAN 1（即port hybrid untagged vlan 1） Damping time 0s Disabled 配置注意事项： 建议独立规划业务VLAN和管理VLAN，以便业务VLAN上发生的任何广播风暴不会影响到设备的管理。 实际运用中，Trunk接口需要透传哪些VLAN就透传哪些VLAN，最好不使用port trunk allow-pass vlan all 由于设备所有的接口都默认加入VLAN1，因此当网络中存在VLAN1的未知单播、组播或者广播报文时，可能会引起广播风暴。因此VLAN1的使用要注意如下事项。 对于不需要加入VLAN1的接口要及时退出VLAN1，以避免环路。 在Eth-Trunk、环形组网环境下建议接口退出VLAN1。 在与接入设备对接时，接入设备的上行接口建议不要透传VLAN1，防止在VLAN1中产生广播风暴。 VLAN配置命令行##创建VLAN配置VLAN接口类型等： 123456789101112131415161718# sysname Router_1#vlan batch 2 to 3 //创建VLAN2和VLAN3#interface Ethernet2/0/1 //将连接User_1的接口配置为Access类型，缺省VLAN为VLAN2 port link-type access port default vlan 2#interface Ethernet2/0/2 //将连接User_3的接口配置为Access类型，缺省VLAN为VLAN3 port link-type access port default vlan 3#interface Ethernet2/0/3 //配置Router_1和Router_2互连的接口配置为Trunk类型，允许VLAN2和VLAN3通过 port link-type trunk port trunk allow-pass vlan 2 to 3#return 配置VLANIF接口实现VLAN间通信的示列：1234567891011121314151617181920# sysname Router#vlan batch 10 20 //创建VLAN#interface Vlanif10 //创建VLANIF接口 ip address 10.10.10.1 255.255.255.0 //相同VLAN内PC终端的网关地址#interface Vlanif20 ip address 10.10.20.1 255.255.255.0#interface Ethernet2/0/1 port link-type access //和PC终端相连，接口类型为Access port default vlan 10 //接口加入VLAN#interface Ethernet2/0/2 port link-type access port default vlan 20#return 配置单臂路由： 图：单臂路由拓扑 命令行： 路由器配置： 12345678910111213#R1interface GigabitEthernet0/0/0.1 dot1q termination vid 10 //dot1q termination vid 用来配置子接口Dot1q终结的单层VLAN ID。 ip address 10.1.1.254 255.255.255.0 arp broadcast enable //arp broadcast命令用来使能终结子接口的ARP广播功能。#interface GigabitEthernet0/0/0.2 dot1q termination vid 20 ip address 20.1.1.254 255.255.255.0 arp broadcast enable# 交换机配置： 12345678910111213#interface GigabitEthernet0/0/1 port link-type trunk port trunk allow-pass vlan 10 20#interface GigabitEthernet0/0/2 port link-type access port default vlan 10#interface GigabitEthernet0/0/3 port link-type access port default vlan 20# 配置三层交换： 图：配置三层交换 配置信息：LSW2，LSW3： 12345678910111213#interface GigabitEthernet0/0/1 port link-type access port default vlan 10#interface GigabitEthernet0/0/2 port link-type access port default vlan 20#interface GigabitEthernet0/0/3 port link-type trunk port trunk allow-pass vlan 10 20# 配置VlAN内Proxy ARP：当VLAN内配置了端口隔离时，属于相同VLAN的用户间无法实现互通。在关联了VLAN的接口上使能VLAN内Proxy ARP功能，可以实现用户间三层互通。 1234//配置命令行cinterface vlanif 10 //进入接口视图arp-proxy inner-sub-vlan-procy enable//使能VLAN内Proxy ARP 配置VLAN间Procy ARP：当属于同一网段但属于不同VLAN的用户间要实现三层互通时，可以在关联了VLAN的接口上使能VLAN间Proxy ARP功能。例如在Super-VLAN对应的VLANIF接口上使能VLAN间Proxy ARP功能，实现Sub-VLAN间用户互通。 1234//配置命令行cinterface vlanif 10 //进入接口视图arp-proxy inter-sub-vlan-procy enable//使能VLAN内Proxy ARP]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>VLAN</tag>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLAN基础知识]]></title>
    <url>%2F2017%2F11%2F05%2FVLAN%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[VLAN简介定义：VLAN（Virtual Local Area Network）即虚拟局域网，是将一个物理的LAN在逻辑上划分成多个广播域的通信技术。VLAN内的主机间可以直接通信，而VLAN间不能直接通信，从而将广播报文限制在一个VLAN内。 目的：以太网是一种基于CSMA/CD（Carrier Sense Multiple Access/Collision Detection）的共享通讯介质的数据网络通讯技术。当主机数目较多时会导致冲突严重、广播泛滥、性能显著下降甚至造成网络不可用等问题。通过交换机实现LAN互连虽然可以解决冲突严重的问题，但仍然不能隔离广播报文和提升网络质量。 在这种情况下出现了VLAN技术，这种技术可以把一个LAN划分成多个逻辑的VLAN，每个VLAN是一个广播域，VLAN内的主机间通信就和在一个LAN内一样，而VLAN间则不能直接互通，这样，广播报文就被限制在一个VLAN内。 作用： 限制广播域：广播域被限制在一个VLAN内，节省了带宽，提高了网络处理能力。 增强局域网的安全性：不同VLAN内的报文在传输时是相互隔离的，即一个VLAN内的用户不能和其它VLAN内的用户直接通信。 提高了网络的健壮性：故障被限制在一个VLAN内，本VLAN内的故障不会影响其他VLAN的正常工作。 灵活构建虚拟工作组：用VLAN可以划分不同的用户到不同的工作组，同一工作组的用户也不必局限于某一固定的物理范围，网络构建和维护更方便灵活。 VLAN的基本概念VLAN标签：要使设备能够分辨不同VLAN的报文，需要在报文中添加标识VLAN信息的字段。IEEE 802.1Q协议规定，在以太网数据帧的目的MAC地址和源MAC地址字段之后、协议类型字段之前加入4个字节的VLAN标签（又称VLAN Tag，简称Tag），用以标识VLAN信息。 VLAN帧格式： 图：VLAN数据帧格式 字段解释： 字段 长度 含义 取值 TPID 2Byte Tag Protocol Identifier（标签协议标识符），表示数据帧类型。 表示帧类型，取值为0x8100时表示IEEE 802.1Q的VLAN数据帧。如果不支持802.1Q的设备收到这样的帧，会将其丢弃。 各设备厂商可以自定义该字段的值。当邻居设备将TPID值配置为非0x8100时， 为了能够识别这样的报文，实现互通，必须在本设备上修改TPID值，确保和邻居设备的TPID值配置一致。 PRI 3bit Priority，表示数据帧的802.1p优先级。 取值范围为0～7，值越大优先级越高。当网络阻塞时，设备优先发送优先级高的数据帧。 CFI 1bit Canonical Format Indicator（标准格式指示位），表示MAC地址在不同的传输介质中是否以标准格式进行封装，用于兼容以太网和令牌环网。 CFI取值为0表示MAC地址以标准格式进行封装，为1表示以非标准格式封装。在以太网中，CFI的值为0。 VID 12bit VLAN ID，表示该数据帧所属VLAN的编号。 VLAN ID取值范围是0～4095。由于0和4095为协议保留取值，所以VLAN ID的有效取值范围是1～4094。 设备利用VLAN标签中的VID来识别数据帧所属的VLAN，广播帧只在同一VLAN内转发，这就将广播域限制在一个VLAN内。 常用设备收发数据帧的VLAN标签情况：在一个VLAN交换网络中，以太网帧主要有以下两种格式： 有标记帧（Tagged帧）：加入了4字节VLAN标签的帧。 无标记帧（Untagged帧）：原始的、未加入4字节VLAN标签的帧。 常用设备中： 用户主机、服务器、Hub只能收发Untagged帧。 交换机、路由器和AC既能收发Tagged帧，也能收发Untagged帧。 语音终端、AP等设备可以同时收发一个Tagged帧和一个Untagged帧。 为了提高处理效率，设备内部处理的数据帧一律都是Tagged帧。 链路类型和接口类型：设备内部处理的数据帧一律都带有VLAN标签，而现网中的设备有些只会收发Untagged帧，要与这些设备交互，就需要接口能够识别Untagged帧并在收发时给帧添加、剥除VLAN标签。同时，现网中属于同一个VLAN的用户可能会被连接在不同的设备上，且跨越设备的VLAN可能不止一个，如果需要用户间的互通，就需要设备间的接口能够同时识别和发送多个VLAN的数据帧。 为了适应不同的连接和组网，设备定义了Access接口、Trunk接口和Hybrid接口3种接口类型，以及接入链路（Access Link）和干道链路（Trunk Link）两种链路类型。 链路类型：根据链路中需要承载的VLAN数目的不同，以太网链路分为： 接入链路 接入链路只可以承载1个VLAN的数据帧，用于连接设备和用户终端（如用户主机、服务器等）。通常情况下，用户终端并不需要知道自己属于哪个VLAN，也不能识别带有Tag的帧，所以在接入链路上传输的帧都是Untagged帧。 干道链路 干道链路可以承载多个不同VLAN的数据帧，用于设备间互连。为了保证其它网络设备能够正确识别数据帧中的VLAN信息，在干道链路上传输的数据帧必须都打上Tag。 接口类型：根据接口连接对象以及对收发数据帧处理的不同，以太网接口分为： Access接口 Access接口一般用于和不能识别Tag的用户终端（如用户主机、服务器等）相连，或者不需要区分不同VLAN成员时使用。它只能收发Untagged帧，且只能为Untagged帧添加唯一VLAN的Tag。 Trunk接口 Trunk接口一般用于连接交换机、路由器、AP以及可同时收发Tagged帧和Untagged帧的语音终端。它可以允许多个VLAN的帧带Tag通过，但只允许一个VLAN的帧从该类接口上发出时不带Tag（即剥除Tag）。 Hybrid接口 Hybrid接口既可以用于连接不能识别Tag的用户终端（如用户主机、服务器等）和网络设备（如Hub），也可以用于连接交换机、路由器以及可同时收发Tagged帧和Untagged帧的语音终端、AP。它可以允许多个VLAN的帧带Tag通过，且允许从该类接口发出的帧根据需要配置某些VLAN的帧带Tag（即不剥除Tag）、某些VLAN的帧不带Tag（即剥除Tag）。 Hybrid接口和Trunk接口在很多应用场景下可以通用，但在某些应用场景下，必须使用Hybrid接口。比如一个接口连接不同VLAN网段的场景中，因为一个接口需要给多个Untagged报文添加Tag，所以必须使用Hybrid接口。 缺省VLAN：缺省VLAN又称PVID（Port Default VLAN ID）。前面提到，设备处理的数据帧都带Tag，当设备收到Untagged帧时，就需要给该帧添加Tag，添加什么Tag，就由接口上的缺省VLAN决定。 接口收发数据帧时，对Tag的添加或剥除过程。 对于Access接口，缺省VLAN就是它允许通过的VLAN，修改缺省VLAN即可更改接口允许通过的VLAN。 对于Trunk接口和Hybrid接口，一个接口可以允许多个VLAN通过，但是只能有一个缺省VLAN。接口的缺省VLAN和允许通过的VLAN需要分别配置，互不影响。 同类型接口添加或剥除VLAN标签的比较： 接口类型 对接收不带Tag的报文处理 对接收带Tag的报文处理 发送帧处理过程 Access接口 接收该报文，并打上缺省的VLAN ID。 当VLAN ID与缺省VLAN ID相同时，接收该报文。当VLAN ID与缺省VLAN ID不同时，丢弃该报文。 先剥离帧的PVID Tag，然后再发送。 Trunk接口 打上缺省的VLAN ID，当缺省VLAN ID在允许通过的VLAN ID列表里时，接收该报文。打上缺省的VLAN ID，当缺省VLAN ID不在允许通过的VLAN ID列表里时，丢弃该报文。 当VLAN ID在接口允许通过的VLAN ID列表里时，接收该报文。当VLAN ID不在接口允许通过的VLAN ID列表里时，丢弃该报文。 当VLAN ID与缺省VLAN ID相同，且是该接口允许通过的VLAN ID时，去掉Tag，发送该报文。当VLAN ID与缺省VLAN ID不同，且是该接口允许通过的VLAN ID时，保持原有Tag，发送该报文。 Hybrid接口 打上缺省的VLAN ID，当缺省VLAN ID在允许通过的VLAN ID列表里时，接收该报文。打上缺省的VLAN ID，当缺省VLAN ID不在允许通过的VLAN ID列表里时，丢弃该报文。 当VLAN ID在接口允许通过的VLAN ID列表里时，接收该报文。当VLAN ID不在接口允许通过的VLAN ID列表里时，丢弃该报文。 当VLAN ID是该接口允许通过的VLAN ID时，发送该报文。可以通过命令设置发送时是否携带Tag。 当接收到不带VLAN标签的数据帧时，Access接口、Trunk接口、Hybrid接口都会给数据帧打上VLAN标签，但Trunk接口、Hybrid接口会根据数据帧的VID是否为其允许通过的VLAN来判断是否接收，而Access接口则无条件接收。 当接收到带VLAN标签的数据帧时，Access接口、Trunk接口、Hybrid接口都会根据数据帧的VID是否为其允许通过的VLAN（Access接口允许通过的VLAN就是缺省VLAN）来判断是否接收。 当发送数据帧时： Access接口直接剥离数据帧中的VLAN标签。 Trunk接口只有在数据帧中的VID与接口的PVID相等时才会剥离数据帧中的VLAN标签。 Hybrid接口会根据接口上的配置判断是否剥离数据帧中的VLAN标签。 因此，Access接口发出的数据帧肯定不带Tag，Trunk接口发出的数据帧只有一个VLAN的数据帧不带Tag，其他都带VLAN标签，Hybrid接口发出的数据帧可根据需要设置某些VLAN的数据帧带Tag，某些VLAN的数据帧不带Tag。 VLAN通信VLAN内互访：同一VLAN内用户互访（简称VLAN内互访）会经过如下三个环节。 用户主机的报文转发 源主机在发起通信之前，会将自己的IP与目的主机的IP进行比较，如果两者位于同一网段，会获取目的主机的MAC地址，并将其作为目的MAC地址封装进报文；如果两者位于不同网段，源主机会将报文递交给网关，获取网关的MAC地址，并将其作为目的MAC地址封装进报文。 设备内部的以太网交换 设备 如果目的MAC地址+VID匹配自己的MAC表且三层转发标志置位，则进行三层交换，会根据报文的目的IP地址查找三层转发表项，如果没有找到会将报文上送CPU，由CPU查找路由表实现三层转发。 如果目的MAC地址+VID匹配自己的MAC表但三层转发标志未置位，则进行二层交换，会直接将报文根据MAC表的出接口发出去。 如果目的MAC地址+VID没有匹配自己的MAC表，则进行二层交换，此时会向所有允许VID通过的接口广播该报文，以获取目的主机的MAC地址。 设备之间交互时，VLAN标签的添加和剥离 设备内部的以太网交换都是带Tag的，为了与不同设备进行成功交互，设备需要根据接口的设置添加或剥除Tag。不同接口VLAN标签添加和剥离情况不同。 从以太网交换原理可以看出，划分VLAN后，广播报文只在同一VLAN内二层转发，因此同一VLAN内的用户可以直接二层互访。根据属于同一VLAN的主机是否连接在不同的设备，VLAN内互访有两种场景：同设备VLAN内互访和跨设备VLAN内互访。 同设备VLAN内互访：如下图所示，用户主机Host_1和Host_2连接在同台设备上，属于同一VLAN2，且位于相同网段，连接接口均设置为Access接口。 当用户主机Host_1发送报文给用户主机Host_2时，报文的发送过程如下（假设Router上还未建立任何转发表项）。 Host_1判断目的IP地址跟自己的IP地址在同一网段，于是发送ARP广播请求报文获取目的主机Host_2的MAC地址，报文目的MAC填写全F，目的IP为Host_2的IP地址10.1.1.3。 报文到达Router的接口IF_1，发现是Untagged帧，给报文添加VID=2的Tag（Tag的VID=接口的PVID），然后根据报文的源MAC地址、VID和报文入接口（1-1-1， 2， IF_1）生成MAC表。 根据报文目的MAC地址+VID查找Router的MAC表，没有找到，于是在所有允许VLAN2通过的接口（本例中接口为IF_2）广播该报文。 Router的接口IF_2在发出ARP请求报文前，根据接口配置，剥离VID=2的Tag。 Host_2收到该ARP请求报文，将Host_1的MAC地址和IP地址对应关系记录ARP表。然后比较目的IP与自己的IP，发现跟自己的相同，就发送ARP响应报文，报文中封装自己的MAC地址2-2-2，目的IP为Host_1的IP地址10.1.1.2。 Router的接口IF_2收到ARP响应报文后，同样给报文添加VID=2的Tag。 Router根据报文的源MAC地址、VID和报文入接口（2-2-2， 2， IF_2）生成MAC表，然后根据报文的目的MAC地址+VID（1-1-1， 2）查找MAC地址表，由于前面已记录，查找成功，向出接口IF_1转发该ARP响应报文。 Router向出接口IF_1转发前，同样根据接口配置剥离VID=2的Tag。 Host_1收到Host_2的ARP响应报文，将Host_2的MAC地址和IP地址对应关系记录ARP表。 后续Host_1与Host_2的互访，由于彼此已学习到对方的MAC地址，报文中的目的MAC地址直接填写对方的MAC地址。 此组网场景下，当同一VLAN的用户处于不同网段时，主机将在报文中封装网关的MAC地址，可借助VLANIF技术（需配置主从IP地址）实现互访。 跨设备VLAN内互访：如下图，用户主机Host_1和Host_2连接在不同的设备上，属于同一个VLAN2，且位于相同网段。为了识别和发送跨越设备的数据帧，设备间通过干道链路连接。 当用户主机Host_1发送报文给用户主机Host_2时，报文的发送过程如下（假设Router_1和Router_2上还未建立任何转发表项）。 经过与同设备VLAN内互访的步骤1～2一样的过程后，报文被广播到Router_1的IF_2接口。 Router_1的IF_2接口在发出ARP请求报文前，因为接口的PVID=1（缺省值），与报文的VID不相等，直接透传该报文到Router_2的IF_2接口，不剥除报文的Tag。 Router_2的IF_2接口收到该报文后，判断报文的Tag中的VID=2是接口允许通过的VLAN，接收该报文。 经过与同设备VLAN内互访的步骤3～6一样的过程后，Router_2将向其出接口IF_2转发Host_2的ARP响应报文，转发前，因为接口IF_2为Trunk接口且PVID=1（缺省值），与报文的VID不相等，直接透传报文到Router_1的IF_2接口。 Router_1的IF_2接口收到Host_2的ARP响应报文后，判断报文的Tag中的VID=2是接口允许通过的VLAN，接收该报文。后续处理同同设备VLAN内互访的步骤7～9一样。 可见，干道链路除可传输多个VLAN的数据帧外，还起到透传VLAN的作用，即干道链路上，数据帧只会转发，不会发生Tag的添加或剥离。 VLAN间互访：划分VLAN后，由于广播报文只在同VLAN内转发，所以不同VLAN的用户间不能二层互访，这样能起到隔离广播的作用。但实际应用中，不同VLAN的用户又常有互访的需求，此时就需要实现不同VLAN的用户互访，简称VLAN间互访。 同VLAN间互访一样，VLAN间互访也会经过用户主机的报文转发、设备内部的以太网交换、设备之间交互时VLAN标签的添加和剥离三个环节。同样，根据以太网交换原理，广播报文只在同一VLAN内转发，不同VLAN内的用户则不能直接二层互访，需要借助三层路由技术或VLAN转换技术才能实现互访。 VLAN间互访技术：华为提供了多种技术实现VLAN间互访，常用的两种技术为VLANIF接口和Dot1q终结子接口。 VLANIF接口 VLANIF接口是一种三层的逻辑接口。在VLANIF接口上配置IP地址后，设备会在MAC地址表中添加VLANIF接口的MAC地址+VID表项，并且为表项的三层转发标志位置位。当报文的目的MAC地址匹配该表项后，会进行三层转发，进而实现VLAN间的三层互通。 VLANIF配置简单，是实现VLAN间互访最常用的一种技术。但每个VLAN需要配置一个VLANIF，并在接口上指定一个IP子网网段，比较浪费IP地址。 Dot1q终结子接口 子接口也是一种三层的逻辑接口。跟VLANIF接口一样，在子接口上配置Dot1q终结功能和IP地址后，设备也会添加相应的MAC表项并置位三层转发标志位，进而实现VLAN间的三层互通。 Dot1q终结子接口适用于通过一个三层以太网接口下接多个VLAN网络的环境。由于不同VLAN的数据流会争用同一个以太网主接口的带宽，网络繁忙时，会导致通信瓶颈。 通过VLANIF接口实现VLAN间互访，必须要求VLAN间的用户都只能处于不同的网段（因为相同网段，主机会封装目的主机的MAC地址，设备判断进行二层交换，二层交换只在同VLAN内，广播报文无法到达不同的VLAN，获取不到目的主机的MAC地址，也就无法实现互通）。现网中，也存在不同VLAN相同网段的组网需求，此时可通过VLAN聚合实现。 VLAN聚合（又称Super VLAN）通过引入Super-VLAN和Sub-VLAN，将一个Super-VLAN和多个Sub-VLAN关联，多个Sub-VLAN共享Super-VLAN的IP地址作为其网关IP，实现与外部网络的三层互通；并通过在Sub-VLAN间启用Proxy ARP，实现Sub-VLAN间的三层互通，进而即节约IP地址资源，又实现VLAN间的三层互通。 VLAN聚合通常用于多个VLAN共用一个网关的组网场景。 同设备VLAN间互访：如下图：互访的源主机Host_1和目的主机Host_2连接在同一台设备Router上，分别属于VLAN2和VLAN3，并位于不同的网段。在Router上分别创建VLANIF2和VLANIF3并配置其IP地址，然后将用户主机的缺省网关设置为所属VLAN对应VLANIF接口的IP地址。 当用户主机Host_1发送报文给用户主机Host_2时，报文的发送过程如下（假设Router上还未建立任何转发表项）。 Host_1判断目的IP地址跟自己的IP地址不在同一网段，因此，它发出请求网关MAC地址的ARP请求报文，目的IP为网关IP 10.1.1.1，目的MAC为全F。 报文到达Router的接口IF_1，Router给报文添加VID=2的Tag（Tag的VID=接口的PVID），然后将报文的源MAC地址+VID与接口的对应关系（1-1-1， 2， IF_1）添加进MAC表。 Router检查报文是ARP请求报文，且目的IP是自己VLANIF2接口的IP地址，给Host_1应答，并将VLANIF2接口的MAC地址3-3-3封装在应答报文中，应答报文从IF_1发出前，剥掉VID=2的Tag。同时，Router会将Host_1的IP地址与MAC地址的对应关系记录到ARP表。 Host_1收到Router的应答报文，将Router的VLANIF2接口的IP地址与MAC地址对应关系记录到自己的ARP表中，并向Router发送目的MAC为3-3-3、目的IP为Host_2的IP地址 10.2.2.2的报文。 报文到达Router的接口IF_1，同样给报文添加VID=2的Tag。 Router根据报文的源MAC地址+VID与接口的对应关系更新MAC表，并比较报文的目的MAC地址与VLANIF2的MAC地址，发现两者相等，进行三层转发，根据目的IP查找三层转发表，没有找到匹配项，上送CPU查找路由表。 CPU根据报文的目的IP去找路由表，发现匹配了一个直连网段（VLANIF3对应的网段），于是继续查找ARP表，没有找到，Router会在目的网段对应的VLAN3的所有接口发送ARP请求报文，目的IP是10.2.2.2。从接口IF_2发出前，根据接口配置，剥掉VID=2的Tag。 Host_2收到ARP请求报文，发现请求IP是自己的IP地址，就发送ARP应答报文，将自己的MAC地址包含在其中。同时，将VLANIF3的MAC地址与IP地址的对应关系记录到自己的ARP表中。 Router的接口IF_2收到Host_2的ARP应答报文后，给报文添加VID=3的Tag，并将Host_2的MAC和IP的对应关系记录到自己的ARP表中。然后，将Host_1的报文转发给Host_2，发送前，同样剥离报文中的Tag。同时，将Host_2的IP、MAC、VID及出接口的对应关系记录到三层转发表中。 至此，Host_1完成对Host_2的单向访问。Host_2访问Host_1的过程与此类似。这样，后续Host_1与Host_2之间的往返报文，都先发送给网关Router，由Router查三层转发表进行三层转发。 跨设备VLAN间互访：由于VLANIF接口的IP地址只能在设备上生成直连路由，当不同VLAN的用户跨多台设备互访时，除配置VLANIF接口的IP地址外，还需要配置静态路由或运行动态路由协议。 如下图所示，互访的源主机Host_1和目的主机Host_2连接在不同的设备Router_1和Router_2上，分别属于VLAN2和VLAN3，并位于不同的网段。在Router_1上分别创建VLANIF2和VLANIF4，配置其IP地址为10.1.1.1和10.1.4.1；在Router_2上分别创建VLANIF3和VLANIF4，配置其IP地址为10.1.2.1和10.1.4.2，并在Router_1和Router_2上分别配置静态路由。Router_1上静态路由的目的网段是10.1.2.0/24，下一跳是10.1.4.2；Router_2上静态路由的目的网段是10.1.1.0/24，下一跳是10.1.4.1。 当用户主机Host_1发送报文给用户主机Host_2时，报文的发送过程如下（假设Router_1和Router_2上还未建立任何转发表项）。 与同设备VLAN间互访的步骤1～6一样，经过“Host_1比较目的IP地址—&gt;Host_1查ARP表—&gt;Host_1获取网关MAC地址—&gt;Host_1将发给Host_2的报文送到Router_1—&gt;Router_1查MAC表—&gt;Router_1查三层转发表”的过程，Router_1上送CPU查找路由表。 Router_1的CPU根据报文的目的IP 10.1.2.2去找路由表，发现匹配了一个路由网段10.1.2.0/24（VLANIF3对应的网段），下一跳IP地址为10.1.4.2，于是继续查找ARP表，没有找到，Router_1会在下一跳IP地址对应的VLAN4的所有接口发送ARP请求报文，目的IP是10.1.4.2。报文从Router_1的接口IF_2发出前，根据接口配置，直接透传该报文到Router_2的IF_2接口，不剥除报文的Tag。 ARP请求报文到达Router_2后，发现目的IP为VLANIF4接口的IP地址，给Router_1回应，填写VLANIF4接口的MAC地址。 Router_2的ARP响应报文从其IF_2接口直接透传到Router_1，Router_1接收后，记录VLANIF4的MAC地址与IP地址的对应关系到ARP表项。 Router_1将Host_1的报文转发给Router_2，报文的目的MAC修改为Router_2的VLANIF4接口的MAC地址，源MAC地址修改自己的VLANIF4接口的MAC地址，并将刚用到的转发信息记录在三层转发表中（10.1.2.0/24，下一跳IP的MAC地址， 出口VLAN， 出接口）。同样，报文是直接透传到Router_2的IF_2接口。 Router_2收到Router_1转发的Host_1的报文后，与同设备VLAN间互访的步骤6～9一样，经过“查MAC表—&gt;查三层转发表—&gt;送CPU—&gt;匹配直连路由—&gt;查ARP表并获取Host_2的MAC地址—&gt;将Host_1的报文转发给Host_2”的过程，同时将Host_2的IP地址、MAC地址、出口VLAN、出接口记录到三层转发表项。 VLAN Damping：VLAN抑制 如果指定VLAN已经创建对应的VLANIF接口，当VLAN中所有接口状态变为Down而引起VLAN状态变为Down时，VLAN会向VLANIF接口上报接口Down状态，从而引起VLANIF接口状态变化。 为避免由于VLANIF接口状态变化引起的网络震荡，可以在VLANIF接口上启动VLAN Damping功能，抑制VLANIF接口状态变为Down的时间。 当使能VLAN Damping功能，VLAN中最后一个处于Up状态的接口变为Down后，会抑制一定时间（抑制时间可配置）再上报给VLANIF接口。如果在抑制时间内VLAN中有接口Up，则VLANIF接口状态保持Up状态不变。即VLAN Damping功能可以适当延迟VLAN向VLANIF接口上报接口Down状态的时间，从而抑制不必要的路由震荡。 VLAN内二层隔离：为了实现用户之间的二层隔离，可以将不同的用户加入不同的VLAN。但若企业规模很大，拥有大量的用户，那么就要为不能互相访问的用户都分配VLAN，这不但需要耗费大量的VLAN，还增加了网络管理者配置和维护的工作量。 为此，华为提供了一些VLAN内二层隔离技术，如端口隔离、MUX VLAN和基于MQC的VLAN内二层隔离等。 端口隔离：端口隔离可实现同一VLAN内端口之间的隔离。用户只需要将端口加入到隔离组中，就可以实现隔离组内端口之间的二层隔离，不同隔离组的端口之间或者不属于任何隔离组的端口与其他端口之间都能进行正常的数据转发。同时，用户还可以通过配置实现端口的单向隔离，为用户提供更安全、更灵活的组网方案。 MUX VLAN：MUX VLAN（Multiplex VLAN）提供了一种通过VLAN进行网络资源控制的机制。它既可实现VLAN间用户通信，也可实现VLAN内的用户相互隔离。 比如，企业有如下需求： 要求企业内部员工之间可以互相交流，而企业客户之间是隔离的，不能够互相访问。 要求企业员工和企业客户都可以访问企业的服务器。 此种场景，通过部署MUX-VLAN就可以实现。 基于流策略的VLAN内二层隔离：流策略是将流分类和流行为关联后形成的完整的QoS策略。基于流策略的VLAN内二层隔离指用户可以根据匹配规则对报文进行流分类，然后通过流策略将流分类与permit/deny动作相关联，使符合流分类的报文被允许或被禁止通过，从而实现灵活的VLAN内单向或双向隔离。 VLAN间三层隔离：VLAN间实现三层互通后，两VLAN内的所有用户之间都可以互相访问，但某些场景中，需要禁止部分用户之间的互访或者只允许用户单向访问，比如用户主机和服务器之间一般是单向访问、企业的访客一般只允许上网和访问部分服务器等。此时，就需要配置VLAN间互访控制。 VLAN间互访控制一般通过流策略实现。用户可根据实际需求定义匹配规则对报文进行流分类，然后通过流策略将流分类与permit/deny动作相关联，使符合流分类的报文被允许或禁止通过，从而实现灵活的VLAN间互访控制。 管理VLAN：当用户通过远端网管集中管理设备时，需要在设备上通过VLANIF接口配置IP地址作为设备管理IP，通过管理IP来STelnet到设备上进行管理。若设备上其他接口相连的用户加入该VLAN，也可以访问该设备，增加了设备的不安全因素。 这种情况下可以配置VLAN为管理VLAN（与管理VLAN对应，没有指定为管理VLAN的VLAN称为业务VLAN），不允许Access类型和Dot1q-tunnel类型接口加入该VLAN。由于Access类型和Dot1q-tunnel类型通常用于连接用户，限制这两种类型接口加入管理VLAN后，与该接口相连的用户就无法访问该设备，从而增加了设备的安全性。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>VLAN</tag>
        <tag>交换基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stdarg.h简介]]></title>
    <url>%2F2017%2F10%2F23%2Fstdarg-h%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[stdarg.h简介： stdarg.h是C语言中C标准函数库的头文件，stdarg是由standard（标准） arguments（参数）简化而来，主要目的为让函数能够接收可变参数。C++的cstdarg头文件中也提供这样的功能；虽然与C的头文件是兼容的，但是也有冲突存在。 &lt; cstdarg &gt;(stdarg.h)。变量参数处理。此标头定义宏以访问未命名参数列表的各个参数，调用的函数不知道这些参数的数量和类型。 函数可以接受不同数量的附加参数，而不需要相应的参数声明，方法是在其常规命名参数之后包括一个逗号和三个点(, …)： 返回_type函数name(参数声明，…)；要访问这些附加参数，可以使用在此标题中声明的宏va_start、va_arg和va_end：首先，va_start将变量参数列表初始化为va_list。随后执行的va_arg将按照传递给函数的相同顺序产生附加参数的值。最后，应在函数返回之前执行va_end。 程序实例：123456789101112131415161718192021222324#include &lt;stdio.h&gt;#include &lt;stdarg.h&gt; /* va_list, va_start, va_arg, va_end */void Print(int n, ...)&#123; int i ,val; printf ("Printing:"); va_list vl; va_start(vl,n); for (i=0;i&lt;n;i++) &#123; val=va_arg(vl,int); printf ("%d\t",val); &#125; va_end(vl); printf ("\n");&#125;int main ()&#123; Print(3,1,3,5); return 0;&#125; 程序运行结果：1Printing:1 3 5]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>头文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组]]></title>
    <url>%2F2017%2F10%2F23%2F%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[数组的定义：数组: 由一组名字相同､下标不同的n(n≥1)个相同数据类型的数据元素a0,a1,a2,…,an-1构成的占用一块地址连续的内存单元的有限集合。 数组的特点： 数组中各元素具有统一的类型; 数组元素的下标一般具有固定的上界和下界,即数组一旦被定义,它的维数和维界就不再改变｡ 数组的基本操作比较简单,除了结构的初始化和销毁之外,只有存取元素和修改元素值的操作｡ 有关stdarg.h头文件的使用请点击：stdarg.h基本简介 数组的基本函数实现：base.h123456789101112131415161718192021//base.h//-----公用的常量和类型----------#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;malloc.h&gt;#include&lt;stdarg.h&gt;//标准头文件，提供宏 va_start、 va_arg、va_end//用于存储变长参数表using namespace std;//函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define OVERFLOW -2#define UNDERFLOW -1typedef int Status;typedef int ElemType; array.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//arryay.h//数组的基本函数实现#define MAX_ARRAY_DIM 8//-----数组的顺序存储表示------typedef struct&#123; ElemType *base; //数组的元素基址，由InitArray分配 int dim; //数组维数 int *bounds; //数组维界基址，由InitArray分配 int *constants; //数组映像函数常量基址，由InitArray分配 int elemtotal = 1; //存放元素总个数&#125;Array;//-----基本操作的函数原型说明----//若维数dim和随后的各维长度合法，则构造相应的数组A，并返回OKStatus InitArray(Array &amp;A, int dim, ...)&#123; if(dim &lt; 1 || dim &gt; MAX_ARRAY_DIM) return ERROR; A.dim = dim; A.bounds = (int *)malloc(dim * sizeof(int)); if(!A.bounds) exit(OVERFLOW); //若各维度合法，则存入A.bounds，并求出A的元素总数elemtotal va_list ap; va_start(ap, dim); //ap为va_list 类型，是存放变长参数表信息的数组 int i; for(i = 0; i &lt; dim; ++i)&#123; A.bounds[i] = va_arg(ap, int);//从ap中取出一个整数值 if(A.bounds[i] &lt; 0) return UNDERFLOW; A.elemtotal *= A.bounds[i]; //元素总数 &#125; va_end(ap); A.base = (ElemType *)malloc(A.elemtotal * sizeof(ElemType)); if(!A.base) exit(OVERFLOW); A.constants = (int *)malloc(dim * sizeof(int)); if(!A.constants) exit(OVERFLOW); A.constants[dim-1] = 1; //L=1；指针的增减以元素的大小为单位 for(i = dim-2; i &gt;= 0; --i) A.constants[i] = A.bounds[i+1] * A.constants[i+1]; return OK;&#125;//InitArray//销毁数组AStatus DestroyArray(Array &amp;A)&#123; if(!A.base) return ERROR; free(A.base); A.base = NULL; if(!A.bounds) return ERROR; free(A.bounds); A.bounds = NULL; if(!A.constants) return ERROR; free(A.constants); A.constants = NULL; cout&lt;&lt;"数组销毁成功！"&lt;&lt;endl; return OK;&#125;//DestroyArray//若ap知识的各下标值合法，则求出给元素在A中的相对地址Status Locate(Array A, va_list ap, int &amp;off)&#123; off = 0; int i; for(i = 0; i &lt; A.dim; ++i)&#123; int ind = va_arg(ap, int); if(ind &lt; 0 || ind &gt;= A.bounds[i]) return OVERFLOW; off += A.constants[i] * ind; &#125; return OK;&#125;//Locate//A是n维数组，e为元素变量，随后是n个下标值//若各下标不超界，则e赋值为所指定的A的元素的值，并返回OKStatus GetValue(Array A, ElemType &amp;e, ...)&#123; va_list ap; va_start(ap, e); int result, off; if((result = Locate(A, ap, off)) &lt;= 0) return result; e = *(A.base + off); return OK;&#125;//GetValue//A是n维数组，e为元素变量，随后是n个下标值//若各下标不超界，则e赋值为所指定的A的元素，并返回OKStatus SetValue(Array &amp;A, ElemType e, ...)&#123; va_list ap; va_start(ap, e); int result, off; if((result = Locate(A, ap, off)) &lt;= 0) return result; *(A.base + off) = e; return OK;&#125;//SetValue//返回数组内元素总个数int ArrayLength(Array A)&#123; return A.elemtotal;&#125;//ArrayLength main.cpp1234567891011121314151617181920212223#include "base.h"#include "array.h"int main()&#123; ElemType e; Array A; InitArray(A, 2, 2, 3); int i, j,k; for(i=0,e=1 ; i&lt;2; i++) for(j=0; j&lt;3; j++, e++) SetValue(A, e , i, j); GetValue(A, e, 1, 2); cout&lt;&lt;"A[1][2]为："&lt;&lt;e&lt;&lt;endl; cout&lt;&lt;"数组总共有："&lt;&lt;ArrayLength(A)&lt;&lt;"个元素"&lt;&lt;endl; for(i=0; i&lt;2; i++)&#123; for(j=0; j&lt;3; j++)&#123; GetValue(A, e , i, j); cout&lt;&lt;"A["&lt;&lt;i&lt;&lt;"]["&lt;&lt;j&lt;&lt;"]="&lt;&lt;e&lt;&lt;" "; &#125; cout&lt;&lt;endl; &#125; return OK;&#125; 程序测试结果：程序输出结果： 1234A[1][2]为：6数组总共有：6个元素A[0][0]=1 A[0][1]=2 A[0][2]=3A[1][0]=4 A[1][1]=5 A[1][2]=6]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSPF命令行配置]]></title>
    <url>%2F2017%2F10%2F20%2FOSPF%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[配置OSPF的基本功能创建OSPF进程：一台路由器如果要运行OSPF协议，必须存在Router ID。路由器的Router ID是一个32比特无符号整数，是一台路由器在自治系统中的唯一标识。为保证OSPF运行的稳定性，在进行网络规划时应该确定Router ID的划分并手工配置。 12345ospf [ process-id | router-id router-id | vpn-instance vpn-instance-name //启动OSPF进程，进入OSPF视图例如：ospf 1 router-id 1.1.1.1//创建opsf进程1，并设置router-id为1.1.1.1 process-id为进程号，缺省值为1。 路由器支持OSPF多进程，可以根据业务类型划分不同的进程。进程号是本地概念，不影响与其它路由器之间的报文交换。因此，不同的路由器之间，即使进程号不同也可以进行报文交换。 router-id router-id为路由器的ID号。 缺省情况下，路由器系统会从当前接口的IP地址中自动选取一个最大值作为Router ID。手动配置Router ID时，必须保证自治系统中任意两台Router ID都不相同。通常的做法是将Router ID配置为与该设备某个接口的IP地址一致 说明： 每个OSPF进程的Router ID要保证在OSPF网络中唯一，否则会导致邻居不能正常建立、路由信息不正确的问题。建议在OSPF设备上单独为每个OSPF进程配置全网唯一的Router ID。 vpn-instance vpn-instance-name表示VPN实例。 如果指定了VPN实例，那么此OSPF进程属于指定的VPN实例，如果未指定则属于公网实例。 创建OSPF区域：区域是从逻辑上将设备划分为不同的组，每个组用区域号（AreaID）来标识。区域的边界是设备，而不是链路。一个网段（链路）只能属于一个区域，或者说每个运行OSPF的接口必须指明属于哪一个区域。 12[OSPF进程下] area area-id//创建并进入ospf区域视图 宣告OSPF网段：创建OSPF进程后，还需要配置区域所包含的网段。一个网段只能属于一个区域，或者说每个运行OSPF协议的接口必须指明属于某一个特定的区域。该处的网段是指运行OSPF协议接口的IP地址所在的网段。 OSPF需要对接收到的Hello报文做网络掩码检查，当接收到的Hello报文中携带的网络掩码和本设备不一致时，则丢弃这个Hello报文，即不能建立邻居关系。 123456789宣告OSPF网段有两种方法：//1、区域下宣告[区域视图下] network ip-address wildcard-mask//配置区域所包含的网段//2.接口下宣告[接口视图下] ospf enable [process-id] area [area-id]//在接口上使能OSPF。 创建虚连接：12[OSPF区域视图下] vlink 1.1.1.1//创建并配置虚连接 OSPF检查配置结果： 在任意视图下执行display ospf [process-id] perr命令，查看OSPF邻居的信息。 在任意视图下执行display ospf [process-id] interface命令，查看OSPF接口的信息。 在任意视图下执行display ospf [process-id] routing命令，查看OSPF路由表的信息。 在任意视图下执行display ospf [process-id] lsdb命令，查看OSPF的LSDB信息。 使用display ospf[ process-id ] brief命令查看OSPF的概要信息。 使用display ospf [process-id] error 查看ospf错误信息 配置OSPF邻居或邻接的会话参数配置OPSF报文重传限制：OSPF路由器发送完DD报文、LSU报文、LSR报文，这三种报文后，若没有在规定时间内收到相应的LSAck报文，会再次重传。当达到限定报文重传次数后，本端就断开和对方的邻接关系。 1234[AR1-ospf-1]retransmission-limit ? INTEGER&lt;2-255&gt; The Number of Retransmission Limitation //配置OSPF重传限制功能 //缺省情况下，不使能此功能。最大重传限制数的缺省值是30。 使能在DD报文中填充接口的实际MTU建立虚连接后，不同的设备制造商可能会使用不同的MTU缺省设置。为了保证一致，应该设置接口发送DD报文时MTU值为缺省值0。 1234[AR1-GigabitEthernet0/0/0]ospf mtu-enable //使能接口发送DD报文时填充MTU值，同时还会检查邻居DD报文所携带的MTU是否超过本端的MTU值。 //缺省情况下，接口发送DD报文的MTU值为0。 注意：当配置DD报文MTU值后，会引起邻居关系的从新建立。 配置OSPF在不同网络类型中的属性OSPF的网络类型和特点: 网络类型 特点 缺省选择 广播类型（Broadcast） 在该类型的网络中，通常以组播形式发送Hello报文、LSU报文和LSAck报文，以单播形式发送DD报文和LSR报文。 当链路层协议是Ethernet、FDDI时，缺省情况下，OSPF认为网络类型是Broadcast。 NBMA类型（Non-broadcast multiple access） 在该类型的网络中，以单播形式发送Hello报文、DD报文、LSR报文、LSU报文、LSAck报文。NBMA网络必须是全连通的，即网络中任意两台路由器之间都必须直接可达。 当链路层协议是ATM时，缺省情况下，OSPF认为网络类型是NBMA。 点到点P2P类型（point-to-point） 在该类型的网络中，以组播形式发送Hello报文、DD报文、LSR报文、LSU报文、LSAck报文。 当链路层协议是PPP、HDLC和LAPB时，缺省情况下，OSPF认为网络类型是P2P。 点到多点P2MP类型（Point-to-Multipoint） 在该类型的网络中：以组播形式发送Hello报文，以单播形式发送DD报文、LSR报文、LSU报文、LSAck报文。 没有一种链路层协议会被缺省的认为是P2MP类型，P2MP必须是由其他的网络类型强制更改的。 配置OSPF路由的收敛优先级：12[进程视图下] prefix-priority &#123; critical | high | medium &#125; ip-prefix ip-prefix-name//配置OSPF路由的收敛优先级。 配置OSPF路由的收敛优先级后，OSPF路由可以按照优先级来计算和泛洪LSA、同步LSDB，从而提高路由收敛速度。当一个LSA满足多个策略优先级时，最高优先级生效。OSPF依次按区域内路由、区域间路由、自治系统外部路由顺序进行LSA计算，该命令可以计算OSPF的收敛优先级。收敛优先级的优先级顺序为：critical&gt;high&gt;medium&gt;low。为了加速处理高优先级的LSA，泛洪过程中，需要按照优先级将相应的LSA分别存放在对应的critical、high、medium和low的队列中。 注：该命令仅在公网配置时有效 配置接口发送Hello报文的时间间隔：12[AR1-GigabitEthernet0/0/0]ospf timer hello 10 //配置接口发送hello报文的时间间隔 缺省情况下，P2P、Broadcast类型接口发送Hello报文的时间间隔的值为10秒；P2MP、NBMA类型接口发送Hello报文的时间间隔的值为30秒；且同一接口上邻居失效时间是Hello间隔时间的4倍。 配置相邻邻居失效的时间:12[AR1-GigabitEthernet0/0/0]ospf timer dead 40//配置相邻邻居失效的时间 缺省情况下，P2P、Broadcast类型接口的OSPF邻居失效时间为40秒，P2MP、NBMA类型接口的OSPF邻居失效时间为120秒；且同一接口上失效时间是Hello间隔时间的4倍。 建议配置的失效时间大于20秒。如果失效的时间小于20秒，可能会造成邻居会话的中断。 修改了网络类型后，Hello与Dead定时器都将恢复缺省值。 配置Smart-discover：路由器的邻居状态或者多址网络（广播型或NBMA）上的DR、BDR发生变化时，需要等到Hello定时器到时才会向邻居发送Hello报文，影响了设备间建立邻居的速度。通过配置Smart-discover，网络中邻居状态，或者DR、BDR发生变化时，设备不必等到Hello定时器到就可以立刻主动的向邻居发送Hello报文。从而提高建立邻居的速度，达到网络快速收敛的目的。 12[AR1-GigabitEthernet0/0/0]ospf smart-discover //配置接口的Smart-discover功能 配置更新LSA的时间间隔:OSPF协议规定LSA的更新时间间隔5秒，是为了防止网络连接或者路由频繁动荡引起的过多占用网络带宽和设备资源。 在网络相对稳定、对路由收敛时间要求较高的组网环境中，可以指定LSA的更新时间间隔为0来取消LSA的更新时间间隔，使得拓扑或者路由的变化可以立即通过LSA发布到网络中，从而加快网络中路由的收敛速度。 12[AR1-ospf-1]lsa-originate-interval &#123; 0 | &#123; intelligent-timer max-interval start-interval hold-interval | other-type interval &#125; //配置LSA的更新时间间隔 intelligent-timer表示通过智能定时器设置OSPF Router LSA和Network LSA的更新间隔时间。 max-interval为更新OSPF LSA的最长间隔时间，单位是毫秒。 start-interval为更新OSPF LSA的初始间隔时间，单位是毫秒。 hold-interval为更新OSPF LSA的基数间隔时间，单位是毫秒。 other-type interval表示设置除OSPF Router LSA和Network LSA外LSA的更新间隔时间。 缺省情况下，使能智能定时器intelligent-timer。使能智能定时器后，更新LSA的最长间隔时间的缺省值为5000毫秒、初始间隔时间的缺省值为500毫秒、基数间隔时间的缺省值为1000毫秒（以毫秒为单位的时间间隔） 配置接收LSA的时间间隔：OSPF协议规定LSA的接收时间间隔1秒，是为了防止网络连接或者路由频繁动荡引起的过多占用网络带宽和设备资源。 在网络相对稳定、对路由收敛时间要求较高的组网环境中，可以指定LSA的接收时间间隔为0来取消LSA的接收时间间隔，使得拓扑或者路由的变化可以立即通过LSA发布到网络中，从而加快网络中路由的收敛速度。 12[AR1-ospf-1] lsa-arrival-interval &#123; interval | intelligent-timer max-interval start-interval hold-interval &#125;//配置LSA接收的时间间隔。 在网络相对稳定、对路由收敛时间要求较高的组网环境中，可以指定LSA被接收的时间间隔为0，使得拓扑或者路由的变化能够立即被感知到。 缺省情况下，使能智能定时器intelligent-timer。使能智能定时器后，接收LSA的最长间隔时间的缺省值为1000毫秒、初始间隔时间的缺省值为500毫秒、基数间隔时间的缺省值为500毫秒（以毫秒为单位的时间间隔）。 配置SPF计算时间间隔：当OSPF的链路状态数据库（LSDB）发生改变时，需要重新计算最短路径。如果网络频繁变化，由于不断的计算最短路径，会占用大量系统资源，影响设备的效率。通过配置智能定时器intelligent-timer，设置合理的SPF计算的间隔时间，可以避免占用过多的路由器内存和带宽资源。 12[AR1-ospf-1]spf-schedule-interval &#123; interval1 | intelligent-timer max-interval start-interval hold-interval | millisecond interval2 &#125;//设置SPF计算间隔。 interval1为OSPF的SPF计算间隔时间，单位是毫秒。 intelligent-timer表示通过智能定时器设置OSPF SPF计算的间隔时间。 max-interval为OSPF SPF计算的最长间隔时间，单位是毫秒。 start-interval为OSPF SPF计算的初始间隔时间，单位是毫秒。 hold-interval为OSPF SPF计算的基数间隔时间，单位是毫秒。 millisecond interval2表示OSPF的SPF计算间隔时间，单位是毫秒。 缺省情况下，使能智能定时器intelligent-timer，SPF计算的最长间隔时间为10000毫秒、初始间隔时间为500毫秒、基数间隔时间为1000毫秒（以毫秒为单位的时间间隔）。 提高OPSF网络的稳定性配置OSPF的协议优先级：由于路由器上可能同时运行多个动态路由协议，就存在各个路由协议之间路由信息共享和选择的问题。系统为每一种路由协议设置一个优先级。在不同协议发现同一条路由时，优先级高的路由将被优选。 12[AR1-ospf-1]preference [ ase ] &#123; preference | route-policy route-policy-name &#125; //配置OSPF协议的优先级。 ase表示设置AS-External路由的优先级。 preference表示OSPF协议路由的优先级。优先级的值越小，其实际的优先程度越高。 route-policy route-policy-name表示对特定的路由通过路由策略设置优先级。 缺省情况下，OSPF路由的优先级为10。当指定ASE时，缺省优先级为150。 配置接口传送LSA的延迟时间：123[AR1-GigabitEthernet0/0/0]ospf trans-delay ? INTEGER&lt;1-500&gt; Second(s) //配置接口传送LSA的延迟时间。 缺省情况下，传输延迟时间为1秒。 配置邻接路由器重传LSA的间隔：当一台路由器向它的邻居发送一条LSA后，需要等到对方的确认报文。若在重传间隔时间内没有收到对方的确认报文，就会向邻居重传这条LSA。 123[AR1-GigabitEthernet0/0/0]ospf timer retransmit ? INTEGER&lt;1-3600&gt; Second(s)//设置邻接路由器重传LSA的间隔 缺省情况下，重传间隔时间为5秒。 配置Stub路由器：配置Stub路由器是一种特殊的路由选路，配置了stub router的路径不被优选。实现方法是将度量值设为最大（65535），尽量避免数据从此路由器转发。用于保护此路由器链路，通常使用在升级等维护操作的场景。 123[AR1-ospf-1]stub-router on-startup ? INTEGER&lt;5-65535&gt; //配置Stub路由器。 缺省情况下，没有路由器为Stub路由器。 如果配置了Stub路由器，缺省情况下，路由器保持为Stub路由器的时间间隔是500秒。 禁止OSPF接口发送和接收协议报文:当用户希望本地OSPF路由信息不被其他网络中的设备获得，并且本地设备不接收网络中其他设备发布的路由更新信息的时候，可以通过配置禁止OSPF接口发送和接收协议报文来实现。 禁止OSPF接口发送和接收协议报文后，该接口的直连路由仍可以发布出去，但接口的Hello报文将被阻塞，无法通过此接口与相邻设备建立邻居关系。这样可以增强OSPF的组网适应能力，减少系统资源的消耗。 12[AR1-ospf-1]silent-interface &#123; all | interface-type interface-number &#125;//禁止OSPF接口发送和接收协议报文。 缺省情况下，允许OSPF接口发送和接收协议报文。 可以在不同的OSPF进程中，禁止同一个接口发送和接收OSPF报文，但[silent-interface]命令只对本进程已经使能的OSPF接口起作用，对其它进程的接口不起作用。 提高OPSF安全性配置OSPF区域验证方式：使用区域验证时，一个区域中所有的路由器在该区域下的验证模式和口令必须一致。例如，在Area0内所有路由器上配置验证模式为简单验证，口令为abc。 注意： 在配置区域认证模式时，如果使用plain选项，密码将以明文形式保存在配置文件中，存在安全隐患。建议使用cipher选项，将密码加密保存。 Simple、MD5和HMAC-MD5密文验证模式存在安全风险，推荐使用HMAC-SHA256密文验证模式。 12345[AR1-ospf-1-area-0.0.0.0]authentication-mode &#123; md5 | hmac-md5 | hmac-sha256 &#125; [ key-id &#123; plain plain-text | [ cipher ] cipher-text &#125; ]//配置OSPF区域的验证模式。[AR1-ospf-1-area-0.0.0.0] authentication-mode keychain keychain-name//配置OSPF区域的Keychain验证模式。 说明： 使用Keychain验证模式，需要在系统视图下配置Keychain信息。必须保证本端ActiveSendKey和对端ActiveRecvKey的key-id、algorithm、key-string相同，才能建立OSPF邻居。 配置OSPF接口验证方式：接口验证方式用于在相邻的路由器之间设置验证模式和口令，优先级高于区域验证方式。 12[AR1-GigabitEthernet0/0/0]ospf authentication-mode &#123; md5 | hmac-md5 | hmac-sha256 &#125; [ key-id &#123; plain plain-text | [ cipher ] cipher-text &#125; ]//配置OSPF接口的验证模式。 维护OSPF清除OSPF：12345&lt;AR1&gt;reset ospf [ process-id ] counters [ neighbor [ interface-type interface-number ] [ router-id ] ]//命令清除OSPF计数器 //counters表示用来将OSPF计数器清零。//neighbor表示指定接口上邻居的信息。 复位OSPF：12&lt;AR1&gt;reset ospf [ process-id ] process [ flush-waiting-timer time | graceful-restart ]//命令重启OSPF进程。 常见命令：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778asbr-summary 10.2.0.0 255.255.0.0 not-advertise tag 2 cost 100//用来设置自治系统边界路由器（ASBR）对OSPF引入的路由进行路由聚合。display ospf abr-asbr//用来显示OSPF的区域边界路由器和自治系统边界路由器信息。display ospf asbr-summary//用来查看OSPF的路由聚合信息。display ospf bfd session//用来查看使能BFD特性邻居的信息。display ospf cumulative//用来显示OSPF的统计信息。display ospf error//用来查看OSPF的错误信息。display ospf global-statistics//用来查看OSPF协议的全局统计信息。如果不指定OSPF进程号，该命令将显示所有OSPF进程的概要信息。display ospf graceful-restart//用来查看OSPF GR的状态信息。display ospf interface//用来显示OSPF的接口信息。display ospf lsdb//用来显示OSPF的链路状态数据库（LSDB）信息。display ospf mesh-group//用来查看OSPF Mesh-Group的概要信息。display ospf nexthop//用来显示OSPF的下一跳信息。display ospf peer//用来显示OSPF中各区域邻居的信息。display ospf routing//命令用来显示OSPF路由表的信息。display ospf spf-statistics//命令用来查看OSPF进程下路由计算的统计信息。display ospf statistics maxage-lsa//命令用来查看达到最大老化时间的Router LSA信息。display ospf vlink//命令用来显示OSPF的虚连接信息。ospf cost//命令用来配置接口上运行OSPF协议所需的开销。ospf dr-priority//命令用来设置接口在选举DR时的优先级。ospf filter-lsa-out//命令用来配置对OSPF接口出方向的LSA进行过滤。ospf mtu-enable//命令用来使能接口在发送DD报文时填MTU值。ospf network-type//命令用来设置OSPF接口的网络类型。ospf p2mp-mask-ignore//命令用来设置在P2MP网络上忽略对网络掩码的检查。ospf smart-discover//命令用来在接口上使能Smart-discover功能。ospf timer hello//命令用来设置接口发送Hello报文的时间间隔。preference//命令用来设置OSPF协议路由的优先级。preference//命令用来设置OSPF协议路由的优先级。 常见配置错误OSPF邻居建立不成功： 检查邻居两端的接口物理和协议状态是否UP，状态是否稳定，接口是否有丢包，两边互ping大包是否能通。 若物理接口不Up或是不稳定（有振荡现象），请排查物理链路和链路层协议，确保物理和协议状态都是Up，并且接口无错误计数。 可以通过ping测试，长ping测试是否存在丢包现象，ping大包（1500字节以上）测试是否存在大包不通的现象。 检查链路两端OSPF进程的Router ID是否一致。 分别在链路两端的设备上执行命令display ospf [ process-id ] brief，查看OSPF进程的Router ID。 Router ID要保证全网唯一，否则会导致邻居不能正常建立、路由信息不正确的问题。建议在设备上单独为每个OSPF进程配置全网唯一的Router ID。 如果链路两端OSPF进程的Router ID一致，请在系统视图下执行命令ospf [ process-id ] router-id router-id，修改OSPF进程的Router ID以保证不冲突。 修改OSPF进程的Router ID之后，必须在用户视图下执行命令display ospf [ process-id ] process后，新配置的Router ID才会生效。 检查链路两端OSPF区域ID是否一致。 分别在链路两端的设备上执行命令display ospf [ process-id ] brief，查看OSPF的区域ID。 如果链路两端的OSPF区域ID不一致，请在OSPF视图下执行命令area area-id，修改OSPF区域ID以保证一致。 检查链接两端OSPF接口的网络类型是否一致。 分别在链路两端的设备上执行命令display ospf [ process-id ] interface，查看OSPF接口的接口类型。 当链路两端的OSPF接口的网络类型一端是广播网而另一端是P2P时，双方仍可以正常的建立起邻居关系，但互相学不到路由信息。 当链路两端的OSPF接口的网络类型一端是P2MP而另一端是P2P时，双方仍可以正常的建立起邻居关系，但互相学不到路由信息。为了相互学到路由信息，此时需要在链路两端的OSPF接口上配置相同的Hello报文发送间隔和邻居失效时间。 如果OSPF接口的网络类型不一致，请在运行OSPF协议的接口视图下执行命令ospf network-type { broadcast | nbma | p2mp | p2p }，修改OSPF接口的网络类型以保证一致。 说明： 如果链路两端OSPF接口的网络类型都是NBMA，则必须在OSPF视图下执行命令peer ip-address [ dr-priority priority ]，配置NBMA网络的OSPF邻居。 检查链路两端OSPF接口的IP地址的掩码是否一致。 分别在链路两端的设备上执行命令display current-configuration interface interface-type interface-number，查看OSPF接口的IP地址。 一般情况下，链路两端的OSPF接口的IP地址的掩码必须一致，否则双方不能正常建立OSPF邻居关系。但在P2MP网络中，可以通过在运行OSPF协议的接口视图下配置命令ospf p2mp-mask-ignore来使设备忽略对网络掩码的检查，从而正常建立OSPF邻居关系。 如果OSPF接口的IP地址的掩码不一致，请在运行OSPF协议的接口视图下执行命令ip address ip-address { mask | mask-length }，修改OSPF接口的IP地址以保证掩码一致。 检查链路两端OSPF接口的IP地址所在网段是否包含在区域内配置的network内。 分别在链路两端的设备上执行命令display current-configuration interface interface-type interface-number，查看OSPF接口的IP地址；执行命令display current-configuration configuration ospf，查看OSPF进程的配置。 满足下面两个条件，OSPF协议才能在接口上运行： 接口的IP地址掩码长度≥network命令中的掩码长度。OSPF使用反掩码，例如0.0.0.255表示掩码长度24位。 接口的主IP地址必须在network命令指定的网段范围之内。 如果检查发现接口IP地址与配置的network不满足上述条件，请在运行OSPF协议的接口视图下执行命令ip addressip-address { mask | mask-length }，修改接口的IP地址；或者在OSPF进程对应的区域视图下执行命令network，修改配置的网段，保证满足上述条件。 检查链路两端OSPF接口的DR优先级是否非零。 分别在链路两端的设备上执行命令display ospf [ process-id ] interface，查看OSPF接口的DR优先级。 对于广播和NBMA类型网络，链路中至少要有一个OSPF接口的DR优先级不为0，这样才能正常选举出DR。否则两边的邻居状态只能达到2-Way。 如果链路两端OSPF接口的DR优先级都为0，请在运行OSPF协议的接口视图下执行命令ospf dr-priority priority，修改OSPF接口的DR优先级以保证至少有一个接口的DR优先级不为0。 OSPF不能发现其他区域的路由： 检查设备所在区域是否与骨干区域相连。 在设备所在区域的ABR上执行命令display ospf [ process-id ] brief，查看ABR的区域配置信息。 OSPF规定所有非骨干区域必须与骨干区域保持连通。 如果ABR上没有配置骨干区域的信息，请在OSPF视图下执行命令area area-id，修改OSPF区域信息以保证ABR上至少有一个接口运行在骨干区域。 说明： 如果因实际组网限制，无法满足所有非骨干区域与骨干区域保持连通的要求，可以通过配置虚连接来满足需求。 检查设备所在区域是否为Totally Stub区域。 在设备上执行命令display current-configuration configuration ospf [ process-id ]，查看OSPF进程的配置信息。 配置非骨干区域为Stub区域时，如果在ABR上配置时加上了参数no-summary （即OSPF区域视图下执行stub no-summary命令），则将该区域配置成了Totally Stub区域。 Totally Stub区域，不允许发布自治系统外部路由和区域间的路由，只允许发布区域内路由。 如果要将该Totally Stub区域恢复为普通区域，则需要在该区域的所有设备的OSPF区域视图下执行命令undo stub。 如果仅仅是需要将Totally Stub区域改成Stub区域，则需要在该区域的ABR的OSPF区域视图下先执行命令undo stub，然后再执行命令undo。 检查设备所在区域是否为Totally NSSA区域。 在设备上执行命令display current-configuration configuration ospf [ process-id ]，查看OSPF进程的配置信息。 配置非骨干区域为NSSA区域时，如果在ABR上配置时加上了参数no-summary （即在OSPF区域视图下执行nssa no-summary命令），则将该区域配置成了Totally NSSA区域。 Totally NSSA区域不允许发布自治系统外部路由和区域间的路由，只允许发布区域内路由。 如果要将该Totally NSSA区域恢复为普通区域，则需要在该区域的所有设备的OSPF区域视图下执行命令undo nssa。 如果仅仅是需要将Totally NSSA区域改成NSSA区域，则需要在该区域的ABR的OSPF区域视图下先执行命令undo nssa，然后再执行命令nssa。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>OSPF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSPF报文类型]]></title>
    <url>%2F2017%2F10%2F20%2FOSPF%E6%8A%A5%E6%96%87%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[OSPF报文头格式OSPF用IP报文直接封装协议报文，协议号为89。OSPF分为5种报文，Hello报文、DD报文、LSR报文、LSU报文和LSAck报文。 OSPF这五种报文具有相同的报文头格式，长度为24字节。 报文格式： 字段解释： Version 1字节 版本，OSPF的版本号。对于OSPFv2来说，其值为2。 字段 长度 含义 Type 1字节 类型，OSPF报文的类型，有下面几种类型：1：Hello报文；2：DD报文；3：LSR报文；4：LSU报文；5：LSAck报文。 Packet length 2字节 OSPF报文的总长度，包括报文头在内，单位为字节。 Router ID 4字节 发送该报文的路由器标识。 Area ID 4字节 发送该报文的所属区域。 Checksum 2字节 校验和，包含除了认证字段的整个报文的校验和。 AuType 2字节 验证类型，值有如下几种表示， 0：不验证；1：简单认证；2：MD5认证。 Authentication 8字节 鉴定字段，其数值根据验证类型而定。当验证类型为0时未作定义；类型为1时此字段为密码信息；类型为2时此字段包括Key ID、MD5验证数据长度和序列号的信息。MD5验证数据添加在OSPF报文后面，不包含在Authenticaiton字段中。 hello 报文抓包： 图：OSPF报文头 OSPF Hello报文格式Hello报文是最常用的一种报文，其作用为建立和维护邻接关系，周期性的在使能了OSPF的接口上发送。报文内容包括一些定时器的数值、DR、BDR以及自己已知的邻居。 OSPF Hello报文格式： 字段解释： 字段 长度 含义 Network Mask 32比特 发送Hello报文的接口所在网络的掩码。 HelloInterval 16比特 发送Hello报文的时间间隔。 Options 8比特 可选项：E：允许Flood AS-External-LSAs MC：转发IP组播报文 N/P：处理Type-7 LSAs DC：处理按需链路 Rtr Pri 8比特 DR优先级。默认为1。如果设置为0，则路由器不能参与DR或BDR的选举。 RouterDeadInterval 32比特 失效时间。如果在此时间内未收到邻居发来的Hello报文，则认为邻居失效。 Designated Router 32比特 DR的接口地址。 Backup Designated Router 32比特 BDR的接口地址。 Neighbor 32比特 邻居，以Router ID标识。 OSPF Hello 抓包： 图：OSPF报文头 OSPF DD 报文格式两台路由器在邻接关系初始化时，用DD报文（Database DescriptionPacket）来描述自己的LSDB，进行数据库的同步。报文内容包括LSDB中每一条LSA的Header（LSA的Header可以唯一标识一条LSA）。LSAHeader只占一条LSA的整个数据量的一小部分，这样可以减少路由器之间的协议报文流量，对端路由器根据LSAHeader就可以判断出是否已有这条LSA。在两台路由器交换DD报文的过程中，一台为Master，另一台为Slave。由Master规定起始序列号，每发送一个DD报文序列号加1，Slave方使用Master的序列号作为确认。 DD 报文格式： 字段解释： 字段 长度 含义 Interface MTU 16比特 在不分片的情况下，此接口最大可发出的IP报文长度。 Options 8比特 可选项：E：允许Flood AS-External-LSAs；MC：转发IP组播报文；N/P：处理Type-7 LSAs；DC：处理按需链路。 I 1比特 当发送连续多个DD报文时，如果这是第一个DD报文，则置为1，否则置为0。 M (More) 1比特 当发送连续多个DD报文时，如果这是最后一个DD报文，则置为0。否则置为1，表示后面还有其他的DD报文。 M/S (Master/Slave) 1比特 当两台OSPF路由器交换DD报文时，首先需要确定双方的主从关系，Router ID大的一方会成为Master。当值为1时表示发送方为Master。 DD sequence number 32比特 DD报文序列号。主从双方利用序列号来保证DD报文传输的可靠性和完整性。 LSA Headers 可变 该DD报文中所包含的LSA的头部信息。 DD 抓包： 图： DD 报文抓包 OSPF LSR报文格式两台路由器互相交换过DD报文之后，知道对端的路由器有哪些LSA是本地的LSDB所缺少的和哪些LSA是已经失效的，这时需要发送LSR报文（Link State Request Packet）向对方请求所需的LSA。内容包括所需要的LSA的摘要。LSR报文格式如下图所示，其中LS type、Link State ID和Advertising Router可以唯一标识出一个LSA，当两个LSA一样时，需要根据LSA中的LS sequence number、LS checksum和LS age来判断出所需要LSA的新旧。 LDR报文格式： 字段解释： 字段 长度 含义 LS type 32比特 LSA的类型号。 Link State ID 32比特 根据LSA中的LS Type和LSA description在路由域中描述一个LSA。 Advertising Router 32比特 产生此LSA的路由器的Router ID。 LSR抓包： 图：LSR 报文抓包 OSPF LSU报文格式用来向对端Router发送其所需要的LSA或者泛洪自己更新的LSA，内容是多条LSA（全部内容）的集合。LSU报文（Link State UpdatePacket）在支持组播和广播的链路上是以组播形式将LSA泛洪出去。为了实现Flooding的可靠性传输，需要LSAck报文对其进行确认。对没有收到确认报文的LSA进行重传，重传的LSA是直接发送到邻居的。 LSU报文格式： 字段解释： 字段 长度 含义 Number of LSAs 32比特 LSA的数量。 LSU抓包： 图：LSU 报文抓包 OPSF LSAck报文格式用来对接收到的LSU报文进行确认。内容是需要确认的LSA的Header（一个LSAck报文可对多个LSA进行确认）。LSAck（Link StateAcknowledgment Packet）报文根据不同的链路以单播或组播的形式发送。 LSAck报文格式： 字段解释： 字段 长度 含义 LSAs Headers 可变 通过LSA的头部信息确认收到该LSA。 LSAck抓包： 图：LSAck 报文抓包 常见的五种LSA常用的LSA共有5种，分别为：Router-LSA、Network-LSA、Network-summary-LSA、ASBR-summary-LSA和AS-External-LSA。 所有的LSA都有相同的报文头： 字段 长度 含义 LS age 16比特 LSA产生后所经过的时间，以秒为单位。无论LSA是在链路上传送，还是保存在LSDB中，其值都会在不停的增长。 Options 8比特 可选项：E：允许泛洪AS-External-LSA；MC：转发IP组播报文；N/P：处理Type-7 LSA；DC：处理按需链路。 LS type 8比特 LSA的类型：Type1：Router-LSA Type2：Network-LSA Type3：Network-summary-LSA Type4：ASBR-summary-LSA Type5：AS-External-LSA Type7：NSSA-LSA Link State ID 32比特 与LSA中的LS Type和LSA description一起在路由域中描述一个LSA。 Advertising Router 32比特 产生此LSA的路由器的Router ID。 LS sequence number 32比特 LSA的序列号。其他路由器根据这个值可以判断哪个LSA是最新的。 LS checksum 16比特 除了LS age外其它各域的校验和。 length 16比特 LSA的总长度，包括LSA Header，以字节为单位。 Router-LSA（1类）Router-LSA（Type1）：每个路由器都会产生，描述了路由器的链路状态和花费，在所属的区域内传播。 字段 长度 含义 Link State ID 32比特 生成LSA的Router ID。 V (Virtual Link) 1比特 如果产生此LSA的路由器是虚连接的端点，则置为1。 E (External) 1比特 如果产生此LSA的路由器是ASBR，则置为1。 B (Border) 1比特 如果产生此LSA的路由器是ABR，则置为1。 # links 16比特 LSA中所描述的链路信息的数量，包括路由器上处于某区域中的所有链路和接口。 Link ID 32比特 路由器所接入的目标，其值取决于连接的类型：1：Router ID；2：DR的接口IP地址；3：网段／子网号；4：虚连接中对端的Router ID。 Link Data 32比特 连接数据，其值取决于连接的类型：unnumbered P2P：接口的索引值；stub网络：子网掩码；其它连接：路由器接口的IP地址。 Type 8比特 路由器连接的基本描述：1：点到点连接到另一台路由器；2：连接到传输网络；3：连接到stub网络；4：虚拟链路。 # TOS 8比特 连接不同的TOS数量。 metric 16比特 链路的开销值。 TOS 8比特 服务类型。 TOS metric 16比特 和指定TOS值相关联的度量。 1234567891011121314151617181920[AR3]dis ospf 1 lsdb router self-originate OSPF Process 1 with Router ID 10.0.13.3 Area: 0.0.0.0 Link State Database Type : Router Ls id : 10.0.13.3 Adv rtr : 10.0.13.3 Ls age : 1128 Len : 36 Options : E seq# : 80000003 chksum : 0xd911 Link count: 1 * Link ID: 10.0.13.1 Data : 10.0.13.3 Link Type: TransNet Metric : 1 Network- LSA(2类)Network-LSA（Type2）：由广播网或NBMA网络中的DR产生,Network-LSA中记录了这一网络上所有路由器的RouterID，描述本网段的链路状态，在所属的区域内传播。 字段 长度 含义 Link State ID 32比特 DR的接口IP地址。 Network Mask 32比特 该广播网或NBMA网络地址的掩码。 Attached Router 32比特 连接在同一个网络上的所有路由器的Router ID，也包括DR的Router ID。 12345678910111213141516171819202122[AR2]dis ospf 1 lsdb network self-originate OSPF Process 1 with Router ID 10.0.2.2 Area: 0.0.0.0 Link State Database Area: 0.0.0.1 Link State Database Type : Network Ls id : 10.0.25.2 Adv rtr : 10.0.2.2 Ls age : 925 Len : 32 Options : E seq# : 80000004 chksum : 0xbe43 Net mask : 255.255.255.0 Priority : Low Attached Router 10.0.2.2 Attached Router 10.0.5.5 Summary-LSA（3类）Network-summary-LSA（Type3）：描述区域内所有网段的路由，并通告给其他相关区域。 ASBR-summary-LSA（Type4）：描述到ASBR的路由，通告给除ASBR所在区域的其他相关区域。 Type3和Type4的LSA有相同的格式，它们都是由ABR产生。 字段 长度 含义 Link State ID 32比特 通告的网络地址。如果是ASBR Summary LSA，此字段表示ASBR的Router ID。 Network Mask 32比特 该广播网或NBMA网络地址的掩码。如果是ASBR Summary LSA，此字段无意义，设置为0.0.0.0。 metric 24比特 到目的地址的路由开销。 TOS 8比特 服务类型。 TOS metric 24比特 和指定TOS值相关联的度量。 通告缺省路由时，Link State ID和Network Mask都设置为0.0.0.0。 123456789101112131415161718[AR2]dis ospf 1 lsdb summary self-originate OSPF Process 1 with Router ID 10.0.2.2 Area: 0.0.0.0 Link State Database Type : Sum-Net Ls id : 10.0.15.0 Adv rtr : 10.0.2.2 Ls age : 199 Len : 28 Options : E seq# : 80000005 chksum : 0xda55 Net mask : 255.255.255.0 Tos 0 metric: 2 Priority : Low ASBR-Summary-LSA(4类)ASBR-Summary-LSA（Type4）：描述到ASBR的路由，通告给除ASBR所在区域的其他相关区域。 Type3和Type4的LSA有相同的格式，它们都是由ABR产生。 AS-External-LSA（5类）AS-External-LSA（Type5）：由ASBR产生，描述到AS外部的路由，这是五种LSA中，唯一一种通告到所有区域（除了Stub区域和NSSA区域）的LSA。 字段 长度 含义 Link State ID 32比特 通告的网络地址。 Network Mask 32比特 通告的目的地址的掩码。 E 1比特 外部度量值类型：0：第一类外部路由；1：第二类外部路由。 metric 24比特 到目的地址的路由开销。 Forwarding Address 32比特 到所通告的目的地址的报文将被转发到这个地址。 External Route Tag 32比特 添加到外部路由上的标记。OSPF本身并不使用这个字段，它可以用来对外部路由进行管理。 TOS 8比特 服务类型。 TOS metric 24比特 TOS附加距离信息。 Type5的LSA可以用来通告缺省路由，此时Link State ID和Network Mask都设置为0.0.0.0。 1234567891011121314151617181920&lt;AR3&gt;dis ospf lsdb ase OSPF Process 1 with Router ID 10.0.13.3 Link State Database Type : External Ls id : 192.168.10.0 Adv rtr : 10.0.4.4 Ls age : 766 Len : 36 Options : E seq# : 80000005 chksum : 0x48fe Net mask : 255.255.255.0 TOS 0 Metric: 1 E type : 2 Forwarding Address : 0.0.0.0 Tag : 1 Priority : Low]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>OSPF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSPF学习笔记]]></title>
    <url>%2F2017%2F10%2F19%2FOSPF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[OSPF邻居：Router-ID设置方式：自动选举： 优先选取本地逻辑接口IP地址大的一个。 如果没有逻辑接口，会选择本地活动的物理接口IP地址最大的一个。 手动设置. 哪些条那件会影响OSPF的邻居建立？ hello interval 和 dead interval 不一致。(1)如果只调整hello interval，dead interval也会随着改变。(2)如果只调整dead interval ，hello interval 不会自动改。配置：需要在接口下修改。 网络类型不一致。（主要原因由于timer不一致导致的，比如：一边是broadcast，另一边是非广播。如果一边是带点到点，另一边是广播，是可以建立邻接关系，但收不到路由条目。） 认证不一致。（1.认证类型不一致。2.认证类型一致，密码不同。） 区域ID不一致。 router-ID冲突（直连设备冲突无法建立邻居关系） OSPF版本不一致 不在同一网段。（只在广播，非广播，点到多点网络类型中有问题，因为在这些网络类型中存在源检测机制（源检测：收到报文后需要检测报文发送源和接收接口的地址是否在是否在同一网段），P2P，虚链路中是没有源检测机制的）。 掩码长度不一致。（在广播网和非广播中，如果两端掩码长度不一致，无法建立邻居关系（2类LSA中会携带子网掩码）。而在点到点，点到多点，和虚链路中不检测掩码长度。） silent接口。（被silent的接口不会再发送和接收hello报文。） 区域类型不一致。 ACL（人为原因导致） OSPF报文可靠性机制： 由于OSPF议是通过IP承载的，而IP是不可靠协议，所以OSPF需要自己的可靠机制来保证报文交互的可靠性。 在OSPF中有两种确认报文：1、显式确认报文（LSACK）2、隐式确认报文（hello\DBD\LSU）. 可以建立邻接关系的设备，从2-way状态过渡到exstart，开始发送DBD报文，为了保证DBD交换的可靠性，需要选举主（Master）从(slave)关系。主从关系的选举是通过第一个DBD报文来选举的。第一个DBD报文用来选举主从，不携带任何的LSA摘要信息。从第二个开始携带摘要信息。 DBD报文中的主要内容： seq number 第一个DBD报文的序列号是随机生成的，而后续的序列号会由master端加1做累加。 I（init）：初始位。如果为1代表第一个DBD报文，如果为0，表示非第一个。 M(More)：更多位。如果为1代表后续还有更多的DBD报文，如果为0代表是最后一个DBD报文。 M/S （Master/slave）：主从位。如果为1 代表master，为0代表slave。 MTU：携带报文发送端口的MTU值。 如何选取主从？ 通过比较router—id选举主从，大的一端成为主，小的成为从。 什么情况下两端都是exstart状态？ 从的MTU值小于主的，从不能接收到这的DD报文，主可以接收从的。 什么情况下一端是exstart，另一端是exchange状态？ 从的MTU大于主的，从可以接收主的DD报文，状态从exstart过度到exchange，但是主不能接受从的。 ospf mtu-enable \接口下开启MTU检测，如果不配置，从接口发送的DD报文中的MTU字段填充为0，如果开启则填充该接口的MTU值。如果收到的DBD报文MTU值大于接口的MTU值，则丢弃该报文。 有哪些条件会影响邻接（Adjacency）关系的建立？ MTU 链路状态请求列表或链路重传列表不为空（Loadding） DR优先级为0 OSPF接口状态机：（根据接口网络类型判定） DOWN-&gt;loopback(Loopback网络类型) DOWN-&gt;P2P（点到点，虚链路，点到多点） DOWN-&gt;waitting-&gt; ?(DR,BDR,DRother)（广播，非广播） DR和BDR的概念为什么需要有DR？选举DR的目的是为了避免在广播网和非广播网中LSA的重复通告而带来的带宽浪费问题。 在广播网和非广播网中需选举一个DR和BDR（注：DR必须要有，而BDR只是DR的备份，可以没有），其他的非DR设备叫DRother，DRother需要和DR、BDR建立邻接关系，同时和DR和BDR之间也需要建立邻接关系，而DRother之间只能建立邻接关系。DRother只会讲LSA通告给DR和BDR，后续由DR和BDR通告给其他的DRothter。 DR和BDR的选举比较顺序： 比较优先级，优先级越大越优。默认优先级为1,如果游优先级为0没有选举权。 如果优先级一致，比较router-id，越大越优。 DR和BDR的选举流程： 如果同一网段中的DR和BDR为空，首先选举BDR。将所有优先级大于0的设备放入到候选列表中（优先级为0的不参与选举），比较优先级，优先级越大越优。如果优先级一致，比较router-id，越大越优。BDR选举后，由BDR升级为DR并重新选举BDR。 如果同一网段中已有设备通告自己是BDR，但DR为空，则BDR升级为DR，重新选举BDR。 如果同一网段中已有设备通告自己是DR，但BDR为空，则选举BDR。 如果同一网段中只有唯一的一台设备通告自己为DR或BDR，则通告者为DR或BDR，DR或BDR角色不抢占。 如果在同一网段中存在多台设备同时通告自己为DR或BDR，则DR或者BDR需从新选举。 LSALSA报文关键字段： LS age: 此字段表示LSA已经生存的时间，单位是秒。 默认老化时间为3600s，时间是正向计时。LSA通过间隔时间为1800s。如果LSA在老化时间范围内都没有收到更新，则LSA会从老化并从LSDB中被清除。 序列号范围（0x80000001 - 0x7FFFFFFF）第一个比特位为符号。代表正负。 LS type ：次字段标识了LSA的格式和功能。常用的LSA类型有五种。 Link State ID: 此字段是该LSA所描述的那部分链路的标识。例如Router ID。 Asvertisting Router：此字段是产生此LSA的路由器的Router id。 LS sequece number ：此字段用于检测旧的和重复的LSA。 OSPF中如何判断LSA的新旧？ 比较序列号，序列号越大越新（将接收到的LSA和本地保存的LSA做比较）。 如果序列号一样，比较checksum值，越大越新。 如果checksum值一样，需要看LSA age 时间是否等于Max age。如果等于则为最新。 如果LSA age 不等于 max age，需要执行Maxage diff算法，比较两个LSA age 的时间差，如果时间差大于15分钟，则LSA age越小越新，如果小于15分钟，则认为一样，忽略。 LSA名称 Link state id Router-LSA 生成这条LSA的路由器的Router-id Network-LSA 所描述网段上的DR的端口IP地址 Netword-Summary-LSA 所描述的目的网段地址 ASBR-Summary-LSA 所描述的ASBR的Router-id External LSA 所描述的目的网段的router-id Router-LSA中有三个flag位： V(Virtual link): 置1标识本地配置了vlink，为0标识不存在。 E（ASBR）：置1标识本地是ASBR，为0不是ASBR。 B（ABR）：置1标识本地是ABR，为0不是ABR。 LSA中Link ID和date区域在不同类型中的意思： type link id date P2P 邻居的Router ID 该网段上本地接口的IP地址 TransNet DR接口的IP地址 该网段上本地接口的IP地址 StubNet 该Stub网段的IP地址 该Stub网段的网络掩码 VIrtual 虚连接邻居的Router ID 去往该虚连接邻居的本地接口的IP地址 过滤3类LSA的方式（ABR上操作）： 在ABR上通过filter-policy过滤路由间接影响ABR通过3类LSA。 在ABR上通过在区域下配置filter过滤3类LSA，针对3类LSA的起源区域是出方向，针对3类LSA接收区域是入方向。 在ABR上通过区域下配置汇总不通告3类LSA。 在ABR的接口下这配置ospf fliter-lsa-out summary过滤从该接口通告的3类LSA。 虚链路：虚链路的特点： 虚链路永远属于区域0. 虚链路通过单播的方式发送报文，TTL为255. 虚链路只能配置在普通区域中，不能配置在特殊区域中，同时也不能配置在骨干区域中。 虚链路只能在同一个区域建立，不能跨区域建立。 虚链路属于按需电路，需要将option字段中的DC位置置位（华为除外，华为的虚链路是通过点到点的方式来维护的，而不是按需电路）。 虚链路配置是需要指定邻居的Router-id，通过两次SPF算法确定目标地址和源地址，建立单播连接。 OSPF中的路由类型： O：域内路由 OIA：域间路由 OE/ON：外部路由（外部路由还分两种类型，分别是类型1和类型2） 如果在OSPF中通过不同的路由类型收到同一条路由，O&gt;OIA&gt;OE1&gt;OE2. 虚链路有哪些问题？ 虚链路中不能针对来自区域0的路由条目做汇总。 虚链路会引发环路问题。 RID冲突或者修改RID会造成虚链路不稳定。 虚链路的好处： 可以解决网络设计问题。 可以当做后门链路使用，避免次优路径。 虚链路的应用场景：场景一、骨干区域被分割 （A0—A1—A0） ABR从非骨干区域接收到3类LSA后需要判断在骨干区域中是否存在活动的邻接关系，如果存在，则从非骨干区域接收的3类LSA，只接收不选路。如果不存在，则接收并选路。 注1：从虚链路收到的1类或者3类LSA所生成的3类LSA不会在通告回虚链路的始发区域（虚链路的创建区域），可以理解为虚链路的水平分割 注2：在存在虚链路的ABR上不能对来自于区域0（骨干区域）的路由做汇总。无效）（因为在MPLS VPN中会造成标签不连续问题） 注3：ABR如果从虚链路接收到一条3类LSA，但是在虚链路的始发区域中并不存在这条3类LSA，那么ABR不会针对这条3类做路由计算。（华为不会有路由，而思科会有路由，但是不通） 场景二、通过非骨干区域连接到骨干区域 （A0—A1—A2） 场景三、非骨干区域间互联，没有骨干区域 （A3—A1—A2） 注：（华为可以，思科不可以，思科规定虚链路必须建立在ABR上。） 场景四、充当后门链路使用，避免次优路径 华为中的虚链路引发的环路问题 外部路由外部路由类型： 类型1：计算外部路由度量值，累加到达ASBR或者FA地址的链路cost值。 类型2：计算外部路由度量值，不累加到达ASBR或者FA地址的链路cost值。 注意：如果3类LSA中的FA地址被填充，则只计算到大FA的距离，如果FA地址不可达，则路由无效。 FA（forwarding address）：为了避免次优路径。 在5类LSA中什么情况下会填充FA的地址？ 引入外部路由下一跳的出接口被宣告进OSPF 出接口的网络类型不能是点到点或者点到多点 出接口不能是一个OSPF的silent接口 如果外部路由没有下一跳不会填充FA 注：如果引入外部路由的下一跳不是直连可达地址，需要通过迭代查询找到直连接口的下一跳并填充FA接口。 FA地址如何填充？ 填充为引入外部路由下一跳的地址。 计算FA地址的条件？ 到达FA地址必须是OSPF域内或者域间路由可达。 注： 如果5类LSA中FA地址被填充，计算外部路由只计算到达FA的距离，并且需要保证本地路由表中存在到达FA地址的域内或者域间路由。如果不存在路由条目，该5类LSA不能参与路由计算。 如果5类LSA中没有填充FA地址，计算外部路由只计算到达ASBR的距离。 外部路由选路： 如果都是类型2的外部路由，首先比较外部度量值，外部度量值越小越优，如果外部度量值一样，则比较到大ASBR或者FA的内部度量值，内部度量值越小越有。如果内部度量值一样，负载分担。 如果外部路由类型不同，类型1优先于类型2。不同类型的外部路由不会比较度量值。 注：如果存在多条前缀相同，但掩码长度不同的外部路由，需要通过通告子网的广播地址来区分不同的外部路由。原因是在LSA的头部中不携带子网掩码，如果前缀相同是无法区分路由条目的。 注：如果配置多个进程，外部路由计算需要优选度量值小的，如果度量值一样负载分担。（华为） 路由汇总： 域间路由在区域下汇总。 域外路由在进程下汇总。 注：如果不指定汇总路由的cost值，则继承明细路由的最大COST值。 外部路由过滤（只能在ASBR上过滤）： 重分发的同时使用filter-policy实现外部路由过滤 冲分发的同时调用route-policy实现外部路由过滤 在ASBR上配置汇总不通过 在ASBR的接口下过滤5类LSA OSPF中通告默认路由的方式： 在进程下配置 default-router-advertise 通过默认路由，前提是本地存在一条从其他（不包含从同一个进程的OSPF学到的默认路由）路由协议学的的默认路由。默认路由会以5类LSA进行通过。 在进程下配置deafult-route0advertise always 通过默认路由，不需要本地存在默认，可以直接通告 注：如果自己是默认路由的通告着，同时也从同一个进程的OSPF邻居学到默认路由，那么这条默认路由不选路。 特殊区域Stub区域： 不能包含ASBR。 不接收5类LSA Tollay Stub区域： 不接收3类和5类LSA 不能包含ASBR NSSA区域：（非末节区域，在该区域中可以包含ASBR） 可以包含ASBR NSSA区域中的SABR重分发的外部路由会以7类LSA的方式在NSSA区域泛洪，为了让其他的设备也可以接收到外部路由，会由ABR将7类转换位5类通过。 注：如果在区域中包含多个ABR，通过比较RID，由RID大的ABD进行7转5. 配置nssa区域后ABR会向NSSA区域通告一条默认路由，默认路由以7类LSA的方式通告。 Toallay Stub区域： 配置后ABR会向NSSA区域通告一条3类LSA的默认路由。 NSSA区域中过滤外部路由的方式： 重分发的同时通过route-policy过滤 重分发的同时通过filter-policy过滤 在NSSA区域的ASBR的接口上通过ospf filter-list-out nssa过滤7类 在NSSA区域的SABR上配置汇总不通告。 在NSSA区域的ASBR上重分发路由时配置no-import-route参数，不会生成7类LSA，只有默认的7类LSA路由。 注：在华为中如果ABR设备从NSSA区域中收到一条7类的默认路由，不会做选路同时以不会进行7转5，因为如果选择了NSSA区域的默认路由会造成环路问题。（思科中会） NSSA-LSA的Forwarding Address设置规则如下： 如果Options字段显示此LSA不可以被转换成为五类LSA，则Forwarding Address可以被设置成0.0.0.0； 如果Options字段显示此LSA可以被转换成第五类LSA，则Forwarding Address不能被设置成0.0.0.0； 如果所引入的外部 路由的下一跳在OSPF路由域内，则Forwarding Address直接设置为所引入尾部路由的下一跳； 如果所引入外部路由的下一跳不在OSPF路由域内，则Forwarding Address设置为该ASBR上某个OSPF路由域内的Stub网段（例如Loopback0接口）的接口IP地址，有多个Stub网段时选IP地址最大者。 7类LSA中FA地址的填充规则： 如果将引入外部路由下一跳的出接口宣告进OSPF，则FA地址填充为外部路由下一跳地址，并且该接口的网络类型不能是点到点或者点到多点，同时不能是一个silent接口。 优选宣告进OSPF中逻辑接口IP地址大的一个，如果没有逻辑接口，选择物理接口宣告进OSPF物理接口IP地址大的一个。 如果抑制FA地址可能会出环。配置：nssa no-summary suppress-forwarding-address 配置：zero-address-forwarding //通告7类LSA的时候将FA地址设置0，只有在ABR上配置才会有效果。 注：如果从外部路由可以同时通过OE和ON学到，首先比较外部路由类型，类型1&gt;类型2. 如果类型相同，比较Metric值，metric值越小越优，如果metric值也一样，负载分担（华为的实现）。 OSPF故障排除流程如果邻居关系处于Down状态： 检测物理接口是否正常 检测掩码、认证、区域ID等是否匹配 相应的接口是否在OSPF中宣告 如果邻居关系处于Init状态： 检测本端口和对端设备是否方式故障 如果邻居关系处于2-way状态： 查看接口优先级是否为0 如果邻居关系处于Exstart状态： MTU值是否匹配 如果邻居关系处于Exchange/Loading状态： 查看本端接口和对端设备是否发生故障]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>OSPF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSPF基础内容]]></title>
    <url>%2F2017%2F10%2F19%2FOSPF%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[[TOC] OSPF简介OSPF定义：开放式最短路径优先OSPF（Open Shortest Path First）是IETF组织开发的一个基于链路状态的内部网关协议（Interior Gateway Protocol）。 目前针对IPv4协议使用的是OSPF Version 2（RFC2328）；针对IPv6协议使用OSPF Version 3（RFC2740）。 OSPF目的：在OSPF出现前，网络上广泛使用RIP（Routing Information Protocol）作为内部网关协议。 由于RIP是基于距离矢量算法的路由协议，存在着收敛慢、路由环路、可扩展性差等问题，所以逐渐被OSPF取代。 OSPF作为基于链路状态的协议，能够解决RIP所面临的诸多问题。此外，OSPF还有以下优点： OSPF采用组播形式收发报文，这样可以减少对其它不运行OSPF路由器的影响。 OSPF支持无类型域间选路（CIDR）。 OSPF支持对等价路由进行负载分担。 OSPF支持报文加密。 由于OSPF具有以上优势，使得OSPF作为优秀的内部网关协议被快速接收并广泛使用。 OSPF基础OSPF协议具有以下特点： OSPF把自治系统AS（Autonomous System）划分成逻辑意义上的一个或多个区域； OSPF通过LSA（Link State Advertisement）的形式发布路由； OSPF依靠在OSPF区域内各设备间交互OSPF报文来达到路由信息的统一； OSPF报文封装在IP报文内，可以采用单播或组播的形式发送。 报文类型： 报文类型 报文作用 Hello报文 周期性发送，用来发现和维持OSPF邻居关系。 DD报文（Database Description packet） 描述本地LSDB（Link State Database）的摘要信息，用于两台设备进行数据库同步。 LSR报文（Link State Request packet） 用于向对方请求所需的LSA。设备只有在OSPF邻居双方成功交换DD报文后才会向对方发出LSR报文。 LSU报文（Link State Update packet） 用于向对方发送其所需要的LSA。 LSAck报文（Link State Acknowledgment packet） 用来对收到的LSA进行确认。 LSA类型: LSA类型 LSA作用 Router-LSA（Type1） 每个设备都会产生，描述了设备的链路状态和开销，在所属的区域内传播。 Network-LSA（Type2） 由DR（Designated Router）产生，描述本网段的链路状态，在所属的区域内传播。 Network-summary-LSA（Type3） 由ABR产生，描述区域内某个网段的路由，并通告给发布或接收此LSA的非Totally STUB或NSSA区域。 ASBR-summary-LSA（Type4） 由ABR产生，描述到ASBR的路由，通告给除ASBR所在区域的其他相关区域。 AS-external-LSA（Type5） 由ASBR产生，描述到AS外部的路由，通告到所有的区域（除了STUB区域和NSSA区域）。 NSSA LSA（Type7） 由ASBR产生，描述到AS外部的路由，仅在NSSA区域内传播。 Opaque LSA（Type9/Type10/Type11） Opaque LSA提供用于OSPF的扩展的通用机制。其中：Type9 LSA仅在接口所在网段范围内传播。用于支持GR的Grace LSA就是Type9 LSA的一种。Type10 LSA在区域内传播。用于支持TE的LSA就是Type10 LSA的一种。Type11 LSA在自治域内传播，目前还没有实际应用的例子。 路由器类型： 路由器类型 含义 区域内路由器（Internal Router） 该类设备的所有接口都属于同一个OSPF区域。 区域边界路由器ABR（Area Border Router） 该类设备可以同时属于两个以上的区域，但其中一个必须是骨干区域。ABR用来连接骨干区域和非骨干区域，它与骨干区域之间既可以是物理连接，也可以是逻辑上的连接。 骨干路由器（Backbone Router） 该类设备至少有一个接口属于骨干区域。所有的ABR和位于Area0的内部设备都是骨干路由器。 自治系统边界路由器ASBR（AS Boundary Router） 与其他AS交换路由信息的设备称为ASBR。ASBR并不一定位于AS的边界，它可能是区域内设备，也可能是ABR。只要一台OSPF设备引入了外部路由的信息，它就成为ASBR。 路由类型：AS区域内和区域间路由描述的是AS内部的网络结构，AS外部路由则描述了应该如何选择到AS以外目的地址的路由。OSPF将引入的AS外部路由分为Type1和Type2两类。中按优先级从高到低顺序列出了路由类型。 Intra Area 区域内路由。 Inter Area 区域间路由。 第一类外部路由（Type1 External） 这类路由的可信程度高一些，所以计算出的外部路由的开销与自治系统内部的路由开销是相当的，并且和OSPF自身路由的开销具有可比性。到第一类外部路由的开销=本设备到相应的ASBR的开销+ASBR到该路由目的地址的开销。 第二类外部路由（Type2 External） 这类路由的可信度比较低，所以OSPF协议认为从ASBR到自治系统之外的开销远远大于在自治系统之内到达ASBR的开销。所以，OSPF计算路由开销时只考虑ASBR到自治系统之外的开销，即到第二类外部路由的开销=ASBR到该路由目的地址的开销。 区域类型： 区域类型 作用 普通区域 缺省情况下，OSPF区域被定义为普通区域。普通区域包括标准区域和骨干区域。标准区域是最通用的区域，它传输区域内路由，区域间路由和外部路由。骨干区域是连接所有其他OSPF区域的中央区域。骨干区域通常用Area 0表示。 STUB区域 不允许发布自治系统外部路由，只允许发布区域内路由和区域间的路由。在STUB区域中，路由器的路由表规模和路由信息传递的数量都会大大减少。为了保证到自治系统外的路由可达，由该区域的ABR发布Type3缺省路由传播到区域内，所有到自治系统外部的路由都必须通过ABR才能发布。 Totally STUB区域 不允许发布自治系统外部路由和区域间的路由，只允许发布区域内路由。在Totally STUB区域中，路由器的路由表规模和路由信息传递的数量都会大大减少。为了保证到自治系统外和其他区域的路由可达，由该区域的ABR发布Type3缺省路由传播到区域内，所有到自治系统外部和其他区域的路由都必须通过ABR才能发布。 NSSA区域 NSSA区域允许引入自治系统外部路由，由ASBR发布Type7 LSA通告给本区域，这些Type7 LSA在ABR上转换成Type5 LSA，并且泛洪到整个OSPF域中。NSSA区域同时保留自治系统内的STUB区域的特征。该区域的ABR发布Type7缺省路由传播到区域内，所有域间路由都必须通过ABR才能发布。 Totally NSSA区域 Totally NSSA区域允许引入自治系统外部路由，由ASBR发布Type7 LSA通告给本区域，这些Type7 LSA在ABR上转换成Type5 LSA，并且泛洪到整个OSPF域中。Totally NSSA区域同时保留自治系统内的Totally STUB Area区域的特征。该区域的ABR发布Type3和Type7缺省路由传播到区域内，所有域间路由都必须通过ABR才能发布。 OSPF支持的网络类型： 网络类型 含义 广播类型（Broadcast） 当链路层协议是Ethernet、FDDI时，缺省情况下，OSPF认为网络类型是Broadcast。在该类型的网络中：通常以组播形式发送Hello报文、LSU报文和LSAck报文。其中，224.0.0.5的组播地址为OSPF设备的预留IP组播地址；224.0.0.6的组播地址为OSPF DR/BDR（ Backup Designated Router）的预留IP组播地址。以单播形式发送DD报文和LSR报文。 NBMA类型（Non-Broadcast Multi-Access） 当链路层协议是帧中继、X.25时，缺省情况下，OSPF认为网络类型是NBMA。在该类型的网络中，以单播形式发送协议报文（Hello报文、DD报文、LSR报文、LSU报文、LSAck报文）。 点到多点P2MP类型（Point-to-Multipoint） 没有一种链路层协议会被缺省的认为是Point-to-Multipoint类型。点到多点必须是由其他的网络类型强制更改的。常用做法是将非全连通的NBMA改为点到多点的网络。在该类型的网络中：以组播形式（224.0.0.5）发送Hello报文。以单播形式发送其他协议报文（DD报文、LSR报文、LSU报文、LSAck报文）。 点到点P2P类型（point-to-point） 当链路层协议是PPP、HDLC和LAPB时，缺省情况下，OSPF认为网络类型是P2P。在该类型的网络中，以组播形式（224.0.0.5）发送协议报文（Hello报文、DD报文、LSR报文、LSU报文、LSAck报文）。 Stub区域：STUB区域是一些特定的区域，STUB区域的ABR不传播它们接收到的自治系统外部路由，在这些区域中路由器的路由表规模以及路由信息传递的数量都会大大减少。 STUB区域是一种可选的配置属性，但并不是每个区域都符合配置的条件。通常来说，STUB区域位于自治系统的边界，是那些只有一个ABR的非骨干区域。 为保证到自治系统外的路由依旧可达，该区域的ABR将生成一条缺省路由，并发布给STUB区域中的其他非ABR路由器。 配置STUB区域时需要注意下列几点： 骨干区域不能配置成STUB区域。 如果要将一个区域配置成STUB区域，则该区域中的所有路由器都要配置STUB区域属性。 STUB区域内不能存在ASBR，即自治系统外部的路由不能在本区域内传播。 虚连接不能穿过STUB区域。 NSSA区域：NSSA（Not-So-Stubby Area）区域是OSPF特殊的区域类型。NSSA区域与STUB区域有许多相似的地方，两者都不传播来自OSPF网络其它区域的外部路由。差别在于STUB区域是不能引入外部路由，NSSA区域能够将自治域外部路由引入并传播到整个OSPF自治域中。 当区域配置为NSSA区域后，为保证到自治系统外的路由可达，NSSA区域的ABR将生成一条缺省路由，并发布给NSSA区域中的其他路由器。 配置NSSA区域时需要注意下列几点： 骨干区域不能配置成NSSA区域。 如果要将一个区域配置成NSSA区域，则该区域中的所有路由器都要配置NSSA区域属性。 虚连接不能穿过NSSA区域。 邻居状态机： 邻居关系：OSPF设备启动后，会通过OSPF接口向外发送Hello报文，收到Hello报文的OSPF设备会检查报文中所定义的参数，如果双方一致就会形成邻居关系，两端设备互为邻居。 邻接关系：形成邻居关系后，如果两端设备成功交换DD报文和LSA，才建立邻接关系。 OSPF共有8种状态机，分别是：Down、Attempt、Init、2-way、Exstart、Exchange、Loading、Full。 Down：邻居会话的初始阶段，表明没有在邻居失效时间间隔内收到来自邻居路由器的Hello数据包。 Attempt：该状态仅发生在NBMA网络中，表明对端在邻居失效时间间隔（dead interval）超时前仍然没有回复Hello报文。此时路由器依然每发送轮询Hello报文的时间间隔（poll interval）向对端发送Hello报文。 Init：收到Hello报文后状态为Init。 2-way：收到的Hello报文中包含有自己的Router ID，则状态为2-way；如果不需要形成邻接关系则邻居状态机就停留在此状态，否则进入Exstart状态。 Exstart：开始协商主从关系，并确定DD的序列号，此时状态为Exstart。 Exchange：主从关系协商完毕后开始交换DD报文，此时状态为Exchange。 Loading：DD报文交换完成即Exchange done，此时状态为Loading。 Full：LSR重传列表为空，此时状态为Full。 OSPF报文认证：OSPF支持报文验证功能，只有通过验证的OSPF报文才能接收，否则将不能正常建立邻居。 路由器支持两种验证方式： 区域验证方式 接口验证方式 当两种验证方式都存在时，优先使用接口验证方式。 OSPF路由聚合：路由聚合是指ABR可以将具有相同前缀的路由信息聚合到一起，只发布一条路由到其它区域。 区域间通过路由聚合，可以减少路由信息，从而减小路由表的规模，提高设备的性能。 OSPF有两种路由聚合方式： ABR聚合 ABR向其它区域发送路由信息时，以网段为单位生成Type3 LSA。如果该区域中存在一些连续的网段，则可以通过命令将这些连续的网段聚合成一个网段。这样ABR只发送一条聚合后的LSA，所有属于命令指定的聚合网段范围的LSA将不会再被单独发送出去。 ASBR聚合 配置路由聚合后，如果本地设备是自治系统边界路由器ASBR，将对引入的聚合地址范围内的Type5 LSA进行聚合。当配置了NSSA区域时，还要对引入的聚合地址范围内的Type7 LSA进行聚合。 如果本地设备既是ASBR又是ABR，则对由Type7 LSA转化成的Type5 LSA进行聚合处理。 OSPF缺省路由：缺省路由是指目的地址和掩码都是0的路由。当设备无精确匹配的路由时，就可以通过缺省路由进行报文转发。由于OSPF路由的分级管理，Type3缺省路由的优先级高于Type5或Type7路由。 OSPF缺省路由通常应用于下面两种情况： 由区域边界路由器（ABR）发布Type3缺省Summary LSA，用来指导区域内设备进行区域之间报文的转发。 由自治系统边界路由器（ASBR）发布Type5外部缺省ASE LSA，或者Type7外部缺省NSSA LSA，用来指导自治系统（AS）内设备进行自治系统外报文的转发。 OSPF路由器只有具有对区域外的出口时，才能够发布缺省路由LSA。 如果OSPF路由器已经发布了缺省路由LSA，那么不再学习其它路由器发布的相同类型缺省路由。即路由计算时不再计算其它路由器发布的相同类型的缺省路由LSA，但数据库中存有对应LSA。 外部缺省路由的发布如果要依赖于其它路由，那么被依赖的路由不能是本OSPF路由域内的路由，即不是本进程OSPF学习到的路由。因为外部缺省路由的作用是用于指导报文的域外转发，而本OSPF路由域的路由的下一跳都指向了域内，不能满足指导报文域外转发的要求。 OSPF缺省路由发布原则： 区域类型 作用 普通区域 缺省情况下，普通OSPF区域内的OSPF路由器是不会产生缺省路由的，即使它有缺省路由。当网络中缺省路由通过其他路由进程产生时，路由器必须将缺省路由通告到整个OSPF自治域中。实现方法是在ASBR上手动通过命令进行配置，产生缺省路由。配置完成后，路由器会产生一个缺省ASE LSA（Type5 LSA），并且通告到整个OSPF自治域中。 STUB区域 STUB区域不允许自治系统外部的路由（Type5 LSA）在区域内传播。区域内的路由器必须通过ABR学到自治系统外部的路由。实现方法是ABR会自动产生一条缺省的Summary LSA（Type3 LSA）通告到整个STUB区域内。这样，到达自治系统的外部路由就可以通过ABR到达。 Totally STUB区域 Totally STUB区域既不允许自治系统外部的路由（Type5 LSA）在区域内传播，也不允许区域间路由（Type3 LSA）在区域内传播。区域内的路由器必须通过ABR学到自治系统外部和其他区域的路由。实现方法是配置Totally STUB区域后，ABR会自动产生一条缺省的Summary LSA（Type3 LSA）通告到整个STUB区域内。这样，到达自治系统外部的路由和其他区域间的路由都可以通过ABR到达。 NSSA区域 NSSA区域允许引入通过本区域的ASBR到达的少量外部路由，但不允许其他区域的外部路由ASE LSA（Type5 LSA）在区域内传播。即到达自治系统外部的路由只能通过本区域的ASBR到达。只配置了NSSA区域是不会自动产生缺省路由的。此时，有两种选择：如果希望到达自治系统外部的路由通过该区域的ASBR到达，而其它外部路由通过其它区域出去。此时，ABR会产生一条Type7 LSA的缺省路由，通告到整个NSSA区域内。这样，除了某少部分路由通过NSSA的ASBR到达，其它路由都可以通过NSSA的ABR到达其它区域的ASBR出去。如果希望所有的外部路由只通过本区域NSSA的ASBR到达。则必须在ASBR上手动通过命令进行配置，使ASBR产生一条缺省的NSSA LSA（Type7 LSA），通告到整个NSSA区域内。这样，所有的外部路由就只能通过本区域NSSA的ASBR到达。上面两种情况的区别是：在ABR上无论路由表中是否存在缺省路由0.0.0.0，都会产生Type7 LSA的缺省路由。在ASBR上只有当路由表中存在缺省路由0.0.0.0时，才会产生Type7 LSA的缺省路由。因为缺省路由只是在本NSSA区域内泛洪，并没有泛洪到整个OSPF域中，所以本NSSA区域内的路由器在找不到路由之后可以从该NSSA的ASBR出去，但不能实现其他OSPF域的路由从这个出口出去。Type7 LSA缺省路由不会在ABR上转换成Type5 LSA缺省路由泛洪到整个OSPF域。 Totally NSSA区域 Totally NSSA区域既不允许其他区域的外部路由ASE LSA（Type5 LSA）在区域内传播，也不允许区域间路由（Type3 LSA）在区域内传播。区域内的路由器必须通过ABR学到其他区域的路由。实现方法是配置Totally NSSA区域后，ABR会自动产生一条缺省的Type3 LSA通告到整个NSSA区域内。这样，其他区域的外部路由和区域间路由都可以通过ABR在区域内传播。 OSPF路由过滤：OSPF支持使用路由策略对路由信息进行过滤。缺省情况下，OSPF不进行路由过滤。 OSPF可以使用的路由策略包括route-policy，访问控制列表（access-list），地址前缀列表（prefix-list）。 OSPF路由过滤可以应用于以下几个方面： 路由引入 OSPF可以引入其它路由协议学习到的路由。在引入时可以通过配置路由策略来过滤路由，只引入满足条件的路由。 引入路由发布 OSPF引入了路由后会向其它邻居发布引入的路由信息。 可以通过配置过滤规则来过滤向邻居发布的路由信息。该过滤规则只在ASBR上配置才有效。 路由学习 通过配置过滤规则，可以设置OSPF对接收到的区域内、区域间和自治系统外部的路由进行过滤。 该过滤只作用于路由表项的添加与否，即只有通过过滤的路由才被添加到本地路由表中，但所有的路由仍可以在OSPF路由表中被发布出去。 区域间LSA学习 通过命令可以在ABR上配置对进入本区域的Summary LSA进行过滤。该配置只在ABR上有效（只有ABR才能发布Summary LSA）。 区域间LSA学习与路由学习的差异： 区域间LSA学习 路由学习 直接对进入区域的LSA进行过滤。 路由学习中的过滤不对LSA进行过滤，只针对LSA计算出来的路由是否添加本地路由表进行过滤。学习到的LSA是完整的。 区域间LSA发布 通过命令可以在ABR上配置对本区域出方向的Summary LSA进行过滤。该配置只在ABR上配置有效。 OSPF多进程：OSPF支持多进程，在同一台路由器上可以运行多个不同的OSPF进程，它们之间互不影响，彼此独立。不同OSPF进程之间的路由交互相当于不同路由协议之间的路由交互。 路由器的一个接口只能属于某一个OSPF进程。 OSPF多进程的一个典型应用就是在VPN场景中PE和CE之间运行OSPF协议，同时VPN骨干网上的IGP也采用OSPF。在PE上，这两个OSPF进程互不影响。 OSPF Smart-discover定义：通常情况下，路由器会周期性地从运行OSPF协议的接口上发送Hello报文。这个周期被称为Hello Interval，通过一个Dead Timer定时器控制Hello报文的发送。这种按固定周期发送报文的方式减缓了OSPF邻居关系的建立。 通过使能Smart-discover特性，可以在特定场景下加快OSPF邻居的建立。 接口是否配置Smart-discover 处理方式 接口没有配置Smart-discover 必须等待Hello Timer到时才能发送Hello报文；两次报文发送间隔为Hello Interval；在这期间邻居一直在等待接收报文。 接口上配置Smart-discover 直接发送Hello报文，不需要等待Hello Timer超时；邻居可以很快收到报文迅速进行状态迁移。 原理：在以下场景中，使能了Smart-discover特性的接口不需要等待Hello Timer到时，可以主动向邻居发送Hello报文： 当邻居状态首次到达2-way状态。 当邻居状态从2-way或更高状态迁移到Init状态。 OSPF NSSA定义：OSPF规定STUB区域是不能引入外部路由的，这样可以避免大量外部路由对STUB区域路由器带宽和存储资源的消耗。对于既需要引入外部路由又要避免外部路由带来的资源消耗的场景，STUB区域就不再满足需求了。因此产生了NSSA区域。 OSPF NSSA区域（Not-So-Stubby Area）是OSPF新增的一类特殊的区域类型。 NSSA区域和STUB区域有许多相似的地方。两者的差别在于，NSSA区域能够将自治域外部路由引入并传播到整个OSPF自治域中，同时又不会学习来自OSPF网络其它区域的外部路由。 N-bit：一个区域内所有路由器上配置的区域类型必须保持一致。OSPF在Hello报文中使用N-bit来标识路由器支持的区域类型，区域类型选择不一致的路由器不能建立OSPF邻居关系。 虽然协议有要求，但有些厂商实现时违背了，在OSPF DD报文中也置位了N-bit，为了和这些厂商互通，路由器的实现方式是可以通过命令设置N-bit来兼容。 7类LSA： Type7 LSA是为了支持NSSA区域而新增的一种LSA类型，用于描述引入的外部路由信息。 Type7 LSA由NSSA区域的自治域边界路由器（ASBR）产生，其扩散范围仅限于ASBR所在的NSSA区域。 NSSA区域的区域边界路由器（ABR）收到Type7 LSA时，会有选择地将其转化为Type5 LSA，以便将外部路由信息通告到OSPF网络的其它区域。 Type7 LSA转化为Type5 LSA为了将NSSA区域引入的外部路由发布到其它区域，需要把Type7 LSA转化为Type5 LSA以便在整个OSPF网络中通告。 P-bit（Propagate bit）用于告知转化路由器该条Type7 LSA是否需要转化。 缺省情况下，转换路由器的是NSSA区域中Router ID最大的区域边界路由器（ABR）。 只有P-bit置位并且FA（Forwarding Address）不为0的Type7 LSA才能转化为Type5 LSA。FA用来表示发送的某个目的地址的报文将被转发到FA所指定的地址。 区域边界路由器产生的Type7 LSA不会置位P-bit。 缺省路由环路预防:在NSSA区域中，可能同时存在多个ABR，为了防止路由环路产生，边界路由器之间不计算对方发布的缺省路由。 OSPF快速收敛：OSPF快速收敛是为了提高路由的收敛速度而做的扩展特性。包括： OSPF按优先级收敛： OSPF按优先级收敛是指在大量路由情况下，能够让某些特定的路由优先收敛的一种技术。通过对不同的路由配置不同的收敛优先级，达到重要的路由先收敛的目的，提高网络的可靠性。 OSPF按优先级收敛能够让某些特定的路由优先收敛，因此用户可以把和关键业务相关的路由配置成相对较高的优先级，使这些路由更快的收敛，从而使关键的业务受到的影响减小。 PRC（Partial Route Calculation）部分路由计算：当网络上路由发生变化的时候，只对发生变化的路由进行重新计算。 通过智能定时器控制LSA的生成与接收，达到对低频变化快速响应，又能对高频变化起到有效抑制的目的。 在标准RFC2328协议中，通过如下两个规定来避免网络连接或者路由频繁动荡引起的过多占用设备资源的情况。 同一条LSA在1秒内不能再次生成，即LSA的更新时间间隔5秒。 LSA被接收的时间间隔为1秒。 在网络相对稳定、对路由收敛时间要求较高的组网环境中，可以通过智能定时器指定LSA的更新、被接收的时间间隔为0，使得拓扑或者路由的变化可以通过LSA发布到网络中，或者立即被感知到，从而加快路由的收敛。 通过智能定时器控制路由计算： 当网络发生变化时，OSPF需要重新进行路由计算，为避免这种频繁的网络变化对设备造成的冲击，标准RFC2328规定路由计算时要使用延迟定时器，定时器超时后才进行路由计算。但标准协议中，该定时器定时间隔固定，无法做到既能快速响应又能抑制振荡。 通过智能定时器来控制路由计算的延迟时间，达到对低频率变化快速响应，又能对高频率变化起到有效抑制的目的。 OSPF Smart-discover OSPF Datebase Overflow（数据库超限）定义：OSPF协议要求同一个区域中的路由器保存相同的链路状态数据库LSDB（Link-State Database）。 随着网络上路由数量不断增加，一些路由器由于系统资源有限，不能再承载如此多的路由信息，这种状态就被称为数据库超限（OSPF Database Overflow）。 目的：对于路由信息不断增加导致路由器系统资源耗尽而失效的问题，可以通过配置Stub或NSSA区域来解决，但Stub或NSSA区域的方案不能解决动态路由增长导致的数据库超限问题。为了解决数据库超限引发的问题，通过设置LSDB中ExternalLSA的最大条目数，可以动态限制链路数据库的规模。 原理：通过设置路由器上非缺省外部路由数量的上限，来避免数据库超限。 OSPF网络中所有路由器都必须配置相同的上限值。这样，只要路由器上外部路由的数量达到该上限，路由器就进入Overflow状态，并同时启动超限状态定时器（默认超时时间为5秒），路由器在定时器超过5秒后自动退出超限状态。 Overflow状态阶段 OSPF处理流程 进入Overflow状态时 路由器删除所有自己产生的非缺省外部路由。 处于Overflow状态中 不产生非缺省外部路由。丢弃新收到的非缺省外部路由，不回复确认报文。当超限状态定时器超时，检查外部路由数量是否仍然超过上限。N=&gt;退出超限状态。Y=&gt;重启定时器。 退出Overflow状态时 删除超限状态定时器。产生非缺省外部路由。接收新收到的非缺省外部路由，回复确认报文。准备下一次进入超限状态。 OSPF Mesh-Group（网组）定义：OSPF Mesh-Group（网组）是将并行链路场景中的链路分组，从而洪泛时从群组中选取代表链路进行洪泛，避免重复洪泛而造成不必要的系统压力。缺省情况下，不使能Mesh-Group功能。 目的：当OSPF进程收到一个LSA或者新产生一个LSA时，会进行洪泛操作。并行链路场景下，OSPF会对每一条链路洪泛LSA，发送Update报文。 这样，如果有2000条并行链路，则每个LSA洪泛都要发送2000次，然而只有一次洪泛是有效的，其他1999次洪泛为重复洪泛。 为了避免这种重复洪泛而造成的系统压力，使能Mesh Group特性，可以将并行链路进行归组，选取代表链路进行洪泛。 原理：如图一所示，RouterA和RouterB建立OSPF邻居关系，通过3条链路相连。当RouterA从接口4接收到新的LSA后，会将该LSA通过1、2、3接口洪泛到RouterB。 这种洪泛方式会造成并行链路的压力，因为对于存在多条并行链路的邻居来说，只需要选取一条主链路进行洪泛LSA即可。 图1 没有使能OSPF Mesh-Group特性时LSA的洪泛情况 使能了OSPF Mesh-Group特性的设备和邻居存在多条并行链路时，当其收到LSA后，会选取一条主链路进行泛洪，如图2所示。 当主链路上接口状态低于Exchange时，OSPF会在并行链路中重新选取主链路，并继续洪泛LSA，这是因为，OSPF规定，只有当邻居状态达到Exchange时，才能洪泛LSA。并且，当RouterB从链路1收到来自RouterA洪泛的LSA后，不会再将该LSA从链路2、3反向洪泛给RouterA。 图2 使能OSPF Mesh-Group特性时LSA的洪泛情况 Mesh-Group以邻居的Router ID唯一标识一个群组，接口状态大于Exchange且与同一个邻居相连的接口属于同一个Mesh-Group。 如图3所示，RouterA在区域0中有一个群组，分别是接口1和接口2所在的链路。由于接口3所在的链路为广播链路，有超过一个邻居，所以不能加入到群组中。 图3 接口不能加入到群组中的情况 说明： 另外，路由器使能Mesh-Group后，若其直连的邻居路由器Router ID配置重复，会引起全网LSDB不同步、路由计算不正确的情况，需要重新配置邻居路由器的Router ID（注：配置重复Router ID属于错误配置）。 OSPF邻居震荡抑制OSPF邻居震荡抑制功能是一种震荡抑制方式，通过延迟邻居建立或调整链路开销为最大值的方法达到抑制震荡的目的。 产生原因如果承载OSPF业务的接口状态在Up和Down之间切换，就会引起邻居状态的频繁震荡。此时，OSPF会快速发送Hello报文重新建立邻居，同步数据库LSDB，触发路由计算，会造成大量报文交互，影响现有邻居的稳定性，对OSPF业务造成较大影响，同时也会影响依赖OSPF的其他业务（如：LDP、BGP）的正常运行。为了解决这个问题，OSPF实现了邻居震荡抑制功能，即在邻居频繁震荡时，启动震荡抑制，实现邻居延迟建立，或实现业务流量延迟经过频繁震荡的链路，达到抑制震荡的目的。 相关概念 flapping_event：震荡事件，接口上最后一个邻居状态由Full切换为非Full，称之为flapping_event。flapping_event作为震荡源输入，用来触发震荡检测机制启动工作。 flapping_count：当前震荡次数。 detect-interval：震荡检测门限，用于判断是否触发一次有效震荡事件。 threshold：震荡抑制门限，有效震荡事件触发累计大于等于该值时，进入震荡抑制阶段。 resume-interval：震荡检测恢复门限，连续两次有效震荡事件的时间间隔大于该值时，flapping-count清0。 实现原理震荡检测 OSPF接口启动一个flapping_count计数器，相邻两次flapping_event产生时间的间隔在detect-interval之内，记为一次有效震荡事件。flapping_count计数加1，当flapping_count计数大于threshold时，系统判定震荡发生，需要进入震荡抑制阶段。进入震荡抑制阶段后，flapping_count清0。在flapping_count大于threshold之前，如果两次flapping_event的间隔大于resume-interval，则flapping_count清0。邻居震荡抑制从最后一次邻居状态变为ExStart或Down开始计时。 用户可以通过命令行配置detect-interval，threshold，resume-interval三个震荡检测的关键参数。 震荡抑制 震荡抑制分为Hold-down和Hold-max-cost两种模式： Hold-down模式：针对邻居建立过程中的频繁泛洪和拓扑变化的问题，在一段时间内禁止该邻居重新建立，避免频繁的数据库同步和大量的报文交互。 Hold-max-cost模式：针对用户业务流量频繁切换的问题，在一段时间内将链路开销值设置为最大值Max-cost（65535），避免用户的业务流量经过频繁震荡的链路。 Hold-down模式和Hold-max-cost模式可以叠加使用，同时生效时，先进入Hold-down模式，待Hold-down模式退出后，再进入Hold-max-cost模式。 缺省情况下，OSPF使能Hold-max-cost模式，用户可以通过命令行修改震荡抑制方案和震荡抑制周期。 说明： 接口进入震荡抑制阶段后，接口下的全部邻居都会进入震荡抑制阶段。 退出震荡抑制 退出震荡抑制有以下几种方式： 抑制定时器超时。 复位OSPF进程。 用户通过命令行强制退出震荡抑制状态。]]></content>
      <categories>
        <category>路由交换</category>
      </categories>
      <tags>
        <tag>路由基础</tag>
        <tag>OSPF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串的基本操作]]></title>
    <url>%2F2017%2F10%2F16%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[串的定义：字符串或串(String)是由数字、字母、下划线组成的一串字符。一般记为 s=“a1a2···an”(n&gt;=0)。它是编程语言中表示文本的数据类型。在程序设计中，字符串（string）为符号或数值的一个连续序列，如符号串（一串字符）或二进制数字串（一串二进制数字）。 通常以串的整体作为操作对象，如：在串中查找某个子串、求取一个子串、在串的某个位置上插入一个子串以及删除一个子串等。两个字符串相等的充要条件是：长度相等，并且各个对应位置上的字符都相等。设p、q是两个串，求q在p中首次出现的位置的运算叫做模式匹配。串的两种最基本的存储方式是顺序存储方式和链接存储方式。 字符串的基本操作的实现： 对于字符串来说使用顺序存储方式比使用链式存储方式节约空间，且很容易实现，所有下面的代码实现的是字符串的顺序存方式。 注意：规定在串值后面加一个不计入串长度的结束标记字符，比如“\0”来表示串值终结。如果不加“\0”,输出时可能会出现乱码！ base.h1234567891011121314151617//base.h//-----公用的常量和类型----------#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt;using namespace std;#include&lt;malloc.h&gt;#include&lt;string.h&gt;//函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define OVERFLOW -2typedef int Status; String.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194//string.h//字符串的基本操作//---------串的堆分配存储表示----------typedef struct&#123; char *ch; //若是非空串，则按串长分配空间，否则ch为NULL int length; //串的长度&#125;String;//--------串基本操作的函数原型说明--------//生成一个其值等于chars的串Status StrAssign(String &amp;T, char *chars)&#123; if(T.ch) free(T.ch); int i; for(i = 0; *(chars+i); ++i)&#123;&#125; if(!i)&#123; cout&lt;&lt;"空字符！"&lt;&lt;endl; T.ch = NULL; T.length = 0; &#125;else&#123; if(!(T.ch = (char *)malloc(i * sizeof(char)))) exit(OVERFLOW); int j; for(j = 0; j &lt; i; j++)&#123; T.ch[j] = chars[j]; T.length = i; &#125; T.ch[T.length] = '\0'; &#125; return OK;&#125;//StrAssign//返回串内元素个数，串长度int StrLength(String S)&#123; return S.length;&#125;//StrLength//字符串比较，若S&gt;T,则返回&gt;0;若S=T，则返回=0；若S&lt;T，则返回&lt;0;int StrCompare(String S, String T)&#123; int i; for(i = 0; i &lt; S.length &amp;&amp; i &lt; T.length; ++i) if(S.ch[i] != T.ch[i]) return S.ch[i] - T.ch[i]; return S.length - T.length;&#125;//将串S清空Status ClearString(String &amp;S)&#123; if(S.ch)&#123; free(S.ch); S.ch = NULL; &#125; S.length = 0; return OK;&#125;//ClearString//用T返回由S1和S2连接而成的新串Status Concat(String &amp;T, String S1, String S2)&#123; if(T.ch) free(T.ch); //释放旧空间 if(!(T.ch = (char*)malloc((S1.length + S2.length) * sizeof(char)))) exit(OVERFLOW); int i; for(i = 0; i &lt; S1.length; i++) T.ch[i] = S1.ch[i]; T.length = S1.length + S2.length; int j; for( i = 0, j = S1.length; j &lt; T.length; j++, i++) T.ch[j] = S2.ch[i]; T.ch[T.length] = '\0'; return OK;&#125;//Concat//初始条件：串S存在，1&lt;=pos&lt;=StrLength(S) 且 0&lt;=len&lt;=StrLength(S)-pos+1//用Sub返回串S的第pos个字符起长度为len的子串Status SubString(String &amp;Sub, String S, int pos, int len)&#123; if(pos &lt; 1 || pos &gt; S.length || len &lt; 0 || len &gt; S.length - pos + 1) return ERROR; if(Sub.ch) free(Sub.ch); if(!len)&#123; cout&lt;&lt;"Sub不存在！"&lt;&lt;endl; Sub.ch = NULL; Sub.length = 0; &#125;else&#123; Sub.ch = (char *)malloc(len * sizeof(char)); int i; for(i = 0; i &lt; len; i++)&#123; Sub.ch[i] = S.ch [pos + i - 1]; Sub.length = len; &#125; S.ch[S.length] = '\0'; return OK; &#125; return OK;&#125;//SubSting//判空Status StrEmpty(String S)&#123; if(S.length == 0) return TRUE; else return FALSE;&#125;//StrEmpty//串复制Status StrCopy(String &amp;T, String S)&#123; if(!(T.ch = (char*)malloc(S.length * sizeof(char)))) exit(OVERFLOW); T.ch = S.ch; T.length = S.length; return OK;&#125;//StrCopy//若主串S中存在和串T相同的子串，则返回它在主串中的//第pos个字符之后的第一次出现的位置，否则函数值为0Status Index(String S, String T, int pos)&#123; if(pos &gt;= 0)&#123; String Sub; int n, m; n = StrLength(S); m = StrLength(T); int i = pos; while(i &lt;= (n-m+1))&#123; SubString(Sub, S, i, m); if(StrCompare(Sub, T) != 0) ++i; else return i; &#125;//while &#125;//if return 0;&#125;//Index//初始条件：串S存在，1&lt;=pos&lt;=StrLength(S)+1//操作结果：在串S的第pos个字符之前插入串TStatus StrInsert(String &amp;S, int pos, String T)&#123; if(pos &lt; 1 || pos &gt; S.length + 1) //pos不合法 return ERROR; if(T.length)&#123; //T非空，则重新分配空间，插入T if(!(S.ch = (char *)realloc(S.ch,(S.length + T.length) * sizeof(char)))) exit(OVERFLOW); int i; for(i = S.length-1; i &gt;= pos-1; --i) //为插入T而腾出位置 S.ch[i+T.length] = S.ch[i]; for(i = 0; i &lt; T.length; i++) //插入T S.ch[pos+i] = T.ch[i]; S.length += T.length; S.ch[S.length] = '\0'; &#125; return OK;&#125;//StrInsert//初始条件：串S存在，1&lt;=pos&lt;=StrLength(S)-len+1//操作结果：从串S中删除第pos个字符起长度为len的子串Status StrDelete(String &amp;S, int pos, int len)&#123; if(pos &lt; 1 || pos &gt; (StrLength(S)-len+1)) //pos不合法 return ERROR; if(S.length)&#123; //T非空，则重新分配空间，插入T int i; for(i=pos-1; i &lt; (StrLength(S)-len+1); i++) S.ch[i] = S.ch[len+i]; S.length -= len; S.ch[S.length] = '\0'; &#125; return OK;&#125;//StrInsert//初始条件：串S,T,V存在，T是非空串//操作结果：用V替换主串S中出现的所有与T相等的不重叠的子串Status Replace(String &amp;S, String T, String V)&#123; int i; for(i = 0; i &lt; (StrLength(S)-StrLength(T)); i++)&#123; int j = Index(S, T , 0); if(j)&#123; StrDelete(S, j, StrLength(T)); StrInsert(S, j-1, V); &#125; &#125; return OK;&#125;//Replace//销毁串Status DestroyString(String &amp;S)&#123; if(!S.ch) cout&lt;&lt;"字符串不存在，不需要销毁！"&lt;&lt;endl; else&#123; free(S.ch); S.ch = NULL; S.length = 0; cout&lt;&lt;"字符串销毁成功！"&lt;&lt;endl; &#125; return OK;&#125;//DestroyString main.cpp12345678910111213141516171819202122232425262728293031323334353637383940414243444546//用来测试基本操作#include "base.h"#include "string.h"int main()&#123; String S1,S2, T, Sub; char str1[] = &#123;"aaa"&#125;; char str2[] = &#123;"bbb"&#125;; StrAssign(S1, str1); //生成字符串 StrAssign(S2, str2); cout&lt;&lt;"字符串S1为："&lt;&lt;S1.ch&lt;&lt;endl;//输出字符串 cout&lt;&lt;"字符串S2为："&lt;&lt;S2.ch&lt;&lt;endl; Concat(T, S1, S2); cout&lt;&lt;"S1和S2连接合并成字符串T为："&lt;&lt;T.ch&lt;&lt;endl; cout&lt;&lt;"T字符串的长度为："&lt;&lt;StrLength(T)&lt;&lt;endl; cout&lt;&lt;"字符串S1与S2比较："; if(StrCompare(S1, S2) &lt; 0) cout&lt;&lt;"S1 &lt; S2"&lt;&lt;endl; else if(StrCompare(S1, S2) == 0) cout&lt;&lt;"S1 = S2"&lt;&lt;endl; else cout&lt;&lt;"S1 &gt; S2"&lt;&lt;endl; SubString(Sub, T, 2, 3); cout&lt;&lt;"取T的第二个字符开始长度为3的字符串Sub为："&lt;&lt;Sub.ch&lt;&lt;endl; if(StrEmpty(Sub)) cout&lt;&lt;"Sub字符串为空！"&lt;&lt;endl; else cout&lt;&lt;"Sub字符串不为空！"&lt;&lt;endl; StrCopy(Sub, T); cout&lt;&lt;"复制T字符串给Sub："&lt;&lt;Sub.ch&lt;&lt;endl; StrInsert(Sub, 3, S2); cout&lt;&lt;"在第4位之前插入字符串S2："&lt;&lt;Sub.ch&lt;&lt;endl; cout&lt;&lt;"Sub字符串的长度为："&lt;&lt;StrLength(Sub)&lt;&lt;endl; StrDelete(Sub, 4 , 3); cout&lt;&lt;"删除从第4个字符起的3位字符："&lt;&lt;Sub.ch&lt;&lt;endl; cout&lt;&lt;"Sub字符串的长度为："&lt;&lt;StrLength(Sub)&lt;&lt;endl; StrInsert(Sub, 3, S2); cout&lt;&lt;"在第4位之前插入字符串S2："&lt;&lt;Sub.ch&lt;&lt;endl; cout&lt;&lt;"Sub字符串的长度为："&lt;&lt;StrLength(Sub)&lt;&lt;endl; Replace(Sub, S2, S1); cout&lt;&lt;"将字符串Sub中所有与S2相等的子串替换为S1："&lt;&lt;Sub.ch&lt;&lt;endl; cout&lt;&lt;"返回Sub字符串中S2第一次出现时的位置："&lt;&lt;Index(Sub, S2, 0)&lt;&lt;endl; DestroyString(Sub); return 0;&#125; 字符串操作测试结果： 图：字符串操作测试结果]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[队列]]></title>
    <url>%2F2017%2F10%2F03%2F%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[队列的基本概念：队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。队列中没有元素时，称为空队列。 队列的数据元素又称为队列元素。在队列中插入一个队列元素称为入队，从队列中删除一个队列元素称为出队。因为队列只允许在一端插入，在另一端删除，所以只有最早进入队列的元素才能最先从队列中删除，故队列又称为先进先出（FIFO—first in first out）线性表。 链队列： 用链表表示的队列简称为链队列。 链队列的表示与实现：queue.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112//queue.h//单链队列的表示与实现//------------队列的链式存储结构----------------typedef struct QNode&#123; QElemType date; struct QNode *next;&#125;QNode, *QueuePtr;typedef struct &#123; QueuePtr front; //队列指针 QueuePtr rear; //队尾指针 int len;&#125;LinkQueue;//-----------基本操作的函数原型说明---------------//构造一个空队列QStatus InitQueue(LinkQueue &amp;Q)&#123; Q.front = Q.rear = (QueuePtr)malloc(sizeof(QNode)); if(!Q.front) exit(OVERFLOW); Q.front-&gt;next = NULL; Q.len = 0; return OK;&#125;//InitQueue//销毁队列QStatus DestoryQueue(LinkQueue &amp;Q)&#123; while(Q.front)&#123; Q.rear = Q.front-&gt;next; free(Q.front); Q.front = Q.rear; &#125; cout&lt;&lt;"队列销毁成功！"&lt;&lt;endl; return OK;&#125;//DestoryQueue//清空队列QStatus ClearQueue(LinkQueue &amp;Q)&#123; Q.front = Q.rear; Q.front-&gt;next = NULL; return OK;&#125;//ClearQueue//判空Status QueueEmpty(LinkQueue Q)&#123; if(Q.front == Q.rear)&#123; return TRUE; &#125;else&#123; return FALSE; &#125;&#125;//QueueEmpty//返回Q的元素的个数int QueueLength(LinkQueue Q)&#123; return Q.len;&#125;//QueueLength//若队列不为空，用e返回队列的头元素，并返回OK，否则返回ERRORStatus GetHead(LinkQueue Q, QElemType &amp;e)&#123; if(!QueueEmpty(Q))&#123; e = Q.front-&gt;next-&gt;date; return OK; &#125;else&#123; return ERROR; &#125;&#125;//GetHead//插入元素e为Q的新的队尾元素Status EnQueue(LinkQueue &amp;Q, QElemType e)&#123; QueuePtr p = (QueuePtr)malloc(sizeof(QNode)); if(!p) exit(OVERFLOW); p-&gt;date = e; p-&gt;next = NULL; Q.rear-&gt;next = p; Q.rear = p; Q.len++; return OK;&#125;//EnQueue//若队列不为空，则删除Q的队头元素，用e返回其值//并返回OK，否则返回ERRORStatus DeQueue(LinkQueue &amp;Q, QElemType &amp;e)&#123; if(Q.front == Q.rear) return ERROR; QueuePtr p = Q.front-&gt;next; e = p-&gt;date; Q.front-&gt;next = p-&gt;next; if(Q.rear == p) Q.rear = Q.front; free(p); Q.len--; return OK;&#125;//DeQueue//队列的遍历Status QueueTraverse(LinkQueue Q)&#123; if(!QueueEmpty(Q))&#123; QueuePtr p = Q.front-&gt;next; while(p)&#123; cout&lt;&lt;p-&gt;date&lt;&lt;" "; p = p-&gt;next; &#125; cout&lt;&lt;endl; &#125;else&#123; cout&lt;&lt;"这个队列没有元素！"&lt;&lt;endl; &#125;&#125;//QueueTraverse baes.h123456789101112131415161718//base.h//-----公用的常量和类型----------#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt;using namespace std;#include&lt;malloc.h&gt;#include&lt;string.h&gt;//函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define OVERFLOW -2typedef int Status;typedef int QElemType; text.cpp12345678910111213141516171819202122232425262728293031323334353637//text.cpp//测试队列基本操作#include "base.h"#include "queue.h"int main()&#123; LinkQueue Q; QElemType e; InitQueue(Q); cout&lt;&lt;"队列遍历："; QueueTraverse(Q); for(e = 0; e &lt; 10; e++)&#123; EnQueue(Q, e); &#125; cout&lt;&lt;"队列遍历："; QueueTraverse(Q); cout&lt;&lt;"队列内元素个数为："&lt;&lt;QueueLength(Q)&lt;&lt;endl; DeQueue(Q, e); cout&lt;&lt;"删除的队列元素为："&lt;&lt;e&lt;&lt;endl; cout&lt;&lt;"删除元素后队列的遍历："; QueueTraverse(Q); EnQueue(Q, 15); cout&lt;&lt;"插入15后队列的遍历："; QueueTraverse(Q); GetHead(Q, e); cout&lt;&lt;"获得队列的对头元素："&lt;&lt;e&lt;&lt;endl; if(QueueEmpty(Q)) cout&lt;&lt;"判空：队列为空！"&lt;&lt;endl; else cout&lt;&lt;"判空：队列不为空！"&lt;&lt;endl; ClearQueue(Q); cout&lt;&lt;"请空队列后的遍历："; QueueTraverse(Q); DestoryQueue(Q); return OK;&#125; 链队列程序测试结果： 图：链队列测试结果 循环队列： 循环队列使用顺序表的存储结构。 循环队列的代码实现：sqQueu.h1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495//sqQueue.h//循环队列的基本操作//-----循环队列---队列的顺序存储结构------#define MAXQSIZE 100 //最大队列长度typedef struct&#123; QElemType *base; //初始化的动态分配存储空间 int front; //头指针，若队列不空，指向队列对头元素 int rear; //尾指针，若队列不空，指向队列队尾的下一个元素&#125;SqQueue;//------循环队列的基本操作的算法描述-------//构造一个空队列QStatus InitQueue_Sq(SqQueue &amp;Q)&#123; Q.base = (QElemType *)malloc(MAXQSIZE * sizeof(QElemType)); if(!Q.base) exit(OVERFLOW); Q.front = Q.rear = 0; return OK;&#125;//InitQueue_Sq//销毁队列QStatus DestoryQueue_Sq(SqQueue &amp;Q)&#123; free(Q.base); Q.front = Q.rear = 0; cout&lt;&lt;"队列销毁成功！"&lt;&lt;endl; return OK;&#125;//DestoryQueue_Sq//清空队列QStatus ClearQueue_Sq(SqQueue &amp;Q)&#123; Q.front = Q.rear = 0; return OK;&#125;//ClearQueue_Sq//判空Status QueueEmpty_Sq(SqQueue Q)&#123; if(Q.front == Q.rear)&#123; return TRUE; &#125;else&#123; return FALSE; &#125;&#125;//QueueEmpty_Sq//返回Q的元素的个数int QueueLength_Sq(SqQueue Q)&#123; return (Q.rear - Q.front + MAXQSIZE) % MAXQSIZE;&#125;//QueueLength_Sq//若队列不为空，用e返回队列的头元素，并返回OK，否则返回ERRORStatus GetHead_Sq(SqQueue Q, QElemType &amp;e)&#123; if(!QueueEmpty_Sq(Q))&#123; e = Q.base[Q.front]; return OK; &#125;else&#123; return ERROR; &#125;&#125;//GetHead_Sq//插入元素e为Q的新的队尾元素Status EnQueue_Sq(SqQueue &amp;Q, QElemType e)&#123; if((Q.rear + 1) % MAXQSIZE == Q.front) return ERROR; //队列满 Q.base[Q.rear] = e; Q.rear = (Q.rear + 1) % MAXQSIZE; return OK;&#125;//EnQueue_Sq//若队列不为空，则删除Q的队头元素，用e返回其值//并返回OK，否则返回ERRORStatus DeQueue_Sq(SqQueue &amp;Q, QElemType &amp;e)&#123; if(Q.front == Q.rear) return ERROR; //队列空 e = Q.base[Q.front]; Q.front = (Q.front + 1) % MAXQSIZE; return OK;&#125;//DeQueue_Sq//队列的遍历Status QueueTraverse_Sq(SqQueue Q)&#123; if(!QueueEmpty_Sq(Q))&#123; int p = Q.front; while((p % MAXQSIZE) != Q.rear)&#123; cout&lt;&lt;Q.base[p++]&lt;&lt;" "; &#125; cout&lt;&lt;endl; return OK; &#125;else&#123; cout&lt;&lt;"这个队列没有元素！"&lt;&lt;endl; return ERROR; &#125;&#125;//QueueTraverse_Sq ####text.cpp 12345678910111213141516171819202122232425262728293031323334353637//text.cpp//测试队列基本操作#include "base.h"#include "sqQueue.h"int main()&#123; QElemType e; SqQueue SQ; InitQueue_Sq(SQ); cout&lt;&lt;"队列遍历："; QueueTraverse_Sq(SQ); for(e = 0; e &lt; 10; e++)&#123; EnQueue_Sq(SQ, e); &#125; cout&lt;&lt;"队列遍历："; QueueTraverse_Sq(SQ); cout&lt;&lt;"队列内元素个数为："&lt;&lt;QueueLength_Sq(SQ)&lt;&lt;endl; DeQueue_Sq(SQ, e); cout&lt;&lt;"删除的队列元素为："&lt;&lt;e&lt;&lt;endl; cout&lt;&lt;"删除元素后队列的遍历："; QueueTraverse_Sq(SQ); EnQueue_Sq(SQ, 13); cout&lt;&lt;"插入13后队列的遍历："; QueueTraverse_Sq(SQ); GetHead_Sq(SQ, e); cout&lt;&lt;"获得队列的对头元素："&lt;&lt;e&lt;&lt;endl; if(QueueEmpty_Sq(SQ)) cout&lt;&lt;"判空：队列为空！"&lt;&lt;endl; else cout&lt;&lt;"判空：队列不为空！"&lt;&lt;endl; ClearQueue_Sq(SQ); cout&lt;&lt;"清空队列后的遍历："; QueueTraverse_Sq(SQ); DestoryQueue_Sq(SQ); return OK;&#125; 循环队列测试结果： 图：循环队列测试结果]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[栈的应用举例]]></title>
    <url>%2F2017%2F10%2F02%2F%E6%A0%88%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%BE%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[数制转换应用：十进制数N和其他d进制数的转换是计算机实现计算的基本问题，其解决方法很多，其中一个简单算法基于下列原理： N = (N div d) * d + N mod d(其中：div为整除运算，mod为求余运算) 例如，(2007)10 = (3727)8，其运算过程如下： 可以看到上述过程是从低位到高位产生8进制的各个数位，然后从高位到低位进行输出，结果数位的使用具有后出现先使用的特点，因此生成的结果数位可以使用一个栈来存储，然后从栈顶开始依次输出即可得到相应的转换结果。 程序代码：123456789101112131415161718192021222324//conversion.h/* 可以进行数制的转换功能 十进制转换位其他进制数，这能转化为10进制以内进制*/void conversion()&#123; SqStack S; int N,M,e; InitStack_Sq(S); cout&lt;&lt;"请输入要转换的数字"&lt;&lt;endl; cin&gt;&gt;N; cout&lt;&lt;"请选择要转换的进制数（例如二进制，输2,只能转化为10进制以内的）："&lt;&lt;endl; cin&gt;&gt;M; while(N)&#123; Push_Sq(S,N%M); N=N/M; &#125; cout&lt;&lt;N&lt;&lt;"进制的数转化为"&lt;&lt;M&lt;&lt;"进制后为："; while(!StackEmpty_Sq(S))&#123; Pop_Sq(S,e); cout&lt;&lt;e; &#125; cout&lt;&lt;endl; 程序运行结果： 图：十进制转二进制数结果 表达式求值算法：表达式求值是程序设计语言中的一个最基本问题。它的实现是栈应用的又一个典型例子。这里介绍一种简单直观、广为使用的算法，通常称为“算符优先法”。 要把一个表达式翻译成正确求值的一个机器指令序列，或者直接对表达式求值，首先要能够正确解释表达式。例如要对下述表达式求值： 14+（6-10+2*2）*21 首先，要了解算术四则运算的规则。即： （1）先乘除，后加减； （2）从左算到右 （3）先括号内，后括号外 由此，这个算术表达式的计算顺序应为： 14+（6-10+2*2）*2 = 4+（-4+2*2）*2 = 4+（-4+4）*2 = 4+0*2 = 4+0 = 41 任何一个表达式都是由操作数（operand）、运算符（operator）和界限符（delimiter）组成。界限符也就是括号等，运算符包括加减乘除，以及更复杂的求余、三角函数等等。这里我们只讨论比较简单的算术表达式，只包括加减乘除四种运算符。 我们把运算符和界限符统称为算符，根据上述3条运算规则，在运算每一步中，任意两个相继出现的算符θ1和θ2之间的优先关系至多是下面三种关系之一： θ1 &lt; θ2，θ1的优先权低于θ2 θ1 = θ2，θ1的优先权等于θ2 θ1 &gt; θ2，θ1的优先权大于θ2 下表定义了这种优先关系： θ1 \ θ2 + - * / ( ) + &gt; &gt; &lt; &lt; &lt; &gt; - &gt; &gt; &lt; &lt; &lt; &gt; * &lt; &lt; &gt; &gt; &lt; &gt; / &lt; &lt; &gt; &gt; &lt; &gt; ( &lt; &lt; &lt; &lt; &lt; = ) &gt; &gt; &gt; &gt; &gt; 由规则（3），+、-、*和/为θ1时的优先级均低于“(”但高于右括号”)”，由规则（2），当θ1 = θ2时，令θ1 &gt; θ2。 基于上述的论述，首先，我们来讨论使用算符优先算法来实现表达式的求值。 为实现该算法，我们需要使用两个工作栈。一个称作OPTR，用以寄存运算符；另一个称作OPND，用以寄存操作数或运算结果。算法的基本思想是： （1）首先置操作数栈和操作符栈为空栈 （2）依次读入表达式中的每个字符，若是操作数则进OPND栈，若是运算符则和OPTR栈的栈顶运算符比较优先权后作相应操作。 1.若该运算符优先权大于栈顶运算符优先权则该运算符直接进OPTR栈；反之若运算符优先权小于栈顶运算符的优先权，则弹出栈顶运算符，并从操作数OPND栈弹出两个数进行该栈顶运算符的运算，运算结果再加入OPND操作数栈。2.循环往复地进行第1步判断。直到将该操作符加入OPTR操作符栈 （3）表达式读取结束，若两个栈都不为空，则依次弹出OPTR栈中的运算符和OPND栈中的两个操作数，进行运算后，将运算结果在加入OPND栈。直到OPTR栈为空，OPND栈只剩下一个元素，则该元素就是运算结果。 （4）中间出现差错，比如最后OPND栈剩下不止一个数，则视为表达式出错。 程序代码:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798//EvaluateExpression.h//表达式求值算法typedef int OperandType; //运算数类型//------判断两个运算符的优先级-----------char Precede(char theta1, char theta2)&#123; //“#”是表达式的结束符，表达式的最左边也需设一个"#"构成表达式的一对括号 char theta[7] = &#123;'+', '-', '*', '/', '(', ')', '#'&#125;; //定义操作符数组 //优先级比较数组 char prior[7][7]=&#123; &#123;'&gt;','&gt;','&lt;','&lt;','&lt;','&gt;','&gt;'&#125;, &#123;'&gt;','&gt;','&lt;','&lt;','&lt;','&gt;','&gt;'&#125;, &#123;'&gt;','&gt;','&gt;','&gt;','&lt;','&gt;','&gt;'&#125;, &#123;'&gt;','&gt;','&gt;','&gt;','&lt;','&gt;','&gt;'&#125;, &#123;'&lt;','&lt;','&lt;','&lt;','&lt;','=','0'&#125;, &#123;'&gt;','&gt;','&gt;','&gt;','0','&gt;','&gt;'&#125;, &#123;'&lt;','&lt;','&lt;','&lt;','&lt;','0','='&#125;&#125;; int i = 0, j = 0;//i和j分别为两个操作符在数组中的位置 while( i &lt; 7 &amp;&amp; j &lt; 7)&#123; if(theta1!=theta[i]) i++; if(theta2!=theta[j]) j++; if(theta1 == theta[i] &amp;&amp; theta2 == theta[j]) break; &#125; return prior[i][j];//返回相应的优先级&#125;//Precede//------根据给出的操作数op1和op2，以及操作符theta得出运算结果---------OperandType Operate(OperandType op1, char theta, OperandType op2)&#123; switch(theta)&#123; case '+': return op1+op2; case '-': return op1-op2; case '*': return op1*op2; case '/': return op1/op2; default: return ERROR; &#125;&#125;//Operate//------------判断字符e是否为操作符----------------Status In(char e, char *op)&#123; int i = 0; while(i++ &lt; 7)&#123; if(e==(*op++)) return TRUE; &#125; return FALSE;&#125;//In/* 算数表达式求值的算符的优先算法，设OPTR和OPND分别为运算符栈和运算符数栈， 测试时表达式必须以“#"结尾，如"2+3*5#"------------------------------- 这里为了算法简单，不考虑多数据类型，测试时均为一位整数。*/OperandType EvaluateExpression()&#123; char op[7]=&#123;'+', '-', '*', '/', '(', ')', '#'&#125;;//op为运算符集合 SqStack OPTR,OPND; InitStack_Sq(OPTR); Push_Sq(OPTR,'#'); InitStack_Sq(OPND); char c; //每次从键盘接收的字符 cin&gt;&gt;c; SElemType e,x,theta; //e为每次进行判断的栈顶元素 SElemType a,b; //进行运算时栈顶取得的两个操锁数 SElemType result; //运算的最终结果 GetTop_Sq(OPTR,e); //获得数栈栈顶元素 while(c!='#' || e!='#')&#123; if(!In(c,op))&#123;Push_Sq(OPND,c); cin&gt;&gt;c;&#125;//不是运算符则进栈 else&#123; GetTop_Sq(OPTR,e); switch(Precede(e,c))&#123; case '&lt;': //栈顶元素优先权低 Push_Sq(OPTR,c); cin&gt;&gt;c; break; case '=': //脱括号，并接收下一字符 Pop_Sq(OPTR,x); cin&gt;&gt;c; break; case '&gt;': //退栈并将运算结果入栈 Pop_Sq(OPTR,theta); Pop_Sq(OPND,a); Pop_Sq(OPND,b); Push_Sq(OPND,Operate(b-48,theta,a-48)+48); //-48是将字符转化为数字 break; &#125;//switch &#125;//if GetTop_Sq(OPTR,e); &#125;//while GetTop_Sq(OPND,result); cout&lt;&lt;"result="&lt;&lt;result-48&lt;&lt;endl; return result-48;&#125;//Eva;uteExpression 程序运行结果： 图：表达式求值结果]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[顺序栈与链式栈的实现]]></title>
    <url>%2F2017%2F10%2F01%2F%E9%A1%BA%E5%BA%8F%E6%A0%88%E4%B8%8E%E9%93%BE%E5%BC%8F%E6%A0%88%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[栈的概念：栈（stack）又名堆栈，它是一种运算受限的线性表。其限制是仅允许在表的一端进行插入和删除运算。这一端被称为栈顶，相对地，把另一端称为栈底。向一个栈插入新元素又称作进栈、入栈或压栈，它是把新元素放到栈顶元素的上面，使之成为新的栈顶元素；从一个栈删除元素又称作出栈或退栈，它是把栈顶元素删除掉，使其相邻的元素成为新的栈顶元素。 顺序栈：base.h 这个头文件主要用来存放公用的常量和类型。 12345678910111213141516171819//base.h//-----公用的常量和类型----------#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt;using namespace std;#include&lt;malloc.h&gt;#include&lt;string.h&gt;//函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define INFEASIBLE -1 //不可行的 infeaslble#define OVERFLOW -2typedef int Status;typedef int SElemType; sq_Stack.h sq_Stack.h头文件用来具体实体实现栈的基本操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126//sq_stack.h 顺序栈//-------------栈的顺序存储表示----------------#define STACK_INIT_SIZE 100 //存储空间初始分配量#define STACKINCREMENT 10 //存储空间分配增量typedef struct&#123; SElemType *base; //在栈构造之前和销毁之后，base的值为NULL SElemType *top; //栈顶指针 int stacksize; //当前分配的存储空间，以元素为单位&#125;SqStack;//----基本操作的函数原型说明-----------//构建一个空栈SStatus InitStack_Sq(SqStack &amp;S)&#123; S.base = (SElemType *)malloc(STACK_INIT_SIZE * sizeof(SElemType)); if(!S.base) //判断是否空间分配成功 exit(OVERFLOW); S.top = S.base; //栈顶与栈底指向同一个位置 S.stacksize = STACK_INIT_SIZE; return OK;&#125;//InitStack_Sq//销毁栈SStatus DestroyStack_Sq(SqStack &amp;S)&#123; if(S.base)&#123; free(S.base); S.top = S.base = NULL; S.stacksize = 0; cout&lt;&lt;"栈销毁成功！"&lt;&lt;endl; return OK; &#125;else&#123; cout&lt;&lt;"栈不存在,不需要销毁！"&lt;&lt;endl; return ERROR; &#125;&#125;//DestroyStack_Sq//初始条件：栈S存在//操作结果：清空栈Status CleanStack_Sq(SqStack &amp;S)&#123; S.top = S.base; return OK;&#125;//CleanStack_Sq//初始条件：栈S存在//操作结果：若为空栈，返回TRUE，否则FALSEStatus StackEmpty_Sq(SqStack S)&#123; if(S.top == S.base)&#123; cout&lt;&lt;"栈为空！"&lt;&lt;endl; return FALSE; &#125; else&#123; cout&lt;&lt;"栈不为空！"&lt;&lt;endl; return TRUE; &#125;&#125;//StackEmpty_Sq//初始条件：栈S存在//操作结果：返回栈内元素个数，即栈的长度int StackLength_Sq(SqStack S)&#123; int len; len = (S.top - S.base); return len;&#125;//StackLength_Sq//初始条件：栈S存在//操作结果：用e返回S的栈顶元素Status GetTop_Sq(SqStack S, SElemType &amp;e)&#123; if(S.top == S.base)//判空 return ERROR; else&#123; e = *(S.top - 1); return OK; &#125;&#125;//GetTop_Sq//初始条件：栈S存在//操作结果：插入元素e为新的栈顶元素Status Push_Sq(SqStack &amp;S, SElemType e)&#123; //判满，追加存储空间 if(S.top - S.base &gt;= S.stacksize)&#123; S.base = (SElemType *)realloc(S.base, (S.stacksize + STACKINCREMENT) * sizeof(SElemType)); if(!S.base)//存储分配失败 exit(OVERFLOW); S.top = S.base + S.stacksize; S.stacksize += STACKINCREMENT; &#125; *S.top++ = e; //插入元素 return OK;&#125;//Push_Sq//初始条件：栈S存在//操作结果：删除S的栈顶元素，并用e返回其值Status Pop_Sq(SqStack &amp;S, SElemType &amp;e)&#123; if(S.top == S.base) //判空 return ERROR; e = *--S.top; //返回删除元素的值 return OK;&#125;//Pop_Sq//初始条件：栈S存在//操作结果：遍历栈元素并显示Status StackTraverse_Sq(SqStack S)&#123; if(S.base)&#123; //判断栈是否存在 if(S.top == S.base) //判空 cout&lt;&lt;"此栈是个空栈！"&lt;&lt;endl; else&#123; SElemType *p; p = S.top; while(p &gt; S.base) &#123; p--; cout&lt;&lt;*p&lt;&lt;" "; &#125; cout&lt;&lt;endl; &#125; return OK; &#125;else&#123; cout&lt;&lt;"栈不存在！"&lt;&lt;endl; return ERROR; &#125;&#125;//StackTraverse_Sq sqStackText.cpp 用来测试顺序栈的基本操作函数。 12345678910111213141516171819202122232425262728293031323334353637#include "base.h"#include "sq_stack.h"//用来测试顺序栈的基本操作int main()&#123; SqStack S; SElemType e; InitStack_Sq(S); StackTraverse_Sq(S); //给空栈赋值 for(e = 0; e&lt;10; e++)&#123; Push_Sq(S, e); &#125; cout&lt;&lt;"栈的遍历："; StackTraverse_Sq(S); Push_Sq(S, 15); cout&lt;&lt;"压栈15后栈的遍历："; StackTraverse_Sq(S); Pop_Sq(S, e); cout&lt;&lt;"出栈后栈的遍历："; StackTraverse_Sq(S); cout&lt;&lt;"被删除的元素是："&lt;&lt;e&lt;&lt;endl; GetTop_Sq(S, e); cout&lt;&lt;"获取栈顶元素："&lt;&lt;e&lt;&lt;endl; cout&lt;&lt;"栈的长度为（即栈内元素个数）：" &lt;&lt;StackLength_Sq(S)&lt;&lt;endl; cout&lt;&lt;"判栈空："; StackEmpty_Sq(S); cout&lt;&lt;"清空栈!"&lt;&lt;endl; CleanStack_Sq(S); cout&lt;&lt;"判栈空："; StackEmpty_Sq(S); cout&lt;&lt;"销毁栈："; DestroyStack_Sq(S); cout&lt;&lt;"再次销毁栈："; DestroyStack_Sq(S); return OK;&#125; 程序运行结果： 图：顺序栈测试的运行结果 链式栈：link_stack.h 链式表的具体代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119//link_stack.h 链式栈//-------------栈的链式存储表示----------------#define STACK_INIT_SIZE 100 //存储空间初始分配量#define STACKINCREMENT 10 //存储空间分配增量typedef struct StackNode&#123; SElemType date; //数据域 struct StackNode *next;&#125;StackNode, *LinkStackPtr;typedef struct LinkStack&#123; LinkStackPtr top; //栈顶 int count; //记录栈元素个数&#125;*PLinkStack;//----基本操作的函数原型说明-----------//构建一个空栈SStatus InitStack_L(PLinkStack* S)&#123; //分配一个节点的初始化空间 *S = (PLinkStack)malloc(sizeof(struct LinkStack)); (*S)-&gt;top = NULL; //栈顶指针指向空 (*S)-&gt;count = 0; //栈中元素个数初始为0 return OK;&#125;//InitStack_L//初始条件：栈S存在//操作结果：清空栈Status CleanStack_L(PLinkStack &amp;S)&#123; LinkStackPtr p; //栈不为空时,进行循环，释放每一个节点的空间 while(S-&gt;top)&#123; p = S-&gt;top; S-&gt;top = S-&gt;top-&gt;next; S-&gt;count--; free(p); &#125; return OK;&#125;//CleanStack_L//销毁栈SStatus DestroyStack_L(PLinkStack* S)&#123; CleanStack_L(*S); //先清空栈 free(*S); //释放栈所有空间 cout&lt;&lt;"栈销毁成功！"&lt;&lt;endl; return OK;&#125;//DestroyStack_L//初始条件：栈S存在//操作结果：若为空栈，返回TRUE，否则FALSEStatus StackEmpty_L(PLinkStack S)&#123; if(S-&gt;top)&#123; //栈顶存在 cout&lt;&lt;"栈不为空！"&lt;&lt;endl; return FALSE; &#125;else&#123; cout&lt;&lt;"栈为空！"&lt;&lt;endl; return TRUE; &#125;&#125;//StackEmpty_L//初始条件：栈S存在//操作结果：返回栈内元素个数，即栈的长度int StackLength_L(PLinkStack S)&#123; return S-&gt;count;&#125;//StackLength_L//初始条件：栈S存在//操作结果：用e返回S的栈顶元素Status GetTop_L(PLinkStack S, SElemType &amp;e)&#123; if(!S-&gt;top) return ERROR; e = S-&gt;top-&gt;date; return OK;&#125;//GetTop_L//初始条件：栈S存在//操作结果：插入元素e为新的栈顶元素Status Push_L(PLinkStack &amp;S, SElemType e)&#123; LinkStackPtr p = (LinkStackPtr)malloc(sizeof(struct StackNode)); p-&gt;date = e; p-&gt;next = S-&gt;top; S-&gt;top = p; S-&gt;count++; return OK;&#125;//Push_L//初始条件：栈S存在//操作结果：删除S的栈顶元素，并用e返回其值Status Pop_L(PLinkStack &amp;S, SElemType &amp;e)&#123; LinkStackPtr p; if(!S-&gt;top)&#123; return ERROR; &#125; e = S-&gt;top-&gt;date; p = S-&gt;top; S-&gt;top = S-&gt;top-&gt;next; S-&gt;count--; free(p); return OK;&#125;//Pop_L//初始条件：栈S存在//操作结果：遍历栈元素并显示Status StackTraverse_L(PLinkStack S)&#123; if(S-&gt;top)&#123; LinkStackPtr p; p = S-&gt;top; while(p)&#123; cout&lt;&lt;p-&gt;date&lt;&lt;" "; p = p-&gt;next; &#125; cout&lt;&lt;endl; return OK; &#125;else&#123; cout&lt;&lt;"此栈为空栈！"&lt;&lt;endl; return OK; &#125;&#125;//StackTraverse_L linkStackText 链式栈的测试： 123456789101112131415161718192021222324252627282930313233void linkStackText()&#123; PLinkStack S; SElemType e; InitStack_L(&amp;S); StackTraverse_L(S); //给空栈赋值 for(e = 0; e&lt;10; e++)&#123; Push_L(S, e); &#125; cout&lt;&lt;"栈的遍历："; StackTraverse_L(S); Push_L(S, 15); cout&lt;&lt;"压栈15后栈的遍历："; StackTraverse_L(S); Pop_L(S, e); cout&lt;&lt;"出栈后栈的遍历："; StackTraverse_L(S); cout&lt;&lt;"被删除的元素是："&lt;&lt;e&lt;&lt;endl; GetTop_L(S, e); cout&lt;&lt;"获取栈顶元素："&lt;&lt;e&lt;&lt;endl; cout&lt;&lt;"栈的长度为（即栈内元素个数）：" &lt;&lt;StackLength_L(S)&lt;&lt;endl; cout&lt;&lt;"判栈空："; StackEmpty_L(S); cout&lt;&lt;"清空栈!"&lt;&lt;endl; CleanStack_L(S); cout&lt;&lt;"栈的遍历："; StackTraverse_L(S); cout&lt;&lt;"判栈空："; StackEmpty_L(S); cout&lt;&lt;"销毁栈："; DestroyStack_L(&amp;S);&#125; 链式栈测试运行结果： 图：链式栈测试结果]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性链式表]]></title>
    <url>%2F2017%2F09%2F28%2F%E7%BA%BF%E6%80%A7%E9%93%BE%E5%BC%8F%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[链表的定义：链表就是由多个结点离散分配，彼此通过指针相连，每个结点只有一个前驱结点和后继结点。首节点无前驱结点，为结点无后继结点的一种存储结构。 链表中的一些基本概念：头结点：链表的第一个有效结点前面的结点，头结点并不存放有效数据，也就是数据域为空，加头结点的主要目的是为了方便链表的操作。 首节点：链表的第一个有效结点，结点包含数据域和指针域。 尾结点：尾结点的指针域为空。 头指针：指向头结点的指针变量，它存放了头结点的地址(在这里注意一下，指针变量存放的是地址，也就是说头指针存放的是头结点的地址,一般通过头指针对链表进行操作)。 链表的种类： 单向链表： 链表中最简单的一种是单向链表，它包含两个域，一个信息域和一个指针域。这个链接指向列表中的下一个节点，而最后一个节点则指向一个空值。 双向链表： 一种更复杂的链表是“双向链表”或“双面链表”。每个节点有两个连接：一个指向前一个节点，（当此“连接”为第一个“连接”时，指向空值或者空列表）；而另一个指向下一个节点，（当此“连接”为最后一个“连接”时，指向空值或者空列表）。 双向链表也叫双链表。双向链表中不仅有指向后一个节点的指针，还有指向前一个节点的指针。这样可以从任何一个节点访问前一个节点，当然也可以访问后一个节点，以至整个链表。一般是在需要大批量的另外储存数据在链表中的位置的时候用。 循环链表： 在一个 循环链表中, 首节点和末节点被连接在一起。这种方式在单向和双向链表中皆可实现。要转换一个循环链表，你开始于任意一个节点然后沿着列表的任一方向直到返回开始的节点。再来看另一种方法，循环链表可以被视为“无头无尾”。这种列表很利于节约数据存储缓存， 假定你在一个列表中有一个对象并且希望所有其他对象迭代在一个非特殊的排列下。 指向整个列表的指针可以被称作访问指针。 块状链表： 块状链表本身是一个链表，但是链表储存的并不是一般的数据，而是由这些数据组成的顺序表。每一个块状链表的节点，也就是顺序表，可以被叫做一个块。 块状链表通过使用可变的顺序表的长度和特殊的插入、删除方式。块状链表另一个特点是相对于普通链表来说节省内存，因为不用保存指向每一个数据节点的指针。 链表的存储结构：123456789//----------链表的存储结构表示------------typedef struct LNode&#123;//节点类型 ElemType data;//这里表示了每一项，其指数和系数 struct LNode *next;&#125;*Link,*Position;typedef struct&#123;//链表类型 Link head, tail;//分别指向线性链表中的头结点和最后一个结点 int len;//指示线性链表中数据元素的个数&#125;LinkList;//每一项组成一个列表 链式线性表的具体实现代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173//----------链表函数的具体实现代码-----------Status InitList(LinkList *L)&#123; // 构造一个空的线性链表 Link p; p = (Link)malloc(sizeof(LNode)); // 生成头结点 if (p) &#123; p-&gt;next = NULL; (*L).head = (*L).tail = p; (*L).len = 0; return OK; &#125; else return ERROR;//内存分配不够&#125;//InitListStatus MakeNode(Link *p, ElemType e)&#123; // 分配由p指向的值为e的结点，并返回OK；若分配失败。则返回ERROR *p = (Link)malloc(sizeof(LNode)); if (!*p) return ERROR; (*p)-&gt;data = e; return OK;&#125;//MakeNodevoid FreeNode(Link *p)&#123; // 释放p所指结点 free(*p); *p = NULL;&#125;//FreeNodeStatus InsFirst(LinkList *L, Link h, Link s)&#123; // h指向L的一个结点，把h当做头结点，将s所指结点插入在第一个结点之前 s-&gt;next = h-&gt;next; h-&gt;next = s; if (h == (*L).tail) // h指向尾结点 (*L).tail = h-&gt;next; // 修改尾指针 (*L).len++; return OK;&#125;//InsFirstPosition GetHead(LinkList L)&#123; // 返回线性链表L中头结点的位置 return L.head;&#125;//GetHeadStatus SetCurElem(Link p, ElemType e)&#123; // 已知p指向线性链表中的一个结点，用e更新p所指结点中数据元素的值 p-&gt;data = e; return OK;&#125;//SetCurElemStatus LocateElemP(LinkList L, ElemType e, Position *q, int(*compare)(ElemType, ElemType))&#123; // 若升序链表L中存在与e满足判定函数compare()取值为0的元素，则q指示L中 // 第一个值为e的结点的位置，并返回TRUE；否则q指示第一个与e满足判定函数 // compare()取值&gt;0的元素的前驱的位置。并返回FALSE。（用于一元多项式） Link p = L.head, pp; do &#123; pp = p; p = p-&gt;next; &#125; while (p &amp;&amp; (compare(p-&gt;data, e)&lt;0)); // 没到表尾且p-&gt;data.expn&lt;e.expn if (!p || compare(p-&gt;data, e)&gt;0) // 到表尾或compare(p-&gt;data,e)&gt;0 &#123; *q = pp; return FALSE; &#125; else // 找到 &#123;// 没到表尾且p-&gt;data.expn=e.expn *q = p; return TRUE; &#125;&#125;//LocateElemPPosition NextPos(Link p)&#123; // 已知p指向线性链表L中的一个结点，返回p所指结点的直接后继的位置 // 若无后继，则返回NULL return p-&gt;next;&#125;//NextPosElemType GetCurElem(Link p)&#123; // 已知p指向线性链表中的一个结点，返回p所指结点中数据元素的值 return p-&gt;data;&#125;//GetCurElemStatus DelFirst(LinkList *L, Link h, Link *q)&#123; // 形参增加L,因为需修改L // h指向L的一个结点，把h当做头结点，删除链表中的第一个结点并以q返回。 // 若链表为空(h指向尾结点)，q=NULL，返回FALSE *q = h-&gt;next; if (*q) // 链表非空 &#123; h-&gt;next = (*q)-&gt;next; if (!h-&gt;next) // 删除尾结点 (*L).tail = h; // 修改尾指针 (*L).len--; return OK; &#125; else return FALSE; // 链表空&#125;//DelFirstStatus ListEmpty(LinkList L)&#123; // 若线性链表L为空表，则返回TRUE，否则返回FALSE if (L.len) return FALSE; else return TRUE;&#125;//ListEmptyStatus Append(LinkList *L, Link s)&#123; // 将指针s(s-&gt;data为第一个数据元素)所指(彼此以指针相链,以NULL结尾)的 // 一串结点链接在线性链表L的最后一个结点之后,并改变链表L的尾指针指向新 // 的尾结点 int i = 1; (*L).tail-&gt;next = s; while (s-&gt;next) &#123; s = s-&gt;next; i++; &#125; (*L).tail = s; (*L).len += i; return OK;&#125;//AppendStatus ListTraverse(LinkList L, void(*visit)(ElemType))&#123; // 依次对L的每个数据元素调用函数visit()。一旦visit()失败，则操作失败 Link p = L.head-&gt;next; int j; for (j = 1; j &lt;= L.len; j++) &#123; visit(p-&gt;data); p = p-&gt;next; &#125; cout &lt;&lt; "\b "; //退格，每次输出多项式后删掉的最后输出的"+" if (L.len == 0) cout &lt;&lt; "0"; return OK;&#125;//ListTraversevoid visit(ElemType e)&#123; if (e.coef &gt; 0 &amp;&amp; e.coef != 1 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; e.coef &lt;&lt; "x+"; else if (e.expn &gt; 0) cout &lt;&lt; e.coef &lt;&lt; "x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; e.coef &lt;&lt; "x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.coef &lt; 0 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; "(" &lt;&lt;e.coef &lt;&lt; ")x+"; else if (e.expn &gt; 0) cout &lt;&lt; "(" &lt;&lt; e.coef &lt;&lt; ")x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; "(" &lt;&lt; e.coef &lt;&lt; ")x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.coef == 1 &amp;&amp; e.expn != 0) &#123; if(e.expn == 1) cout&lt;&lt; "x+"; else if (e.expn &gt; 0) cout &lt;&lt; "x^" &lt;&lt; e.expn &lt;&lt; "+"; else cout &lt;&lt; "x^(" &lt;&lt; e.expn &lt;&lt; ")+"; &#125; else if (e.expn == 0 &amp;&amp; e.coef != 0) cout &lt;&lt; e.coef&lt;&lt;"+"; else cout &lt;&lt; "";//考虑用户输入可能有系数为0的情况&#125;//visit 这个visit是对一元多项式中的应用。打印一元多项式。 链式线性表的应用：一元多项式的表示及相加。请点击跳转到一元多项式。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算的概念和价值]]></title>
    <url>%2F2017%2F09%2F25%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BB%B7%E5%80%BC%2F</url>
    <content type="text"><![CDATA[云计算的概念：云计算(cloud computing)是一种按是使用量付费的模式，这种模式是可用的、便捷的、按需的网络访问，进入可配置的计算机资源共享池（资源包括网络，服务器，存储，应用软件，服务），这些资源能够被快速提供，只需要投入很少的管理工作，或与服务供应商进行很少的交互。 ​ —————-美国国家标准与技术研究院 云计算是一种基于互联网的计算方式，通过这种方式，共享的软硬件资源和信息可以按需求提供给计算机和其它设备。云计算依赖资源的共享以达成规模经济，类似基础设施（如电力站网）。 ​ ———————————-维基百科 云计算的关键特征： 按需自助服务（On-demand Self-sercice） 无处不在的网络接入（Ubiquitous network access） 与位置无关的资源池（Location independent resource） 快速弹性（Rapid Elastic） 按使用付费（Pay per user） 从不同角度看云计算：技术视角： 云计算 = 计算 / 存储的网络 , 云计算包含两部分：云设备和云服务。 云设备包含用于数据计算处理的服务器，用于数据保存的存储设备和用于数据通信的交换设备。 云服务包含物理资源虚拟化调度管理的云平台软件和用于向用户提供服务的应用平台软件。 商业视角： 云计算 = 信息电厂 用户模式变化：通过互联网提供软硬件与服务；用户通过浏览器或轻量级终端获取、使用服务。 商业模式发生变化：从“购买软硬件产品”向“购买信息服务”转变，如同100年前用电的转变。 云计算技术的发展趋势： 海量低成本服务器代替专有大型机、小型机、高端服务器。 分布式软件代替传统单机操作系统。 自动管控软件代替传统集中管理。 云计算的演进：云计算产生的背景：云计算的产生是需求推动，技术进步，商业模式转变共同促进的结果。 需求推动： 政企客户低成本且高性能的信息化需求。 个人用户的互联网、移动互联网应用需求强烈，追求更好的用户体验。 技术进步： 虚拟化技术、分布与并行计算、互联网技术的发展与成熟，使得基于互联网提供包括IT基础设施、开发平台、软件应用称为可能。 宽带技术及用户发展，使得基于互联网的服务使用模式逐渐成为主流。 商业模式转变： 少数云计算的先行者（例如Amazon的IaaS、PaaS）的云计算服务已开始运营。 市场对云计算商业模式已认可，越来越多的用户接受并使用云计算服务。 生态系统正在形成，产业链开始发展和整合。 IT的转变历史： 大型机集中模式：集中于大型应用的处理，并且受限于数据中心内部。 客户端服务器模式：应用从数据中心走进千家万户。 PC：Personal Computer，个人计算机。 云计算模式：应对爆炸式的信息增长和对动态灵活架构的迫切需求。 云计算的演进历程： 计算模式 定义 特点 并行计算（Paralle Computing） 同时使用多种计算资源解决计算问题的过程，主要目的是快速解决大型且复杂的计算问题 把计算任务分配给系统内的多个运算单元 分布式计算（Distributed Computing） 把一个需要巨大计算能力才能解决的问题分成多个小部分，把这些小部分分配给多个计算进行处理，最后综合这些计算结果得到最终结果 把计算任务分配给网络中多台独立的机器 网格计算（Grid Computing） 利用互联网把地理上广泛分布的各种资源连成一个逻辑的整体，就像一台超级计算机一样 分布式计算的一种。为用户提供一体化的信息和应用服务。 云计算是网格计算、分布式计算、并行计算、网络存储、虚拟化、负载均衡等传统计算机和网络技术发展融合的产物。 云计算的模式：云计算的部署模式： 有三种：私有云、共有云、混合云。 私有云计算：一般由一个组织来使用，同时由这个组织来运营。华为数据中心属于这种模式，华为自己是运营者，也是它的使用者，也就是说使用者和运营者是一体，这就是私有云。 公有云计算：就如共用的交换机一样，电信运营商去运营这个交换机，但是它的用户可能是普通的大众，这就是公有云。 混合云计算：它强调基础设施是由二种或更多的云来组成的，但对外呈现的是一个完整的实体。企业正常运营时，把重要数据保存在自己的私有云里面（比如：财务数据），把不重要的信息放到公有云里，两种云组合形成一个整体，就是混合云。比如说电子商务网站，平时业务量比较稳定，自己购买服务器搭建私有云运营，但到了圣诞节促销的时候，业务量非常大，就从运营商的公有云租用服务器，来分担节日的高负荷；但是可以统一的调度这些资源，这样就构成了一个混合云。 云计算的商务模式： IaaS（Infrastructure as a service）：基础设施即服务，指的是把基础设施以服务形式提供给最终用户使用。包括计算、存储、网络和其它的计算资源，用户能够部署和运行任意软件，包括操作系统和应用程序。例如：虚拟机出租、网盘等。 PaaS（Platform as a service）：平台即服务，指的是把二次开发的平台以服务形式提供给最终用户使用，客户不需要管理或控制底层的云计算基础设施，但能控制部署的应用程序开发平台。例如：微软的Visual Studio开发平台。 SaaS（Software as a service）：软件即服务，提供给消费者的服务是运行在云计算基础设施上的应用程序。例如：企业办公系统。 服务类别 服务内容 盈利模式 实例 SaaS 互联网Web 2.0应用， 企业应用， 电信业务 通过提供满足最终用户需求的业务，按使用收费 Salesforce：CRM PaaS 提供应用和开发环境， 提供应用开发的组件（如：数据库） 通过将IT资源、Web通用能力、通信能力打包出租给应用开发和运营者，按使用收费 Microsoft：Azure的Visio Studio工具 IaaS 出租计算、存储、网络等IT资源 按使用收费， 通过规模获取利润 Amazon： EC2云主机 云计算的流派： 云计算有两个典型的流派：大分小模式和小聚大模式 大分小模式：资源在应用间时分复用；关键技术点包括计算、存储和网络虚拟化以及虚拟机监控、调度和迁移。典型代表：Amazon EC2。 小聚大模式：应用资源需求大，可以划分为子任务；关键技术点包括任务分解、调度、分布式通信总线和全局一致性。典型代表：Google。 VM：Virtual Machine，虚拟机。VMM：Virtual Machine Monitor，虚拟机监控器。App：Application，应用系统。 云计算的技术：云计算技术体系：核心技术识别 从物理设备（服务器、存储和网络设备）、虚拟化软件平台、分布式计算和存储资源调度、一体化自动化管控软件、虚拟化数据中心的安全和E2E的集成交付能力，都是构建高效绿色云数据中心的关键技术。 简化设计的大内存、高网络和存储IOPS的服务器，可以为云数据中心提供强大的计算能力。 高IOPS，支持链接克隆、精简置备、快照等功能的存储设备，可以为数据中心提供强大的存储能力。 高密度、低成本，支持大二层网络技术的交换设备为数据在二层网络流动提供交换能力。 虚拟化软件平台，可以抽象物理资源为资源池，给云用户配置不同规格虚拟机提供底层支撑。 灵活、高效的分布式计算或存储框架，为云计算的资源调度和调整提供支撑。 从门禁监控、网络接入、虚拟化平台软件安全、经过安全加固的OS和DB到用户的分权分域管理，保证数据中心的放心使用。 一体化自动化的管控软件，提升维护人员的效率，降低企业成本。 云计算的关键技术： 通过对多项核心技术进行归类汇总，可归结为三个方面：整体的计算架构、承载的硬件设备和软件系统。 整体的计算架构，需要涵盖高性能、高可靠和可扩展。 云计算硬件包括：高可靠和高性能的计算服务器提供计算资源；低成本、数据安全的存储设备提供数据存储空间；支持大二层网络的高密度交换机进行数据的通信和交流。 云计算软件包括：用于大数据的并行分析计算技术；整合存储资源提供动态可伸缩资源池的分布式存储技术；用于数据管理的分布式文件管理；计算、存储等资源池化的虚拟化技术；简化运维人员工作，方便高效智能运维的系统管理技术。 云计算的硬件技术：技术架构许多系统开始很简单，但当需要进行系统扩展时就会变得复杂。升级系统最常见的原因是需要更多的容量，以支持更多的用户、文件、应用程序或连接的服务器。常见的系统扩展方式有Scale up和Scale out两种。 Scale up(纵向扩展) 主要是利用现有的系统，通过不断增加存储容量来满足数据增长的需求。但是这种方式只增加了容量，而带宽和计算能力并没有相应的增加。所以，整个系统很快就会达到性能瓶颈，需要继续扩展。 Scale out横向扩展架构的升级通常是以节点为单位，每个节点往往将包含容量、处理能力和I/O带宽。一个节点被添加到系统，系统中的三种资源将同时升级。而且，Scale out架构的系统在扩展之后，从用户的视角看起来仍然是一个单一的系统。所以Scale out方式使得系统升级工作大大简化，用户能够真正实现按需购买，降低TCO。 云计算的设计思想是以最低成本构建出整体的性能最优，与传统电信设备和IT设备（服务器、大型机、企业存储等）追求设备可靠性和性能的思路完全不同。 云计算的硬件技术：存储系统企业存储一般采用专用的存储设备，成本高。 分布式存储系统把使用便宜IDE/SATA硬盘的服务器本地存储构建存储资源池，既降低了服务器的成本，也降低了存储成本，构建最低成本的计算和存储。通过“分布式存储和多副本备份”来解决海量信息的存储和系统可靠性，数据存储可以配置多份副本，保证数据的安全性。 云计算的硬件技术：数据中的联网随着云计算的发展，越来越多业务承载在数据中心的虚拟机上，业务数据的流动从南北向转变为东西向，对数据中心网络的需求和冲击提出了很大挑战。 数据中心内部虚拟机的迁移促进了大二层网络虚拟交换技术的发展，支持大容量数据的通信和超高的端口密度，可以连接更多的服务器提升数据中心的处理能力。 云计算的软件技术：集群管理云计算虚拟化平台软件，支持分布式的集群管理。可以针对业务模型，对物理服务器创建不同的业务集群，并在集群内实现资源调度和负载均衡，在业务负载均衡的基础上实现资源的动态调度，弹性调整。 云计算虚拟化平台需要支持各种不同的存储设备，包括本地存储、SAN存储、NAS存储和分布式本地存储，保证业务的广适配性。 同时，提供链接克隆、资源复用、精简置备和快照功能，降低企业成本并提供高效率、高可靠性的资源池。 云计算的价值：资源整合、提高资源利用率 利用虚拟化技术，实现资源的弹性伸缩。 每台服务器虚拟出多台虚拟机，避免原来的服务器只能给某个业务独占的问题。 可通过灵活调整虚拟机的规格（CPU、内存等），增加虚拟机/减少虚拟机，快速满足业务对计算资源需求量的变化。 利用虚拟化计算，将一定量的物理内存资源虚拟出更多的虚拟内存资源，可以创建更多的虚拟机。 快速部署，弹性扩容 开局初期，业务规模较小，可部署较少服务器。后续需要扩容时十分简单，只需要通过PXE或者iso新装几台计算节点，然后通过操作维护Portal将服务器添加到系统即可 基于云的业务系统采用虚拟机批量部署 短时间实现大规模资源部署，快速响应业务需求，省时高效 根据业务需求可以弹性扩展/收缩资源满足业务需要 人工操作较少，以自动化部署为主 客户不再因为业务部署太慢而失去市场机会 传统业务部署周期以月为计划周期，基于云的业务部署周期缩短到以分钟/小时为计时周期 数据集中，信息安全传统IT平台，数据分散在各个业务服务器上，可能存在某单点有安全漏洞的情况；部署云系统后，所有数据集中在系统内存放和维护，并提供以下安全保障： 网络传输：数据传输采用HTTPS加密 系统接入：需要证书或者账号 数据安全： 架构安全，经过安全加固的VMM，保证虚拟机间隔离； 虚拟机释放时，磁盘被全盘擦除，避免被恢复的风险； 系统内账户等管理数据，加密存放。 趋势防病毒软件 自动调度，节能减排基于策略的智能化、自动化资源调度，实现资源的按需取用和负载均衡，消峰填谷，达到节能减排的效果： 白天，基于负载策略进行资源监控，自动负载均衡，实现高效热管理 夜晚，基于时间策略进行负载整合，将不需要的服务器关机，最大限度降低耗电量 节能减排即动态电源管理(DPM)可以优化数据中心的能耗。开启DPM后，当集群中虚拟机使用资源比较低时，可以聚合虚拟机到少量主机，并关闭其它无虚拟机运行的主机，实现节能减排。当虚拟机所需资源增加时，DPM动态上电主机，确保提供足够资源。 降温去燥，绿色办公 物理PC机的主机替换为TC，可以大大降低发热量，改善办公环境。 物理主机的处理资源在本地，需要配置比较强的CPU、硬盘和风扇等组件，产生较大的噪音污染；替换为TC之后，计算等资源在远端的数据中心中，本地TC仅仅支持指令输入和页面展示，所以噪音较低，提升办公感受。 PC：Personal Computer，个人计算机。 TC：Thin Client，瘦终端，用于云计算环境中虚拟桌面的接入和使用。 高效维护，降低成本使用传统PC办公，从PC选型、购买、库房存放、分发和维护等多个流程都需要IT支撑人员参与，可以产生下面几方面的困扰：从立项购买到投入使用所需流程时间较长； 传统PC能耗较高，导致企业成本增加； 传统PC出现故障，从报修到重新可以使用，所需时间较长，影响企业办公； 传统PC一般3年需要更新换代，无法利旧； 传统IT环境下，PC数量多并且分布于各个办公地点，所需维护人力较多，提升人力成本。 使用桌面云办公场景，处理资源数量较少并且集中于数据中心，可以改善企业办公的困扰。 无缝切换，移动办公在桌位、办公室、旅途中、家里的不同终端上随时随地远程接入，桌面立即呈现。 数据和桌面都集中运行和保存在数据中心，用户可以不必中断应用运行，实现热插拔更换终端。 升级扩容不中断业务管理节点的升级，由于有主备两个节点，可先升级一个节点，做主备切换后再升级另外一个节点。 计算节点的升级，可以先将该节点的虚拟机迁移到其他节点，然后对该节点升级，再将虚拟机迁回。 软硬件系统统一管理华为云解决方案支持对一体机、服务器、存储设备、网络设备、安全设备、虚拟机、操作系统、数据库、应用软件等进行统一的管理。 华为云解决方案支持异构业界主流的服务器、存储设备。 不仅支持集成华为虚拟化软件FusionCompute，而且支持集成VMware虚拟化软件。 从上面描述可以看出，软硬件系统统一管理，可以提升管理的便利性，降低管理系统的购置成本和人力成本。 假如：一个公司采购的设备需要多个不同的管理系统来管理维护，那么: 需要购置多个不同的管理系统； 对于维护人员来说，需要学习多个管理系统的技能； 再考虑系统升级、技能储备和人员流动因素，企业的成本更高。 云计算的应用：云计算正处于快速增长前的“零界点”云计算有三个阶段：准备、起飞和成熟 准备阶段：云计算各种模式都处于探索阶段，应用较少，无成功案例可参考。 起飞阶段：经过准备阶段的探索之后，探索出一些成功的应用模式。 成熟阶段：云计算商业模式已成熟，整个生态系统已完善，云计算也成为企业成功必备的IT资源。 云计算市场空间潜力巨大：云计算市场空间潜力巨大，可以应用到政府、电信、教育、医疗、金融、石化和电力各个行业。 云计算应用：Amazon EC2：虚拟机出租，支持Linux、Windows虚拟机使用，支持数据处理和存储租用。 微软Azure 提供基于Windows Server 和Linux系统的虚拟机的Visual Studio 开发平台。 阿里云服务器（Elastic Compute Service 简称ECS）是一种简单高效，处理能力可弹性伸缩的计算服务。 华为云计算战略：云计算产业中，包括云计算设备商、云计算服务提供商和云计算终端用户。 云计算设备商指的是提供搭建云计算环境所需的软硬件的设备厂商，包括硬件厂商（服务器、存储设备、交换机、安全、TC等）和软件厂商（云虚拟化平台、云管理平台、云桌面接入、云存储软件等）。 互联网服务提供商是云计算的先行者，先进技术及创新商业模式领导者，主要基于云计算提供低成本的海量信息处理服务（Google、Amazon等） 电信运营商利用云计算解决现实问题，当前引入云计算提升电信业务网的能力（海量的计算和存储）和降低成本（BT、AT&amp;T） 传统IT巨头被迫转型，将云计算引入优势的产品及解决方案（IBM、Microsoft、HP等） 网络供应商利用技术革新的时机进入，利用传统的网络、服务器和海量软件优势纷纷进入云计算领域（CISCO等） IT和CT边界模糊：技术融合驱动通讯厂家进入传统的IT领域，特别是数通技术成为云计算的关键技术之一。制造商与服务商边界模糊：商业模式的变化驱动部分大制造商（IBM/微软等）进入服务领域，而大型的互联网服务商（Google/Amazon等）自己开发设备提供服务。 ICP：Internet Content Provider，互联网内容提供商，负责提供网站的内容和与之相关的服务。例如：新浪等。 华为云计算解决方案产品： 为更好的帮助企业客户进行基于云计算架构IT建设与转型，并综合业界最新的IT技术发展趋势，华为公司制定了以“融合”为核心特征的FusionCloud云计算战略，并针对每一个核心特征，将这一战略落实到四大产品系列之中。 “水平融合”战略主要贯彻了IT基础设施的横向融合的发展趋势，横向融合，是在IT组件与产品极为多样化的今天，通过横向融合实现对IT基础设施的统一运营与管理；华为在这一战略方向推出的产品叫云操作系统FusionSphere。 “垂直融合”战略主要贯彻了，垂直整合的思想，背景是源自企业对IT系统性价比不断优化的需求，只有从底层各类硬件到顶层各种应用进行垂直的端到端整合，才能实现最优性家比的解决方案。华为在这一战略方向推出的产品叫FusionCube融合一体机。“接入融合”战略，主要贯彻了协同效率提升思想，背景源自企业在保障安全、体验前提下，对员工办公效率不断提升的需求，这一需求的产品体现是华为FusionAccess桌面云产品，来实现企业在云环境下的泛在接入。 “数据融合”战略主要通过大数据分析解决方案，为客户提供更多的价值增长空间。 FusionSphere云操作系统、FusionCube融合一体机、FusionInsight企业级大数据平台、FusionAccess桌面云产品共同组成FusionCloud云计算整体解决方案，可以企业客户构建完善的整体云计算平台。 华为部署全球最大的云办公桌面云: 按员工类型划分安全分区级别：红，黄，绿 TC本地无硬盘，通过数字证书接入认证 通过SSL加密传输信息 多种接入认证方式，平台统一认证 高速互联网络，多数据中心间资源管理及调度 办公，集成测试分时（白天，晚上）共享资源 华为桌面云案例：效果分析 从华为的使用情况来看，使用桌面云构建办公系统之后，可以从设备成本、能耗、维护人力、设备更新等几个方面降低企业的成本。 专业名词缩略语： IT：Information technology，信息技术。 ICT ：Information and Communications Technology，信息与通信技术。 PC：Personal Computer，个人电脑。 API：Application Programming Interface，应用编程接口。 CRM：Customer Telationship Management，客户关系管理。 IaaS：Infrastructure as a Service，基础设施即服务。 PaaS：Platform as a Service，平台即服务。 SaaS：Software as a Service ，软件即服务。 VM：Virtual Machine，虚拟机。 VMM: Virtual Machine Monitor，虚拟机监控器。 EC2：Elastic Compute Cloud，弹性计算云。 IDC：International Data Center，互联网数据中心。 GE：Gigabit Ethernet，千兆以太网。 IOPS：I/O Operations Per Second，每秒读写次数。 App：Applacation，应用系统。 TC：Thin Client，瘦客户端。 TRILL：Transparent Interconnection of Lots of Links，多链接透明互联。 SQL：Structured Query Language，结构化数据库查询语言。 ECS：Elastic Compute Service，弹性计算服务。 SLB：Service Load Balancer，负载均衡。 RDS：Relationship Database Service，关系型数据库服务。 OSS：Open Storage Service，开发存储服务。 CDN：Content Delivery Network， 内容分发网络。 ICP：Internet Content Provider，互联网内容提供商。 STB：Set Top Box, 机顶盒设备。 DC：Date Center，数据中心。]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>云计算</tag>
        <tag>华为网络大赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记（3）控制结构]]></title>
    <url>%2F2017%2F09%2F18%2FPython%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[if语句： Python使用if-elif-else描述多分支决策，简化分支结构的嵌套问题. 可能会有零到多个elif部分，else是可选的。关键词elif是else if 的缩写，这可可以有效避免过深的缩进。if…elif….elif序列用来替代其他语言中的switch或case语句。 例如： 12345678910111213141516print("请输入（0-3）的一个整数：")x = int(input())if x == 0: print("输入的数为0")elif x == 1: print("输入的数为1")elif x == 2: print("输入的数为2")elif x == 3: print("输入的数为3")程序运行结果：请输入（0-3）的一个整数：2输入的数为2&gt;&gt;&gt; for语句：Python中的for语句和C中的略有不同。通常循环可能会依据一个等差数值步来进行，或者有用户自定义迭代步骤和终止条件。Python的for语句依据任意序列（列表或字符串）中的子项，按它们在序列中的顺序来进行迭代。 12345678910&gt;&gt;&gt; list1 = [1,2,3,4,5,6]&gt;&gt;&gt; for i in list1: print(list1[i-1]) 123456&gt;&gt;&gt; range()函数：如果你需要一个数值序列，内置函数range()会很方便，它生成一个等差级数列表。range(5,10),定义了5到10的等差数列。range（0,10,2）定义了0到10以2为步长增长的数列。 1234567&gt;&gt;&gt; for i in range(1,10,2): print(i) 13579 break和continue语句以及循环中的else子句： break语句和C中的类似，用于跳出最近一级的循环. continre语句只是结束本次循环，而不是结束整个循环的执行。 循环中可以有一个else子句，它在循环迭代完整个列表后（对于for）或执行条件为false（对于while）时执行，但循环被break中止的情况下不会执行。 123456789101112131415161718for n in range(2,10): for x in range(2,n): if(n % 2 ==0): print(n, "是2的倍数") break else: print(n, "不是2的倍数")#程序运行结果：2 不是2的倍数3 不是2的倍数4 是2的倍数5 不是2的倍数6 是2的倍数7 不是2的倍数8 是2的倍数9 不是2的倍数&gt;&gt;&gt; pass语句： pass语句什么也不做。它用于那些语法上必须要有的什么语句，但程序什么也不做的场合。 另一方面，pass可以在创建新代码时用来做函数或控制体的占位符。可以让你在更抽象的级别上思考。pass可以默默的被忽视。 def语句：关键字def引入了一个函数的定义。在其后面必须跟有函数名和包括形式参数的圆括号。函数体语句从下一行开始，必须是缩进的。 函数：使用函数的目的： 降低编程的难度 代码重用 函数调用执行的四个步骤： 调用程序在调用处暂停执行 函数的形参在调用时被赋值为实参 执行函数体 函数被调用结束，给出返回值 函数的返回值： return语句：程序退出该函数，并返回到函数被调用的地方 return语句返回的值传递给调用程序 Python函数的返回值有两种形式：返回一个值，返回多个值 无返回值的return语句等价于return None 返回值可以是一个变量，也可以是一个表达式。 异常处理：Python使用try…except…来进行异常处理，基本格式如下： 123456try: &lt;body&gt;except &lt;ErrorEype1&gt;: &lt;handler1&gt;except &lt;ErrorEype2&gt;: &lt;handler2&gt; 当Python解释器遇到一个try语句，它会尝试执行try语句体内的语句如果没有错误，控制转到try-except后面的语句如果发生错误，Python解释器会寻找一个符合该错误的异常语句，然后执行处理代码.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记—常用库简介]]></title>
    <url>%2F2017%2F09%2F17%2FPython%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E5%B8%B8%E7%94%A8%E5%BA%93%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Turtle库：Turtle库是Python语言中一个很流行的绘制图像的函数库。 常用turtle功能函数： 函数 含义 turtle.bgcolor(“red”) 设置画面背景颜色 turtle.setup(width = 200,height = 200,startx = 0,starty = 0) 设置窗口大小和在屏幕上的坐标 turtle.bgpic(“1.gif”) 设置背景图片，只支持gif格式 turtle.onscreenclick(x,y) 用户点击屏幕时获得笔的坐标，制作app时响应用户的点击操作 turtle.bye() 退出turtle，无任何提示信息 turtle.exitonclick() 点击后退出turtle turtle.done() 关闭turtle，一般在使用完turtle后添加，否则会无响应 turtle.Pen() 启用画笔 turtle.Pen().color(“cc4455”) 画笔颜色设置 turtle.Pen().forward(2) 画笔前进长度，以像素为单位 turlte.Pen().backward(2) 画笔后退长度 turtle.Pen().home() 画笔初始位置 turtle.Pen().left(90) 画笔向左转 turtle.Pen().right(90) 画笔向右转 turtule.width(3) 设置画笔宽度，以像素为单位 t = turtle.Pen() 让t代表turtle.Pen(),简化代码 t.penup() 抬起笔，停止写 t.pendown() 放下笔，开始写 t.write(“Python”,font=(“Arial”,”23”,”bold”)) 写指定内容“Python”，并设置字体，字号，加粗 t.circle(4) 以参数为半径画圆 t.dot(4) 以参数为直径画点 t.postion() 笔的坐标 t.heading() 笔的朝向 t.setx(position[0]) 设置笔的x坐标为position记录的x坐标，position由position = t.position()获得 t.sety(Position[1]) 设置笔的y坐标 t.setheading(30) 设置笔的朝向，画笔默认向右为正方向 t.setpos(x,y) 设置笔的坐标 t.fillcolor(“red”) 设置填充颜色 t.begin_fill() 开始填充 t.circle(5) 画圆填充 t.end_find() 填充结束 t.goto(x,y) 笔移动到坐标(x,y) t.speed(1) 笔的移动速冻，参考范围0.5-10，范围之外为0，最快，不设置为最慢 t.hideturtle()/t.showturtle() 隐藏画笔/显示画笔 t.reset() 删除画的内容，还原画笔参数初始值 t.clear() 删除画的内容，不修改画笔参数 蟒蛇绘制实例：程序代码：1234567891011121314151617181920import turtledef drawSnake(rad, angle, len, neckrad): for i in range(len): turtle.circle(rad, angle) turtle.circle(-rad, angle) turtle.circle(rad, angle/2) turtle.fd(rad) turtle.circle(neckrad+1, 180) turtle.fd(rad*2/3)def main(): turtle.setup(1300, 800, 0, 0) pythonsize = 30 turtle.pensize(pythonsize) turtle.pencolor("blue") turtle.seth(-40) drawSnake(40, 80, 5, pythonsize/2)main() turtle.pensize()函数表示小乌龟运动轨迹的宽度。它包含一个输入参数，这里我们把它设为30像素，用pythonsize变量表示。 turtle.pencolor()函数表示小乌龟运动轨迹的颜色。 turtle.seth(angle)函数表示小乌龟启动时运动的方向。他包含一个输入参数，是角度值。其中，0表示向东，90度向北，180度向西，270度向南。负值表示相反的方向。 main()函数给出了小乌龟爬行的窗体大小，爬行轨迹颜色和宽度以及初始爬行的方位。 turtle.circle()函数让小乌龟沿着一个圆形爬行。参数rad描述圆形轨迹半径的位置。 参数angle表示小乌龟沿着圆形爬行的弧度值。 turtle.fd()函数表示乌龟向前直线爬行移动。 程序运行结果： 图： 程序运行结果图 math库：math库中常用的数学函数： 函数 含义 圆周率pi ∏的近似值，15位小数 自然数e e的近似值，15位小数 ceil(x) 对浮点数向上取整 floor(x) 对浮点数向下取整 pow(x,y) 计算x的y次方 log(x) 以e为基的对数 log10(x) 以10为基的对数 sqrt(x) 平方根 exp(x) e的x次幂 degress(x) 将弧度值转换成角度 radians(x) 将角度值转换位弧度值 sin(x) 正弦函数 cos(x) 余弦函数 tan(x) 正切函数 asin(x) 反正弦函数 acos(x) 反余弦函数 atan(x) 反正切函数 random库： random库为随机数库。 random库中常用的函数： 函数 含义 seed(x) 给随机数一个种子值，默认随机种子是系统时钟 random() 生成一个[0,1.0)之间的随机小数 uniform(a,b) 生成一个a到b之间的随机小数 randint(a,b) 生成一个a到b之间的随机整数 randrange(a,b,c) 随机生成一个从a到b以c递增的数 choice(&lt; lsit &gt;) 从列表中随机返回一个元素 shuffle(&lt; list &gt; ) 键列表中的元素随机打乱 sample(&lt; list &gt;, k) 从指定列表随机获取k个元素 随机数库及其使用： 因为计算机是一个确定设备，不能生成真正的随机数。所以一个，由计算机产生的随机数都是由一个种子开始的伪随机序列。 相同的随机种子，产生相同的伪随机序列，也有利于程序的执行验证。 示例： 123456789101112131415161718192021&gt;&gt;&gt; from random import *&gt;&gt;&gt; seed(10)&gt;&gt;&gt; random() #生成随机数0.5714025946899135&gt;&gt;&gt; uniform(1,10) #生成1-10的随机小数4.860001492076032&gt;&gt;&gt; randint(1,10) #生成1-10的随机整数10&gt;&gt;&gt; randrange(1,10,2) #生成从1开始到10以2递增的数1&gt;&gt;&gt; randrange(1,10,2)3&gt;&gt;&gt; vlist = [1,2,3,4,5]&gt;&gt;&gt; choice(vlist) #从列表中随机返回一个元素4&gt;&gt;&gt; shuffle(vlist) #将列表中元素随机打乱&gt;&gt;&gt; vlist[2, 1, 5, 3, 4]&gt;&gt;&gt; sample(vlist,2) #随机获取列表中2个元素[2, 3]&gt;&gt;&gt; math库与random库的使用实例：圆周率π的计算： 圆周率π是一个无理数，没有任何一个精确公式能够计算，π的计算只能采用近似法。 国际公认的PI值计算采用蒙特卡洛方法。又称为随机抽样或统计实验方法。 应用蒙特卡洛方法：首先构造一个单位正方形和1/4圆。 随机向单位正方形和圆结构抛洒大量点，对于每个点，可能在圆内或者圆外，当随机抛点数量达到一定程度，圆内点将构成圆的面积，全部抛点将构成矩形面积。圆内点数除以圆外点数就是面积之比，即π/4。随机点数越大，得到的π值越精确。 π计算问题的IPO表示如下： 输入：抛点的数量 处理：对于每个抛洒点，计算点到圆心的距离，通过距离判断该点在圆内或是圆外。统计在圆内点的数量 输出：π值 程序代码如下： 12345678910111213141516171819202122#pi.pyfrom random import randomfrom math import sqrtfrom time import clockDARTS = 12000000 #定义投掷的数量hits = 0 #用来存放投到圆内得数量clock() #获取程序开始时的时间for i in range(1,DARTS): #模拟循环进行投掷 x, y = random(), random() #获得随机坐标 dist = sqrt(x**2 + y**2) #点到原点的距离 if dist &lt;= 1.0: #如果距离&lt;=1,hits加1 hits = hits + 1pi = 4 * (hits/DARTS) print("Pi的值是%s"% pi)print("程序运行的时间是 %-5.5ss" % clock())#程序执行结果：#===================== RESTART: D:/我的文件/Python程序/π的计算.py =====================Pi的值是3.1420456666666667程序运行的时间是 13.67s&gt;&gt;&gt; OS库常用函数 os.getcwd() 获得当前路径 os.listdir(path) 获得目录中的内容 os.mkdir(path) 创建目录 os.rmdir(path) 删除目录 os.isdir(path) os.isfile(path) 判断是否为目录或者文件 os.remove(path) 删除文件 os.rename(old, new) 重命名文件或者目录 os.name 输出字符串指示正在使用的平台。如果是window 则用’nt’表示，对于Linux/Unix用户，它是’posix’ os.system() 运行shell命令 os.path.split() 返回一个路径的目录名和文件名 os.path.splitext() 分离文件名与扩展名 os.path.getsize(name) 获得文件大小，如果name是目录返回0L os.getegid() 返回当前进程(process)所属的有效group id 只有unix可用 os.geteuid() 返回当前进程所属的用户ID (Unix) os.getgid() 返回当前进程所属的真实组ID(real group id) os.getlogin() 返回当前登陆用户名 os.getpgrp() 返回当前进程组的ID(Unix) os.getpid() 返回当前进程的PID，( Unix, Windows ) os.getppid() 返回当前进程父进程的ID(Unix) os.getuid() 返回当前进程所属用户ID(Unix) random库 random.random() 生成一个0到1之间的随机浮点数，包括0但不包括1，也就是[0.0, 1.0)。 random.uniform(a, b) 生成a、b之间的随机浮点数。不过与randint不同的是，a、b无需是整数，也不用考虑大小。 random.choice(seq) 从序列中随机选取一个元素。seq需要是一个序列，比如list、元组、字符串。 random.choice([1, 2, 3, 5, 8, 13]) #list random.choice(‘hello’) #字符串 random.choice([‘hello’, ‘world’]) #字符串组成的list random.choice((1, 2, 3)) #元组 都是可行的用法。 random.randrange(start, stop, step) 生成一个从start到stop（不包括stop），间隔为step的一个随机数。start、stop、step都要为整数，且start&lt;stop。 random.sample(population, k) 从population序列中，随机获取k个元素，生成一个新序列。sample不改变原来序列。 random.shuffle(x) 把序列x中的元素顺序打乱。shuffle直接改变原有的序列。 seed()方法改变随机数生成器的种子，可以在调用其他随机模块函数之前调用此函数, 注意其实是伪随机数，只要初始值一样，得到的结果会是一样的，在python中，默认用系统时间作为seed。你也可以手动调用random.seed(x)来指定seed。 datetime库datetime模块定义了5个类，分别是 datetime.date：表示日期的类 datetime.datetime：表示日期时间的类 datetime.time：表示时间的类 datetime.timedelta：表示时间间隔，即两个时间点的间隔 datetime.tzinfo：时区的相关信息 datetime.date类：date类有三个参数,datetime.date(year,month,day)，返回year-month-day 方法： datetime.date.ctime(),返回格式如 Sun Apr 16 00:00:00 2017 datetime.date.fromtimestamp(timestamp),根据给定的时间戮，返回一个date对象；datetime.date.today()作用相同 datetime.date.isocalendar():返回格式如(year，month，day)的元组,(2017, 15, 6) datetime.date.isoformat()：返回格式如YYYY-MM-DD datetime.date.isoweekday()：返回给定日期的星期（0-6），星期一=0，星期日=6 datetime.date.replace(year,month,day)：替换给定日期，但不改变原日期 datetime.date.strftime(format):把日期时间按照给定的format进行格式化。 datetime.date.timetuple()：返回日期对应的time.struct_time对象 datetime.date.weekday()：返回日期的星期 datetime.time类：time类有5个参数，datetime.time(hour,minute,second,microsecond,tzoninfo),返回08:29:30 datetime.time.replace() datetime.time.strftime(format):按照format格式返回时间 datetime.time.tzname()：返回时区名字 datetime.time.utcoffset()：返回时区的时间偏移量 datetime.datetime类：datetime类有很多参数，datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])，返回年月日，时分秒 datetime.datetime.ctime() datetime.datetime.now().date()：返回当前日期时间的日期部分 datetime.datetime.now().time()：返回当前日期时间的时间部分 datetime.datetime.fromtimestamp() datetime.datetime.now()：返回当前系统时间 datetime.datetime.replace() datetime.datetime.strftime()：由日期格式转化为字符串格式 datetime.datetime.strptime():由字符串格式转化为日期格式 datetime.timedelta类： datetime.datetime.timedelta用于计算两个日期之间的差值， datetime.datetime.strptime():由字符串格式转化为日期格式]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记（2）数据类型]]></title>
    <url>%2F2017%2F09%2F16%2FPython%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[类型的概念：类型是编程语言对数据的一种划分。 Python语言的类型： 数字类型、字符串类型、元组类型、列表类型、文件类型、字典类型。 数字类型：数字类型对Python语言中数字的表示和使用进行了定义和规范。 Python语言包括三种数字类型： 整数类型：与数学中的整数概念一致，没有取值范围限制。 浮点数类型：Python语言中浮点数的数值范围存在限制，小数精度也存在限制。这种限制与在不同计算机系统有关。一般计算机范围为，从10的-308次方 —到10的308次方，小数点后精度可达53位。 复数类型：与数学中的复数概念一致，z = a + bj , a是实数部分，b是虚数部分，a和b都是浮点类型，虚数部分用j 或者J标识。例：12.3+4j。对于复数z，可以用z.real获得实数部分，z.imag获得虚数部分。 数字类型之间的关系： 三种类型存在一种逐渐“扩展”的关系： 整数 -&gt; 浮点数 -&gt; 复数 (整数是浮点数的特例，浮点数是复数的特例) 不同数字类型之间可以进行混合运算，运算后生成结果为最宽类型。 数字类型的转换：三种类型可以相互转换，函数：int(), float(), complex(). 示例： int(4.5) = 4 (直接去掉小数部分) float(4) = 4.0 (增加小数部分) complex(4) = 4 + 0j 数字类型的判断：函数：type(x)，返回x的类型，使用与所用类型的判断。 示例： 123&gt;&gt;&gt; type(5.2)&lt;class 'float'&gt;&gt;&gt;&gt; 数字类型的运算： 运算符和运算函数 操作含义 x//y 不大于x与y之商的最大整数 x%y x与y之商的余数 x **y x的y次幂 abs(x) x的绝对值 divmod(x,y) (x//y,x%y) pow(x,y) x的y次幂 字符串类型： 字符串是用双引号””或者单引号’’括起来的一个或多个字符。 字符串可以保存在变量中，也可以单独存在。 可以用type()函数测试一个字符串的类型。 Python语言转义符： \。 输出带有引号的字符串，可以使用转义符。 使用\ 输出带有转移符的字符串。 字符串操作： 字符串是一个字符序列：字符串最左端位置标记为0，依次增加。字符串中的编号叫做“索引” 单个索引辅助访问字符串中的特定位置 。格式为： &lt; string &gt;[&lt; 索引 &gt;]。 Python中字符串索引从0开始，一个长度为L的字符串最后一个字符的位置是L-1 Python同时允许使用负数从字符串右边末尾向左边进行反向索引，最右侧索引值是-1。 可以通过两个索引值确定一个位置范围，返回这个范围的子串。格式： &lt; string &gt;[&lt; start &gt; : &lt; end &gt;]。 start和end都是整数型数值，这个子序列从索引start开始直到索引end结束，但不包括end位置。 字符串之间可以通过+或*进行连接。 加法操作(+)将两个字符串连接成为一个新的字符串。 乘法操作(*)生成一个由其本身字符串重复连接而成的字符串。 len()函数能否返回一个字符串的长度。 大多数数据类型都可以通过str()函数转换为字符串。 字符串操作示例： 123456789101112131415161718192021&gt;&gt;&gt; str1 = "hello"&gt;&gt;&gt; str2 = "Python"&gt;&gt;&gt; type(str1) #用type()测试字类型&lt;class 'str'&gt;&gt;&gt;&gt; print("\"hello\"") #输入引号"hello"&gt;&gt;&gt; print(str1[1]) #输出字符串str1的第2个字符e&gt;&gt;&gt; str1[-4] #字符串倒数第四个字符'e'&gt;&gt;&gt; str1[0:4] #字符串第一个到第四个字符'hell'&gt;&gt;&gt; str1 + str2 #字符串加法操作'helloPython'&gt;&gt;&gt; 3 * str1 #字符串乘法操作'hellohellohello'&gt;&gt;&gt; len(str1) #字符串长度5&gt;&gt;&gt; str(123) #把数组转换位字符串'123'&gt;&gt;&gt; 字符串使用实例：输入一个月份数字，返回对应月份名称缩写 这个问题的IPO模式是： 输入：输入一个表示月份的数字(1-12) 处理：利用字符串基本操作实现该功能 输出：输入数字对应月份名称的缩写 123456789101112#month.pymonths = "JanFebMarAprMayJunJulAugSepOctNovDec"n = input("请输入月份数（1-12）：")pos = (int(n) - 1) * 3monthAbbrev = months[pos:pos+3]print("月份简写是：" + monthAbbrev + ".")#程序运行结果：#=============== RESTART: D:\我的文件\Python程序\输入数字月#份，转换位英语缩写月份.py ===============请输入月份数（1-12）：11月份简写是：Nov.&gt;&gt;&gt; 字符串的处理方法： 操作 含义 + 连接 * 重复 &lt; string &gt;[ ] 索引 &lt; string &gt;[ : ] 剪切 len(&lt; string &gt;) 长度 &lt; string &gt;.upper() 字符串中字母大写 &lt; string &gt;.lower() 字符串中字母小写 &lt; string &gt;.strip() 去两边空格及去指定字符 &lt; string &gt;.split() 按指定字符分割字符串为数组 &lt; string &gt;.join() 连接两个字符串序列 &lt; string &gt;.find() 搜索指定字符串 &lt; string &gt;.replace() 字符串替换 for &lt; var &gt; in &lt; string &gt; 字符串迭代 可以通过for 和in 组成的循环来遍历字符串中每个字符。 1格式：for &lt; var &gt; in &lt; string &gt;: 操作 字符串的格式化方法：Python语言中提供两种字符串的格式化方法。一种类似C语言的格式化方法，使用%；另一种采用format()方法，Python推荐使用第二种。 字符串类型格式化采用format()方法，基本使用格式是： &lt;模板字符串&gt;.format(&lt;逗号分隔的参数&gt;) &lt;模板字符串&gt;由一系列的槽组成，用来控制修改字符串中嵌入值出现的位置，其基本思想是将format()方法的&lt;逗号分隔的参数&gt;中的参数按照序号关系替换到&lt;模板字符串&gt;的槽中。 槽用大括号({})表示，如果大括号中没有序号，则按照出现顺序替换。如下图： 方法槽顺序.png) 如果大括号中指定了使用参数的序号，按照序号对应参数替换，如下图所示。调用format()方法后会返回一个新的字符串，参数从0 开始编号。 例如： 1234567#默认排序&gt;&gt; "&#123;&#125;:计算机&#123;&#125;的CPU占用率为&#123;&#125;%。".format("2016-12-31","Python",10)'2016-12-31:计算机Python的CPU占用率为10%。'#指定排序&gt;&gt;&gt; "&#123;1&#125;:计算机&#123;2&#125;的CPU占用率为&#123;0&#125;%。".format(10,"2016-12-31","Python")'2016-12-31:计算机Python的CPU占用率为10%。'&gt;&gt;&gt; format()方法可以非常方便地连接不同类型的变量或内容，如果需要输出大括号，采用{ {表示 { ， } } 表示 } ，例如： 12345678910&gt;&gt;&gt; "&#123;&#125;&#123;&#125;&#123;&#125;".format("圆周率",3.1415926,"...")'圆周率3.1415926...'&gt;&gt;&gt; "圆周率&#123;&#123;&#123;1&#125;,&#123;2&#125;&#125;&#125;是&#123;0&#125;".format("无理数",3.1415926,"...")'圆周率&#123;3.1415926,...&#125;是无理数'&gt;&gt;&gt; s = "圆周率&#123;&#123;&#123;1&#125;,&#123;2&#125;&#125;&#125;是&#123;0&#125;" #大括号本身是字符串的一部分&gt;&gt;&gt; s'圆周率&#123;&#123;&#123;1&#125;,&#123;2&#125;&#125;&#125;是&#123;0&#125;'&gt;&gt;&gt; s.format("无理数",3.1415926,"...") #当调用format()是解析大括号'圆周率&#123;3.1415926,...&#125;是无理数'&gt;&gt;&gt; format()方法中&lt;模板字符串&gt;的槽除了包括参数序号，还可以包括格式控制信息。此时，槽的内部样式如下： {&lt;参数序号&gt;: &lt;格式控制标记&gt;} 其中，&lt;格式控制标记&gt;用来控制参数显示时的格式，如下图： &lt;格式控制标记&gt;包括：&lt;填充&gt;&lt;对齐&gt;&lt;宽度&gt;,&lt;.精度&gt;&lt;类型&gt;6 个字段，这些字段都是可选的，可以组合使用，逐一介绍如下。 &lt;填充&gt;、&lt;对齐&gt;和&lt;宽度&gt;是3 个相关字段。&lt;宽度&gt;指当前槽的设定输出字符宽度，如果该槽对应的format()参数长度比&lt;宽度&gt;设定值大，则使用参数实际长度。如果该值的实际位数小于指定宽度，则位数将被默认以空格字符补充。&lt;对齐&gt;指参数在&lt;宽度&gt;内输出时的对齐方式，分别使用&lt;、&gt;和^三个符号表示左对齐、右对齐和居中对齐。&lt;填充&gt;指&lt;宽度&gt;内除了参数外的字符采用什么方式表示，默认采用空格，可以通过&lt;填充&gt;更换。例如： 123456789101112&gt;&gt;&gt; s = "Python"&gt;&gt;&gt; "&#123;0:30&#125;".format(s) #指定宽度为30,'Python '&gt;&gt;&gt; "&#123;0:&gt;30&#125;".format(s) #右对齐' Python'&gt;&gt;&gt; "&#123;0:*^30&#125;".format(s) #居中对齐,填充*'************Python************'&gt;&gt;&gt; "&#123;0:-^30&#125;".format(s) #居中对齐,填充-'------------Python------------'&gt;&gt;&gt; "&#123;0:3&#125;".format(s) #指定宽度为3,'Python'&gt;&gt;&gt; &lt;格式控制标记&gt;中逗号（，）用于显示数字的千位分隔符，例如： 123456789&gt;&gt;&gt; "&#123;0:-^20,&#125;".format(1234567890) #填充-，居中对齐，宽度为20，逗号分割千位分割符'---1,234,567,890----'&gt;&gt;&gt; "&#123;0:-^20&#125;".format(1234567890) #不分割输出'-----1234567890-----'&gt;&gt;&gt; "&#123;0:-^20&#125;".format(123456.7890)'-----123456.789-----'&gt;&gt;&gt; "&#123;0:-^20,&#125;".format(123456.7890)'----123,456.789-----'&gt;&gt;&gt; &lt;.精度&gt;表示两个含义，由小数点（.）开头。对于浮点数，精度表示小数部分输出的有效位数。对于字符串，精度表示输出的最大长度。 123456&gt;&gt;&gt; "&#123;0:.2f&#125;".format(12345.67890)'12345.68'&gt;&gt;&gt; "&#123;0:H^20.3f&#125;".format(12345.67890) #填充H，居中对齐，宽度20，保留3位小数'HHHHH12345.679HHHHHH'&gt;&gt;&gt; "&#123;0:.4&#125;".format("Python") #保留前四位字符'Pyth' &lt;类型&gt;表示输出整数和浮点数类型的格式规则。对于整数类型，输出格式包括6 种： b: 输出整数的二进制方式； c: 输出整数对应的 Unicode 字符； d: 输出整数的十进制方式； o: 输出整数的八进制方式； x: 输出整数的小写十六进制方式； X: 输出整数的大写十六进制方式； 12&gt;&gt;&gt; "&#123;0:b&#125;,&#123;0:c&#125;,&#123;0:d&#125;,&#123;0:o&#125;,&#123;0:x&#125;,&#123;0:X&#125;".format(255)'11111111,ÿ,255,377,ff,FF' 对于浮点数类型，输出格式包括4 种： e: 输出浮点数对应的小写字母 e 的指数形式； E: 输出浮点数对应的大写字母 E 的指数形式； f: 输出浮点数的标准浮点形式； %: 输出浮点数的百分形式。 浮点数输出时尽量使用&lt;.精度&gt;表示小数部分的宽度，有助于更好控制输出格式。 1234&gt;&gt;&gt; "&#123;0:e&#125;,&#123;0:E&#125;,&#123;0:f&#125;,&#123;0:%&#125;".format(3.14)'3.140000e+00,3.140000E+00,3.140000,314.000000%'&gt;&gt;&gt; "&#123;0:.2e&#125;,&#123;0:.2E&#125;,&#123;0:.2f&#125;,&#123;0:.2%&#125;".format(3.14) #都知道保留两位小数'3.14e+00,3.14E+00,3.14,314.00%' 元组类型：元组的概念 元组是包含多个元素的类型，元素之间用逗号分割。例如：t1 = 123,456, “hello” 元组可以是空的，t2=() 元组包含一个元素时：t3=123, 元组外侧可以使用括号，也可以不使用 元组的特点： 元组中元素可以是不同类型；一个元组也可以作为另一个元组的元素，此时，作为元素的元组需要增加括号，从而避免歧义。 元组中各元素存在先后关系，可以通过索引访问元组中元素。例如：t3[0]. 元组定义后不能更改，也不能删除。例如：t3[0]=456 与字符串类型类似，可以通过索引区间来访问元组中部分元素。例如：t[1:]与字符串一样，元组之间可以使用+号和*号进行运算。 例如： 1&gt;&gt;&gt; t3 = 123,456,("hello", "中国") 元组总结 Python语言中的元组类型定义后不能修改 因为tuple(元组)不可变，所以代码更安全。 如果仅考虑代码的灵活性，也可以用列表类型代替元组类型。 列表类型：列表的概念 列表(list)是有序的元素集合； 列表元素可以通过索引访问单个元素； 列表与元组类似 列表中每个元素类型可以不一样 访问列表中元素时采用索引形式 列表与元组不同 列表大小没有限制，可以随时修改 列表的操作： 针对列表有一些基本操作，这些操作与字符串操作类似。 列表操作符 含义 &lt; list1 &gt; + &lt; list2&gt; 连接两个列表 &lt; list &gt; * &lt; 整数类型&gt; 对列表进行整数次重复 &lt; list &gt; [&lt; 整数类型&gt;] 索引列表中的元素 len( &lt; seq &gt; ) 列表中元素个数 &lt; list &gt;[ &lt; 整数类型&gt; : &lt; 整数类型&gt;] 取列表的一个子序列 for &lt; var &gt; in &lt; list &gt; : 对列表进行循环列举 &lt; expr &gt; in &lt; list &gt; 成员检查，判断是否 列表操作示例： 1234567891011121314151617181920212223&gt;&gt;&gt; list1 = [1,2,3,4,5]&gt;&gt;&gt; lsit2 = [6,7,8,9,10]&gt;&gt;&gt; list1 + list2 #加法操作[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; list1 * 3 #乘法操作[1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5]&gt;&gt;&gt; list1[1] #列表中第二个元素2&gt;&gt;&gt; len(list1) #列表list1的长度5&gt;&gt;&gt; list1[1:4] #取出列表第2到第四个元素[2, 3, 4]&gt;&gt;&gt;for i in list1[:5]: #遍历列表 print(i)12345&gt;&gt;&gt; 2 in list1 #2是否在列表1中存在True&gt;&gt;&gt; 2 in list2 #2是否在列表2中存在False 列表相关方法： 方法 含义 &lt; list &gt; . append ( x ) 将元素x增加到列表的最后 &lt; list &gt; . sort ( ) 将列表元素排序 &lt; list &gt; . reverse ( ) 将序列元素反转 &lt; list &gt; . index ( ) 返回第一次出现元素x的索引值 &lt; list &gt; . insert ( i, x ) 在位置i处插入新元素x &lt; list &gt; . count ( x ) 返回元素x在列表中的数量 &lt; list &gt; . remove ( x ) 删除列表中第一次出现的元素x &lt; list &gt; . pop ( i ) 取出列表中位置i的元素，并删除它 示例： 123456789101112131415161718192021&gt;&gt;&gt; list3[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; list3.reverse() #列表反转&gt;&gt;&gt; list3[6, 5, 4, 3, 2, 1]&gt;&gt;&gt; list3.index(3) #f返回第一次3出现的索引值3&gt;&gt;&gt; list3.insert(2,7) #在第3个位置插入7&gt;&gt;&gt; list3[6, 5, 7, 4, 3, 2, 1]&gt;&gt;&gt; list3.sort() #排序&gt;&gt;&gt; list3[1, 2, 3, 4, 5, 6, 7]&gt;&gt;&gt; list3.count(4) #返回4在列表中的数量1&gt;&gt;&gt; list3.remove(7) #删除第一次出现的7&gt;&gt;&gt; list3[1, 2, 3, 4, 5, 6]&gt;&gt;&gt; list3.pop(3) #取出列中位置3的元素，并删除它4&gt;&gt;&gt; 对于字符串，可以通过split()函数，将字符串拆分成一个列表，默认以空格分割。 例如： 123&gt;&gt;&gt; "hello word hello python 1 123".split()['hello', 'word', 'hello', 'python', '1', '123']&gt;&gt;&gt; 文件类型：打开文件： 建立磁盘上的文件与程序中的对象相关联。 通过相关的文件对象获得。 文件操作：读取、写入、定位、追加、计算等。 关闭文件： 切断文件与程序的联系 写入磁盘，并释放文件缓冲区 打开文件：Open() 格式： 1234Open() &lt;variavle&gt; = open(&lt;name&gt;, &lt;mode&gt;) &lt;name&gt;磁盘文件名 &lt;mode&gt;打开模式 打开模式： 符号 含义 r 只读。如果文件不存在，则输出错误 w 只写。如果文件不存在，则自动创建文件 a 附加文件到末尾 rb 只读二进制文件。如果文件不存在，则输出错误 wb 只写二进制文件。如果文件不存在，则自动创建文件 ab 附加文件到二进制文件末尾 r+ 读写 例如： 1234#打开一个名为“number.dat”的文本文件。&gt;&gt;&gt;infile = open("number.dat", "r")#打开一个名为“music.mp3”的音频文件。&gt;&gt;&gt;infile = open("music.mp3", "rb") 文件读取： read()返回值为包含整个文件内容的一个字符串。 readline()返回值为文件下一行内容的字符串。 readlines()返回值为整个文件内容的列表，每项是以换行符为结尾的一行字符串。 例如： 12345678910111213#将文件内容输出到屏幕上def main(): fname = eval(input("Enter filename:")) infile = open(fname, "r") date = infile.read() print(date)main()#输出文件前五行内容infile = open(someFile, "r")for i in range(5) line = infile.readline() print(line[:-1]) 写入文件： 从计算机内存向文件写入数据。 write()：把含有文本数据或二进制数据块的字符串写入文件中。 writelines():针对列表操作，接收一个字符串列表作为参数，将它们写入文件。 例如： 123&gt;&gt;&gt;outfile = open("outfile.txt", "w")&gt;&gt;&gt;outfile.writelines(["hello", " " , "word" ])&gt;&gt;&gt;outfile.close() 文件遍历 常用为：拷贝文件，根据数据文件定义行走路径，将文件由一种编码转换位另外一种编码。 通用代码框架： 1234file = open(someFlie, "r")for line in file.readlines(): #处理一行的文件内容flie.close() 简化代码框架： 1234file = open(someFlie, "r")for line in file: #处理一行文件内容file.close() 例如：文件拷贝： 1234567891011121314151617def main(): #打开文件 infile = open("原文件", "r") #默认原文件已存在 outfile = open("新文件", "w") #拷贝数据 for line in infile: outfile.write(line) #关闭文件 infile.close() outfile.close() print("文件拷贝成功！")main() 字典类型： 字典是针对非序列集合而提供的一种数据类型。 字典的概念： 映射：通过任意键值查找集合中值信息的过程。 pthony中通过字典实现映射。 字典是键值对的集合：该集合以键为索引。同一个键信息对应一个键。 字典类型与序列类型的区别： 存取和访问方式不同。 键的类型不同：序列类型只能用熟悉类型的键。 字典类型可以用其他对象类型的键。 排序方式不同：序列元素保持了元素的相对关系。 而字典中的数据都是无序排列的。 映射方式不同：序列类型通过地址映射到值。 而字典类型通过键直接映射到值。 字典的操作：创建字典：字典由键和对应的值成对组成。字典也被称为关联数组或哈希表。基本语法如如下： 123dictionaryName[key] = value#创建一个字典students = &#123;"001":"小明", "002":"大明"&#125; 注意： 每个键与值用冒号隔开（：）,每对用逗号分开，整体放在花括号中{}. 键必须独一无二，但值不必。 值可以取任何的数据类型，但必须是不可变的，如字符串，数或元组。 访问字典里的值：dictionaryNmae[key] 返回键key对应的值value。 123456789101112&gt;&gt;&gt; students&#123;'001': '小明', '002': '大明'&#125;&gt;&gt;&gt; students["001"]'小明'#如果用字典里没有的键访问数据，会报错&gt;&gt;&gt; students["003"]Traceback (most recent call last): File "&lt;pyshell#11&gt;", line 1, in &lt;module&gt; students["003"]KeyError: '003'&gt;&gt;&gt; 添加数据：dictionaryNmae[key] = value 来向字典里添加数据。 1234&gt;&gt;&gt; students["003"] = "小张"&gt;&gt;&gt; students&#123;'001': '小明', '002': '大明', '003': '小张'&#125;&gt;&gt;&gt; 删除字典数据： del dictionaryNmae[key] 可以删除其中一组数据。 del dictionaryNmae 可以删除整个字典。 dictionaryNmae.clear() 可以清空字典内容。 1234567891011&gt;&gt;&gt; del students["002"] #删除编号为“002”的元素&gt;&gt;&gt; students&#123;'001': '小明', '003': '小张'&#125;&gt;&gt;&gt; del students #删除整个字典&gt;&gt;&gt;studnets.clear() #清空字典数据&gt;&gt;&gt; students #报错，因为字典不存在Traceback (most recent call last): File "&lt;pyshell#22&gt;", line 1, in &lt;module&gt; studentsNameError: name 'students' is not defined&gt;&gt;&gt; 字典的遍历： 遍历字典的键key: for key in dictionaryName.keys(): print(key) 遍历字典的值value: for value in dictionaryName.values(): print(value) 遍历字典的项 : for item in dicitonaryName.items(): print(item) 遍历字典的key-value: for item，value in adict.items(): print(item, value) 12345678910&gt;&gt;&gt; students = &#123;"001":"小明", "002":"大明" , "003":"小张"&#125; #创建字典&gt;&gt;&gt; students #显示字典&#123;'001': '小明', '002': '大明', '003': '小张'&#125;&gt;&gt;&gt; for key in students: #字典的遍历 print(key + ":" + str(students[key]))#程序运行结果：001:小明002:大明003:小张&gt;&gt;&gt; 判断一个键是否在在字典中：in 或者 not in。 1234567&gt;&gt;&gt;students&#123;'001': '小明', '002': '大明', '003': '小张'&#125;&gt;&gt;&gt; "001" in students #判断001 是否在字典中True &gt;&gt;&gt; "004" in studentsFalse&gt;&gt;&gt; 字典常用的方法： 方法名 含义 cmp(dict1，dict2) 比较两个字典元素 len(dict) 计算字典元素的个数，即键的总数 str(dict) 输出字典可打印的字符串提示 type(variable) 返回输入类型的变量 dict.clear() 清空字典元素 dict.copy() 返回一个字典的 浅复制。 dict.fromkeys() 创建一个新的字典， 以序列seq中元素做字典的键，val为字典所有键对应的初始值 dict.get(key, default = None) 返回指定键的值，如果值不在字典中返回default值 in 或 not in 判断某键是否在字典中 dict.items() 以列表返回可遍历的(键, 值) 元组数组 dict.update(dict1) 把字典dict1的键/值对更新到dict里 dict.pop(key) 删除并返回字典中的key对应的值 示例： 12345678910111213141516171819&gt;&gt;&gt; students #原字典列表&#123;'001': '小明', '002': '大明', '003': '小张'&#125;&gt;&gt;&gt; tuple(students.keys()) #遍历键('001', '002', '003')&gt;&gt;&gt; tuple(students.values()) #遍历值('小明', '大明', '小张')&gt;&gt;&gt; tuple(students.items()) #遍历键值对(('001', '小明'), ('002', '大明'), ('003', '小张'))&gt;&gt;&gt; students.get("001") #获得某键对应的值'小明'&gt;&gt;&gt; students.pop("001") #删除某个键对应的键值对，并返回删除的值'小明'&gt;&gt;&gt; students #删除后的字典列表&#123;'002': '大明', '003': '小张'&#125;&gt;&gt;&gt; type(students) #返回数据类型&lt;class 'dict'&gt;&gt;&gt;&gt; students1 = students.copy() #字典的复制&gt;&gt;&gt; students1&#123;'002': '大明', '003': '小张'&#125;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记（1）语法规则]]></title>
    <url>%2F2017%2F09%2F15%2FPython%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%E8%AF%AD%E6%B3%95%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[Python语言简介：Python，是一种面向对象的解释型计算机程序设计语言，由荷兰人Guido van Rossum于1989年发明，第一个公开发行版发行于1991年。 Python 译为 蟒蛇。 Python语言是通用语言。 Python语言是脚本语言。 Python语言是开源语言。 Python语言是跨平台语言。 Python语言是多模型语言。 程序编写的基本方法：IPO模式 I：Input 输入，程序的输入。 P：Process 处理，程序的主要逻辑。 O：Output 输出，程序的输出。 程序编写模板：input-print模板： 用户输入：input()获得输入。 运算部分：根据算法实现。 结果输出：print()输出结果。 initial-print模板： 初始变量：运算需要的初始值。 运算部分：根据算法实现。 结果输出：print()输出结果。 Python语法元素：缩进: 1个缩进 = 4个空格 缩进是用来在Python中标明代码之间的层次关系。 缩进是Python语言中表明程序框架的唯一手段。 注释： 注释是程序员在代码中加入的辅助说明信息，他不能被计算机执行，也不受语法约束，可以在里面写入任何内容。 一般来说，注释用来帮助程序员记录程序的设计方法，辅助程序阅读。 注释有两种方法： 单行注释一 # 开头 多行注释’’’（三分单引号）开头和结尾 变量： 变量是程序中最常使用，能够表示值的一个名称。 变量可以表示值的变化。 命名： 命名指给程序中自定义元素关联名字的过程，命名需要保证在程序中，名字具有唯一性。 命名需要符合如下规则： 命名规则使用大小写字母、数字和下划线的组和，但首字母只能是大小写字母或下划线，不能使用空格。 中文等非字母符号也可以作为名字。 合法命名的标识符： python_is_good python_is_not_good is_it_a___question_ python语言 表达式： 表达式指程序中产生或计算新数据值的一行代码。 Python语言的33个保留字或者操作符可以产生符合语法的表达式。 空格的使用： 表示缩进关系的空格不能改变。 空格不能将一个命名分割。 除上述两条外，程序中可以任意使用空格增加程序的可读性。 输入函数： Input()函数从控制台获得用户输入。 使用方法如下： &lt;变量&gt; = input（”&lt;提示性文字&gt;”） 获得的用户输入字符以字符串形式保存在&lt;变量&gt;中。 分支语句： 分支语句用来根据判断条件选择程序执行不同的路径。 分支语句基本过程： 123456789if &lt;条件1成立&gt; &lt;表达式组1&gt;elif&lt;条件2成立&gt; &lt;表达式组2&gt; ······elif&lt;条件N-1成立&gt; &lt;表达式组N-1&gt;else: &lt;表达式组N&gt; 赋值语句： 同步赋值指同时给多个变量赋值，即先运算右侧N个表达式，然后同时将表达式结果赋值给左侧。 1&lt;变量1&gt;,···，&lt;变量N&gt; = &lt;表达式1&gt;,···，表达式N&gt; 例如：将x与y交换。 正常为 t = x; x =y; y =t; 采用同步赋值语句，仅需一行代码：x , y = y , x 输入函数： print()函数用来输出字符信息，或以字符的形式输出变量的值。 print() 函数的通过%来选择要输出的变量。 循环语句： 循环语句是控制程序循环运行的语句。该类语句一般根据判断条件或者技术条件确定一段程序的运行次数。 计数循环的基本过程： 12for i in range(&lt;计数值&gt;); &lt;表达式组&gt; 例：使某一段程序连续运行10次、 12for i in range (10); &lt;表达式组&gt; def定义函数： 函数是一组代码的集合，用于表达一个功能，或者说函数表示一组代码的归属，函数名称是这段代码的名字。 def所定义的函数在程序中未经调用不能直接执行，需要通过函数名调用才能够执行。 import： import &lt;库名&gt; from &lt;库名&gt; import &lt;函数名&gt; 两种引用方式的区别： 这两种引用方式对程序运行没有区别，需注意： 如果采用第一种方式，用户自定义的函数名字可以和库函数中的名字一样。 如果采用第二种方式，用户程序中不能用函数库中的名字定义函数。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性顺序表]]></title>
    <url>%2F2017%2F09%2F14%2F%E7%BA%BF%E6%80%A7%E9%A1%BA%E5%BA%8F%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[线性表：简介：线性表是最基本、最简单、也是最常用的一种数据结构。 线性表中数据元素之间的关系是一对一的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的（注意，这句话只适用大部分线性表，而不是全部。比如，循环链表逻辑层次上也是一种线性表（存储层次上属于链式存储），但是把最后一个数据元素的尾指针指向了首位结点）。 我们说“线性”和“非线性”，只在逻辑层次上讨论，而不考虑存储层次，所以双向链表和循环链表依旧是线性表。 在数据结构逻辑层次上细分，线性表可分为一般线性表和受限线性表。一般线性表也就是我们通常所说的“线性表”，可以自由的删除或添加结点。受限线性表主要包括栈和队列，受限表示对结点的操作受限制。 线性表的逻辑结构简单，便于实现和操作。因此，线性表这种数据结构在实际应用中是广泛采用的一种数据结构。 定义：线性表（linear list）是数据结构的一种，一个线性表是n个具有相同特性的数据元素的有限序列。数据元素是一个抽象的符号，其具体含义在不同的情况下一般不同。 在稍复杂的线性表中，一个数据元素可由多个数据项（item）组成，此种情况下常把数据元素称为记录（record），含有大量记录的线性表又称文件（file）。 线性表中的个数n定义为线性表的长度，n=0时称为空表。在非空表中每个数据元素都有一个确定的位置，如用ai表示数据元素，则i称为数据元素ai在线性表中的位序。 线性表的相邻元素之间存在着序偶关系。如用（a1，…，ai-1，ai，ai+1，…，an）表示一个顺序表，则表中ai-1领先于ai，ai领先于ai+1，称ai-1是ai的直接前驱元素，ai+1是ai的直接后继元素。当i=1,2，…，n-1时，ai有且仅有一个直接后继，当i=2，3，…，n时，ai有且仅有一个直接前驱。 特征： 集合中必存在唯一的一个“第一元素”。 集合中必存在唯一的一个 “最后元素” 。 除最后一个元素之外，均有 唯一的后继(后件)。 除第一个元素之外，均有 唯一的前驱(前件)。 基本操作： MakeEmpty(L) 这是一个将L变为空表的方法 Length（L） 返回表L的长度，即表中元素个数 Get（L，i） 这是一个函数，函数值为L中位置i处的元素（1≤i≤n） Prior（L，i） 取i的前驱元素 Next（L，i） 取i的后继元素 Locate（L，x） 这是一个函数，函数值为元素x在L中的位置 Insert（L，i，x）在表L的位置i处插入元素x，将原占据位置i的元素及后面的元素都向后推一个位置 Delete（L，p） 从表L中删除位置p处的元素 IsEmpty(L) 如果表L为空表(长度为0)则返回true，否则返回false Clear（L）清除所有元素 Init（L）同第一个，初始化线性表为空 Traverse（L）遍历输出所有元素 Find（L，x）查找并返回元素 Update（L，x）修改元素 Sort（L）对所有元素重新按给定的条件排序 strstr(string1,string2)用于字符数组的求string1中出现string2的首地址 顺序表的定义： 顺序表是在计算机内存中以数组的形式保存的线性表，是指用一组地址连续的存储单元依次存储数据元素的线性结构。线性表采用顺序存储的方式存储就称之为顺序表。顺序表是将表中的结点依次存放在计算机内存中一组地址连续的存储单元中。 将表中元素一个接一个的存入一组连续的存储单元中，这种存储结构是顺序结构。 顺序表的表示与实现：base.h： 这个头文件主要用来存放公用的常量和类型。 12345678910111213141516171819//base.h//-----公用的常量和类型----------#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;time.h&gt;using namespace std;#include&lt;malloc.h&gt;#include&lt;string.h&gt;//函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define INFEASIBLE -1 //不可行的 infeaslble#define OVERFLOW -2typedef int Status;typedef int ElemType; sqList.h： aqList.h头文件用来具体实体实现各函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181//sqList.h//线性表存储空间的初始化分配量，为100#define LIST_INIT_SIZE 100//线性表存储空间的分配增量 10#define LISTINCREMENT 10typedef struct&#123; ElemType * elem; //存放空间基址 int length; //当前长度 int listsize; //当前分配的存储容量&#125;SqList;//构造一个空的线性表Status InitList_Sq(SqList &amp;L)&#123; //构造一个空的线性表L L.elem = (ElemType *)malloc(LIST_INIT_SIZE * sizeof(ElemType)); if(!L.elem) exit(OVERFLOW); //如果存储分配失败，退出 L.length = 0; //空白长度为0 L.listsize = LIST_INIT_SIZE; //初始存储容量 return OK;&#125;//InitList_Sq//销毁列表LStatus DestroyList(SqList &amp;L)&#123; if(L.elem)&#123; free(L.elem); L.elem = NULL; cout&lt;&lt;"线性表销毁成功！"&lt;&lt;endl; return OK; &#125;else&#123; cout&lt;&lt;"线性表不存在,不需要销毁！"&lt;&lt;endl; return ERROR; &#125;&#125;//DestroyList//初始条件：线性表L已存在//操作结果：将L置为空表Status ClearList_Sq(SqList &amp;L)&#123; L.length = 0; cout&lt;&lt;"线性表清空成功！"&lt;&lt;endl; return OK;&#125;//ClearList_Sq//初始条件：线性表L已存在//操作结果：若为空表返回TRUE，不为空返回FALSEStatus ListIsEmpty_Sq(SqList L)&#123; if(L.length == 0) //如果列表长度为0，返回TRUE return TRUE; else //否则返回FALSE return FALSE;&#125;// ListIsEmpty_Sq//初始条件：线性表L已存在//操作结果：返回线性表中元素的个数Status ListLength_Sq(SqList L)&#123; return L.length;&#125;//ListLength//初始条件：线性表L已存在//操作结果：获得列表第i个值Status GetElem_Sq(SqList L, int i, ElemType &amp;e)&#123; if(L.length == 0 || i &lt; 1 || i &gt; L.length) return ERROR; e = L.elem[i-1]; return OK;&#125;//GetElem_Sq//初始条件：线性表L已存在//操作：查找其中某个值，返回L中第一个与e相等的数据元素的位序// 若没找到返回0Status LocateElem_Sq(SqList L, ElemType e)&#123; int i = 1; ElemType *p = L.elem; while(i &lt;= L.length &amp;&amp; *p++ != e) ++i; if(i &lt; L.length) return i; else return 0;&#125;//LocateElem_Sq//初始条件：线性表L已存在//操作：获得前驱Status PriorElem_Sq(SqList L, ElemType cur_e, ElemType pre_e)&#123; int i=0; while(i &lt; L.length &amp;&amp; !(L.elem[i] == cur_e)) ++i; if(i == 0 || i == L.length)&#123; cout&lt;&lt;cur_e&lt;&lt;"没有前驱！"&lt;&lt;endl; return ERROR; &#125;else&#123; pre_e = L.elem[i-1]; cout&lt;&lt;cur_e&lt;&lt;"的前驱是："&lt;&lt;pre_e&lt;&lt;endl; return OK; &#125;&#125;//PriorElem_Sq//初始条件：线性表L已存在//操作：求后继Status NextElem_Sq(SqList L, ElemType cur_e, ElemType next_e)&#123; int i=0; while(i &lt; L.length &amp;&amp; !(L.elem[i] == cur_e)) ++i; if(i &gt;= L.length - 1)&#123; cout&lt;&lt;cur_e&lt;&lt;"没有后继！"&lt;&lt;endl; return ERROR; &#125;else&#123; next_e = L.elem[i+1]; cout&lt;&lt;cur_e&lt;&lt;"的后继是："&lt;&lt;next_e&lt;&lt;endl; return OK; &#125;&#125;//NextElem_Sq//初始条件：线性表L已存在//操作，插入一个元素Status ListInsert_Sq(SqList &amp;L, int i, ElemType e)&#123; //在顺序线性表L中第i个位置之前插入新的元素e //i的合法值为 1&lt;= i &lt;=ListLength_Sq(L) + 1; if(i &lt; 1 || i &gt; L.length+1) return ERROR; //如果i的值不合法，返回错误 if(L.length &gt;= L.listsize)&#123; ElemType *newbase; newbase = (ElemType *)realloc(L.elem, (L.listsize + LISTINCREMENT) * sizeof(ElemType)); if(!newbase) //如果空间分配失败，返回溢出 return OVERFLOW; L.elem = newbase; //把分配的新地址给列表 L.listsize += LISTINCREMENT; //增加存储容量 &#125; ElemType *q, *p; q = &amp;(L.elem[i-1]); //q为插入的位置 for(p = &amp;(L.elem[L.length - 1]); p &gt;= q; --p) *(p + 1) = *p; //插入位置之后的元素右移 *q = e; //插入e ++L.length; //列表长度加1 return OK;&#125;//ListInsert_Sq//初始条件：线性表L已存在//操作：删除某个元素Status ListDelete_Sq(SqList &amp;L, int i, ElemType &amp;e)&#123; //在顺序线性表中删除第i个元素，并用e返回其值 //i的合法值为 1&lt;= i &lt;= L.length_Sq(L) if(i &lt; 1 || i &gt; L.length) return ERROR; ElemType *p = &amp;(L.elem[i-1]);//p为删除元素的位置 e = *p; //被删除元素的值赋给e ElemType *q = L.elem + L.length - 1; //q为列表尾元素地址 for(++p; p &lt;= q; ++p) *(p-1) = *p; //被删除元素之后的位置左移 --L.length; //表常减1 return OK;&#125;//ListDelete_Sq//初始条件：线性表L已存在//操作：修改表中元素Status Update_Sq(SqList L, ElemType cur_e, ElemType new_e)&#123; if(LocateElem_Sq(L,cur_e) != 0) &#123; L.elem[LocateElem_Sq(L,cur_e)-1] = new_e; cout&lt;&lt;"元素更新成功！"&lt;&lt;endl; return OK; &#125;else&#123; cout&lt;&lt;"本列表中没有 "&lt;&lt;cur_e&lt;&lt;"元素，无法更新数据！"&lt;&lt;endl; return ERROR; &#125;&#125;//Update_Sq//遍历列表Status ListTraverse(SqList &amp;L)&#123; if(L.length == 0) cout&lt;&lt;"列表为空表！"&lt;&lt;endl; else&#123; for(int i = 1; i &lt;= L.length; i++)&#123; if(i == L.length) //如果为最后一个数，最后输出换行符 cout&lt;&lt;L.elem[i-1]&lt;&lt;endl; else cout&lt;&lt;L.elem[i-1]&lt;&lt;" , "; &#125; &#125; return OK;&#125;//LisetTraverse main.cpp： 用来测试上面的函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243#include "base.h"#include "sqList.h"int main()&#123; SqList L; int i; ElemType e; InitList_Sq(L); //初始化线性表 cout&lt;&lt;"遍历表："; ListTraverse(L); //遍历表 //给表赋值 for(i = 0; i &lt; 10; i++) ListInsert_Sq(L,1,i); cout&lt;&lt;"列表是否为空："&lt;&lt;ListIsEmpty_Sq(L)&lt;&lt;endl; cout&lt;&lt;"在给列表赋值十个值后的遍历表："; ListTraverse(L); //遍历表 cout&lt;&lt;"列表的长度是："&lt;&lt;ListLength_Sq(L)&lt;&lt;endl; ListInsert_Sq(L,5,500); //在第五个位置插入500 cout&lt;&lt;"第五个位置插入500后的遍历表："; ListTraverse(L); ListDelete_Sq(L,5,e); cout&lt;&lt;"删除操作，删除的数是："&lt;&lt;e&lt;&lt;endl; cout&lt;&lt;"删除第五个位置的元素后的遍历表："; ListTraverse(L); GetElem_Sq(L,5,e); cout&lt;&lt;"获取第五个位置的数："&lt;&lt;e&lt;&lt;endl; cout&lt;&lt;"与1相等的是第："&lt;&lt;LocateElem_Sq(L,1)&lt;&lt;"位"&lt;&lt;endl; cout&lt;&lt;"把8改为3操作："; Update_Sq(L,8,3); cout&lt;&lt;"更新元素后的遍历表："; ListTraverse(L); PriorElem_Sq(L,5,e); PriorElem_Sq(L,9,e); NextElem_Sq(L,5,e); NextElem_Sq(L,0,e); cout&lt;&lt;"清空线性表："; ClearList_Sq(L); cout&lt;&lt;"列表是否为空："&lt;&lt;ListIsEmpty_Sq(L)&lt;&lt;endl; DestroyList(L); //第一次销毁线性表 DestroyList(L);//第二次销毁线性表 return 0;&#125; 主方法测试结果： 图：程序测试结果]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据通信基础]]></title>
    <url>%2F2017%2F09%2F04%2F%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[信道特性 模拟带宽：模拟信道：信道带宽W = 最高频率f2 - 最低频率f1， 两者都是由信道的物理特性决定的。 数字信道： 只能传送离散的数字信号。信道的带宽决定了信道中能不能不失真传输的脉冲序列的最高频率。 一个数字脉冲称为一个码元，用码元速率来表示单位时间内信号波形的变换次数，即单位时间内通过信道传输的码元个数。 码元速率也叫波特率。 奈奎斯特和香农定理：奈奎斯特抽样定理 ： 要从抽样信号中无失真地恢复原信号，抽样频率应大于2倍信号最高频率。 抽样频率小于2倍频谱最高频率时，信号的频谱有混叠。 抽样频率大于2倍频谱最高频率时，信号的频谱无混叠。 香农定理：香农定理是所有通信制式最基本的原理，它描述了有限带宽、有随机热噪声信道的最大传输速率与信道带宽、信号噪声功率比之间的关系。其用公式可表示为：$$C = W log2(1+S/N)$$其中：C是信道支持的最大速度或者叫信道容量；W是信道的带宽；S是平均信号功率；N是平均噪声功率；S/N*即信噪比。 理解香农公式须注意以下几点： （1）信道容量由带宽及信噪比决定，增大带宽、提高信噪比可以增大信道容量； （2）在要求的信道容量一定的情况下，提高信噪比可以降低带宽的需求，增加带宽可以降低信噪比的需求； （3）香农公式给出了信道容量的极限，也就是说，实际无线制式中单信道容量不可能超过该极限，只能尽量接近该极限。在卷积编码条件下，实际信道容量离香农极限还差3dB；在Turbo编码的条件下，接近了香农极限。 （4）LTE中多天线技术没有突破香农公式，而是相当于多个单信道的组合。 图：奈奎斯特与香农定理 在使用香农定理时，由于S/N(信噪比)的比值通常太大，因此通常使用分贝数（dB）来表示。$$dB = 10 log 10 （S/N）$$例如：S/N = 1000时，用分贝表示就是30dB。如果带宽是3KHz，则这时的极限数据速率就应该是：$$C = W log 2 ( 1 + S/N) = 3000 * 9.97 = 30 kbps$$ 时延的计算发送时延：发送数据时使用报文或分组从节点进入到传输媒体所需的时间，计算公式为： 发送时延 = 报文或分组长度 / 信道带宽 传播时延：电磁波在信道中需要传播一定的距离而花费的时间，计算公式为： 传播时延 = 信道长度 / 电磁波在信道上的传播速率 光速：300,000km/s 电缆中的传播速度：200,000km/s , 卫星传输：约为270ms。 处理时延：数据在交换节点为存储转发进行一些必要的处理所花费的时。]]></content>
      <categories>
        <category>软考网工</category>
      </categories>
      <tags>
        <tag>通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程---贪吃蛇游戏]]></title>
    <url>%2F2017%2F09%2F03%2FJava%E7%BC%96%E7%A8%8B-%E8%B4%AA%E5%90%83%E8%9B%87%E6%B8%B8%E6%88%8F%2F</url>
    <content type="text"><![CDATA[目标： 制作使用Java语言编写贪吃蛇小游戏，实现基本贪吃蛇功能。更深刻体会Java语言的应用。 功能简介： 在本游戏中，开始游戏前有设置项可以选择。首先，可以选择是否显示网格。其次，设置地图，共提供了三种选择，地图1 是默认地图，地图2可选，还有个随机地图，会随机获取40个坐标作为石头。最后，可以设置蛇的速度，提供了三种速度。 在游戏过程中，蛇吃到自己，或者碰到石头，以及当吃完所有食物没有地方再可以生成食物时，蛇都会死亡，并弹出提示框，显示得分。在程序中还提供了一些快捷键可以使用。Shift：开始新游戏，空格键：暂停继续，方向键：控制蛇的方向等。 在游戏过程中，每次吃到一个食物，分数都会更新显示。游戏还会记录历史最高分。也会显示当前蛇移动的速度。 图：游戏主界面 游戏框架分析： Snake，Food，Ground：这是三个类，每个类里面完成各自的方法。如，蛇有蛇初始化，蛇吃食物，蛇运动等方法。食物类有判断蛇是否吃到食物，尝试食物的方法。石头类有产生石头，判断蛇是否撞到石头等方法。这是三个实体类。 Controller控制类：所有控制游戏，以及逻辑上的方法在这里面实现。比如，控制蛇的方向，开始新游戏等方法。 SnakeListener蛇监听类：一个接口，用来监听蛇是否运动。 GamePanel游戏界面类：用来显示游戏的画面。 Global全局类：用来存放全局变量，如游戏界面的宽度，高度。 MainWindow类：这是游戏的主窗体。各种按键事件在这里面实现。 Game类：游戏的主方法，用来开始程序。 图：游戏结构图 代码实现及解释：有关蛇的代码实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252package snake.entities;import java.awt.Color;import java.awt.Graphics;import java.awt.Point;import java.util.HashSet;import java.util.LinkedList;import java.util.Set;import snake.listener.SnakeListener;import snake.util.Global;public class Snake &#123; //定义方向变量，用来控制蛇的方向 public static final int UP = -1; public static final int DOWN = 1; public static final int LEFT = 2; public static final int RIGHT = -2; /* * 定义一个旧方向，和新方向。用来在改变方向时 * 判断新方向与旧方向是否相同，如果相同则说明 * 是无效方向，忽略。如果不同方向改变 */ private int oldDirection, newDirection; Ground ground = new Ground(); //定义一个坐标，用来存放食物坐标 public Point point = null; //存放蛇身体总长度，占用坐标个数 public int snakeBodyCount; private Point oldTail;//存放尾巴的坐标 private boolean life; //判断蛇是否活着 private boolean pause; //蛇是否暂停 private boolean isPause; //每次开开局蛇为暂停状态 public boolean isDie; //蛇是否死亡 public int speed = 500; //初始化蛇速度： 500ms/格 //存放蛇身体节点坐标 private LinkedList&lt;Point&gt; body = new LinkedList&lt;Point&gt;(); //定义蛇监听列表 private Set&lt;SnakeListener&gt; listener = new HashSet&lt;SnakeListener&gt;(); //构造方法，进行蛇的初始化 public Snake() &#123; init(); &#125; /* * 初始化蛇的位置，让蛇头出现在游戏界面中心， */ public void init() &#123; int x = Global.WIDTH/ 2 - 3; int y = Global.HEIGHT / 2 ; //初始化蛇，给蛇添加三个节点 for(int i = 0; i &lt; 3; i++) &#123; body.addLast(new Point(x--, y)); &#125; //初始化方向，向右 oldDirection = newDirection = RIGHT; life = true; pause = false; isPause = true; &#125; /* * 蛇移动，先判断新旧方向是否相同，相同则忽略 * 不同，进行改变方向。蛇移动，通过添加一个头节点， * 去除一个最后一个节点，达到移动的目的 */ public void move() &#123; if (!(oldDirection + newDirection == 0)) &#123; oldDirection = newDirection; &#125; //去尾 oldTail = body.removeLast(); int x = body.getFirst().x; int y = body.getFirst().y; switch(oldDirection) &#123; case UP: //向上移动 y--; //到边上了可以从另一边出现 if (y &lt; 0) &#123; y = Global.HEIGHT - 1; &#125; break; case DOWN: y++; //到边上了可以从另一边出现 if (y &gt;= Global.HEIGHT) &#123; y = 0; &#125; break; case LEFT: x--; if (x &lt; 0) &#123; x = Global.WIDTH - 1; &#125; break; case RIGHT: x++; if (x &gt;= Global.WIDTH) &#123; x = 0; &#125; break; &#125; //记录蛇头的坐标 Point newHead = new Point(x, y); //加头 body.addFirst(newHead); &#125; //蛇改变方向 public void chanceDirection(int direction) &#123; newDirection = direction; &#125; //蛇吃食物 public void eatFood() &#123; //通过添加删去的最后的尾节点，达到吃食物的目的 body.addLast(oldTail); &#125; //判断蛇是否吃到身体 public boolean isEatBody() &#123; //body.get(0)存放的为蛇头的坐标， //所有要排除蛇头，从i=1开始比较 for (int i = 1; i &lt; body.size(); i++) &#123; if (body.get(i).equals(getHead())) &#123; return true; &#125; &#125; return false; &#125; /** * 获取蛇的snakeBody链表，让食物与蛇身不重叠 * body 表示蛇身体的链表 * 返回与蛇身体坐标不重复的坐标 */ public Point getFood(LinkedList&lt;Point&gt; body) &#123; //获得与石头不重叠的坐标 point = ground.getPoint(); while (checkPoints(body)) &#123; point = ground.getPoint(); &#125; // 如果发现食物的位置和蛇身体重叠，则重新随机食物的位置 return point; // 返回这个对象本身，为创建实例时带来方便 &#125; //获得食物坐标 public Point getFoodPoint() &#123; return getFood(body); &#125; /** * 检查蛇身体链表中是否有一块与当前食物坐标相同 * @return 如果有重复返回true * 否则返回 false */ public boolean checkPoints(LinkedList&lt;Point&gt; body) &#123; for (Point p : body) if (p.getX() == point.getX() &amp;&amp; p.getY() == point.getY()) return true; // 循环遍历是否有重复 return false; &#125; //画蛇 public void drawMe(Graphics g) &#123; for(Point p : body) &#123; g.setColor(Color.PINK);//设置身体颜色 g.fill3DRect(p.x * Global.CELL_SIZE, p.y * Global.CELL_SIZE, Global.CELL_SIZE, Global.CELL_SIZE, true); //最后一个参数，raised 是否凸起的，true为是。 &#125; //画蛇头，覆盖蛇头位置 g.setColor(Color.RED); g.fill3DRect(getHead().x * Global.CELL_SIZE, getHead().y * Global.CELL_SIZE, Global.CELL_SIZE, Global.CELL_SIZE, true); &#125; //获得蛇头的坐标 public Point getHead() &#123; return body.getFirst(); &#125; //蛇死亡，生命改为false public void die() &#123; life = false; isDie = true; &#125; //一个内部类, 驱动蛇定时移动 public class SnakerDriver implements Runnable&#123; public void run() &#123; //当蛇活着的时候才进行循环 while(life) &#123; //入伙蛇没有暂停才能移动 if (!pause) &#123; move(); //蛇每次移动后，获得蛇身体总长度 getSnakeBodyCount(); //触发 SnakeListener 的状态改变事件 for(SnakeListener l : listener) &#123; l.snakeMove(Snake.this); &#125; //让蛇开开始时为暂停状态 if (isPause) &#123; pause = true; isPause = false; &#125; &#125; try &#123; //定时移动 Thread.sleep(speed); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; //让蛇开始运动， 开启一个新的线程 public void start() &#123; new Thread(new SnakerDriver()).start(); &#125; //添加监听器 public void addSnakeListener(SnakeListener l) &#123; if(l != null) &#123; this.listener.add(l); &#125; &#125; public void getSnakeBodyCount() &#123; snakeBodyCount = body.size(); &#125; //改变蛇暂停状态 public void changePause() &#123; pause = !pause; &#125; //清除身体所有节点 public void bodyClear() &#123; body.clear(); &#125;&#125; 石头的代码实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165package snake.entities;import java.awt.Color;import java.awt.Graphics;import java.awt.Point;import java.util.Random;import snake.util.Global;public class Ground &#123; /* *定义存放石头坐标的数组，1为石头，0为空白区域。 *一定要用全局静态变量，始终占用空间。否则会在产生食物时出错 */ private static final int rocks[][] = new int[Global.WIDTH][Global.HEIGHT]; //存放石头的个数 public int rocksCount = 0; //是否画网格 private boolean isDrawGriding; //选择地图是使用 public int MAP = 1; //构造方法，初始化地图 public Ground() &#123; init(); &#125; //清除所有石头 public void clear() &#123; for (int x = 0; x &lt; Global.WIDTH; x++) for (int y = 0; y &lt; Global.HEIGHT; y++) rocks[x][y] = 0; &#125; //初始化石头位置 public void init() &#123; //清除所有石头 clear(); //选择地图 switch(MAP) &#123; case 1: map1(); //地图1 //获得石头个数 getScoksCount(); break; case 2: map2(); //地图2 getScoksCount(); break; case 3: map3(); //随机地图 getScoksCount(); break; default : map1(); //默认地图1 getScoksCount(); break; &#125; &#125; //第一组默认地图石头坐标 public void map1() &#123; for(int x = 0; x &lt; Global.WIDTH; x++) &#123; rocks[x][0] = 1; rocks[x][Global.HEIGHT-1] = 1; &#125; for(int y = 0; y &lt; Global.HEIGHT; y++) &#123; rocks[0][y] = 1; rocks[Global.WIDTH-1][y] = 1; &#125; &#125; //第二个地图 public void map2() &#123; for(int x = 5; x &lt; Global.WIDTH-5; x++) &#123; rocks[x][5] = 1; rocks[x][Global.HEIGHT-4] = 1; &#125; for(int y = 9; y &lt; Global.HEIGHT-8; y++) &#123; rocks[9][y] = 1; rocks[Global.WIDTH-9][y] = 1; &#125; &#125; //随机地图，随机获得40个坐标座位石头 public void map3() &#123; Random random = new Random(); int x = 0,y = 0; for(int i = 0; i &lt; 40; i++) &#123; x = random.nextInt(Global.WIDTH); y = random.nextInt(Global.HEIGHT); rocks[x][y] = 1; &#125; &#125; //获得石头总共数目 public void getScoksCount() &#123; //每次更换地图时清零，重新获得 rocksCount = 0; for (int x = 0; x &lt; Global.WIDTH; x++) for (int y = 0; y &lt; Global.HEIGHT; y++) if (rocks[x][y] == 1) &#123; rocksCount++; &#125; &#125; //判断蛇是否吃到石头 //把蛇的所有节点与石头坐标进行比较如果想等则证明吃到石头 public boolean isSnakeEatRock(Snake snake) &#123; for(int x = 0; x &lt; Global.WIDTH; x++) &#123; for (int y = 0; y &lt; Global.HEIGHT; y++) &#123; if (rocks[x][y] == 1 &amp;&amp; x == snake.getHead().x &amp;&amp; y == snake.getHead().y) &#123; return true; &#125; &#125; &#125; return false; &#125; //获得不会与石头重叠的随机坐标 public Point getPoint() &#123; Random random = new Random(); int x = 0, y = 0; do&#123; x = random.nextInt(Global.WIDTH); y = random.nextInt(Global.HEIGHT); &#125;while(rocks[x][y] == 1); return new Point(x, y); &#125; //画石头和网格 public void drawMe(Graphics g) &#123; drawRocks(g); if (isDrawGriding) &#123; drawGriding(g); &#125; &#125; //画石头 public void drawRocks(Graphics g) &#123; for(int x = 0; x &lt; Global.WIDTH; x++) &#123; for (int y = 0; y &lt; Global.HEIGHT; y++) &#123; if (rocks[x][y] == 1) &#123; g.setColor(Color.DARK_GRAY); g.fill3DRect(x * Global.CELL_SIZE, y * Global.CELL_SIZE, Global.CELL_SIZE, Global.CELL_SIZE, true); &#125; &#125; &#125; &#125; //画网格 public void drawGriding(Graphics g) &#123; for(int x = 0; x &lt; Global.WIDTH; x++) &#123; for (int y = 0; y &lt; Global.HEIGHT; y++) &#123; g.setColor(Color.GRAY); g.fillRect(x * Global.CELL_SIZE , y * Global.CELL_SIZE, 1 , Global.HEIGHT * Global.CELL_SIZE); g.fillRect(x * Global.CELL_SIZE , y * Global.CELL_SIZE, Global.HEIGHT * Global.CELL_SIZE, 1 ); &#125; &#125; &#125; //需要要画网格 public void drawGriding() &#123; isDrawGriding = true; &#125; //不需要画网格 public void notDrawGriding() &#123; isDrawGriding = false; &#125;&#125; 食物的代码实现：1234567891011121314151617181920212223242526package snake.entities;import java.awt.Color;import java.awt.Graphics;import java.awt.Point;import snake.util.Global;public class Food extends Point&#123; Point point = null; //设置食物位置坐标 public void newFood(Point p) &#123; this.point = p; this.setLocation(p); &#125; //判断蛇是否吃到食物 public boolean isSnakeEatFood(Snake snake) &#123; return this.equals(snake.getHead()); &#125; //显示食物 public void drawMe(Graphics g) &#123; g.setColor(Color.GREEN); g.fill3DRect(point.x * Global.CELL_SIZE, point.y * Global.CELL_SIZE, Global.CELL_SIZE, Global.CELL_SIZE, true); &#125;&#125; 游戏界面GamePanel代码： 1234567891011121314151617181920212223242526272829303132333435363738394041package snake.view;import java.awt.Color;import java.awt.Graphics;import javax.swing.JPanel;import snake.entities.Food;import snake.entities.Ground;import snake.entities.Snake;import snake.util.Global;//游戏的显示界面@SuppressWarnings("serial")public class GamePanel extends JPanel&#123; private Snake snake; private Food food; private Ground ground; //显示画面 public void display(Snake snake, Food food, Ground ground) &#123; this.snake = snake; this.food = food; this.ground = ground; //会重新显示，此方法会调用下面的方法 this.repaint(); &#125; @Override protected void paintComponent(Graphics g) &#123; //重新显示 //设置背景颜色 g.setColor(Color.LIGHT_GRAY); g.fillRect(0, 0, Global.WIDTH * Global.CELL_SIZE, Global.HEIGHT * Global.CELL_SIZE); if(ground != null &amp;&amp; snake != null &amp;&amp; food != null ) &#123; this.ground.drawMe(g); this.snake.drawMe(g); this.food.drawMe(g); &#125; &#125;&#125; 蛇监听类代码：123456789package snake.listener;import snake.entities.Snake;public interface SnakeListener&#123; //蛇移动的监听 void snakeMove(Snake snake); &#125; 控制类代码实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230package snake.controller;import java.awt.event.KeyAdapter;import java.awt.event.KeyEvent;import java.io.BufferedReader;import java.io.BufferedWriter;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStreamReader;import java.io.OutputStreamWriter;import java.io.UnsupportedEncodingException;import javax.swing.JOptionPane;import snake.entities.Food;import snake.entities.Ground;import snake.entities.Snake;import snake.listener.SnakeListener;import snake.util.Global;import snake.view.GamePanel;/*控制器* 控制Ground, Snake, Food&lt;BR&gt;* 负责游戏的逻辑* 处理按键事件* 实现了SnakeListener接口, 可以处理Snake 触发的事件*/public class Controller extends KeyAdapter implements SnakeListener &#123; private Snake snake; private Food food; private Ground ground; private GamePanel gamePanel; //存放当局游戏得分 public int score = 0; //存放历史最高得分，这个数据通过读取文件来赋值 public int maxScore; public Thread thread; //构造方法，初始化 public Controller(Snake snake, Food food, Ground ground, GamePanel gamePanel) &#123; super(); this.snake = snake; this.food = food; this.ground = ground; this.gamePanel = gamePanel; //每次开始游戏读取文件，给maxScore赋值 readFile(); &#125; @Override //处理按键事件 public void keyPressed(KeyEvent e) &#123; switch (e.getKeyCode()) &#123; case KeyEvent.VK_UP://向上 snake.chanceDirection(Snake.UP); break; case KeyEvent.VK_DOWN://向下 snake.chanceDirection(Snake.DOWN); break; case KeyEvent.VK_LEFT://向左 snake.chanceDirection(Snake.LEFT); break; case KeyEvent.VK_RIGHT://向右 snake.chanceDirection(Snake.RIGHT); break; case KeyEvent.VK_SPACE://空格键，实现游戏暂停 snake.changePause(); break; case KeyEvent.VK_SHIFT://Shift键，实现开始新游戏 newGame(); break; &#125; &#125; //处理Snake 触发的 snakeMoved 事件 @Override public void snakeMove(Snake snake)&#123; /* * 判断是否还可以放下食物 * 当身体占满全部空位，没有地方再可以放食物时 * 游戏结束 * Global.count : 全局游戏界面总坐标，默认1000 * this.snake.snakeBodyCount ： 蛇的身体总长度 * ground.rocksCount ： 石头总数 * */ if (Global.count - this.snake.snakeBodyCount - ground.rocksCount &lt; 3) &#123; snake.die(); writeMaxScore(); //弹出消息框，提示游戏结束，并显示得分 JOptionPane.showMessageDialog(gamePanel, "您已获得最高分，游戏结束！\n 游戏得分："+ score); &#125; //如果蛇吃到食物，，处理蛇吃到食物的方法，并获得新的食物 if (food.isSnakeEatFood(snake)) &#123; snake.eatFood(); food.newFood(snake.getFoodPoint()); this.score +=10; &#125; //判断是否吃到石头，如果吃到石头，蛇死亡。 if (ground.isSnakeEatRock(snake)) &#123; snake.die(); //如果游戏得分大于历史记录最高分，把当前得分赋给最高分，并写入文件 writeMaxScore(); //弹出消息框，提示游戏结束，并显示得分 JOptionPane.showMessageDialog(gamePanel, "蛇撞墙死亡，游戏结束！\n 游戏得分："+ score); &#125; //如果蛇吃到身体也死亡 if(snake.isEatBody()) &#123; snake.die(); writeMaxScore(); JOptionPane.showMessageDialog(gamePanel, "蛇咬到自己死亡，游戏结束！\n 游戏得分："+ score); &#125; //如果蛇死亡，最后一次不刷新画面，如果刷新，蛇头会与石头重叠 if (!(ground.isSnakeEatRock(snake) | snake.isEatBody())) &#123; gamePanel.display(snake, food, ground); &#125; &#125; //开始游戏 public void beginGame() &#123; //开始游戏时，得分归零 score = 0; //每次开始游戏是读取文件，获得历史最高分 readFile(); //获得新的食物坐标 food.newFood(snake.getFoodPoint()); //开始蛇驱动的线程 snake.start(); //开启主窗体界面刷新的线程，用来更新分数 new Thread(thread).start(); &#125; //开始新游戏 public void newGame() &#123; //开始新游戏后，清除蛇的身体 snake.bodyClear(); //重新初始化蛇 snake.init(); //得分归零 score = 0; //获得新食物坐标 food.newFood(snake.getFoodPoint()); /* * 判断蛇是否处于死亡状态，如果是， * 则在蛇驱动中已经跳出循环，不会触发蛇的监听 * 此时再开始调用开始游戏，重新初始化游戏，重新监听蛇运动 * * 如果蛇不是死亡状态，则不执行开始游戏初始化，此时蛇处于正常监听状态 * 只重新初始化蛇和食物，分数即可开始新游戏。 */ if (snake.isDie) &#123; beginGame(); snake.isDie = false; &#125; &#125; //读文件，获取历史最高分 public void readFile()&#123; File file = new File("MaxScore.txt"); //如果文件不存在，文件输出流会自动创建文件 if (!file.exists()) &#123; try &#123; file.createNewFile(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //读取文件 BufferedReader br; try &#123; br = new BufferedReader( new InputStreamReader( new FileInputStream(file), "UTF-8")); maxScore = br.read(); br.close(); &#125; catch (UnsupportedEncodingException e1) &#123; e1.printStackTrace(); &#125; catch (FileNotFoundException e1) &#123; e1.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void writeMaxScore() &#123; if (score &gt; maxScore) &#123; maxScore = score; writeFile(); &#125; &#125; public void writeFile() &#123; File file = new File("MaxScore.txt"); //如果文件不存在，文件输出流会自动创建文件 if (!file.exists()) &#123; try &#123; file.createNewFile(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //写文件 try &#123; BufferedWriter bw = new BufferedWriter( new OutputStreamWriter( new FileOutputStream(file), "UTF-8")); bw.write(maxScore);//向文件写入最高分 bw.close();//关闭流 &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //接收主窗体中刷新界面的线程 public Thread startRefresh(Thread thread) &#123; this.thread = thread; return this.thread; &#125;&#125; 工具类全局代码：12345678910111213package snake.util;public class Global &#123; //定义格子大小 public static final int CELL_SIZE = 20; //定义边界的宽度 public static final int WIDTH = 40; //定义边界的高度 public static final int HEIGHT = 25; //记录游戏界面总共有多少坐标 public static final int count = WIDTH * HEIGHT;&#125; 游戏主窗体代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563package snake.view;import java.awt.BorderLayout;import java.awt.Component;import java.awt.ComponentOrientation;import java.awt.FlowLayout;import java.awt.event.MouseAdapter;import java.awt.event.MouseEvent;import javax.swing.ButtonGroup;import javax.swing.GroupLayout;import javax.swing.GroupLayout.Alignment;import javax.swing.JButton;import javax.swing.JCheckBox;import javax.swing.JFrame;import javax.swing.JLabel;import javax.swing.JPanel;import javax.swing.JRadioButton;import javax.swing.JSeparator;import javax.swing.JTextField;import javax.swing.LayoutStyle.ComponentPlacement;import javax.swing.SwingConstants;import javax.swing.border.EmptyBorder;import javax.swing.border.EtchedBorder;import snake.controller.Controller;import snake.entities.Food;import snake.entities.Ground;import snake.entities.Snake;import snake.util.Global;/* * 这些代码基本都在窗体直接涉及而成，所有代码基本可以忽略不看。 * 只看有注释的关键地方即可。 * 在设计中，除了让GamePanel获得焦点，其他组件都不能获得焦点。 */@SuppressWarnings("serial")public class MainWindow extends JFrame&#123; protected static final Object SnakeListener = null; private JPanel contentPane; Snake snake = new Snake(); Food food = new Food(); Ground ground = new Ground(); public JTextField txt_score; private JTextField txt_speed; private JTextField txt_maxScore; GamePanel gamePanel = new GamePanel(); Controller controller = new Controller(snake, food, ground, gamePanel); public MainWindow() &#123; setResizable(false); setTitle("\u8D2A\u5403\u86C7"); setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); //让窗体居中 setLocation(getToolkit().getScreenSize().width / 2 - Global.CELL_SIZE * Global.WIDTH / 2, getToolkit().getScreenSize().height / 2 - Global.CELL_SIZE * Global.WIDTH / 2); setSize(821, 760); addKeyListener(controller); contentPane = new JPanel(); contentPane.setFocusCycleRoot(true); contentPane.setFocusTraversalPolicyProvider(true); contentPane.setBorder(new EmptyBorder(5, 5, 5, 5)); setContentPane(contentPane); JPanel panel = new JPanel(); panel.setBorder(new EtchedBorder(EtchedBorder.LOWERED, null, null)); panel.setFocusCycleRoot(true); panel.setFocusTraversalPolicyProvider(true); gamePanel.setFocusTraversalPolicyProvider(true); gamePanel.setFocusCycleRoot(true); gamePanel.setSize(Global.CELL_SIZE * Global.WIDTH, Global.CELL_SIZE * Global.HEIGHT); gamePanel.setLayout(new BorderLayout(0, 0)); GroupLayout gl_panel = new GroupLayout(panel); gl_panel.setHorizontalGroup( gl_panel.createParallelGroup(Alignment.LEADING) .addGroup(gl_panel.createSequentialGroup() .addComponent(gamePanel, GroupLayout.PREFERRED_SIZE, 800, GroupLayout.PREFERRED_SIZE) .addContainerGap(GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)) ); gl_panel.setVerticalGroup( gl_panel.createParallelGroup(Alignment.LEADING) .addComponent(gamePanel, GroupLayout.DEFAULT_SIZE, 505, Short.MAX_VALUE) ); panel.setLayout(gl_panel); JPanel panel_1 = new JPanel(); panel_1.setFocusable(false); GroupLayout gl_contentPane = new GroupLayout(contentPane); gl_contentPane.setHorizontalGroup( gl_contentPane.createParallelGroup(Alignment.TRAILING) .addGroup(gl_contentPane.createSequentialGroup() .addComponent(panel, GroupLayout.PREFERRED_SIZE, 801, Short.MAX_VALUE) .addGap(10)) .addGroup(Alignment.LEADING, gl_contentPane.createSequentialGroup() .addComponent(panel_1, GroupLayout.PREFERRED_SIZE, 795, Short.MAX_VALUE) .addContainerGap()) ); gl_contentPane.setVerticalGroup( gl_contentPane.createParallelGroup(Alignment.LEADING) .addGroup(gl_contentPane.createSequentialGroup() .addComponent(panel, GroupLayout.PREFERRED_SIZE, 505, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(panel_1, GroupLayout.PREFERRED_SIZE, 205, Short.MAX_VALUE) .addContainerGap()) ); JPanel lable = new JPanel(); lable.setFocusable(false); lable.setBorder(new EtchedBorder(EtchedBorder.LOWERED, null, null)); JPanel panel_control = new JPanel(); panel_control.setFocusable(false); panel_control.setBorder(new EtchedBorder(EtchedBorder.LOWERED, null, null)); JPanel panel_set = new JPanel(); panel_set.setFocusable(false); panel_set.setBorder(new EtchedBorder(EtchedBorder.LOWERED, null, null)); JPanel panel_display = new JPanel(); panel_display.setFocusable(false); panel_display.setBorder(new EtchedBorder(EtchedBorder.LOWERED, null, null)); GroupLayout gl_panel_1 = new GroupLayout(panel_1); gl_panel_1.setHorizontalGroup( gl_panel_1.createParallelGroup(Alignment.LEADING) .addGroup(gl_panel_1.createSequentialGroup() .addComponent(panel_set, GroupLayout.PREFERRED_SIZE, 302, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addGroup(gl_panel_1.createParallelGroup(Alignment.TRAILING) .addComponent(panel_display, GroupLayout.PREFERRED_SIZE, 216, GroupLayout.PREFERRED_SIZE) .addComponent(panel_control, 0, 0, Short.MAX_VALUE)) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(lable, GroupLayout.PREFERRED_SIZE, GroupLayout.DEFAULT_SIZE, GroupLayout.PREFERRED_SIZE) .addGap(19)) ); gl_panel_1.setVerticalGroup( gl_panel_1.createParallelGroup(Alignment.TRAILING) .addGroup(gl_panel_1.createSequentialGroup() .addGroup(gl_panel_1.createParallelGroup(Alignment.LEADING) .addComponent(panel_set, GroupLayout.DEFAULT_SIZE, 197, Short.MAX_VALUE) .addGroup(gl_panel_1.createSequentialGroup() .addComponent(panel_display, GroupLayout.PREFERRED_SIZE, 123, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(panel_control, GroupLayout.DEFAULT_SIZE, 68, Short.MAX_VALUE)) .addComponent(lable, GroupLayout.DEFAULT_SIZE, 195, Short.MAX_VALUE)) .addContainerGap()) ); JLabel lable_score = new JLabel("\u5F53\u524D\u5F97\u5206\uFF1A"); lable_score.setFocusable(false); lable_score.setHorizontalAlignment(SwingConstants.LEFT); lable_score.setHorizontalTextPosition(SwingConstants.CENTER); lable_score.setAlignmentX(Component.CENTER_ALIGNMENT); txt_score = new JTextField(); txt_score.setText("0 分"); txt_score.setEditable(false); txt_score.setFocusable(false); txt_score.setColumns(10); JLabel label_maxScore = new JLabel("\u5386\u53F2\u6700\u9AD8\u5206\uFF1A"); label_maxScore.setFocusable(false); txt_maxScore = new JTextField(); txt_maxScore.setText(controller.maxScore + " 分"); txt_maxScore.setEditable(false); txt_maxScore.setFocusable(false); txt_maxScore.setColumns(10); JLabel label_speed = new JLabel("\u5F53\u524D\u901F\u5EA6\uFF1A"); label_speed.setFocusable(false); txt_speed = new JTextField(); txt_speed.setText(snake.speed + " 毫秒 / 格"); txt_speed.setEditable(false); txt_speed.setFocusable(false); lable_score.setLabelFor(txt_speed); txt_speed.setColumns(10); GroupLayout gl_panel_display = new GroupLayout(panel_display); gl_panel_display.setHorizontalGroup( gl_panel_display.createParallelGroup(Alignment.LEADING) .addGroup(gl_panel_display.createSequentialGroup() .addGap(6) .addGroup(gl_panel_display.createParallelGroup(Alignment.LEADING) .addComponent(lable_score, GroupLayout.PREFERRED_SIZE, 75, GroupLayout.PREFERRED_SIZE) .addComponent(label_maxScore, GroupLayout.PREFERRED_SIZE, 78, GroupLayout.PREFERRED_SIZE) .addComponent(label_speed, GroupLayout.DEFAULT_SIZE, 83, Short.MAX_VALUE)) .addPreferredGap(ComponentPlacement.RELATED) .addGroup(gl_panel_display.createParallelGroup(Alignment.LEADING, false) .addComponent(txt_maxScore, GroupLayout.DEFAULT_SIZE, 111, Short.MAX_VALUE) .addComponent(txt_speed, GroupLayout.DEFAULT_SIZE, 111, Short.MAX_VALUE) .addComponent(txt_score)) .addContainerGap(26, Short.MAX_VALUE)) ); gl_panel_display.setVerticalGroup( gl_panel_display.createParallelGroup(Alignment.LEADING) .addGroup(gl_panel_display.createSequentialGroup() .addContainerGap(24, Short.MAX_VALUE) .addGroup(gl_panel_display.createParallelGroup(Alignment.TRAILING) .addGroup(gl_panel_display.createSequentialGroup() .addComponent(txt_score, GroupLayout.PREFERRED_SIZE, 21, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.UNRELATED) .addComponent(txt_maxScore, GroupLayout.PREFERRED_SIZE, GroupLayout.DEFAULT_SIZE, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(txt_speed, GroupLayout.PREFERRED_SIZE, GroupLayout.DEFAULT_SIZE, GroupLayout.PREFERRED_SIZE) .addGap(16)) .addGroup(gl_panel_display.createSequentialGroup() .addComponent(lable_score, GroupLayout.PREFERRED_SIZE, 18, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.UNRELATED) .addComponent(label_maxScore, GroupLayout.PREFERRED_SIZE, 25, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(label_speed) .addGap(21)))) ); panel_display.setLayout(gl_panel_display); JLabel label_set = new JLabel("\u8BBE\u7F6E\u9879\uFF1A"); label_set.setFocusable(false); JSeparator separator = new JSeparator(); JCheckBox checkBox_isGriding = new JCheckBox("\u663E\u793A\u7F51\u683C"); checkBox_isGriding.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; if (checkBox_isGriding.isSelected()) &#123; ground.drawGriding(); &#125;else &#123; ground.notDrawGriding(); &#125; &#125; &#125;); checkBox_isGriding.setFocusable(false); JSeparator separator_1 = new JSeparator(); JLabel label_isGriding = new JLabel("\u662F\u5426\u663E\u793A\u7F51\u683C\uFF1A"); label_isGriding.setFocusable(false); JSeparator separator_2 = new JSeparator(); JPanel panel_setMap = new JPanel(); panel_setMap.setFocusable(false); JPanel panel_setSpeed = new JPanel(); panel_setSpeed.setFocusable(false); panel_setSpeed.setComponentOrientation(ComponentOrientation.LEFT_TO_RIGHT); GroupLayout gl_panel_set = new GroupLayout(panel_set); gl_panel_set.setHorizontalGroup( gl_panel_set.createParallelGroup(Alignment.LEADING) .addGroup(gl_panel_set.createSequentialGroup() .addGroup(gl_panel_set.createParallelGroup(Alignment.LEADING, false) .addGroup(gl_panel_set.createSequentialGroup() .addGap(10) .addComponent(label_set)) .addGroup(gl_panel_set.createSequentialGroup() .addGap(20) .addComponent(label_isGriding) .addPreferredGap(ComponentPlacement.UNRELATED) .addComponent(checkBox_isGriding)) .addGroup(gl_panel_set.createSequentialGroup() .addGap(20) .addComponent(separator_1, GroupLayout.PREFERRED_SIZE, 222, GroupLayout.PREFERRED_SIZE)) .addGroup(gl_panel_set.createSequentialGroup() .addGap(20) .addComponent(separator_2, GroupLayout.PREFERRED_SIZE, 224, GroupLayout.PREFERRED_SIZE)) .addGroup(gl_panel_set.createSequentialGroup() .addGap(14) .addComponent(panel_setSpeed, GroupLayout.PREFERRED_SIZE, 264, GroupLayout.PREFERRED_SIZE)) .addGroup(gl_panel_set.createSequentialGroup() .addContainerGap() .addComponent(panel_setMap, GroupLayout.DEFAULT_SIZE, GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE))) .addGap(10)) .addGroup(gl_panel_set.createSequentialGroup() .addContainerGap() .addComponent(separator, GroupLayout.DEFAULT_SIZE, 272, Short.MAX_VALUE) .addContainerGap()) ); gl_panel_set.setVerticalGroup( gl_panel_set.createParallelGroup(Alignment.LEADING) .addGroup(gl_panel_set.createSequentialGroup() .addGap(10) .addComponent(label_set) .addGap(10) .addComponent(separator, GroupLayout.PREFERRED_SIZE, 8, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addGroup(gl_panel_set.createParallelGroup(Alignment.BASELINE) .addComponent(label_isGriding) .addComponent(checkBox_isGriding)) .addGap(12) .addComponent(separator_2, GroupLayout.PREFERRED_SIZE, GroupLayout.DEFAULT_SIZE, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(panel_setMap, GroupLayout.PREFERRED_SIZE, 37, GroupLayout.PREFERRED_SIZE) .addGap(12) .addComponent(separator_1, GroupLayout.PREFERRED_SIZE, 2, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(panel_setSpeed, GroupLayout.DEFAULT_SIZE, 34, Short.MAX_VALUE) .addGap(14)) ); JLabel label_5 = new JLabel("\u9009\u62E9\u96BE\u5EA6\uFF1A"); label_5.setFocusable(false); JRadioButton radioButton_speed1 = new JRadioButton("\u521D\u7EA7"); radioButton_speed1.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; snake.speed = 500; txt_speed.setText(snake.speed + " 毫秒 / 格"); &#125; &#125;); radioButton_speed1.setSelected(true); radioButton_speed1.setFocusable(false); JRadioButton radioButton_speed2 = new JRadioButton("\u4E2D\u7EA7"); radioButton_speed2.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; snake.speed = 300; txt_speed.setText(snake.speed + " 毫秒 / 格"); &#125; &#125;); radioButton_speed2.setFocusable(false); JRadioButton radioButton_speed3 = new JRadioButton("\u9AD8\u7EA7"); radioButton_speed3.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; snake.speed = 100; txt_speed.setText(snake.speed + " 毫秒 / 格"); &#125; &#125;); radioButton_speed3.setFocusable(false); ButtonGroup groupSpeed = new ButtonGroup(); groupSpeed.add(radioButton_speed1); groupSpeed.add(radioButton_speed2); groupSpeed.add(radioButton_speed3); panel_setSpeed.setLayout(new FlowLayout(FlowLayout.CENTER, 5, 5)); panel_setSpeed.add(label_5); panel_setSpeed.add(radioButton_speed1); panel_setSpeed.add(radioButton_speed2); panel_setSpeed.add(radioButton_speed3); JLabel label_setMap = new JLabel("\u9009\u62E9\u5730\u56FE\uFF1A"); label_setMap.setFocusable(false); JRadioButton radioButton_map1 = new JRadioButton("\u5730\u56FE1"); radioButton_map1.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; ground.MAP = 1; ground.init(); &#125; &#125;); radioButton_map1.setSelected(true); radioButton_map1.setFocusable(false); JRadioButton radioButton_map2 = new JRadioButton("\u5730\u56FE2"); radioButton_map2.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; //点击鼠标后，设置为地图2 ground.MAP = 2; //重新初始化地图 ground.init(); &#125; &#125;); radioButton_map2.setFocusable(false); JRadioButton radioButton_map3 = new JRadioButton("\u968F\u673A\u5730\u56FE"); radioButton_map3.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; ground.MAP = 3; ground.init(); &#125; &#125;); radioButton_map3.setFocusable(false); ButtonGroup groupMap = new ButtonGroup(); groupMap.add(radioButton_map1); groupMap.add(radioButton_map2); groupMap.add(radioButton_map3); panel_setMap.setLayout(new FlowLayout(FlowLayout.CENTER, 5, 5)); panel_setMap.add(label_setMap); panel_setMap.add(radioButton_map1); panel_setMap.add(radioButton_map2); panel_setMap.add(radioButton_map3); panel_set.setLayout(gl_panel_set); JButton button_pause = new JButton("\u5F00\u59CB/\u6682\u505C"); button_pause.setFocusable(false); button_pause.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; snake.changePause(); &#125; &#125;); button_pause.setFocusPainted(false); JButton button_newGame = new JButton("\u5F00\u59CB\u65B0\u6E38\u620F"); button_newGame.setFocusable(false); button_newGame.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; controller.newGame(); &#125; &#125;); button_newGame.setFocusPainted(false); GroupLayout gl_panel_control = new GroupLayout(panel_control); gl_panel_control.setHorizontalGroup( gl_panel_control.createParallelGroup(Alignment.TRAILING) .addGroup(gl_panel_control.createSequentialGroup() .addContainerGap(GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE) .addComponent(button_newGame, GroupLayout.PREFERRED_SIZE, 95, GroupLayout.PREFERRED_SIZE) .addGap(3) .addComponent(button_pause, GroupLayout.PREFERRED_SIZE, 94, GroupLayout.PREFERRED_SIZE) .addContainerGap()) ); gl_panel_control.setVerticalGroup( gl_panel_control.createParallelGroup(Alignment.TRAILING) .addGroup(Alignment.LEADING, gl_panel_control.createSequentialGroup() .addContainerGap() .addGroup(gl_panel_control.createParallelGroup(Alignment.BASELINE) .addComponent(button_newGame, GroupLayout.PREFERRED_SIZE, 44, GroupLayout.PREFERRED_SIZE) .addComponent(button_pause, GroupLayout.PREFERRED_SIZE, 44, GroupLayout.PREFERRED_SIZE)) .addContainerGap(18, Short.MAX_VALUE)) ); panel_control.setLayout(gl_panel_control); JLabel lblNewLabel = new JLabel("\u8BF4\u660E\uFF1A"); lblNewLabel.setFocusable(false); lblNewLabel.setHorizontalAlignment(SwingConstants.CENTER); lblNewLabel.setHorizontalTextPosition(SwingConstants.CENTER); JLabel label = new JLabel("\u65B9\u5411\u952E\u64CD\u4F5C\u65B9\u5411"); label.setFocusable(false); JLabel label_1 = new JLabel("\u7A7A\u683C\u952E\u53EF\u5B9E\u73B0\u6682\u505C/\u7EE7\u7EED"); label_1.setFocusable(false); JLabel lblShift = new JLabel("Shift\u952E \u5F00\u59CB\u65B0\u6E38\u620F"); lblShift.setFocusable(false); JLabel label_2 = new JLabel("\u968F\u673A\u5730\u56FE\u4F1A" + "\u968F\u673A\u83B7\u5F9740\u4E2A\u5750\u6807\u4F5C\u4E3A\u77F3\u5934"); label_2.setHorizontalAlignment(SwingConstants.LEFT); label_2.setInheritsPopupMenu(false); label_2.setFocusable(false); label_2.setFocusTraversalKeysEnabled(false); label_2.setAlignmentX(Component.CENTER_ALIGNMENT); GroupLayout gl_lable = new GroupLayout(lable); gl_lable.setHorizontalGroup( gl_lable.createParallelGroup(Alignment.TRAILING) .addGroup(gl_lable.createSequentialGroup() .addGroup(gl_lable.createParallelGroup(Alignment.LEADING) .addComponent(lblNewLabel, GroupLayout.PREFERRED_SIZE, 71, GroupLayout.PREFERRED_SIZE) .addGroup(gl_lable.createSequentialGroup() .addGap(26) .addGroup(gl_lable.createParallelGroup(Alignment.LEADING) .addComponent(label_1, GroupLayout.DEFAULT_SIZE, 212, Short.MAX_VALUE) .addComponent(label, GroupLayout.PREFERRED_SIZE, 113, GroupLayout.PREFERRED_SIZE) .addComponent(lblShift) .addComponent(label_2, GroupLayout.DEFAULT_SIZE, 212, Short.MAX_VALUE)))) .addContainerGap()) ); gl_lable.setVerticalGroup( gl_lable.createParallelGroup(Alignment.LEADING) .addGroup(gl_lable.createSequentialGroup() .addGap(8) .addComponent(lblNewLabel, GroupLayout.PREFERRED_SIZE, 30, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(label, GroupLayout.PREFERRED_SIZE, 26, GroupLayout.PREFERRED_SIZE) .addGap(2) .addComponent(label_1, GroupLayout.PREFERRED_SIZE, 26, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(lblShift, GroupLayout.PREFERRED_SIZE, 25, GroupLayout.PREFERRED_SIZE) .addPreferredGap(ComponentPlacement.UNRELATED) .addComponent(label_2) .addContainerGap(39, Short.MAX_VALUE)) ); lable.setLayout(gl_lable); panel_1.setLayout(gl_panel_1); contentPane.setLayout(gl_contentPane); //给游戏面板和蛇添加监听器 gamePanel.addKeyListener(controller); snake.addSnakeListener(controller); //开始一个新的线程，用来更新分数 controller.startRefresh(new Thread(new refresh())); //开始游戏 controller.beginGame(); &#125; //创建一个线程让一直刷新分数 public class refresh implements Runnable&#123; @Override public void run() &#123; //当蛇活着的时候才进行循环 while(!snake.isDie) &#123; txt_score.setText(controller.score + " 分"); txt_maxScore.setText(controller.maxScore + " 分"); try &#123; Thread.sleep(snake.speed); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 主方法启动程序：12345678910111213141516171819202122232425package snake.game;import java.awt.EventQueue;import snake.view.MainWindow;/* * 作为游戏的主方法，启动游戏，通过启动窗体，实现启动程序 */public class Game &#123; public static void main(String[] args) &#123; EventQueue.invokeLater(new Runnable() &#123; public void run() &#123; try &#123; MainWindow frame = new MainWindow(); frame.setVisible(true); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125; 程序运行效果：设置项效果：游戏是否显示网格，可通过是否选中来设置。包括选择地图，选择速度。所有设置后在开始新游戏后生效。速度在游戏过程中也可以随时调节。效果如下图： 图：显示网格，随机地图 显示分数：在蛇每次吃到食物后，分数会加10分，并实时更新分数。以及有历史最高分。包括蛇的速度也会显示。 图：分数实时更新 蛇穿越边界：在边界没有石头时，蛇可以从一边进去，从另外一边出来。 图：穿越边界 蛇吃到石头：蛇吃到石头后就会死亡，并弹出提框，同时显示分数。 图：蛇撞墙 蛇咬到自己：蛇咬到自己也会死亡，弹出提示框。 图：蛇咬到自己 游戏代码下载：可点击下载原代码包。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语笔记（1）---语法]]></title>
    <url>%2F2017%2F08%2F26%2F%E8%8B%B1%E8%AF%AD%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89-%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[情态动词 用法： 情态动词 内容 may / might / could / must 可能性 can / be able to 能力 must / hava to 义务，必要性 表示可能性：might / may, could , must 都可以表示“可能性”， 且表示肯定的程度，一次增强。 might / could + have done 有时可以表示来发生但没有发生，或者本来可能完成却没有完成的动作。 例句： 1、_I could hava passed the exam__(我本可以通过考试的)，but I failed. 2、_Tom might have killed himself _(汤姆本来可能送命的)，but his friend sent him to the hospital. 表示能力：can , could 和 be able to 表能力时，常可以互换。但因时态限制，be able to 用途最广泛。be able to 可以强调在特定情况下能够做某事。 例句： Perhaps you can’t control you job , but you may be able to make other changes in your life. People could’t have enough time to watch TV or even couldn’t get enough money to buy one in the past. However, scientists said that TV could be cheaper , thinner and more portable at that time . Nowadays, every family can own a TV. Thus many people become couch potatoes. They can stay in front of TV for a whole day , watching soap operas. Then it is reported that obesity will be able to kill more people in the future. 表示义务，必要性：当说话人感到某事是必须的时候，用must。当客观情况要求必须做某事的时候，用have to。 例句： A: I must buy flowers for my mother. 心甘情愿的 B: I have to buy flowers for my mother-in-law. 不情愿的 Jack: “You must do me this honor… promise me you will survive… that you will never give up… no matter what happens… no matter how hopeless… Promise me now, and never let go of that promise. ​ ——The Titanic 不定式 用法： 不定式 内容 to do / to be doing / to have been doing / to have been done 根据不同语境，不定式会发生不同的形态变化。 To be or not to be ,that is a question.（生存还是毁灭，这是一个问题。） 做主语 The princess said to Shrek, “Don’t hesitate to marry me .” 做宾语 Who is the first person to fall in love with? 做定语 I got up early, so as to （为了）catch the bus . 做状语 形态变化：​ occur(发生，出现) read work give 1、It has been proved that some poeple’s best ideas seem to _ occur _ when they are relaxing and daydreaming. 事实证明，有些人的最佳想法似乎是在他们放松和做白日梦的时候发生的。 2、The boy pretended to _ be reading _when the teacher came in . 3、He is said to _ have been working _ in this company since it was established. 4、I am glad that my company sent me to another country to study . I am very pleasesd to _ have been given _ the opportunity to learn about another culture. 翻译： (1)会议上要讨论的那件事真是棘手。 难：hard / difficult / tough the issue/ the matter which (that) … is very hard / tough. The matter to be discussed at the meeting is a hard nut to crack. (2)我们花一分钟的时间去认识一个人，一小时喜欢上他，或者一天去爱上他，却会用一生去忘记他。 We take a minute to know someone , one hour to like someone , and one day to love someone , but the whole life to forget someone. 做主语：it 形式做主语。 To hold people accountable for their actions is important. It is important to hold people accountable for their actions. It is important that (we / the society) hold poeple accountable for their actions. accountable :adj , 负责任的 = responsible puppet ： n. 傀儡 在诗话，谚语等中，不定式做主语的表达固定不变。 To err is human , to forgive divine. 犯错者为人，谅错者为神。 err ：v . 犯错。 divine : adj. 神圣的。 To do this project in 24 hours is a good idea / impossible . = It’s impossible / a good idea to do this project in 24 hours. 做宾语： Why should anyone bother to risk____(risk) losing his treasure to help a stranger? The princess said to Shrek , “Don’t hesitate to marry_______(marry) me.” If you find it unworkable, we may as well call_ (call) the deal off. I would rather _die (die) than marry him. 一些动词只能 + to do ， 如 ：hesitate ,afford , appear(出现) , neglect（忽略） , determine, 另一些动词只能+ do ，如：may / might as well , would rather , cannot help but. 做定语： They say a person needs just three things to be truly happy in this world — someone to love , something to do , something to hope for. 大多数情况下，不定式 to do + prep 结构中，介词不可以省略。 Who is the first person to fall in love? Who is the first person to fall in love with ? He fell in love with a person /a girl。 例外情况，当不定式修饰time , place 或 way ， 介词可以省去。 Where is the best place to live (in)? 做状语：不定式做目的状语：为了…. I just call to say I love you , I just call to say how much I care. I just call to say I loce you ….（表目的） ___ _ （为了确保他参加会议），I called him up in advance. To ensure (guarantee) that he can join (attend ) the meeting = In order to ensure that he can… I got up early , so as to catch bus. 不定式做目的状语可以放在句首或句尾，相当于in order to 或 so as to ，so as to 一般放在句中或句尾，不放在句首。 常用 only to do 引出意想不到的或不愉快的结果。 He worked very hard. ( noly to find ) he had not finished half of the job. 短语： may / might as well do sth : 不妨做某事 risk doing sth 冒险做某事 hesitate to do 犹豫做某事 a hard nut（坚果） to crack（破裂）： 棘手的问题 in advance 提前，预先 princess : 公主。 pretended to : 假装做什么 分词和动名词 用法： Samples(样例) Grammar Points 1. A woman carrying a cut puppy(小狗) walked into the rome. (同时发生) 2. Their car was caught in a traffic jam , thus causing the delay.(表结果) 3. The running water provided a picturesque view.(做形容词)。 现在分词 4. The paintings stolen from the National Gallery last week have been found.(被动关系) 。 5. Fallen snow covered the sidewalks . （做形容词）。 过去分词 6. Seeing is believing . 动名词 7.Being deeply loved by someone gives you strength ; while loving someone deeply give you courage. 动名词 现在分词：可以表示意料中的结果，通常放于句尾。前面为原因。例子： Their car was caught in a traffic jam , (thus) causing the delay. His parents died , making / leaving him an orphan.(孤儿) 现在分词可以表示两个动作完全同时发生。加在动词之后。例子： When leaving the airport , they waved again and again to us. = When they were leaving the airport , they waved again and again to us. David turned away and walked quickly down the street , (完全无视他的存在) （totally neglecting her presence）。 = 无视： ignore 、neglect ， 存在：present ，n： presence 完全： torally completely 加在动词之后，现在分词做修饰语，同形容词用法一致。例子： The running water provides a picturesque view. The smoke coming out of the chimneys installed in factories is a mahor cause for air pollution . A man holdding a gun shouted at us to lie down. (趴下) = A man who was holing a gun shouted at us to lie down. Leaping in to the air , the dancer thrilled the audience. 因为听到外面有吵闹声，James突然停下了工作。 = Hearing a noise outside , James abruptly stopped his work. 突然停止： abruptly suddenly stopped sth 听到外面的噪音：hear a noise outside 。 过去分词：在语态上：现在分词表主动，过去分词表被动。 在时态上：现在分词表进行，过去分词表完成。 过去分词的四种用法 从结构上看，过去分词要比现在分词简单得多，因为过去分词只有一种形式，它既没有完成式，也没有被动式。为什么会这样“简单”呢？因为从意义上看，过去分词本身既可表示完成意义，同时也可表示被动意义——既然自己就身兼数职，可以轻易地搞掂多种用法，所以就不用那么麻烦了。 用法一：表示过去即表示过去某时已发生的被动动作——由于既有完成的意味，又有被动意味，符合过去分词的基本特征。如： The paintings stolen from the museum haven’t been found. 博物馆失窃的画仍未找到。 根据句意可知，“画被盗”的事已经发生了，属于已经完成的过去动作；另一方面，“画”与“偷”之间显然是被动关系，即“画”是“被”偷了，所以它又具有被动意味。 They found the windows broken. 他们发现窗户给砸碎了。 句中的过去分词broken表示窗户“破碎”在先，“发现”这一情况在后，因为先碎了，然后才能被人发现；另一方面“窗户”与“破碎”为被动关系，因为窗户破碎不是窗户自己在搞鬼，而是外界因素所致。 用法二：表示同时即表示与谓语动词同时(或几乎同时)发生的被动动作。如： Asked why he came, he kept silent. 问他为什么要来，他一言不发。 句中的过去分词asked一方面表示“问”与“他”之间为被动关系，即是别人问他（＝他被别人问），而不是他问别人；另一方面还表示“别人问他”与“他保持沉默”是同时的——当然，我们也可理解为asked要稍稍先于kept一点。不过，这没关系，这样更符合过去分词的基本用法特点。 用法三：表示状态即现在已经存在的态或过去(当时)的存在的一种被动的状态。如： The murderer was brought in, his hands tied behind. 凶手被带了进来，双手被绑在后面。 句中的过去分词tied表明“他的手”与“绑”之间为被动关系，同时它表明“绑着”这一状态发生在“凶手被带进来”之前。 用法四：表示经常性或泛指过去分词有两个基本特点，一是表示被动，二是表示完成。但有时也有例外，比如下面的例子，虽然其中的过去分词也表示被动，但它们并不表示完成，而是表示经常性，或不表明具体的时间，带有泛指的意味： He is a man loved by all. 他是一个受大家爱戴的人。 句中的过去分词loved表示“他”与“爱戴”之间为被动关系，但是它并不表示先后关系。 A letter sent by airmail should arrive sooner than the one sent by regular mail. 航空信应该比平信到得快。 句中的两个过去分词sent均用作定语，修饰其前的a letter和the one，虽然这里的sent带有被动意味，但是它并不表示完成，而只是陈述一种情况，没有时间的先后关系。 动名词： 动词ing形式的一种，兼有动词和名词特征的非限定动词。它可以支配宾语，也能被副词修饰。动名词有时态和语态的变化。动名词是非谓动词的又一种形式。它在形式上与现在分词相同，都是在动词原形的词末加-ing。在现代语法中，这两种形式同视为”-ing形式”。这两种形式的另一个相同之处是：它们都是由动词变化而成的，它们都保留了动词的某些特征，它们都能带自己的宾语、状语，而构成动名词短语或是现在分词短语去担当句子成分。动名词一般式表示的动作通常是一般性动作，即不是明确地发生在过去、现在或将来的动作，或是与谓语动词所表示的动作同时发生的动作。 例子： Being deeply loved by someone gives you strength; while loving someone deeply gives you courage. 被一个人深爱给你力量，而深爱一个人给你勇气。 Seing is believing。眼见为实。 In football , deliberately tripping an opponent is a foul. 足球运动里，故意让对方绊倒就算犯规。 绊倒：trip 。 故意的：deliberately . 犯规：foul]]></content>
      <categories>
        <category>English</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vlcj--java-制作视频播放器]]></title>
    <url>%2F2017%2F08%2F21%2Fvlcj-java-%E5%88%B6%E4%BD%9C%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE%E5%99%A8%2F</url>
    <content type="text"><![CDATA[目标：制作一个简易的视频播放器，实现对视频文件的打开，播放，暂停，退出，以及实现进度条的显示，通过点击视频播放进度条可以更改视频的播放时间。还添加调节音量的功能。 工程的准备：因为通过java制作的视频播放器是基于vlcj库建立的，所有必须首先下载vlcj，然后解压导入Java工程中调用。还要下载slf4j库，点击可下载slf4j库，最后由于视频播放器的内核是基于VLC播放器的，所有需要在电脑上下载VLC播放器，下载后安装，我这里选择安装的路径是默认路径。 一、首先下载vlcj后解压，将其中的jna-3.5.3.jar、platform-3.5.2.jar、vlcj-3.8.0.jar三个文件复制到java工程的lib文件夹中，lib文件夹需自建。 图：所需要的三个文件 二、下载slf4j库后，解压，将其中的slf4j-api-1.7.25.jar和slf4j-nop-1.7.25.jar,两个文件添加到java工程的lib文件夹中。把添加好的库添加到构建路径中，用来引用。工程结构如下图： 图：工程结构图 关于vlcj库使用说明：关于vlcj库的使用，具体可点击：Vlcj查看。在这个Java工程中，首先使用是按照官方给出的例子使用。 第一步使用自动发现本地库： 123//NativeDiscovery().discover();函数返回的是一个布尔类型的值，所有可以定义一个布尔类型的值，用来接收，利用控制台打印，是否发现本地库boolean found = new NativeDiscovery().discover(); System.out.println(found); 官方提示原代码： 12345678910111213package tutorial;import uk.co.caprica.vlcj.binding.LibVlc;import uk.co.caprica.vlcj.discovery.NativeDiscovery;public class Tutorial &#123; public static void main(String[] args) &#123; boolean found = new NativeDiscovery().discover(); System.out.println(found); System.out.println(LibVlc.INSTANCE.libvlc_get_version()); &#125;&#125; 图：使用说明 第二步，需要指定VLC路径。 1234//指定VLC路径，这里使用的路径是安装默认路径。NativeLibrary.addSearchPath(RuntimeUtil.getLibVlcLibraryName(), "C:\\Program Files\\VideoLAN\\VLC");//打印版本，用来检验是否获得文件System.out.println(LibVlc.INSTANCE.libvlc_get_version()); 官方原代码： 12345678910111213141516package tutorial;import uk.co.caprica.vlcj.binding.LibVlc;import uk.co.caprica.vlcj.runtime.RuntimeUtil;import com.sun.jna.NativeLibrary;public class Tutorial &#123; private static final String NATIVE_LIBRARY_SEARCH_PATH = "/home/vlc"; public static void main(String[] args) &#123; NativeLibrary.addSearchPath(RuntimeUtil.getLibVlcLibraryName(), NATIVE_LIBRARY_SEARCH_PATH); System.out.println(LibVlc.INSTANCE.libvlc_get_version()); &#125;&#125; 图：使用说明 只有当运行代码后，控制台什么都没有输出，一切正常，证明准备工作已做好，可以进行下面的进程。 图：运行后，控制台正常 播放器代码的实现： 主方法代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114package videoPlayer.Main;import java.awt.EventQueue;import java.io.File;import javax.swing.JFileChooser;import javax.swing.SwingWorker;import com.sun.jna.NativeLibrary;import uk.co.caprica.vlcj.discovery.NativeDiscovery;import uk.co.caprica.vlcj.runtime.RuntimeUtil;import videoPlayer.views.MainWindow;public class MainVideoPlayler &#123; //声明全局变量MainWindow static MainWindow frame; public static void main(String[] args) &#123; //实例化NativeDiscovery类 new NativeDiscovery().discover(); //通过判断选择系统，Windows，Mac OS，Liunx。以下都是各个系统的VLC默认安装路径 if (RuntimeUtil.isWindows()) &#123; NativeLibrary.addSearchPath( RuntimeUtil.getLibVlcLibraryName(), "C:\\Program Files\\VideoLAN\\VLC"); &#125;else if (RuntimeUtil.isMac()) &#123; NativeLibrary.addSearchPath( RuntimeUtil.getLibVlcLibraryName(), "/Applications/VLC.app/Contents/MacOS/lib"); &#125;else if (RuntimeUtil.isNix()) &#123; NativeLibrary.addSearchPath( RuntimeUtil.getLibVlcLibraryName(), "/home/linux/vlc/install/lib"); &#125; EventQueue.invokeLater(new Runnable() &#123; public void run() &#123; try &#123; frame = new MainWindow(); frame.setVisible(true); //通过--subsdec-encoding= 可以指定字幕文件编码格式 String options[] = &#123;"--subsdec-encoding=GB18030"&#125;; //让窗体获得视频资源 frame.getMediaPlayer().prepareMedia( "D:\\我的文件\\06、Java语言\\7、界面设计\\10、Java视频播放器的制作\\1、工程的准备.mp4",options); //prepareMedia（）；是准备播放视频。而PlayMedia（）；是直接播放视频 //frame.getMediaPlayer().playMedia( // "D:\\我的文件\\06、Java语言\\7、界面设计\\10、Java视频播放器的制作\\1、工程的准备.mp4",options); new SwingWorker&lt;String, Integer&gt;() &#123; //调节视频音量 protected String doInBackground() throws Exception &#123; while (true) &#123; //获得当前视频总时间长度 long total = frame.getMediaPlayer().getLength(); //获得当期播放时间 long curr = frame.getMediaPlayer().getTime(); //获取播放视频的百分比 float percent = ((float)curr/total); publish((int)(percent*100)); Thread.sleep(100); &#125; &#125; protected void process(java.util.List&lt;Integer&gt; chunks) &#123; for (int v:chunks) &#123; frame.getProgressBar().setValue(v); &#125; &#125;; &#125;.execute(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; //开始播放 public static void play() &#123; frame.getMediaPlayer().play(); &#125; //暂停播放 public static void pause() &#123; frame.getMediaPlayer().pause(); &#125; //停止播放 public static void stop() &#123; frame.getMediaPlayer().stop(); &#125; //通过进度条调整播放时间 public static void jumpTo(float to) &#123; //传入进度条的值的百分比，乘以视频总长度就是当前视频需要播放的值 frame.getMediaPlayer().setTime((long)( to*frame.getMediaPlayer().getLength())); &#125; //实现菜单打开视频文件 public static void openVideo() &#123; JFileChooser chooser = new JFileChooser(); int v = chooser.showOpenDialog(null); if (v == JFileChooser.APPROVE_OPTION) &#123; File file = chooser.getSelectedFile(); frame.getMediaPlayer().playMedia(file.getAbsolutePath()); &#125; &#125; //实现菜单打开字幕文件 public static void openSubtitle() &#123; JFileChooser chooser = new JFileChooser(); int v = chooser.showOpenDialog(null); if (v == JFileChooser.APPROVE_OPTION) &#123; File file = chooser.getSelectedFile(); frame.getMediaPlayer().playMedia(file.getAbsolutePath()); &#125; File file = chooser.getSelectedFile(); frame.getMediaPlayer().setSubTitleFile(file); &#125; //实现软件退出 public static void exit() &#123; frame.getMediaPlayer().release(); System.exit(0); &#125; //调节音量 public static void volume(int v) &#123; frame.getMediaPlayer().setVolume(v); &#125;&#125; 窗体代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166package videoPlayer.views;import java.awt.BorderLayout;import java.awt.FlowLayout;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import java.awt.event.MouseAdapter;import java.awt.event.MouseEvent;import javax.swing.JButton;import javax.swing.JFrame;import javax.swing.JLabel;import javax.swing.JMenu;import javax.swing.JMenuBar;import javax.swing.JMenuItem;import javax.swing.JPanel;import javax.swing.JProgressBar;import javax.swing.JSlider;import javax.swing.border.EmptyBorder;import javax.swing.event.ChangeEvent;import javax.swing.event.ChangeListener;import uk.co.caprica.vlcj.component.EmbeddedMediaPlayerComponent;import uk.co.caprica.vlcj.player.embedded.EmbeddedMediaPlayer;import videoPlayer.Main.MainVideoPlayler;import javax.swing.ImageIcon;public class MainWindow extends JFrame &#123; private JPanel contentPane; //创建播放器界面组件 EmbeddedMediaPlayerComponent playerComponent = new EmbeddedMediaPlayerComponent(); private final JPanel panel = new JPanel(); private JProgressBar progress; public MainWindow() &#123; setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); setBounds(100, 100, 712, 512); //菜单条 JMenuBar menuBar = new JMenuBar(); setJMenuBar(menuBar); //菜单中的文件 JMenu menu = new JMenu("文件"); menuBar.add(menu); //一级菜单中的打开文件选项 JMenuItem menuItem = new JMenuItem("打开文件"); menu.add(menuItem); menuItem.addActionListener(new ActionListener() &#123; //点击后会文件选择器 @Override public void actionPerformed(ActionEvent e) &#123; MainVideoPlayler.openVideo(); &#125; &#125;); //一级菜单中的打开字符选项 JMenuItem menuItem_1 = new JMenuItem("打开字幕"); menu.add(menuItem_1); menuItem_1.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; MainVideoPlayler.openSubtitle(); &#125; &#125;); //退出 JMenuItem menuItem_2 = new JMenuItem("退出"); menu.add(menuItem_2); menuItem_2.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; MainVideoPlayler.exit(); &#125; &#125;); contentPane = new JPanel(); contentPane.setBorder(new EmptyBorder(5, 5, 5, 5)); contentPane.setLayout(new BorderLayout(0, 0)); setContentPane(contentPane); JPanel videopanel = new JPanel(); //因为playerComponent布局为边界布局，所以Jpanl布局也必须边界布局，不然只能听到声音，看不到画面 contentPane.add(videopanel, BorderLayout.CENTER); videopanel.setLayout(new BorderLayout(0, 0)); //将播放器界面添加到videopanel中，用来播放视频，并设置布局为居中 playerComponent = new EmbeddedMediaPlayerComponent(); videopanel.add(playerComponent, BorderLayout.CENTER); videopanel.add(panel, BorderLayout.SOUTH); panel.setLayout(new BorderLayout(0, 0)); JPanel controlPanel = new JPanel(); panel.add(controlPanel); controlPanel.setLayout(new FlowLayout(FlowLayout.CENTER, 5, 5)); JButton button_1 = new JButton("\u9000\u51FA"); controlPanel.add(button_1); JButton btnNewButton = new JButton(""); btnNewButton.setIcon(new ImageIcon(MainWindow.class.getResource( "/com/sun/javafx/webkit/prism/resources/mediaPlayDisabled.png"))); controlPanel.add(btnNewButton); JButton button = new JButton(""); button.setIcon(new ImageIcon(MainWindow.class.getResource( "/com/sun/javafx/webkit/prism/resources/mediaPause.png"))); controlPanel.add(button); JLabel label = new JLabel(""); label.setIcon(new ImageIcon(MainWindow.class.getResource( "/com/sun/javafx/webkit/prism/resources/mediaMuteDisabled.png"))); controlPanel.add(label); JSlider slider = new JSlider(); slider.setValue(100);//设置默认音量100 slider.setMaximum(120);//设置最大音量120 controlPanel.add(slider); slider.addChangeListener(new ChangeListener() &#123; public void stateChanged(ChangeEvent arg0) &#123; //将音量条的值传递给播放器的音量控件 MainVideoPlayler.volume(slider.getValue()); &#125; &#125;); //视频播放进度条 progress = new JProgressBar(); progress.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; //获得鼠标点击进度条时的横坐标x值 int x = e.getX(); //x除以进度条总长度为当前百分比 MainVideoPlayler.jumpTo(((float)x/progress.getWidth())); &#125; &#125;); progress.setStringPainted(true); panel.add(progress, BorderLayout.NORTH); button.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; MainVideoPlayler.pause(); &#125; &#125;); btnNewButton.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent arg0) &#123; MainVideoPlayler.play(); &#125; &#125;); btnNewButton.addActionListener(new ActionListener() &#123; public void actionPerformed(ActionEvent arg0) &#123; &#125; &#125;); button_1.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; MainVideoPlayler.stop(); &#125; &#125;); &#125; //定义一个方法，返回视频播放器 public EmbeddedMediaPlayer getMediaPlayer() &#123; return playerComponent.getMediaPlayer(); &#125; //定义一个方法，获得经度条的进度 public JProgressBar getProgressBar() &#123; return progress; &#125;&#125; 程序运行效果图： 图：程序运行主界面 图：菜单栏 图：选择文件 导处程序：第一步：选中项目工程，单击鼠标右键，选择导出选项。点击后如下图，选择Java文件夹中的Runnable JAR file选项。 图：导出第一步，选择导出类型 第二步：点击Launch configuration，进行选择要导出的主方法。我的主方法为MainVideoPlayer。 图：导出第二步，选择导出类型主方法 第三步：选择要导出的文件位置，一般选择放在本工程文件中的release文件夹中，此文件夹需新建。 图：导出第三步，选择导出文件位置 第四步：选择导出文件库 包装类型，一般选择第二个，把所有需要库都打包。 图：导出第四步，选择导出包装类型 第五步：导出完成，只要在有Java运行环境的电脑中，双击此文件即可运行程序。 图：第五步，导出完成]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于socket---简单聊天室的实现]]></title>
    <url>%2F2017%2F08%2F20%2F%E5%9F%BA%E4%BA%8Esocket-%E7%AE%80%E5%8D%95%E8%81%8A%E5%A4%A9%E5%AE%A4%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[Socket简介：网络上的两个程序通过一个双向的通信连接实现数据的交换，这个连接的一端称为一个socket。 建立网络通信连接至少要一对端口号(socket)。socket本质是编程接口(API)，对TCP/IP的封装，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口；HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。 Socket的英文原义是“孔”或“插座”。作为BSD UNIX的进程通信机制，取后一种意思。通常也称作”套接字“，用于描述IP地址和端口，是一个通信链的句柄，可以用来实现不同虚拟机或不同计算机之间的通信。在Internet上的主机一般运行了多个服务软件，同时提供几种服务。每种服务都打开一个Socket，并绑定到一个端口上，不同的端口对应于不同的服务。Socket正如其英文原意那样，像一个多孔插座。一台主机犹如布满各种插座的房间，每个插座有一个编号，有的插座提供220伏交流电， 有的提供110伏交流电，有的则提供有线电视节目。 客户软件将插头插到不同编号的插座，就可以得到不同的服务。 Socket连接过程：根据连接启动的方式以及本地套接字要连接的目标，套接字之间的连接过程可以分为三个步骤：服务器监听，客户端请求，连接确认。 （1）服务器监听：是服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态。 （2）客户端请求：是指由客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。 （3）连接确认：是指当服务器端套接字监听到或者说接收到客户端套接字的连接请求，它就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，连接就建立好了。而服务器端套接字继续处于监听状态，继续接收其他客户端套接字的连接请求。 Java Socket编程：对于Java Socket编程而言，有两个概念，一个是ServerSocket，一个是Socket。服务端和客户端之间通过Socket建立连接，之后它们就可以进行通信了。首先ServerSocket将在服务端监听某个端口，当发现客户端有Socket来试图连接它时，它会accept该Socket的连接请求，同时在服务端建立一个对应的Socket与之进行通信。这样就有两个Socket了，客户端和服务端各一个。 ​ 对于Socket之间的通信其实很简单，服务端往Socket的输出流里面写东西，客户端就可以通过Socket的输入流读取对应的内容。Socket与Socket之间是双向连通的，所以客户端也可以往对应的Socket输出流里面写东西，然后服务端对应的Socket的输入流就可以读出对应的内容。 两种常用的Socket类型： 流式Socket（STREAM）：是一种面向连接的Socket，针对于面向连接的TCP服务应用，安全，但是效率低 数据报式Socket（DATAGRAM）：是一种无连接的Socket,对应于无连接的UDP服务应用.不安全(丢失,顺序混乱,在接收端要分析重排及要求重发),但效率高. Socket在网络层中的位置: 图：socket在网络模型中的位置 Socket聊天室的简介： 通过Socket（套接字）的通信原理，可以制作socket服务器和socket客户端，一个服务器又可以接入多个客户端，服务器和客户端通过输入流输出流实现数据读取写入，从而实现聊天的功能。 Socket通信过程： 服务器端：通过申请一个socket，绑定到一个IP地址和一个端口上，开启侦听，等待接收连接。 客户端：通过申请一个socket，连接服务器（通过指定IP地址和端口号），服务器端接到连接请求后，产生一个新的Socket（端口号大于1024）与客户端建立连接并进行通信，原端口继续监听。 聊天室功能简介：通过学习socket原理，建立了简单的聊天室，实现的功能是通过一个客户端发送消息，其他客户端能同时收到这个消息。 在这个聊天室中涉及的知识有：socket原理，添加鼠标事件，键盘事件，界面布局，输入流输出流的操作等。 Socket服务器代码解释： 服务器监听代码：1234567891011121314151617181920212223242526272829package socket服务器;import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;import javax.swing.JOptionPane;public class ServerListening extends Thread &#123; @Override public void run() &#123; try &#123; @SuppressWarnings("resource") //创建一个socket监听端口12345，端口取值范围1-65535 ServerSocket serverSocket = new ServerSocket(12345) ; //通过循环实现一直监听12345端口 while (true) &#123; Socket socket = serverSocket.accept(); //当有客户端连接到端口是，弹出消息提示框提示 JOptionPane.showMessageDialog(null, "有客户端连接到本机12345端口"); //把连接的客户端传到新的线程 ChatSocket csChatSocket = new ChatSocket(socket); csChatSocket.start(); //将连接的通信添加到服务器管理集合 ServerManager.getServetManager().add(csChatSocket); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; ChatSocket服务器数据处理：12345678910111213141516171819202122232425262728293031323334353637383940414243package socket服务器;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.Socket;//创建一个聊天socket继承自Thread类public class ChatSocket extends Thread &#123; Socket socket; //构造函数 public ChatSocket(Socket s) &#123; this.socket = s; &#125; //用于得到输出流，写数据 public void out(String out) &#123; try &#123; socket.getOutputStream().write((out+"\n").getBytes("UTF-8")); &#125; catch (IOException e) &#123; ServerManager.getServetManager().remove(this); e.printStackTrace(); &#125;; &#125; @Override public void run() &#123; //当客户端连接到服务器后，服务器给客户端提示 out("你已连接到本服务器"); try &#123; //获取socket的输入流 BufferedReader br = new BufferedReader( new InputStreamReader( socket.getInputStream(),"UTF-8")); String line = null; //循环读取数据，当输入流的数据不为空时，把数据写发送到每一个客户端 while ((line = br.readLine()) != null) &#123; ServerManager.getServetManager().publish(this, line); &#125; br.close();//没有数据后，关闭输入流 ServerManager.getServetManager().remove(this); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; ServerManager服务器管理模块：1234567891011121314151617181920212223242526272829303132package socket服务器;import java.util.Vector;public class ServerManager &#123; //单例化处理 private ServerManager() &#123;&#125; private static final ServerManager sm = new ServerManager(); public static ServerManager getServetManager() &#123; return sm; &#125; //定义一个集合，用来存放不同的客户端 Vector&lt;ChatSocket&gt; vector = new Vector&lt;ChatSocket&gt;(); //实现往Vector中添加个体 public void add(ChatSocket cs) &#123; vector.add(cs); &#125; //实现删除vector中断开连接的线程 public void remove(ChatSocket cs) &#123; vector.remove(cs); &#125; //把获取的消息发布给除自己以外的其他客户端 public void publish(ChatSocket cs,String out) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; ChatSocket csChatSocket = vector.get(i); //把vector中的每一个个体与传进来的线程进行比较，如果不是自己则发送 if (!cs.equals(csChatSocket)) &#123; csChatSocket.out(out); &#125; &#125; &#125;&#125; 服务器启动模块：123456package socket服务器;public static void main(String[] args) &#123; //启动监听线程 new ServerListening().start();&#125; socket客户端代码解释： 启动客户端代码：1234567891011121314151617181920package Socket客户端;import java.awt.EventQueue;public class StartClient &#123; public static void main(String[] args) &#123; //将MainWiondow中的代码复制到这，实现通过主方法启动程序 EventQueue.invokeLater(new Runnable() &#123; public void run() &#123; try &#123; MainWindow frame = new MainWindow(); frame.setVisible(true); ChatManager.getCM().setWindow(frame); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125;&#125; ChatManager聊天管理代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package Socket客户端;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.OutputStreamWriter;import java.io.PrintWriter;import java.net.Socket;import java.net.UnknownHostException;public class ChatManager &#123; private ChatManager() &#123;&#125; private static final ChatManager instance = new ChatManager(); public static ChatManager getCM() &#123; return instance; &#125; MainWindow window;//定义窗体变量 Socket socket; String IP;//定义IP变量，用来存放传进来的IP地址 BufferedReader reader;//定义读取数据的输入流 PrintWriter writer;//定义写数据的输出流 //设置给窗体中添加文字的方法，实现消息的显示 public void setWindow(MainWindow window)&#123; this.window = window; window.appendText("文本框已经和ChatManager绑定了"); &#125; public void connect(String ip) &#123; //把传进来的ip赋值给IP this.IP = ip; //定义一个线程的执行 new Thread() &#123; public void run() &#123; try &#123; //用于接收ip地址，传到socket中 socket = new Socket(IP, 12345); writer = new PrintWriter( new OutputStreamWriter( socket.getOutputStream(),"UTF-8")); reader = new BufferedReader( new InputStreamReader( socket.getInputStream(), "UTF-8")); String line; //点读取到的数据不为空时，把读取的数据输出到窗口文本区中 while ((line = reader.readLine()) != null) &#123; window.appendText("收到: "+line); &#125; writer.close();//关闭输入输出流 reader.close(); writer = null; reader = null; &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;; &#125;.start(); &#125; //这是聊天输入框的后台处理，当按了发送后，会把输入框中的数据发送出去 public void send(String out) &#123; if(writer != null) &#123; writer.write(out+"\n"); writer.flush();//写完数据后必须刷新缓存区，才能发出去 &#125;else &#123; window.appendText("当前连接已断开"); &#125; &#125;&#125; 客户端主窗体代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116package Socket客户端;import java.awt.event.KeyAdapter;import java.awt.event.KeyEvent;import java.awt.event.MouseAdapter;import java.awt.event.MouseEvent;import javax.swing.GroupLayout;import javax.swing.GroupLayout.Alignment;import javax.swing.JButton;import javax.swing.JFrame;import javax.swing.JPanel;import javax.swing.JScrollPane;import javax.swing.JTextArea;import javax.swing.JTextField;import javax.swing.LayoutStyle.ComponentPlacement;import javax.swing.border.EmptyBorder;public class MainWindow extends JFrame &#123; private JPanel contentPane; private JTextField ip; private JTextField send; private JTextArea txt; //这是主窗体的定义 public MainWindow() &#123; setTitle("聊天室");//窗体的标题 setAlwaysOnTop(true);//设置窗体的属性，总是在最上面显示 setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); setBounds(100, 100, 638, 460); contentPane = new JPanel(); contentPane.setBorder(new EmptyBorder(5, 5, 5, 5)); setContentPane(contentPane); //这是放置聊天内容的地方。文本区组件 ip = new JTextField(); ip.setText("127.0.0.1"); ip.setColumns(10); send = new JTextField(); //键盘事件，实现当输完要发送的内容后，直接按回车键，实现发送 send.addKeyListener(new KeyAdapter() &#123; @Override public void keyPressed(KeyEvent e) &#123; if (e.getKeyCode() == KeyEvent.VK_ENTER) &#123; ChatManager.getCM().send(send.getText()); appendText("我说："+send.getText()); send.setText(""); &#125; &#125; &#125;); send.setText("\u4F60\u597D"); send.setColumns(10); //发送按钮的定义，功能 JButton button = new JButton("发送"); button.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent arg0) &#123; //鼠标单击发送按钮后，调用聊天管理的send方法，把输入框中的数据发出去 ChatManager.getCM().send(send.getText()); //向聊天窗体区域添加自己发送的消息 appendText("我说："+send.getText()); //发送玩后，是输入框中内容为空 send.setText(""); &#125; &#125;); //定义一个连接到服务器的按钮 JButton button_1 = new JButton("连接到服务器"); button_1.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent arg0) &#123; //单击按钮后，把ip地址传递到socket进程中，实现连接 ChatManager.getCM().connect(ip.getText()); &#125; &#125;); JScrollPane scrollPane = new JScrollPane(); GroupLayout gl_contentPane = new GroupLayout(contentPane); gl_contentPane.setHorizontalGroup( gl_contentPane.createParallelGroup(Alignment.TRAILING) .addGroup(gl_contentPane.createSequentialGroup() .addGroup(gl_contentPane.createParallelGroup(Alignment.TRAILING) .addComponent(scrollPane, Alignment.LEADING, GroupLayout.DEFAULT_SIZE, 612, Short.MAX_VALUE) .addGroup(gl_contentPane.createSequentialGroup() .addComponent(ip, GroupLayout.DEFAULT_SIZE, 372, Short.MAX_VALUE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(button_1, GroupLayout.DEFAULT_SIZE, 234, Short.MAX_VALUE)) .addGroup(gl_contentPane.createSequentialGroup() .addComponent(send, GroupLayout.DEFAULT_SIZE, 425, Short.MAX_VALUE) .addPreferredGap(ComponentPlacement.RELATED) .addComponent(button, GroupLayout.DEFAULT_SIZE, 181, Short.MAX_VALUE))) .addGap(0)) ); gl_contentPane.setVerticalGroup( gl_contentPane.createParallelGroup(Alignment.LEADING) .addGroup(gl_contentPane.createSequentialGroup() .addGroup(gl_contentPane.createParallelGroup(Alignment.BASELINE) .addComponent(ip, GroupLayout.PREFERRED_SIZE, 36, GroupLayout.PREFERRED_SIZE) .addComponent(button_1, GroupLayout.PREFERRED_SIZE, 36, GroupLayout.PREFERRED_SIZE)) .addGap(2) .addComponent(scrollPane, GroupLayout.DEFAULT_SIZE, 328, Short.MAX_VALUE) .addPreferredGap(ComponentPlacement.RELATED) .addGroup(gl_contentPane.createParallelGroup(Alignment.BASELINE) .addComponent(send, GroupLayout.PREFERRED_SIZE, 41, GroupLayout.PREFERRED_SIZE) .addComponent(button, GroupLayout.PREFERRED_SIZE, 36, GroupLayout.PREFERRED_SIZE))) ); txt = new JTextArea(); scrollPane.setViewportView(txt); txt.setText("Ready..."); contentPane.setLayout(gl_contentPane); &#125; //定义一个追加文本的方法 public void appendText(String in) &#123; txt.append("\n"+in); &#125;&#125; 程序实现截图： 图：客户端截图 图：向服务器请求连接后，服务器会弹出消息框，提示 图：提示成功连接到服务器 图：实现多人聊天功能]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java编程</tag>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（4）界面设计]]></title>
    <url>%2F2017%2F08%2F18%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[[TOC] Java GUI编程中AWT、Swing和SWT的区别： AWT： AWT(Abstarct Window Toolkit)抽象窗口工具包。是SUN专门针对Java GUI编程提供的最早的开发工具包。用来建立和设置Java图形用户界面，这个工具包提供了一套与本地图形界面交互的接口。AWT 中的图形函数与操作系统所提供的图形函数之间有着一一对应的关系（peers）。也就是说，当我们利用 AWT 来构件图形用户界面的时候，实际上是在利用操作系统所提供的图形库。不过由于不同操作系统的图形库所提供的功能是不完全一样，所以在一个平台上存在的功能在另外一个平台上则可能不存在。这就导致一些应用程序在测试时界面非常美观，而一旦移植到其他的操作系统平台上后就可能变得“惨不忍睹”。为了实现Java语言”一次编译，到处运行”，AWT 不得不通过牺牲功能来实现其平台无关性，其所提供的图形功能被定格为各种通用型操作系统所提供的图形功能的交集。由于AWT 是依靠本地方法来实现其功能的，所以通常把AWT组件称为重量级组件。 AWT的优势： 虽然AWT是Sun不推荐使用的工具集，但是它在许多非桌面坏境中有着自己的优势： 更少的内存：对运行在有限环境中的GUI程序的开发，是合适的。 更少的启动事件：由于AWT组件是本地由操作系统实现的。绝大多数的二进制代码已经在如系统启动的时候被预装载了，这降低了它的启动事件。 更好的响应：由于本地组件由操作系统渲染。 成熟稳定的：能够正常工作并很少使你的程序崩溃。 AWT的缺点： 更少组件类型：表和树这些重要的组件缺失了。它们是桌面应用程序中普遍使用的。 缺乏丰富的组件特征：按钮不支持图片。 无扩展性：AWT的组件是本地组件。JVM中的AWT类实例实际只是包含本地组件的引用。唯一的扩展点是AWT的Canvas组件，可以从零开始创建自定义组件。然而无法继承和重用一个已有的AWT组件 Swing: Swing 是在AWT的基础上构建的一套新的图形界面系统，是JFC（Java Foundation Class）的一部分，是试图解决AWT缺点的一个尝试。它提供了AWT 所能够提供的所有功能，并且用纯粹的Java代码对AWT 的功能进行了大幅度的扩充。所有的swing组件实际上也是AWT的一部分。Swing 对基于对等体的组件使用的术语是重量级，对于模拟的组件使用的术语是轻量级。实际上，Swing 可以支持在一个 GUI 中混合使用重量级组件和轻量级组件，不过一般将其称之为轻量级组件。 Swing是三者中最强大的GUI工具集，同时它也是SUN推荐使用的GUI工具集 Swing的优点： 丰富的组件类型:Swing提供了非常广泛的标准组件。这些组件和SWT一样丰富。基于它良好的可扩展性，除了标准组件，Swing还提供了大量的第三方组件。许多商业或开源的Swing组件库在开发多年后都已经可以方便地获取了。 丰富的组件特性:Swing不仅包含了所有平台上的特性，它还支持根据程序所运行的平台来添加额外特性。Swing组件特性遵循特定原则，易于扩展，因此能够提供较SWT和AWT更多的功能。 好的组件API模型支持:Swing遵循MVC模式，这是一种非常成功的设计模式。它的API成熟并设计良好。经过多年的演化，Swing组件APIs变得越来越强大，灵活和可扩展。它的API设计被认为是最成功的GUI API之一。较之SWT和AWT更面向对象，也更灵活而可扩展。MVC结构：Model View Control ，模型+视图+控制。 标准的GUI库：Swing和AWT一样是JRE中的标准库。因此，你不用单独地将它们随你的应用程序一起分发。它们是平台无关的，不用担心平台兼容性。 成熟稳定：由于它是纯Java实现的，不会有SWT的兼容性问题。Swing在每个平台上都有相同的性能，不会有明显的性能差异。 可扩展和灵活性。Swing完全由Java代码实现。Swing基于MVC的结构使得它可以发挥Java作为一门面向对象语言的优势。它提供了许总体上良好的性能。 可编程的外观，呈现器与编辑器。 支持以任意顺序构建GUI。 可访问性和支持自动销毁。是标准Java的一部分。 Swing的缺点： Swing比AWT和SWT更多的消耗内存。Swing自己实现了所有组件。因此，它在运行时装载了大量的类。而在运行时Java在堆上创建小的对象导致了额外的堆空间消耗。而许多小的对象难以有效地被垃圾回收机制回收。因此，Swing应用程序通常会因无法及时回收冗余的对象而导致性能下降。 SWT： SWT是Standard WidgetToolkit的缩写。是由IBM构建的一个新的GUI库，其目的在于尝试彻底解决AWT和swing带来的诸多问题，提供比AWT更为丰富的组件集。SWT和swing一样通过Java代码模拟了一些平台缺失的组件，不过与 AWT 的概念相比，SWT 是一个低级的 GUI 工具包，在构建SWT的过程中，构建者从 AWT 和 Swing 实现中学习了很多经验，他们试图构建一个集二者优点于一体而没有二者的缺点的系统。因此SWT可以说是AWT与swing的融合体。 SWT的优点： 丰富的组件类型：SWT提供了种类繁多的组件，从基础组件如按钮和标签到高级的表格和树。 相对的丰富组件特性：尽管SWT也遵循最大公倍数原则，它采用模拟的方式重新设计了对更多组件特性的支持。所以同AWT相比，它有着相对丰富的组件特性。 更快的响应时间：基于和AWT同样的原因，SWT组件包装了本地组件，由操作系统实现渲染。操作系统通常对渲染处理做了优化，保存GUI二进制代码为标准库，减少了内存的使用，提高了响应性能。 更少的内存消耗。 SWT的缺点： 不在JRE的标准库中。因此必须将它和程序捆绑在一起，并为所要支持的每个操作系统创建单独的安装程序。 不够成熟和稳定。SWT因其设计上的一些缺陷，如资源管理，Windows友好等，被认为是不稳定的。它可以在Windows上表现得很好，但在其他操作系统上，它经常是不稳定且容易崩溃的。这很大程度上是因为它把资源管理交给开发者来处理，而并不是所有的开发人员能够正确地处理这些。 在非Windows平台下的性能不高，无Look AndFeel 支持。和AWT同样的原因。 不可扩展。 不支持GUI的自动销毁。 仅支持自顶而下构建GUI。 对JAVA2D支持不够完善。 不属于标准Java的一部分。 三者在使用上的选择： 综上所述，在对GUI编程时的工具包选择得根据具体项目决定：若是需要用低内存来运行GUI程序，使用AWT会是一个不错的选择，而如果只考虑平台的移植性可优先考虑SWT/swing。 Swing是最灵活、最强的工具包，在界面开发中，首选Swing，它可以胜任绝大多数开发工作。是有一种场合不是用于Swing：在使用SWT开发的程序上继续编写界面，比如为Eclipse开发插件，因为Eclipse是基于SWT构建的。SWT与Swing不兼容，所以不能混合使用。 Swing基本组件： Swing组件简介： 在Java语言提供的GUI构建工具中，可以分为“组件”（component）和“容器”（Container）两类。 在Java语言中，提供了以下组件：按钮、标签、复选框、单选按钮、选择框、列表框、文本框、滚动、条画布、菜单。 容器有：窗体（Form）、对话框（Dialog）。 Java语言是通过AWT（抽象窗口化工具包）和Java基础类（JFC或更常用的Swing）来提供这些GUI组件的。 其中Java.awt是最原始的GUI工具包，存放在java.awt包中。现在有许多功能被已被Swing取代并得到了很大的增加与提高，因此一般我们很少再使用Java.awt，但是AWT中还是包含了最核心的功能，通常，一个Java的GUI程序至少还要使用下面几个类： java.awt.Color：基本颜色定义 java.awt.Font：基本字体定义 java.awt.Cursor：光标操作定义 而Swing是JAVA提供的一组丰富的与平台无关的方式来创建图形用户界面的库。 组件与容器：Jcomponent Swing的整个可是组件库的基础构造块是Jcomponent，它是所有组件的父类，所以不能直接创建Jcomponent对象。组件都是矩形形状，组件本身有一个默认的坐标系，组件左上角的坐标值是（0，0）。然后向右向下延伸。最大值由组件的宽和高决定。组件默认的边框是一个黑色的矩形。可以通过方法设置组件的参数： 123456789101112131415161718192021222324252627//设置颜色setBackground(Color c)； //设置组件的背景色。setForeground(Color c)；//设置组件的前景色。getBackground(Color c)；//获取组件的背景色。getForeground(Color c);//获取组件的前景色。Color(int red,int green,ing blue)；//创建一个颜色对象，其中red、green、blue的取值在0到255之间。//---------------------------------------//字体setFont(Font f)；//组件调用该方法设置组件上的字体。getFont(Font f;//组件调用该方法获取组件上的字体。 public void setSize(int width,int height)：设置组件的大小。//------------------------------------------ setLocation(int x,int y);//设置组件在容器中的位置，组件距容器的左、上边界 x、y 个像素。getSize(); //返回当前组件的宽度和高度。getLocation(int x,int y);//返回组件的左上角在容器的坐标系中的x坐标和y坐标。psetBounds(int x,int y,int width,int height)：//设置组件在容器中的位置和组件的大小。getBounds();//返回当前组件左上角在容器坐标系中的x坐标和y坐标，宽度和高度。//----------------------------------------------setEnabled(boolean b);//设置组件是否可被激活。 //当参数b取值true时，组件可以被激活。 //当参数b取值false 时，组件不可激活。setVisible(boolean b);//设置组件在该容器中的可见性。//-------------------------------------------------add( );//将组件添加到该容器中。removeAll() ;//移掉容器中的全部组件。remove(Component c) ;//移掉容器中参数指定的组件。validate();//每当容器添加新的组件或移掉组件时，调用该方法以保证容器中的组件能正确显示出来。 JFrame（窗体）： JFrame类是一个顶层窗口，也是一个容器，允许将其他组件添加到它里面。 JFrame实际上不仅仅让您把组件放入其中并呈现给用户。比起它表面上的简单性，它实际上是 Swing 包中最复杂的组件。为了最大程度地简化组件，在独立于操作系统的Swing组件与实际运行这些组件的操作系统之间，JFrame起着桥梁的作用。JFrame在本机操作系统中是以窗口的形式注册的，这么做之后，就可以得到许多熟悉的操作系统窗口的特性：最小化/最大化、改变大小、移动。 JFrame常用构造方法： 12JFrame()；//可以创建一个无标题的窗口JFrame(String title)；//创建一个有标题的窗口 JFrame常用方法： 123456789getTitle()； setTitle()； //获取/设置窗口标题getState()； setState()； //获取和设置窗口的最小化、最大化等状态。isVisible()； setVisible()；//获取和设置窗口是否可见getLocation()； setLoaction()；//获取和设置窗口在屏幕上出现的位置getSize()； setSize()；//获取和设置窗口的大小setBounds()； //获取和设置窗口出现在屏幕上时初始位置的大小setResizable()；//设置是否可调节大小add()；//添加组件到窗口中setDefaultCloseOperation()；//设置单击窗体右上角的关闭图标后，程序作出的处理。 JDialog(对话框)： 对话框可分为无模式和有模式两种。 如果一个对话框是有模式的对话框，那么当这个对话框处于激活状态时，只让程序响应对话框内部的事件，程序不能再激活它所依赖的窗口或组件，而且它将堵塞当前线程的执行，直到该对话框消失不可见。 无模式对话框处于激活状态时，程序仍能激活它所依赖的窗口或组件，它也不堵塞线程的执行。 JMenu(菜单组件)： Swing菜单由菜单条(JMenuBar)、菜单(JMenu)和菜单项(JMenuItem)构成。菜单条是所有菜单和菜单项的根(容器)。 一、JMenuBar是Jcomponent类的子类，负责创建菜单条。 二、Jmenu是Jcomponent类的间接子类，负责创建菜单。 常用构造方法： pulbic JMenu()：建立一个没有标题的菜单。 pulbic JMenu(String title)：建立一个指定标题菜单，标题由参数title确定 常用方法： add(MenuItem item)：向菜单增加由参数item指定的菜单选项对象。 add(String s)：向菜单增加指定的选项。 getItem(int n)：得到指定索引处的菜单选项。 getItemCount()：得到菜单选项数目。 三、JMenultem是Jcomponent的间接子类，负责创建菜单项。 常用构造方法： public JMenuItem(String s)：构造有标题的菜单项。 public JMenuItem(String text, Icon icon)：构造有标题和图标的菜单项。创建图标对象 Icon icon=new ImageIcon(“图标文件名”); 常用方法： public void setEnabled(boolean b)：设置当前菜单项是否可被选择。 public String getLabel()：得到菜单选项的名字。 public void setAccelerator(KeyStroke keystroke)：为菜单项设置快捷键。 KeyStroke类静态方法： keyCode一般取值范围：KeyEvent.VK_A~KeyEvent.VK_Zmodifiers一般取值：InputEvent.ALT_MASK，InputEvent.CTRL_MASK，InputEvent.SHIFT_MASK 中间容器：用来添加组件的轻容器，称为中间容器。 JPanel（面板对象）:JPanel类用来创建一个面板对象，可以向这个面板添加组件(直接使用add方法)。 使用时需要把这个面板添加到底层容器或其他中间容器中。 JPanel面板的默认布局是FlowLayout布局。 JScrollPane（可滑动宽格）:滚动窗格，把一个组件放到一个滚动窗格中，然后通过滚动条来观察这个组件。 例如，JTextArea不自带滚动条，如果希望使用带滚动条的多行文本框，可把JTextArea放到一个滚动窗格中。 JSplitPane（拆分窗格）:拆分窗格，将容器拆分成两部分，拆分窗格有两种类型： 水平拆分：用一条拆分线把容器分成左右两部分，拆分线可以水平移动。 垂直拆分：用一条拆分线分成上下两部分，拆分线可以垂直移动。 JLayeredPane（分层窗格）:分层窗格，如果添加到容器中的组件经常需要处理重叠问题，就可以将组件添加到JLayeredPane容器中。 JLayeredPane将容器分成5个层，容器使用add(Jcomponent component, int layer)方法添加组件component，并指定component所在的层layer。 layer取值： DEFAULT_LAYER：最底层 PALETTE_LAYER MODAL_LAYER POPUP_LAYER DRAG_LAYER：最上面的层 JTextFIeld(单行文本框)：单行文本框，用来建立文本框的组件，用户可以在文本框中输入单行的文本。 常用构造方法： JTextField(int x)：创建文本框对象，可以在文本框中输入若干个字符，文本框的可见字符个数由参数x指定。 JTextField(String s)：创建文本框对象，则文本框的初始字符串为s，可以在文本框中输入若干个字符。 常用方法： public void setText(String text)：设置文本框中的文本为参数text指定的文本。 public String getText()：获取文本框中的文本。 public void setEditable(boolean b)：指定文本框的可编辑性(默认为true-可编辑的)。 public void setHorizontalAlignment(int alignment)：设文本在文本框中的对齐方式，其中alignment的有效值确定对齐方式，如：LEFT、CENTER、RIGHT。 JPasswordField(密码框):密码框，用于接收密码信息，输入的文本不会以明文形式显示出来。 常用方法： setEchoChar(char echoChar)：设置回显字符（默认的回显字符是‘*’）。 char[] getPassword()：获取密码框中的密码。 JTextArea（多行文本框）：多行文本框，用户可以在文本区输入多行的文本。 常用构造方法： JTextArea(int rows, int columns)：构造一个可见行和可见列分别是rows、columns的文本区。 常用方法： setLineWrap(boolean b)：决定输入的文本能否在文本区的右边界自动换行。 setWrapStyleWord(boolean b)：决定是以单词为界(b取true时)或以字符为界(b取false时)进行换行。 getText()：获取文本区的文本。 setText(String text)：设置文本内容。 append(String text)：尾部加文本。 insert(String text,int index)：在文本区的指定位置处插入文本。 public void copy()：拷贝选定的区域。 public void cut()：剪切选定的区域。 public void paste()：在指定的区域粘贴。 JButton(按钮组件):按钮组件，常用构造方法： public JButton(String text)：创建名字是text的按钮。 public JButton(Icon icon)：创建带有图标icon的按钮。 public JButton(String text, Icon icon)：创建名字是text且带有图标icon的按钮。 常用方法： public String getText()：获取当前按钮上的名字。 public void setText(String text)：重新设置当前按钮的名字，名字由参数text指定。 public Icon getIcon()：获取当前按钮上的图标。 public void setIcon(Icon icon)：重新设置当前按钮上的图标。 public void setHorizontalTextPosition(int textPosition)：设置按钮名字相对按钮上图标的水平位置。textPosition取值：SwingConstants.RIGHTSwingConstants.LEFTSwingConstants.CENTERSwingConstants.LEADINGSwingConstants.TRAILING public void setVerticalTextPosition(int textPosition)：设置按钮上名字相对按钮上图标的垂直位置。 public void addActionListener(ActionListener)：按钮对象调用该方法可以向按钮增加动作监视器。 public void removeActionListener(ActionListener)：按钮对象调用该方法可以移去按钮上的动作监视器。 JLable（标签组件）：标签组件，一般用来显示信息，但没有编辑功能。 常用构造方法： public JLabel()：创建空标签对象。 public JLabel(String text)：创建带文本的标签对象。 public JLabel(String text, int aligment)：创建带文本的标签对象，并设置文本对齐方式 常用方法： String getText()：获取标签的名字。 void setText(String s)：设置标签的名字。 JCheckBox(复选框):复选框，提供两种状态，一种是选中，另一种是未选中，用户通过单击该组件切换状态。如果不对复选框进行初始化设置,默认的初始化设置均为未选中。 常用构造方法： public JCheckBox()：创建一个没有名字的复选框。 public JCheckBox(String text)：创建一个名字是text的复选框。 常用方法： public void setSelected(boolean b)：设置按钮状态–是否选中 public boolean isSelected()：如果复选框处于选中状态该方法返回true，否则返回false。 JRadioButton(单选按钮):单选按钮，一组单选按钮同一时刻只能有一个被选中。 当创建了若干个单选按钮后，应使用ButtonGroup再创建一个对象，然后利用这个对象把这若干个单选按钮归组。归到同一组的单选按钮每一时刻只能选一。 JTable(表格对象):表格对象。 常用构造方法： public JTable(Object[][] data , Object[] columnName) 表格的视图将以行和列的形式显示数组data每个单元中对象的字符串表示。 参数columnName用来指定表格的列名。 用户在表格单元中输入的数据都被认为是一个Object对象。 用户通过表格视图对表格单元中的数据进行编辑，以达到修改二维数组data中对应的数据。 JPopupMenu(弹出式菜单):弹出式菜单，由JPopupMenu类负责创建，通常用于右键菜单。 常用构造方法：- public JPopupMenu()：构造无标题弹出式菜单。- public JPopupMenu(String label)：构造由参数label指定标题的弹出式菜单。 常用方法： public void show(Component invoker, int x, int y)：设置弹出式菜单在组件invoker上的弹出的位置。 Swing布局管理器： 布局管理器： 用于指定各个视图组件在窗口中的分布位置，实现动态布局。有助于创建复合式的复杂界面，一个复合式的界面由一些简单的基本界面组成。 使用方法 setLayout(LayoutManager) 可以设置布局。 Absolute Layout（绝对布局)： 1) 可以不借助布局管理器由用户直接精确定义组件的位置以及大小； ​ 2) 直接使用Component的方法setSize、setLocation、setBounds即可； ​ 3) 但是绝对布局不仅费神，需要提前精确计算，而其会丧失跨平台特性，在Java图形界面编程中绝对不推荐绝对定位的方式； ​ 4) 如果一定要使用绝对布局，那么就先调用容器的setLayout，传递null参数，就表示启用绝对定位，然后就调用组件的set三方法定位后add进容器即可：c.setLayout(null); BorderLayout（边界布局）：边界布局管理器，是Window型容器的默认布局，比如Jframe类，JDialog类。每个被BorderLayout管理的容器均被划分为五个区域：东（East）、南（South）、西（West）、北（North）、中（Center）。容器的每个区域，只能加入一个组件，如果加入多个组件，其中只有一个是可见的。 对于东南西北四个边界区域，如果其中的某个区域没有用，它的大小将边为0，中间区域将扩展并占用整个区域。 在BorderLayout布局管理器的管理下，组件必须通过add()方法加入到容器的去个命名区域之一，否则他们是不可见的。方法：add（组件，区域）。 FlowLayout（流式布局）：流式布局管理器，将组件按照加入的顺序逐个地放在容器中的一行上，一行放满后再另起一个新行。 每一行中的组件按布局指定的方式对齐方，默认情况下是居中对齐。 FlowLayout布局管理器不强行设定组件的大小，而是允许组件拥有自己希望的大小。 每个组件都有一个getPreferredSize()方法，容器布局管理器会调用此方法取得每个组件希望的大小。 FlowLayout布局管理器是JPanle容器的默认布局管理器。 GridLayout（网格式布局）：网格式的布局管理器，它将容器空间划分成若干行乘若干列的网格，每个格放一个组件。 各组件按照从上到下，从左至右的顺序排列。 使用GridLayout布局设计的一般步骤： 使用GridLayout的构造方法创建布局对象，指定划分网格的行数和列数。 使用GridLayout布局容器调用方发add将组件加入容器。 GridLayout布局中每个网格都是相同大小并且强制组件与网格相同大小。 BoxLayout（卡式布局）：卡式布局管理器，可以容纳多个组件，但是同一时刻容器只能从这些组件中选出一个来显示，被显示的组件占据容器的整个空间。 选项卡窗格(JTabbedPane)的默认布局是CardLayout。 BoxLayout（盒式布局）：盒式布局管理器。Box类创建的容器称作一个盒式容器，盒式容器的的默认布局是盒式布局，而且不允许更改盒式容器的布局。 行型盒式布局，特点： 容器中组件的上沿在同一水平线上。 Box类的类方法createHorizontalBox()可以获得一个具有行型盒式布局的盒式容器。 行型盒式容器中组件间的间距：Box类调用静态方法createHorizontalStrut(int width)可以得到一个不可见的水平Struct类型对象，称做水平支撑。 列型盒式布局，特点： 容器中组件的左沿在同一垂直线上。 Box类的类方法createVerticalBox()可以获得一个具有列型盒式布局的盒式容器。 列型盒式容器中组件间的间距：Box类调用静态方法createVertialStrut(int height)可以得到一个不可见的垂直Struct类型对象，称做垂直支撑。 GroupLayout（组布局）：分组布局管理器。它将组建按层次分组，以决定它们在 Container 中的位置。GroupLayout 主要供生成器使用（生成 并行组 和 串行组）。分组由GroupLayout.Group类的实例来完成，每个组可以包含任意数量的元素（Group、Component 或 Gap）。 GroupLayout支持两种组: 串行组 (sequential group)：按顺序沿指定方向（水平/垂直）逐个放置元素。 并行组 (parallel group)：沿指定方向（水平/垂直）并行排列元素，能够以四种不同方式对齐其子元素。 界面消息提示 JOptionPane.showConfirmDialog(确认提示框)：12345678910111213141516JPanel panel = new JPanel(); contentPane.add(panel, BorderLayout.CENTER); JButton button = new JButton("确认提示框按钮"); button.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent arg0) &#123; //确认会话框，（父级容器，消息，标题，选择按钮的类型，提示消息的类型，图标）; //JOptionPane.showConfirmDialog(parentComponent, message, title, optionType, messageType, icon); //确认框返回值类型为整型。 int value = JOptionPane.showConfirmDialog(NewFrame.this, "确认退出吗？", "请确认", JOptionPane.YES_NO_CANCEL_OPTION, JOptionPane.QUESTION_MESSAGE, null); //如果选择了确认，则系统退出，否则返回软件界面 if(value == JOptionPane.YES_OPTION) &#123; System.exit(0); &#125; &#125;&#125;); 图：确认提示框 JOptionPane.showMessageDialog(消息提示框)：12345678JButton button_1 = new JButton("\u6D88\u606F\u63D0\u793A\u6846"); button_1.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent arg0) &#123; //消息提示框，可指定（父级容器，消息内容，标题，消息类型，图标） JOptionPane.showMessageDialog(NewFrame.this, "警告！","提示框",JOptionPane.WARNING_MESSAGE,null); &#125;&#125;); 图：消息提示框（警告类型） JOptionPane.showInputDialog(输入框)：12345678JButton button_2 = new JButton("\u8F93\u5165\u6846"); button_2.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent arg0) &#123; //输入框，可以指定（父级容器，提示消息，标题，消息类型，图标，数组，默认选项） JOptionPane.showInputDialog(NewFrame.this, "请输入密码", "输入框", JOptionPane.INFORMATION_MESSAGE); &#125;&#125;); 图：输入框 JOptionPane.showOptionDialog( 选择框)：123456789JButton button_3 = new JButton("\u9009\u62E9\u6846"); button_3.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent arg0) &#123; //选择框，可以指定（父级容器，提示消息，标题，消息类型，图标，数组，默认选项） String options[] = &#123;"a","b","c","d"&#125;; JOptionPane.showOptionDialog(NewFrame.this,"选择正确答案", "请选择",JOptionPane.OK_OPTION, JOptionPane.INFORMATION_MESSAGE, null,options, "a"); &#125;&#125;); 图：选择框 Java文件选择器 文件选择器：12345678910111213141516171819202122232425JButton btnNewButton = new JButton("打开文件或文件夹"); btnNewButton.addMouseListener(new MouseAdapter() &#123; JFileChooser chooser = new JFileChooser(); public void mouseClicked(MouseEvent e) &#123; //设置文件选择模式，可选择，文件，文件夹，或文件和文件夹 chooser.setFileSelectionMode(JFileChooser.FILES_AND_DIRECTORIES); //设置多选是否开启 chooser.setMultiSelectionEnabled(true); //设置文件过滤器，指定可选择文件类型 FileNameExtensionFilter filter = new FileNameExtensionFilter("可选择文件类型", "txt","jar","js"); chooser.setFileFilter(filter); //设置打开文件会话框 int value = chooser.showOpenDialog(OpenSaveFile.this); //如果选择文件，则获取所有选择文件的路径 if (value == JFileChooser.APPROVE_OPTION) &#123; File file[] = chooser.getSelectedFiles(); /进行循环，把所有选择文档路径，输出到文本框 for(int i = 0; i &lt; file.length; i++) &#123; textArea.append("\n"+file[i].getAbsolutePath()); &#125; &#125; &#125;&#125;);//文本显示框 textArea = new JTextArea(); textArea.setText("\u6587\u4EF6\u8DEF\u5F84\uFF1A"); 选择文件以前 图：文件选择器 图：选择文件后输出路径 图：文件选择过滤器，只能选择指定文件类型 保存文件：12345678910111213141516171819button = new JButton("\u4FDD\u5B58\u6587\u4EF6"); button.addMouseListener(new MouseAdapter() &#123; @Override public void mouseClicked(MouseEvent e) &#123; JFileChooser chooser1 = new JFileChooser(); int value = chooser1.showSaveDialog(OpenSaveFile.this); if (value == JFileChooser.APPROVE_OPTION) &#123; File newFile = chooser1.getSelectedFile(); if (newFile.exists() == false) &#123; try &#123; newFile.createNewFile(); textArea.setText("文件已经保存，文件路径："+newFile.getAbsolutePath()); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; &#125; &#125; &#125; &#125;); 图：文件保存器 图：文件保存成功，输出路径 Java 事件处理机制 Java事件驱动模型：驱动模型的三大要素： 事件源：能够接收外部事件的源体。 监听器：能够接收事件源通知的对象。 事件处理程序：用于处理事件的对象。 窗口事件：WindowListener接口 JFrame类是Window类的子类，Window型对象都能触发WindowEvent事件。当一个JFrame窗口被激活、撤消激活、打开、关闭、图标化或撤消图标化时，就引发了窗口事件。通过调用 addWindowlistener()来注册监听器。 WindowListener接口中有7个不同的方法，分别是： public void windowActivated(WindowEvent e)：当窗口从非激活状态到激活时，窗口的监视器调用该方法。 public void windowDeactivated(WindowEvent e)：当窗口激活状态到非激活状态时调用该方法。 public void windowClosing(WindowEvent e)：当窗口正在被关闭时调用该方法。 public void windowClosed(WindowEvent e)：当窗口关闭时调用该方法。 public void windowIconified(WindowEvent e)：当窗口图标化时调用该方法。 public void windowDeiconified(WindowEvent e)：当窗口撤消图标化时调用该方法。 public void windowOpened(WindowEvent e)：当窗口打开时调用该方法。 鼠标事件：鼠标事件是鼠标的移动、点击、拖放等行为。鼠标在组件上的操作(如点击按钮、菜单)，不需要处理为鼠标事件，该组件会进行相应的处理。 用户的下列7种操作都可以使得组件触发鼠标事件： 鼠标指针从组件之外进入 鼠标指针从组件内退出 鼠标指针停留在组件上时，按下鼠标 鼠标指针停留在组件上时，释放鼠标 鼠标指针停留在组件上时，单击鼠标 在组件上拖动鼠标指针 在组件上运动鼠标指针 MouseListener接口与MouseMotionListener接口：MouseListener、MouseMotionListener都是处理MouseEvent的接口。 MouseListener处理对象对于鼠标的进入、离开、下压、释放及敲击事件，使用addMouseMotionListener (MouseListener listener) 注册监听器。 MouseListener接口中的5个方法： mousePressed(MouseEvent)：负责处理鼠标按下触发的鼠标事件。 mouseReleased(MouseEvent e)：负责处理鼠标释放触发的鼠标事件。 mouseEntered(MouseEvent e)：负责处理鼠标进入组件触发的鼠标事件。 mouseExited(MouseEvent e)：负责处理鼠标退出组件触发的鼠标事件。 mouseClicked(MouseEvent e)：负责处理鼠标单击或连击触发的鼠标事件。 MouseMotionListener用于处理鼠标的移动及拖曳，使用addMouseMotionListener(MouseListener listener)方法注册监听器 MouseMotionListener接口中的两个方法： mouseDragged(MouseEvent e)：负责处理鼠标拖动事件 mouseMoved(MouseEvent e)：负责处理鼠标移动事件 MouseEvent类：MouseEvent类的重要方法： getX()：返回触发当前鼠标事件时，鼠标指针在事件源坐标系中的x-坐标。 getY()：返回触发当前鼠标事件时，鼠标指针在事件源坐标系中的y-坐标。 getClickCount()：返回鼠标被连续单击的次数。 getModifiers()：返回一个整数值。左键返回的值是常量BUTTON1_MASK，右键返回的值是常量BUTTON3_MASK。 getSource()：返回触发当前鼠标事件的事件源。 鼠标位置的坐标变换：程序可能需要知道鼠标指针在容器坐标系中的坐标，这就需要进行坐标变换。 public static Point convertPoint(Component source, int x, int y,Component destination)：该方法返回一个Point对象。 根据鼠标指针在当前事件源source坐标系中的坐标(x,y)，得到鼠标在容器 destination坐标系中的坐标。该对象再调用getX()和getY()方法就可以获取鼠标在容器destination坐标系中的坐标。 鼠标事件的转移：假如正监视一个容器上的鼠标事件，而容器中添加了一些组件，则当在组件上鼠标操作时，容器将不知道这些操作的发生。 MouseEvent convertMouseEvent(Component source, MouseEvent sourceEvent, Component destination)：使鼠标事件从一个事件源转移到另一个事件源上。该方法是javax.swing包中的SwingUtilities类的静态方法。 获取鼠标在系统桌面上的坐标：PointerInfo类 是JDK1.5在java.awt包中新增的一个类，可以帮助程序获取鼠标指针在系统图形设备中的位置坐标。使用MouseInfo的方法：getPointerInfo()，可以实例化一个PointerInfo对象。 方法： GraphicsDevice getDevice()：返回在创建此 PointerInfo 时鼠标指针所在的 GraphicsDevice。 Point getLocation()：返回在屏幕上表示指针坐标的 Point。 键盘事件：在具有键盘焦点的组件中按下或者释放按键时，将会激发键盘事件。键盘事件由接口KeyListener的方法来处理，组件使用addKeyListener()注册监听器。 接口KeyListener中有3个方法： public void keyPressed(KeyEvent e)：按下键盘上某个键时，方法keyPressed方法会自动执行。 public void keyTyped(KeyEvent e)：当键被按下又释放时，keyTyped方法被调用 public void KeyReleased(KeyEvent e)：当键被释放时，KeyReleased方法被调用。 KeyEvent的重要方法： public int getKeyCode()：返回一个整形值，常用于在keyPressed方法中获取用户敲击的键的虚拟键代码。 public char getKeyChar()：返回与此事件中的键关联的字符。 public int getModifiers()：返回此事件的修饰符掩码。以指出所按住的修改键（例如 shift、ctrl、alt、meta），该动作被定义为 InputEvent 的一部分。 java对字符和虚拟键代码进行了明确区分，虚拟键代码和键盘的扫描码类似，没有单独的小写虚拟键代码。虚拟键代码以VK_开头，是定义在KeyEvent类中的int型类变量，比如：VK_0, VK_A, VK_SHIFT, VK_RIGHT。在使用keyPressed()和keyReleased()方法时，需要进行虚拟键代码的检查，在使用keyTyped()方法时需要进行字符进行检查 Swing界面响应与线程安全 Swing界面响应与线程安全:Java程序的主线程： 当Java程序启动时，一个线程立刻运行，该线程通常叫做程序的主线程（main thread），因为它是程序开始时就执行的。一般来说，某个类中会有一个main函数，当程序启动时，该函数就会有第一个自动得到执行，并成为程序的主线程。主线程的特征如下： 它是产生其他子线程的线程。 主线程中执行程序的控制。 通常它必须最后完成执行，因为他执行各种关闭动作。 Swing的UI线程：Swing API的设计目标是强大、灵活和易用。但是Swing组件不支持多线程访问，程序要操作或改变界面内容，必须向单一线程执行请求，我们把这个单一个线程称为事件的派发线程。（可简称为UI线程）。这也意味着Swing是线程不安全的，所有对于UI元素的修改必须都提交给UI线程执行，不能再主线程或其他任何线程中直接操作UI的内容。 如果需要从UI线程或绘制代码以外的地方访问UI，那么需要使用SwingUtilities类的invokeLater（）或invokerAndWait（）方法、 如果需要处理一些耗费大量计算能力或受I/O能力限制的工作，可以使用一个线程工具类，如SwingWorker或Timer。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSON-JavaScript对象表示法--学习笔记]]></title>
    <url>%2F2017%2F08%2F15%2FJSON-JavaScript%E5%AF%B9%E8%B1%A1%E8%A1%A8%E7%A4%BA%E6%B3%95-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[JSON简介： JSON：JavaScript对象表示法（JavaScript Object Notation）。JSON是存储和交换文本信息的语法。 JOSN是轻量级的文本数据交换格式。 JSON独立于语言和平台。 JSON具有自我描述性，更易理解。 JOSN与XML： JOSN类似XML，比XML更小、更快、更易简析。 没有结束标签。 更短。 读写的速度更快。 使用数组。 不适用保留字。 能够使用内建的JavaScript ecal（）方法进行解析。 类似 XML： JSON 是纯文本 JSON 具有“自我描述性”（人类可读） JSON 具有层级结构（值中存在值） JSON 可通过 JavaScript 进行解析 JSON 数据可使用 AJAX 进行传输 使用JSOON与使用XML的不同： 使用 XML: 读取 XML 文档 使用 XML DOM 来循环遍历文档 读取值并存储在变量中 使用 JSON: 读取 JSON 字符串 用 eval() 处理 JSON 字符串 JSON语法： JSON 语法是 JavaScript 语法的子集。 JSON 语法规则： JSON 语法是 JavaScript 对象表示法语法的子集。 数据在名称/值对中 数据由逗号分隔 花括号保存对象 方括号保存数组 JSON 值可以是： 数字（整数或浮点数） 字符串（在双引号中） 逻辑值（true 或 false） 数组（在方括号中） 对象（在花括号中） null JSON 对象： JSON 对象在花括号中书写：对象可以包含多个名称/值对： 1&#123;"firstName":"John","lastName":"Doe"&#125; JSON 数组: JSON 数组在方括号中书写： 数组可包含多个对象： 1234567&#123;"employees": [&#123; "firstName":"John" , "lastName":"Doe" &#125;,&#123; "firstName":"Anna" , "lastName":"Smith" &#125;,&#123; "firstName":"Peter" , "lastName":"Jones" &#125;]&#125; JSON 文件： JSON 文件的文件类型是 “.json” JSON 文本的 MIME 类型是 “application/json”]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XML(扩展标记语言)学习笔记]]></title>
    <url>%2F2017%2F08%2F14%2FXML-%E6%89%A9%E5%B1%95%E6%A0%87%E8%AE%B0%E8%AF%AD%E8%A8%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[什么是XML？ XML指可扩展标记语言（Extensible Markup Language）。 XML 是一种标记语言，很类似 HTML XML 的设计宗旨是传输数据，而非显示数据 XML 标签没有被预定义。您需要自行定义标签。 XML 被设计为具有自我描述性。 XML 是 W3C 的推荐标准 XML 与 HTML 的主要差异: XML 不是 HTML 的替代。 XML 和 HTML 为不同的目的而设计： XML 被设计为传输和存储数据，其焦点是数据的内容。 HTML 被设计用来显示数据，其焦点是数据的外观。 HTML 旨在显示信息，而 XML 旨在传输信息。 XML的特点： 没有任何行为的 XML，XML 是不作为的。XML 不会做任何事情。XML 被设计用来结构化、存储以及传输信息。 XML 仅仅是纯文本而已。有能力处理纯文本的软件都可以处理 XML。不过，能够读懂 XML 的应用程序可以有针对性地处理 XML 的标签。标签的功能性意义依赖于应用程序的特性。 XML 允许创作者定义自己的标签和自己的文档结构。 XML不是多HTML的替代，XML 是对 HTML 的补充。XML 不会替代 HTML，理解这一点很重要。在大多数 web 应用程序中，XML 用于传输数据，而 HTML 用于格式化并显示数据。 对 XML 最好的描述是：XML 是独立于软件和硬件的信息传输工具。 XML 无所不在。XML 是各种应用程序之间进行数据传输的最常用的工具，并且在信息存储和描述领域变得越来越流行。 XML的用途： XML 应用于 web 开发的许多方面，常用于简化数据的存储和共享。 XML 把数据从 HTML 分离。 XML 简化数据共享。 XML 简化数据传输。 XML 简化平台的变更。 由于 XML 独立于硬件、软件以及应用程序，XML 使您的数据更可用，也更有用。不同的应用程序都能够访问您的数据，不仅仅在 HTML 页中，也可以从 XML 数据源中进行访问。通过 XML，您的数据可供各种阅读设备使用（手持的计算机、语音设备、新闻阅读器等），还可以供盲人或其他残障人士使用。 XML 用于创建新的 Internet 语言。 XML语法规则： 1、所有 XML 元素都须有关闭标签。在 XML 中，省略关闭标签是非法的。 2、XML 标签对大小写敏感。在 XML 中，标签 与标签 是不同的。必须使用相同的大小写来编写打开标签和关闭标签。 3、XML 必须正确地嵌套。 4、XML 文档必须有根元素。XML 文档必须有一个元素是所有其他元素的父元素。该元素称为根元素。 5、XML 的属性值须加引号。 6、 实体引用。在 XML 中，一些字符拥有特殊的意义。如果你把字符 “&lt;” 放在 XML 元素中，会发生错误，这是因为解析器会把它当作新元素的开始。为了避免这个错误，请用实体引用来代替 “&lt;” 字符： 1&lt;message&gt;if salary &amp;lt; 1000 then&lt;/message&gt; 在 XML 中，有 5 个预定义的实体引用： 实体引用符 原符号 名称 &amp;gt； &gt; 大于 &amp;lt； &lt; 小于 &amp;amp； &amp; 和号 &amp;apos； ‘ 单引号 %quot； “ 引号 注释：在 XML 中，只有字符 “&lt;” 和 “&amp;” 确实是非法的。大于号是合法的，但是用实体引用来代替它是一个好习惯。 7、 XML 中的注释。在 XML 中编写注释的语法与 HTML 的语法很相似： 1&lt;!-- This is a comment --&gt; 8、在 XML 中，空格会被保留。 9、XML 以 LF 存储换行在 Windows 应用程序中，换行通常以一对字符来存储：回车符 (CR) 和换行符 (LF)。这对字符与打字机设置新行的动作有相似之处。在 Unix 应用程序中，新行以 LF 字符存储。而 Macintosh 应用程序使用 CR 来存储新行。 XML元素： XML 元素：指的是从（且包括）开始标签直到（且包括）结束标签的部分。元素可包含其他元素、文本或者两者的混合物。元素也可以拥有属性。 XML 元素必须遵循以下命名规则： 名称可以含字母、数字以及其他的字符 名称不能以数字或者标点符号开始 名称不能以字符 “xml”（或者 XML、Xml）开始 名称不能包含空格 可使用任何名称，没有保留的字词。 XML 元素是可扩展的 XML属性： 属性通常提供不属于数据组成部分的信息。 XML属性必须加引号。单引号和双引号都可使用。如果属性值本身包含双引号，则必须使用单引号。 元数据（有关数据的数据）应当存储为属性，而数据本身应当存储为元素。 XML的显示： 使用 XSLT 显示 XML。 XSLT 是首选的 XML 样式表语言。 XSLT (eXtensible Stylesheet Language Transformations) 远比 CSS 更加完善。 使用 XSLT 的方法之一是在浏览器显示 XML 文件之前，先把它转换为 HTML]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>XML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（3）网络通信]]></title>
    <url>%2F2017%2F08%2F14%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%883%EF%BC%89%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[1、Java中的XML操作 有关XML的简介请点击：XML学习笔记。 使用Dom4j操作XML数据： 首先在https://dom4j.github.io/点击下在dom4j-1.6.1 java库。导入到java工程中调用。 12345678910111213141516171819package java网络通信;import org.dom4j.Document;import org.dom4j.DocumentException;import org.dom4j.DocumentHelper;import org.xml.sax.DocumentHandler;public class Dom4j创建xml &#123; public static void main(String[] args) &#123; String xmlString = "&lt;root&gt;&lt;people&gt;cao&lt;/people&gt;&lt;/root&gt;"; try &#123; Document document = DocumentHelper.parseText(xmlString); System.out.println(document.asXML()); &#125; catch (DocumentException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 程序执行结果： 12&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;root&gt;&lt;people&gt;cao&lt;/people&gt;&lt;/root&gt; 在Java中创建xml数据：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package java网络通信;import java.io.File;import java.io.StringWriter;import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import javax.xml.parsers.ParserConfigurationException;import javax.xml.transform.Transformer;import javax.xml.transform.TransformerException;import javax.xml.transform.TransformerFactory;import javax.xml.transform.dom.DOMSource;import javax.xml.transform.stream.StreamResult;import org.w3c.dom.Document;import org.w3c.dom.events.DocumentEvent;public class 创建xml文件 &#123; public static void main(String[] args) &#123; //Java中常用的通过DOM方式生成xml文档 try &#123; //创建xml文件 DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = factory.newDocumentBuilder(); Document document = builder.newDocument(); //创建根元素root org.w3c.dom.Element root = document.createElement("Languages"); //创建第一组元素 root.setAttribute("cat", "it");//为根元素添加属性 org.w3c.dom.Element lan1 = document.createElement("lan"); lan1.setAttribute("id", "1"); org.w3c.dom.Element name1 = document.createElement("name"); name1.setTextContent("Java"); org.w3c.dom.Element ide1 = document.createElement("ide"); ide1.setTextContent("eclipse"); lan1.appendChild(name1); //把&lt;name&gt;标签添加到&lt;lan&gt;里。作为子节点 lan1.appendChild(ide1); //创建第二组元素 org.w3c.dom.Element lan2 = document.createElement("lan"); lan2.setAttribute("id", "2"); org.w3c.dom.Element name2 = document.createElement("name"); name2.setTextContent("Swift"); org.w3c.dom.Element ide2 = document.createElement("ide"); ide2.setTextContent("Xcode"); lan2.appendChild(name2); lan2.appendChild(ide2); //创建第三组元素 org.w3c.dom.Element lan3 = document.createElement("lan"); lan3.setAttribute("id", "1"); org.w3c.dom.Element name3 = document.createElement("name"); name3.setTextContent("C#"); org.w3c.dom.Element ide3 = document.createElement("ide"); ide3.setTextContent("Visual Studio"); lan3.appendChild(name3); lan3.appendChild(ide3); //最后用根元素包围所有元素 root.appendChild(lan1); root.appendChild(lan2); root.appendChild(lan3); document.appendChild(root); //xml文件的输出 TransformerFactory transformerFactory = TransformerFactory.newInstance(); Transformer transformer = transformerFactory.newTransformer(); StringWriter writer = new StringWriter(); //定义存放数据的变量writer //以输入字符串的方式输出文本 transformer.transform(new DOMSource(document), new StreamResult(writer)); System.out.println(writer); //输出xml文件 transformer.transform(new DOMSource(document),new StreamResult(new File("xml文件"))); &#125; catch (ParserConfigurationException e) &#123; e.printStackTrace(); &#125; catch (TransformerException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出的xml文本内容： 1234567891011121314&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;Languages cat="it"&gt; &lt;lan id="1" &lt;name&gt;Java&lt;/name&gt; &lt;ide&gt;eclipse&lt;/ide&gt; &lt;/lan&gt; &lt;lan id="2"&gt; &lt;name&gt;Swift&lt;/name&gt; &lt;ide&gt;Xcode&lt;/ide&gt; &lt;/lan&gt;&lt;lan id="1"&gt; &lt;name&gt;C#&lt;/name&gt; &lt;ide&gt;Visual Studio&lt;/ide&gt; &lt;/lan&gt;&lt;/Languages&gt; 2、Java中的JSON操作： 有关JSON的简介请点击：JSON学习笔记。 在Java中创建JSON文件： 首先可以在http://vdisk.weibo.com/s/9emUo下载google-gson-2.2.4 Java库，然后导入到Java工程中调用。 1234567891011121314151617181920212223242526272829303132333435363738package java网络通信;import com.google.gson.JsonArray;import com.google.gson.JsonObject;public class 创建JSON文件 &#123; public static void main(String[] args) &#123; //创建一个目标文件 JsonObject object = new JsonObject(); object.addProperty("cat", "it");//添加目标属性 //创建JOSN数组 JsonArray array = new JsonArray(); //创建第一个数组元素 JsonObject lan1 = new JsonObject(); lan1.addProperty("id", 1); lan1.addProperty("name", "Java"); lan1.addProperty("ide", "Eclipse"); array.add(lan1); //创建第一个数组元素 JsonObject lan2 = new JsonObject(); lan2.addProperty("id", 2); lan2.addProperty("name", "Swift"); lan2.addProperty("ide", "Xcode"); array.add(lan2); //创建第一个数组元素 JsonObject lan3 = new JsonObject(); lan3.addProperty("id", 3); lan3.addProperty("name", "C#"); lan3.addProperty("ide", "Visual Studio"); array.add(lan3); //包装数组 object.add("languages", array); object.addProperty("pop", true); //输出josn文本 System.out.println(object.toString()); &#125;&#125; 输出的JSON文本： 123456789&#123; "cat":"it", "languages":[ &#123;"id":1,"name":"Java","ide":"Eclipse"&#125;, &#123;"id":2,"name":"Swift","ide":"Xcode"&#125;, &#123;"id":3,"name":"C#","ide":"Visual Studio"&#125; ], "pop":true&#125; 在Java中读取JSON文本：通过Java读取上面输出的文本文件： 123456789101112131415161718192021222324252627282930313233343536373839package java网络通信;import java.io.FileNotFoundException;import java.io.FileReader;import com.google.gson.JsonArray;import com.google.gson.JsonIOException;import com.google.gson.JsonObject;import com.google.gson.JsonParser;import com.google.gson.JsonSyntaxException;public class 读取JSON文本 &#123; public static void main(String[] args) &#123; try &#123; //创建JSON解析器，用于解析json文档 JsonParser parser = new JsonParser(); JsonObject object = (JsonObject) parser.parse(new FileReader("json.json")); System.out.println("cat="+ object.get("cat").getAsString()); System.out.println("pop="+ object.get("pop").getAsBoolean()); JsonArray array = object.get("languages").getAsJsonArray(); for (int i = 0; i &lt; array.size(); i++) &#123; System.out.println("-------------"); JsonObject subObject = array.get(i).getAsJsonObject(); System.out.println("id=" + subObject.get("id").getAsInt()); System.out.println("name=" + subObject.get("name").getAsString()); System.out.println("ide=" + subObject.get("ide").getAsString()); &#125; &#125; catch (JsonIOException e) &#123; e.printStackTrace(); &#125; catch (JsonSyntaxException e) &#123; e.printStackTrace(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 程序运行结果： 1234567891011121314cat=itpop=true-------------id=1name=Javaide=Eclipse-------------id=2name=Swiftide=Xcode-------------id=3name=C#ide=Visual Studio 3、Java中的HTTP通信 使用 Http 的 Get 方式读取网络数据:123456789101112131415161718192021222324252627282930313233343536373839404142package java网络通信;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.MalformedURLException;import java.net.URL;import java.net.URLConnection;import org.omg.CORBA.portable.InputStream;import java基础.stringBuffer;public class 读取网络数据 &#123; public static void main(String[] args) &#123; try &#123; //获取百度首页信息 URL url = new URL("https://www.baidu.com/"); URLConnection connection = url.openConnection(); //把获取的信息转换位输入流 java.io.InputStream is = connection.getInputStream(); //读取输入流，并指定编码格式为“UTF-8” InputStreamReader isr = new InputStreamReader(is,"UTF-8"); //读取数据缓存区 BufferedReader br = new BufferedReader(isr); String line;//定义数据存放位置 StringBuilder builder = new StringBuilder(); while ((line = br.readLine())!= null) &#123; builder.append(line); &#125; br.close(); isr.close(); is.close(); //打印数据 System.out.println(builder.toString()); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 使用HttpClient进行Get方式通信: 先从http://hc.apache.org/downloads.cgi下载httpcomponents库，导入到java工程中使用。 12345678910111213141516171819202122232425262728293031323334package java网络通信;import java.io.IOException;import org.apache.http.HttpEntity;import org.apache.http.HttpResponse;import org.apache.http.client.ClientProtocolException;import org.apache.http.client.HttpClient;import org.apache.http.client.methods.HttpGet;import org.apache.http.impl.client.HttpClients;import org.apache.http.util.EntityUtils;public class 使用HttpClient进行Get方式通信 &#123; public static void main(String[] args) &#123; new Get().start(); &#125;&#125;class Get extends Thread&#123; HttpClient client = HttpClients.createDefault(); public void run() &#123; HttpGet get = new HttpGet("http://www.baidu.com"); try &#123; HttpResponse response = client.execute(get); HttpEntity entity = response.getEntity();//实用工具 String string = EntityUtils.toString(entity,"UTF-8"); System.out.println(string); &#125; catch (ClientProtocolException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 4、Java中的Socket通信 Socket介绍： Socket又称为“套接字”，英语程序通常通过“套接字”向网络发出请求或者应答网络请求。 对于Java Socket编程而言，有两个概念，一个是ServerSocket，一个是Socket。服务端和客户端之间通过Socket建立连接，之后它们就可以进行通信了。首先ServerSocket将在服务端监听某个端口，当发现客户端有Socket来试图连接它时，它会accept该Socket的连接请求，同时在服务端建立一个对应的Socket与之进行通信。这样就有两个Socket了，客户端和服务端各一个。 ​ 对于Socket之间的通信其实很简单，服务端往Socket的输出流里面写东西，客户端就可以通过Socket的输入流读取对应的内容。Socket与Socket之间是双向连通的，所以客户端也可以往对应的Socket输出流里面写东西，然后服务端对应的Socket的输入流就可以读出对应的内容。 Socket链接的建立过程： 服务器监听。 客户端发出请求。 建立链接。 通信。 Socket特点： Socket基于TCP链接，数据传输有保障。 Socket适用于建立长时间链接。 Socket编程通常用于即时通信。 有关Socket的更多介绍请点击：基础socket—简单聊天室的实现。 ServerSocket的建立与使用：123456789101112131415161718192021package java网络通信;import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;import javax.swing.JOptionPane;public class ServerSocket的创建与使用 &#123; public static void main(String[] args) &#123; try &#123; //端口范围1-65535 ServerSocket serverSocket = new ServerSocket(12345); //block，监听本地12345端口 Socket socket = serverSocket.accept(); //建立连接 JOptionPane.showMessageDialog(null, "有客户端链接到本地的12345端口"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（2）Java语言进阶]]></title>
    <url>%2F2017%2F08%2F12%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89Java%E8%AF%AD%E8%A8%80%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[1、Java集合类详解 Collection接口： 集合可以理解为一个动态的对象数组，不同的是集合中的对象内容可以任意扩充。 集合的特点：1、性能高。 2、容易扩展和修改。 Collection的常用子类： List Set Queue List接口： List接口可以存放任意的数据，而且在List接口中的内容是可以重复的。 List接口常用子类： ArrayList 和 Vector 。 常用操作：（1）、判断集合是否为空：Boolean isEmpty（）（2）、查找指定对象是否存在：int indexOf（Object o）。若存在，返回值为元素所在位置序列号。若不存在，返回值为-1。 ArrayList与Vector的区别： 比较 ArrayList Vertor 推出时间 JDK1.2之后推出 JDK1.0推出 性能 采用异步处理方式，性能高 采用同步处理方法，性能低 线程安全 属于非线程安全 属于线程安全 例如： 1234567891011121314151617181920212223242526272829303132333435package java进阶;import java.util.ArrayList;import java.util.List;public class List接口 &#123; public static void main(String[] args) &#123; List&lt;String&gt; lists = null; lists = new ArrayList&lt;String&gt;(); lists.add("A"); //添加元素 lists.add("B"); lists.add("A"); for (int i = 0; i &lt; lists.size(); i++) &#123; System.out.println(lists.get(i)); &#125; lists.remove(0); //删除指定序列号元素 System.out.println("删除之后---"); for (int i = 0; i &lt; lists.size(); i++) &#123; System.out.println(lists.get(i)); &#125; System.out.println("集合是否为空："+lists.isEmpty());//查看集合是否为空 System.out.println("B是否存在："+lists.indexOf("B")); //查找指定对象是否存在：int indexOf（Object o）。若存在，返回值为元素所在位置序列号。若不存在，返回值为-1。 &#125;&#125;程序执行结果： A B A 删除之后--- B A 集合是否为空：false B是否存在：0 Set接口： Set接口中不能加入重复元素，但可以排序。 Set接口常用子类：（1）散列存放：HashSet。（2）有序存放：TreeSet. 例如： 123456789101112131415161718192021222324package java进阶;import java.util.HashSet;import java.util.Set;import java.util.TreeSet;public class Set接口 &#123; public static void main(String[] args) &#123; Set&lt;String&gt; s = new HashSet&lt;String&gt;(); s.add("E"); s.add("A"); s.add("D"); s.add("C"); s.add("B"); System.out.println(s);//不保证按顺序存放 TreeSet&lt;String&gt; s1 = new TreeSet&lt;String&gt;(); s1.add("E"); s1.add("A"); s1.add("D"); s1.add("C"); s1.add("B"); System.out.println(s1);//保证按顺序存放 &#125;&#125; Iterator接口： 集合输出的标准操作： 标准做法，使用Iterator接口。 操作原理：Iterator是专门的迭代输出接口，迭代输出就是讲元素一个个进行判断，判断其是否有内容，如果有内容则把内容取出。 其接口下定义如下： 12345public interface Iterator &#123; boolean hasNext(); Object next(); void remove(); &#125; 其中： ​ Object next()：返回迭代器刚越过的元素的引用，返回值是Object，需要强制转换成自己需要的类型 ​ boolean hasNext()：判断容器内是否还有可供访问的元素 ​ void remove()：删除迭代器刚越过的元素 ​ 对于我们而言，我们只一般只需使用next()、hasNext()两个方法即可完成迭代。如下： 1234for(Iterator it = c.iterator(); it.hasNext(); ) &#123; Object o = it.next(); //do something &#125; 例如： 1234567891011121314151617181920212223242526272829package java进阶;import java.util.ArrayList;import java.util.Iterator;import java.util.List;public class 迭代输出Iterator接口 &#123; public static void main(String[] args) &#123; List&lt;String&gt; lists = null; lists = new ArrayList&lt;String&gt;(); lists.add("A"); //添加元素 lists.add("B"); lists.add("C"); lists.add("D"); lists.add("E"); Iterator&lt;String&gt; iter = lists.iterator();//迭代接口实例化 while (iter.hasNext()) &#123; String str = iter.next(); if("A".equals(str)) &#123; iter.remove(); //删除A &#125;else &#123; System.out.println(str); &#125; &#125; &#125;&#125;程序执行结果： B C D E Map接口： Map用于保存具有映射关系的数据（key-vlaue）。Map的key不允许重复，即同一个Map对象的任何两个key通过equals方法比较总是返回false Collection 接口是保存单值最大的父接口，那么 Map接口保存的内容是一对值，所有的内容是以：key-&gt;value 的形式保存的。 常用子类：（1）HashMap：无序存放，key不允许重复。（2）Hashtable：无序存放，key不允许重复. HashMap与Hashtable的区别： 区别点 HashMap Hashtable 推出时间 在JDK1.2之后推出的，属于新的类 在JDK1.0是推出的，属于旧的类 操作 采用异步的出来操作 性能相对较低 性能 性能高 性能相对较低 安全 非线程安全的操作 线程安全 Map接口中定义如下方法： 方法 描述 void clear() 删除Map对象中所有key-value对。 boolean containsKey(Object key) 查询Map中是否包含指定key，如果包含则返回true。 boolean containsValue(Object value) 查询Map中是否包含一个或多个value，如果包含则返回true。 Set entrySet() 返回Map中所有包含的key-value对组成的Set集合，每个集合元素都是Map.Entry(Entry是Map的内部类）对象。 Object get(Obejct key) 返回指定key所对应的value；如果此Map中不包含key，则返回null。 boolean isEmpty(): 查询该Map是否为空（即不包含任何key-value对），如果为空则返回true。 Set keySet() 返回该Map中所有key所组成的set集合。 Object put(Object key, Object value) 添加一个key-value对，如果当前Map中已有一个与该key相等的key-value对，则新的key-value对会覆盖原来的key-value对。 Object remove(Object key) 删除指定key对应的key-value对，返回被删除key所关联的value，如果该key不存在，返回null。 int size() 返回该Map里的key-value对的个数。 Collection values() 返回该Map里所有value组成的Collection。 例如： 1234567891011121314151617181920212223242526272829303132333435363738394041package java进阶;import java.util.Collection;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Set;public class Map接口 &#123; public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;String,String&gt;(); map.put("key1", "A"); //添加数据 map.put("key2", "B"); map.put("key3", "C"); map.put("key4", "D"); map.put("key5", "E"); String str = map.get("key1"); System.out.println(str); //通过键值找到对应值 if (map.containsKey("key1")) &#123; //判断键是否存在 System.out.println("key1存在"); &#125;else &#123; System.out.println("key1不存在"); &#125; if (map.containsValue("A")) &#123; //判断值是否存在 System.out.println("A存在"); &#125;else &#123; System.out.println("A不存在"); &#125; Set&lt;String&gt; s = map.keySet(); //将所有键打印出来 Iterator&lt;String&gt; i = s.iterator(); while (i.hasNext()) &#123; System.out.println(i.next()); &#125; Collection&lt;String&gt; c = map.values();//将所有值打印出来 Iterator&lt;String&gt; i1 = c.iterator(); while (i1.hasNext()) &#123; System.out.println(i1.next()); &#125; &#125;&#125; 2、Java本地文件操作 文件的创建、重命名、删除：1234567891011121314151617181920212223242526272829package java进阶;import java.io.File;import java.io.IOException;public class 文件的基本操作 &#123; //文件夹结果必须处于同一分区 //文件夹处于不同的分区，需要使用文件的拷贝。而不是重命名 public static void main(String[] args) &#123; File file = new File("hello.txt"); //判断文件是否存在 if(file.exists()) &#123; File nameto = new File("new hello"); file.renameTo(nameto); //文件重命名 &#125;else &#123; System.out.println("文件不存在"); try &#123; file.createNewFile(); //如果文件不存在创建新文件 System.out.println("文件已经成功创建"); &#125; catch (IOException e) &#123; System.out.println("文件无法创建"); &#125; &#125; System.out.println(file.isFile()); System.out.println(file.isDirectory()); file.delete(); System.out.println("文件已删除"); &#125;&#125; 文件夹的创建、重命名、删除：1234567891011121314151617181920212223242526272829303132package java进阶;import java.io.File;public class 文件夹的基本操作 &#123; public static void main(String[] args) &#123; File folder = new File("my new folder/two/three/main"); if (folder.mkdirs()) &#123; System.out.println("文件夹创建成功"); &#125;else &#123; if (folder.exists()) &#123; System.out.println("文件夹已经存在无需创建"); &#125;else &#123; System.out.println("文件创建失败"); &#125; &#125; File newfolder = new File("my new folder-new/one/two"); if (folder.renameTo(newfolder)) &#123; System.out.println("文件夹重命名成功"); &#125;else &#123; if (newfolder.exists()) &#123; System.out.println("文件夹已经重命名成功"); &#125;else &#123; System.out.println("文件夹重命名失败"); &#125; &#125; //只能删除空文件夹 if (newfolder.delete()) &#123; System.out.println("文件夹删除成功"); &#125;else &#123; System.out.println("文件夹删除失败"); &#125; &#125;&#125; 获取文件的属性：12345678910111213141516171819202122232425262728293031323334353637383940package java进阶;import java.awt.geom.FlatteningPathIterator;import java.io.Filepublic class 获取文件属性 &#123; public static void main(String[] args) &#123; File file = new File("new hello");// 判断文是否存在 System.out.println("判断文是否存在:"+file.exists());// 读取文件名称 System.out.println("读取文件名称:"+file.getName());// 读取文件路径 System.out.println("读取文件路径:"+file.getPath());// 读取文件绝对路径 System.out.println("读取文件绝对路径:"+file.getAbsolutePath());// 读取文件父级路径 System.out.println("读取文件父级路径:"+ new File(file.getAbsoluteFile().getParent()));// 读取文件大小 System.out.println("读取文件大小:"+ file.length()+"Byte");// 判断文件是否被隐藏 System.out.println("判断文件是否被隐藏:"+file.isHidden());// 判断文件是否可写 System.out.println("判断文件是否可写:"+file.canWrite());// 判断文件是否可读 System.out.println("判断文件是否可读:"+file.canRead());// 判断文件是否为文件夹 System.out.println("判断文件是否为文件夹:"+file.isDirectory()); &#125;&#125;程序执行结果： 判断文是否存在:true 读取文件名称:new hello 读取文件路径:new hello 读取文件绝对路径:D:\我的软件\eclipse\java学习\new hello 读取文件父级路径:D:\我的软件\eclipse\java学习 读取文件大小:21Byte 判断文件是否被隐藏:false 判断文件是否可写:true 判断文件是否可读:true 判断文件是否为文件夹:false 文件属性的设置：123456789101112131415package java进阶;import java.io.File;public class 文件属性的设置 &#123; public static void main(String[] args) &#123; File file = new File("new hello"); if (file.exists()) &#123; //将文件设置为可写 file.setWritable(true); //将文件设置为可读 file.setReadable(true); //将文件设置为只读 file.setReadOnly(); &#125; &#125;&#125; 文件的遍历：123456789101112131415161718192021package java进阶;import java.io.File;public class 文件的遍历 &#123; public static void main(String[] args) &#123; printFiles(new File("../java学习"),1); &#125; public static void printFiles(File dir,int tab) &#123; if (dir.isDirectory()) &#123; File next[] = dir.listFiles(); //返回文件的目录文件名数组 for (int i = 0; i &lt; next.length; i++) &#123; for (int j = 0; j &lt; tab; j++) &#123; System.out.print("|---"); &#125; System.out.println(next[i].getName()); if (next[i].isDirectory()) &#123; printFiles(next[i],tab+1); &#125; &#125; &#125; &#125;&#125; 程序执行结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141|---.classpath|---.project|---.settings|---|---org.eclipse.jdt.core.prefs|---bin|---|---java基础|---|---|---stringBuffer.class|---|---|---Switch开关语句.class|---|---|---字符串操作.class|---|---|---异常处理.class|---|---|---找最大数.class|---|---|---控制台输入.class|---|---|---数组排序.class|---|---|---逻辑运算.class|---|---java进阶|---|---|---List接口.class|---|---|---Map接口.class|---|---|---Set接口.class|---|---|---文件夹的基本操作.class|---|---|---文件属性的设置.class|---|---|---文件的基本操作.class|---|---|---文件的遍历.class|---|---|---获取文件属性.class|---|---|---迭代输出Iterator接口.class|---|---java面向对象|---|---|---A.class|---|---|---A1.class|---|---|---A2.class|---|---|---Abs.class|---|---|---Abs3.class|---|---|---B.class|---|---|---B1.class|---|---|---B2.class|---|---|---C.class|---|---|---C1.class|---|---|---Computer.class|---|---|---D.class|---|---|---Father.class|---|---|---Gener.class|---|---|---Generic.class|---|---|---Gin.class|---|---|---I.class|---|---|---Ineter1.class|---|---|---instanceof关键字.class|---|---|---Inter2.class|---|---|---Inter3.class|---|---|---Interface.class|---|---|---J.class|---|---|---People.class|---|---|---People1.class|---|---|---People2.class|---|---|---People3.class|---|---|---Person.class|---|---|---Person1.class|---|---|---PetWorker.class|---|---|---Point.class|---|---|---Printer.class|---|---|---Ref.class|---|---|---Son.class|---|---|---Student.class|---|---|---Student1.class|---|---|---Student2.class|---|---|---this关键字.class|---|---|---USB.class|---|---|---USBDesk.class|---|---|---Worker.class|---|---|---Worker2.class|---|---|---匿名对象.class|---|---|---多态性.class|---|---|---子类对象的实例化.class|---|---|---对象多态性的应用.class|---|---|---封装性.class|---|---|---引用传递.class|---|---|---抽象类.class|---|---|---抽象类的应用.class|---|---|---接口的实现.class|---|---|---接口的应用.class|---|---|---构造方法.class|---|---|---构造方法中使用泛型.class|---|---|---泛型接口.class|---|---|---泛型数组.class|---|---|---泛型方法.class|---|---|---继承.class|---|---|---继承方法的重写.class|---|---|---继承的限制.class|---|---|---认识泛型.class|---|---|---递归调用.class|---my new folder|---|---one|---|---|---two|---|---|---|---three|---|---|---|---|---main|---|---two|---|---|---three|---|---|---|---main|---my new folder-new|---|---one|---new hello|---src|---|---java基础|---|---|---stringBuffer.java|---|---|---Switch开关语句.java|---|---|---字符串操作.java|---|---|---异常处理.java|---|---|---找最大数.java|---|---|---控制台输入.java|---|---|---数组排序.java|---|---|---逻辑运算.java|---|---java进阶|---|---|---List接口.java|---|---|---Map接口.java|---|---|---Set接口.java|---|---|---文件夹的基本操作.java|---|---|---文件属性的设置.java|---|---|---文件的基本操作.java|---|---|---文件的遍历.java|---|---|---获取文件属性.java|---|---|---迭代输出Iterator接口.java|---|---java面向对象|---|---|---instanceof关键字.java|---|---|---this关键字.java|---|---|---匿名对象.java|---|---|---多态性.java|---|---|---子类对象的实例化.java|---|---|---对象多态性的应用.java|---|---|---封装性.java|---|---|---引用传递.java|---|---|---抽象类.java|---|---|---抽象类的应用.java|---|---|---接口的实现.java|---|---|---接口的应用.java|---|---|---构造方法.java|---|---|---构造方法中使用泛型.java|---|---|---泛型接口.java|---|---|---泛型数组.java|---|---|---泛型方法.java|---|---|---继承.java|---|---|---继承方法的重写.java|---|---|---继承的限制.java|---|---|---认识泛型.java|---|---|---递归调用.java 文件的简单读写：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package java进阶;import java.io.BufferedReader;import java.io.BufferedWriter;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStreamReader;import java.io.OutputStream;import java.io.OutputStreamWriter;import java.io.UnsupportedEncodingException;public class 文件的简单读写 &#123; public static void main(String[] args) &#123; File file = new File("hello word"); //如果文件不存在，文件输出流会自动创建文件 //写文件 try &#123; FileOutputStream fos = new FileOutputStream(file); //创建文件输出流 OutputStreamWriter osw = new OutputStreamWriter(fos,"UTF-8");//创建输出流 BufferedWriter bw = new BufferedWriter(osw); //创建缓冲区的write bw.write("hello word!\n");//向文件写入“hello word！” bw.close();//关闭流 osw.close(); fos.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //读取文件 try &#123; FileInputStream fis = new FileInputStream(file); InputStreamReader isr = new InputStreamReader(fis, "UTF-8"); BufferedReader br = new BufferedReader(isr); String list; //定义一个变量用于存放读取的数据 while ((list = br.readLine()) != null) &#123; System.out.println(list); &#125; br.close(); isr.close(); fis.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125;程序执行结果： hello word！ 3、Java中的IO操作 Java IO简介： IO也写作“I/O”，可理解为In和Out，即输入与输出。所有，IO体系的基本功能就是：读和写。 IO流作用：读写设备上的数据，硬盘文件、内存、键盘、网络··· 根据数据的走向，可以分为：输入流、输出流。 根据处理的数据类型，可分为：字节流、字符流。 字节流与字符流： 字节流可以处理所有类型的数据，如MP3、图片、文字、视频等。在读取时，读到一个字节就返回一个字节。在Java中对应的类都以“Stream”结尾。 字符流仅能够处理纯文本数据，如txt文本等。在读取时，读到一个或多个字节，先查找指定的编码表，然后将查到的字符返回。在Java中对应的类都以“Reader”或“Writer”结尾。 字符、字节与编码的区别： 说明 举例 字符 人们使用的记号，抽象意义上的一个符号。 “1”，”中”,”a” 字节 计算机中的存储数据的单元，一个8位的二进制大数，是一个很具体的存储空间。 0x01，0x45 ANSI编码 系统预设的标准文字存储格式，不是具体的某一种编码，不同的国家和地区使用不同的标准。ANSI编码的一个字符可能使用一个字节或多个字节来表示。 “中文123”(7Byte) Unicode编码 为了是国际间信息交流更加方便，国际组织制定了Unicode字符集，为各种语言中的每一个字符设定了统一并且唯一的数字编码，以满足跨语言、跨平台进行文本转换、处理的要求。 中文123”(10Byte) 字符集（Charset） 字符集，也称作“编码”。 使用文件流读写文件：123456789101112131415161718192021222324252627package java进阶;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;public class 使用字节流读写数据 &#123; public static void main(String[] args) &#123; try &#123; FileOutputStream fos = new FileOutputStream("hello word1"); FileInputStream fis = new FileInputStream("hello word"); byte input[] = new byte[30]; //定义读取文件存放位置 fis.read(input); //读文件 String inputString = new String(input); System.out.println(inputString);//输出文件内容 fos.write(input); //写入新的文件，实现文件的复制 fos.close(); //关闭流 fis.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 4、Java多线程编程: 线程与进程： 线程：程序中单独顺序的控制流。特点：（1）线程本身依靠程序进行运行。（2）线程是程序中的顺序控制流，只能使用分配给程序的资源和环境。 进程：执行中的程序。（1）一个进程可以包含一个或多个线程。（2）一个进程至少要包含一个线程。 单线程：程序中只存在一个线程，实际上主方法就是一个主线程。 多线程：（1）多线程是一个程序中运行多个任务。（2）多线程的母的是为了更好的使用CPU资源。 线程的实现： 在Java中，线程的实现有2种。（1）继承Thread类。（2）实现Runnable接口。 Thread类：是在Java.lang包中定义的，继承Thread类必须重写run（）方法。定义格式： 123class className extends Thread&#123; run（）&#123;&#125;；&#125; Runnable接口 例如： 通过继承Thread类实现线程： 1234567891011121314package java进阶;//通过继承Thread类实现线程public class MyThread extends Thread&#123; private String name; public MyThread(String name) &#123; //构造方法用于传参 this.name = name; &#125; public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; System.out.println(name+":"+i); &#125; super.run(); &#125;&#125; 通过Runnable接口实现线程： 12345678910111213package java进阶;//通过Runnable接口实现线程public class MyRunnable implements Runnable&#123; private String name; public MyRunnable(String name) &#123; this.name = name; &#125; public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; System.out.println(name+":"+i); &#125; &#125;&#125; 用过主函数调用方法: 1234567891011121314151617181920package java进阶;public class 线程主函数 &#123; public static void main(String[] args) &#123; //通过Thread方法实现线程 MyThread t1 = new MyThread("A"); MyThread t2 = new MyThread("B"); t1.start(); //线程的启动时通过start t2.start(); //通过Runnable实现线程 MyRunnable r1 = new MyRunnable("C"); MyRunnable r2 = new MyRunnable("D"); Thread t3 = new Thread(r1); Thread t4 = new Thread(r2); t3.start(); t4.start(); &#125;&#125; 线程的状态：线程有固定的操作状态： 创建状态：准备好了一个多线程的对象。 就绪状态：调用start（）方法，等待CPU进行调度。 运行状态：执行run（）方法。 阻塞状态：暂时停止执行，可能将资源交给其他线程使用。 终止状态（死亡状态）: 线程销毁。 线程的常用方法： 取得线程名称：getName(); 取得当前线程对象：currentThread(); 判断线程是否启动：isAlive(); 线程的强行运行：join(); 线程的休眠：sleep(); 线程的礼让：yield(); 例如： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package java进阶;class Thread1 extends Thread&#123; private String name; public Thread1(String name) &#123; this.name = name; &#125; public void run() &#123; for (int i = 0; i &lt; 50; i++) &#123; System.out.println(name+":"+i); if (i == 10) &#123; System.out.println("礼让"); Thread.yield(); &#125; try &#123; Thread.sleep(10); //线程的休眠 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //取得当前线程对象 System.out.println(Thread.currentThread()); //取得当前线程名称 System.out.println(Thread.currentThread().getName()); super.run(); &#125;&#125;public class 线程的常用方法 &#123; public static void main(String[] args) &#123; Thread1 t1 =new Thread1("A"); Thread1 t2 =new Thread1("B"); //判断线程是否启动 System.out.println(t1.isAlive()); t1.start(); for (int i = 0; i &lt; 50; i++) &#123; if (i &gt; 10) &#123; try &#123; t1.join(); //线程的强制执行 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println("主线程："+i); &#125; t2.start(); System.out.println(t1.isAlive()); &#125;&#125; 线程优先级： MIN_Priority—1 MAX_Priority—10 NORM——Priority—5. 默认值为5 注意：线程优先级不是一定按优先级执行。而是提高了执行概率。 1t1.setPtiority(Thread.MIN_PRIOITY); 同步与死锁： 同步代码块：在代码块上加上“synchronized”关键字，则此代码块就称为同步代码块。 同步代码块格式： 123synchronized(同步对象)&#123; 需要同步的代码块；&#125; 同步方法：除了代码块可以同步，方法也可以同步。 方法同步的格式：synchronized void 方法名称（）{} 同步实现了资源的共享。 死锁：死锁是两个甚至多个线程被永久阻塞时的一种运行局面，这种局面的生成伴随着至少两个线程和两个或者多个资源。 1234567891011121314151617181920212223242526272829303132package java进阶;//三个窗口卖一辆车的车票，实现数据的同步class Synchornized implements Runnable&#123; private int ticket = 5; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; tell(); &#125; &#125; public synchronized void tell() &#123; //同步方法 if(ticket &gt; 0) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("ticket:" + ticket-- ); &#125; &#125;&#125;public class 线程的同步 &#123; public static void main(String[] args) &#123; Synchornized s = new Synchornized(); Thread t1 = new Thread(s); Thread t2 = new Thread(s); Thread t3 = new Thread(s); t1.start(); t2.start(); t3.start(); &#125;&#125; 线程的生命周期： 图：线程的生命周期]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java学习笔记（1）面向对象]]></title>
    <url>%2F2017%2F08%2F12%2FJava%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[1、Java面向对象中类与对象的概念和使用 方法的定义： 方法就是一段可以重复调用的代码。 定义格式：123访问修饰符 返回值类型 方法名（）&#123; 方法主体 &#125; 方法的返回值类型： void类型不需要返回值，其他类型的全部需要返回值。 方法的重载： 方法名称不同，但是参数的类型和个数相同，通过传递参数的个数和类型不同来完成不同的功能。 类的定义：1234class 类名称&#123; 属性 方法 &#125; 声明一个类需要通过一个关键字class。 类与对象的关系： 类是对某一类事物的描述，是抽象的、概念上的意义，对象是实际存在的该类事物的每一个个体，也被称为对象或实例。 了解面向对象：1、程序的发展历程：面向过程、面向对象。 2、解释面向过程和面向对象：（比如制作一个盒子） 面向过程：不去想做什么样子的盒子，随机取工具制作。 面向对象：先想好做一个什么样的盒子，再去找对应的工具去做。 面向对象的三大特征： 封装性：对外部不可见。 继承：扩展类的功能。 多态性：方法的重载。 对象的多态性。 方法的递归： 递归调用就是方法自己调用自己。 例如：求1-100的和。 123456789101112131415package java面向对象;public class 递归调用 &#123; public static void main(String[] args) &#123; System.out.println(sum(100)); &#125; //求1-100的和 public static int sum(int n)&#123; if (n == 1) //程序出口 return 1; else return n+sum(n-1); &#125;&#125; 2、Java面向对象的基本特征之一：封装性 封装性： 1、封装性的目的：保护某些属性和方法不被外部所看见。 2、封装的实现：为属性和方法进行封装是通过关键字private声明的。 实现该属性的set和get方法，为外部所访问。 例如： 1234567891011121314151617181920212223242526272829303132package java面向对象;//private 实现分装，外部不可直接调用。//get set 是外界访问的接口。class Person&#123; private int age; private String name; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; if (age&gt;=0 &amp;&amp; age&lt;150) &#123; //判断年龄是否合法。若非法显示为0 this.age = age; &#125; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void tell()&#123; //get是得到 System.out.println("姓名："+getName()+" 年齡："+getAge()); &#125;&#125;public class 封装性 &#123; public static void main(String[] args) &#123; Person per = new Person(); per.setName("张三");//set是设置 per.setAge(30); per.tell(); &#125;&#125; 匿名对象： 匿名对象就是没有名字的对象，如果程序中只用一次该对象，就可以事业匿名对象的方式。 例如： 123456789101112131415package java面向对象;class Student&#123; public void tell() &#123; System.out.println("hello"); &#125;&#125;public class 匿名对象 &#123; public static void main(String[] args) &#123; //正常对象 Student stu = new Student(); stu.tell(); //匿名对象 new Student().tell();//调用一次的情况可用匿名对象 &#125;&#125; 构造方法：1、格式： 123访问修饰符 类名称（）&#123; 程序语句 &#125; 2、注意点： 构造方法名称必须与类名一致。 构造方法没有返回值。 3、构造方法主要是为类中的属性初始化。 4、每个类在实例化之后都会调用构造方法，如果没有构造方法，程序在编译的时候回创建一个无参的什么都不做的构造方法。 5、构造方法也可以重载。 例如： 123456789101112package java面向对象;class People&#123; //构造方法 public People(int a) &#123; System.out.println(a); &#125;&#125;public class 构造方法 &#123; public static void main(String[] args) &#123; People per = new People(5); &#125;&#125; 3、Java面向对象中引用的传递引用传递： 也称为传地址。方法调用时，实际参数的引用(地址，而不是参数的值)被传递给方法中相对应的形式参数，在方法执行中，对形式参数的操作实际上就是对实际参数的操作，方法执行中形式参数值的改变将会影响实际参数的值。 值传递： 方法调用时，实际参数把它的值传递给对应的形式参数，方法执行中形式参数值的改变不影响实际参 数的值。 例如： 123456789101112131415package java面向对象;class Ref&#123; String temp = "hello";&#125;public class 引用传递 &#123; public static void main(String[] args) &#123; Ref r1 = new Ref(); System.out.println(r1.temp); tell(r1); System.out.println(r1.temp); &#125; public static void tell(Ref r1) &#123; r1.temp = "word"; &#125;&#125; this关键字： 表示类中的属性和调用方法。 调用本类中的构造方法。 表示当前对象。 12345678910111213141516171819202122232425package java面向对象;class People1&#123; String name; int age; public People1(String name,int age) &#123; this(); //this作用二：调用本类中构造方法 //注意：使用此调用，必须放在第一行 this.name=name; //this作用一：调用本类中属性name this.age=age; &#125; private People1() &#123; System.out.println("调用无参构造方法"); &#125; public void tell() &#123; System.out.println("姓名："+this.name+" 年龄："+this.age); System.out.println(this); //this作用三：表示当前对象 &#125;&#125;public class this关键字 &#123; public static void main(String[] args) &#123; People1 p = new People1("张三",30); p.tell(); &#125;&#125; static关键字： 使用static声明属性：static声明全局属性。 使用static声明方法：直接通过类名调用。 注意点：使用static方法的时候，只能访问static声明的属性和方法，而非static声明的属性和方法是不能被访问的。 4、Java面向对象基本特征：继承 继承的实现： 继承的基本概念：扩展父类的功能。 Java中使用extends关键字完成继承。 class 子类 extends 父类 {} 例如： 1234567891011121314151617181920212223242526package java面向对象;class People2&#123; String name; int age; public void tell() &#123; System.out.println("姓名：" +name+ "年龄："+age); &#125;&#125;//学生为人的子类，可以继承人的属性，姓名，年龄class Student2 extends People2&#123; int score; public void say() &#123; System.out.println("成绩："+score); &#125;&#125;public class 继承 &#123; public static void main(String[] args) &#123; Student2 s = new Student2(); s.age = 15; s.name = "小明"; s.score = 89; s.tell(); s.say(); &#125;&#125; 继承的限制： 在Java中只允许单继承。 子类不能直接访问父类的私有地址。 例如： 12345678910111213141516171819202122232425262728package java面向对象;//只能进行单继承//子类不能直接访问父类的私有地址。class People3&#123; private int age; //封装为私有属性 public void setAge(int age) &#123; this.age = age; &#125; public int getAge() &#123; return age; &#125;&#125;class Worker extends People3&#123; //Worker单继承People3 &#125;class PetWorker extends Worker&#123; //PetWorker单继承Worker public void tell(int age) &#123; setAge(age); //子类通过get和set可调用父类私有地址 System.out.println(getAge()); &#125;&#125;public class 继承的限制 &#123; public static void main(String[] args) &#123; PetWorker p = new PetWorker(); p.tell(30); &#125;&#125; 子类对象的实例化： 在子类对象实例化之前，必须先调用父类中的构造方法，之后调用子类的构造方法。 例如： 1234567891011121314151617181920package java面向对象;class Father&#123; public Father() &#123; System.out.println("父类的构造方法"); &#125;&#125;class Son extends Father&#123; public Son() &#123; System.out.println("子类的构造方法"); &#125;&#125;public class 子类对象的实例化 &#123; public static void main(String[] args) &#123; Son s =new Son(); //声明并实例化 &#125;&#125;程序执行结果： 父类的构造方法 子类的构造方法 继承方法的重写： 在继承中，也存在着重写的概念，其实就是定义了和父类同名的方法。 定义：方法名称相同，返回值类相同，参数也相同。 重写的限制：被子类重写的方法不能拥有比父类更加严格的访问权限。 访问权限：private&lt;default&lt;public public、private、protected、default的区别： 首先就class之间的关系做一个简单的定义，对于继承自己的class，base class可以认为他们都是自己的子女，而对于和自己一个目录下的classes（即同一个包），认为都是自己的朋友friendly。 public：public表明该数据成员、成员函数是对所有用户开放的，所有用户都可以直接进行调用 private：private表示私有，私有的意思就是除了class自己之外，任何人都不可以直接使用，私有财产神圣不可侵犯嘛，即便是子女，朋友，都不可以使用。 protected：protected对于子女、朋友来说，就是public的，可以自由使用，没有任何限制，而对于其他的外部class，protected就变成private。 default：java的默认访问权限，当没有使用上面提到的任何访问限定词时，就使用它，这种权限通常被称为包访问权限，在这种权限下，类可以访问在同一个包中的其他类的成员，也即可以访问我们前面说的朋友，在包之外，这些成员如同指定了private。 java 变量作用域的修饰的作用范围： public:类本身和任何包的任何类都访问 private 只有类本身可以访问，其他类想访问可以通过该类的成员方法访问如getter/setter protected:保护的，这个和缺省的比较容易混淆，记住最主要区别是：protected可以在不同包的子类被访问，而friendly不可以。 protected可以在类本身、同包的子类，不同包的子类，同包的非子类 被访问 缺省的：可以在类本身，同包的子类，同包的非子类 被访问。 同类 同包 不同包子类 不同包非子类 private √ default √ √ protected √ √ √ public √ √ √ √ super关键字： 强行调用父类的方法的执行。 super不一定在重写中使用，也可以表示哪些方法是从父类中继承而来的。 例如： 123456789101112131415161718192021package java面向对象;class A&#123; void tell() &#123; System.out.println("父类的构造方法"); &#125;&#125;class B extends A&#123; void tell() &#123; //方法的重写 super.tell(); //super强行调用父类的方法的执行 System.out.println("子类的构造方法"); &#125;&#125;public class 继承方法的重写 &#123; public static void main(String[] args) &#123; B b = new B(); b.tell(); &#125;&#125;程序执行结果： 父类的构造方法 子类的构造方法 重写与重载的区别：(重点) NO 区别点 重载 重写 1 单词 Overloading Overriding 2 定义 方法名称相同，参数的类型和个数不同 方法名称、参数的类型个数、返回值全部相同 3 权限要求 对权限没要求 被重写的方法不能有比父类更加严格的权限 4 范围 发生在一个类中 发生在继承中 5、Java面向对象-抽象类与接口 final关键字：1、final关键字在java中被称为完结器，表示终结的意思。 2、final使能声明类、方法。属性： 使能final声明的类不能被继承。 使能final声明的方法不能被重写。 使能final声明的变了变成常量。常量是不可以被修改的。 抽象类： 抽象类概念：包含一个抽象方法的类就是抽象类。 抽象方法：声明而未被实现的方法，抽象方法必须使用abstract关键字声明。 抽象类被子类继承，子类（如果不是抽象类）必须重写抽象类中的所有抽象方法。 定义格式： 12345abstract class className&#123; 属性 方法 抽象方法&#125; 抽象类不能直接实例化，要通过其子类进行实例化。 例如： 12345678910111213141516171819202122package java面向对象;abstract class Abs&#123; //抽象类也必须使用abstract声明 int age; private void tell() &#123; &#125; //抽象方法,声明而未被实现的方法 public abstract void say();&#125;class C extends Abs&#123; //抽象类被子类继承，子类（如果不是抽象类）必须重写抽象类中的所有抽象方法。而且方法必须实现。 public void say() &#123; System.out.println(20); &#125;&#125;public class 抽象类 &#123; public static void main(String[] args) &#123; // Abs a = new Abs(); //抽象类不能被直接实例化 C c = new C(); //抽象类必须通过子类实例化 c.say(); &#125;&#125; 接口的实现： 接口是Java中最重要的概念、接口可以理解为一种特殊的类，里面全部是由全局常量和公共的抽象方法所组成的。 接口的格式： 1234interface interfaceName&#123; 全局常量 抽象方法&#125; 接口的实现也必须通过子类，使用关键字implments，而且接口是可以多实现的。 一个子类可以同时继承抽象类和实现多接口。 一个接口不能继承一个抽象类，但是却可以通过extends关键字同时继承多个接口，实现接口的多继承。 例如： 12345678910111213141516171819202122232425262728293031package java面向对象;interface Ineter1&#123; //定义了一个接口1 public static final int AGE = 20; //定义全局常量，全局常量名称必须全部大写 public abstract void tell(); //定义一个抽象方法&#125;interface Inter2&#123; //定义接口2 public abstract void say(); &#125;abstract class Abs3&#123; //定义抽象类 public abstract void print();&#125;//一个子类同时继承抽象类和实现多接口class D extends Abs3 implements Ineter1,Inter2&#123; public void tell() &#123;&#125; //复写接口内的抽象方法 public void say() &#123;&#125; public void print() &#123;&#125;&#125; //一个接口不能继承一个抽象类，但是却可以通过extends关键字同时继承多个接口，实现接口的多继承interface Inter3 extends Inter2,Ineter1&#123;&#125;public class 接口的实现 &#123; public static void main(String[] args) &#123; //Inetr1 i = new Inetr1(); //接口的实例化必须通过子类。 D d= new D(); //实例化接口 d.tell(); d.say(); System.out.println(Ineter1.AGE); &#125;&#125; 6、Java面向对象多态性 多态性：1、多态性的体现：方法的重载和重写。 对象的多态性。 2、对象的多态性： 向上转型：程序会自动完成。 父类 父类对象 = 子类实例 向下转型：强制类型转换。 子类 子类对象 = （子类）父类实例 例如： 1234567891011121314151617181920212223242526272829303132333435363738package java面向对象;//多态性的体现：方法的重载和重写。 对象的多态性。class I&#123; public void tell1() &#123; System.out.println("I--tell1"); &#125; public void tell2() &#123; System.out.println("I--tell2"); &#125;&#125;class J extends I&#123; public void tell1() &#123; System.out.println("J==tell1"); &#125; public void tell3() &#123; System.out.println("J==tell3"); &#125;&#125;public class 多态性 &#123; public static void main(String[] args) &#123; //向上转型 程序会自动完成。 父类 父类对象 = 子类实例// J j = new J();// I i = j;// i.tell1(); //执行tell1重写的// i.tell2(); //向下转型：强制类型转换。 子类 子类对象 = （子类）父类实例 //必须先向上转型，才能向下转型 I i = new J(); //是对向上转型的缩写 J j = (J)i; j.tell1(); j.tell2(); j.tell3(); &#125;&#125;程序执行结果： J==tell1 I--tell2 J==tell3 instanceof关键字： instanceof 运算符是用来在运行时指出对象是否是特定类的一个实例。instanceof通过返回一个布尔值来指出，这个对象是否是这个特定类或者是它的子类的一个实例。 用法：result = object instanceof class 参数： Result：布尔类型。 Object：必选项。任意对象表达式。 Class：必选项。任意已定义的对象类。 说明： 如果 object 是 class 的一个实例，则 instanceof 运算符返回 true。如果 object 不是指定类的一个实例，或者 object 是 null，则返回 false。 例如： 123456789101112131415161718192021package java面向对象;class A2&#123; &#125;class B2 extends A2&#123; &#125;public class instanceof关键字 &#123; public static void main(String[] args) &#123; A2 a2 = new A2(); System.out.println(a2 instanceof A2); System.out.println(a2 instanceof B2); //向上转型 A2 a3 = new B2(); System.out.println(a3 instanceof A2); System.out.println(a3 instanceof B2); &#125;&#125;程序执行结果： true false true true 抽象类的应用举例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package java面向对象;abstract class Person1&#123; private int age; private String name; public void setAge(int age) &#123; this.age = age; &#125; public int getAge() &#123; return age; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public Person1(String name,int age)&#123; this.name = name; this.age = age; &#125; public abstract void want();&#125;class Student1 extends Person1&#123; private int score; public int getScore() &#123; return score; &#125; public void setScore(int score) &#123; this.score = score; &#125; public Student1(String name,int age,int score) &#123; super(name, age); this.score = score; &#125; public void want() &#123; System.out.println("姓名："+getName()+" 年龄："+getAge()+" 工资："+getScore()); &#125;&#125;class Worker2 extends Person1&#123; private int maney; public void setManey(int maney) &#123; this.maney = maney; &#125; public int getManey() &#123; return maney; &#125; public Worker2(String name, int age, int maney) &#123; super(name, age); this.maney = maney; &#125; public void want() &#123; System.out.println("姓名："+getName()+" 年龄："+getAge()+" 工资："+getManey()); &#125;&#125;public class 抽象类的应用 &#123; public static void main(String[] args) &#123; Student1 s = new Student1("小明", 10, 100); s.want(); Worker2 w = new Worker2("小明",30, 3000); w.want(); &#125;&#125;程序执行结果： 姓名：小明 年龄：10 工资：100 姓名：小明 年龄：30 工资：3000 接口的应用举例：12345678910111213141516171819202122232425262728293031323334353637383940414243package java面向对象;interface USB&#123; //定义一个USB接口 void start(); //定义抽象方法 void stop();&#125;class Computer&#123; public static void work(USB u) &#123; u.start(); System.out.println("工作中···"); u.stop(); &#125;&#125;class USBDesk implements USB&#123; //定义一个U盘设备 public void start() &#123; System.out.println("U盘开始工作"); &#125; public void stop() &#123; System.out.println("U盘结束工作"); &#125;&#125;class Printer implements USB&#123; //定义一个打印机设备 public void start() &#123; System.out.println("打印机开始工作"); &#125; public void stop() &#123; System.out.println("打印机结束工作"); &#125;&#125;public class 接口的应用 &#123; public static void main(String[] args) &#123; Computer.work(new USBDesk()); //模拟U盘通过USB接口连接电脑 Computer.work(new Printer()); //模拟打印机通过USB接口连接电脑 &#125;&#125;程序执行结果： U盘开始工作 工作中··· U盘结束工作 打印机开始工作 工作中··· 打印机结束工作 7、Java面向对象之泛型 认识泛型： 泛型是在JDK1.5 之后新增的新功能。泛型（Generic）。 泛型可以解决数据类型的安全性问题，他的主要原理，是在类声明的时候通过一个标识表示类中某个属性的类型或者是某个方法的返回值及参数类型。 格式： 1234访问权限 class 类名称&lt;泛型，泛型···&gt;&#123; 属性 方法&#125; 对象的创建： 类名称&lt;具体类型&gt; 对象名称 = new 类名称&lt;具体类型&gt; 例如： 123456789101112131415161718192021222324252627package java面向对象;//表示经纬度，坐标x，yclass Point&lt;T&gt;&#123; //一般用T表示 private T x; private T y; public T getX() &#123; return x; &#125; public void setX(T x) &#123; this.x = x; &#125; public T getY() &#123; return y; &#125; public void setY(T y) &#123; this.y = y; &#125;&#125;public class 认识泛型 &#123; public static void main(String[] args) &#123; Point p = new Point&lt;String&gt;(); //需要什么类型的数据，就在尖括号中声明什么类型的数据 p.setX("经度为：10"); p.setY("纬度为：20"); System.out.println(p.getX()+" "+p.getY()); &#125;&#125; 构造方法使用泛型： 构造方法可以为类中的属性初始化，那么如果类中的属性通过泛型指定，而又需要通过该构造方法设置属性内容的时候，那么构造方法得的定义与之前并无不同，不需要像声明类那样指定泛型。 例如： 12345678910111213141516171819202122package java面向对象;class Generic&lt;T&gt;&#123; private T value; public Generic(T value) &#123; this.value = value; &#125; public void setValue(T value) &#123; this.value = value; &#125; public T getValue() &#123; return value; &#125;&#125;public class 构造方法中使用泛型 &#123; public static void main(String[] args) &#123; //尖括号中的类型可以根据需要任意指定数据类型 Generic&lt;Integer&gt; g = new Generic(10); System.out.println(g.getValue()); &#125;&#125; 设置多个泛型： 设置多个泛型直接在&lt; &gt;添加多个泛型就可以了。 例如： 1234class G&lt;K,T&gt;&#123; private K key; private T take;&#125; 通配符： 在泛型&lt;&gt;中填入”?” ，代表什么类型都可以匹配。 泛型接口： 在JDK1.5之后，不仅仅可以声明泛型类，也可以声明泛型接口，声明泛型接口和声明泛型类的语法类似，也是在接口的名称后面加上. 格式： interface 接口名称&lt;泛型标识&gt; 例如： 12345678910111213141516package java面向对象;interface Interface&lt;T&gt;&#123; public void say();&#125;class Gin&lt;T&gt; implements Interface&lt;T&gt;&#123; public void say() &#123; System.out.println("泛型接口"); &#125;&#125;public class 泛型接口 &#123; public static void main(String[] args) &#123; Gin&lt;String&gt; g = new Gin&lt;String&gt;(); g.say(); &#125;&#125; 泛型方法： 泛型方法中可以定义泛型参数，此时，参数的类型就是传入数据类型。 格式： 访问权限 &lt;泛型标识&gt; 泛型标识 方法名称（[泛型标识 参数名称]） 例如： 1234567891011121314151617package java面向对象;//格式： 访问权限 &lt;泛型标识&gt; 泛型标识 方法名称（[泛型标识 参数名称]）class Gener&#123; public &lt;T&gt;T tell(T t)&#123; return t; &#125;&#125;public class 泛型方法 &#123; public static void main(String[] args) &#123; Gener g = new Gener(); String str = g.tell("hello"); System.out.println(str); int i = g.tell(10); System.out.println(i); &#125;&#125; 泛型数组： 在使用泛型方法的时候，也可以传递过返回一个泛型数组。 例如： 12345678910111213141516package java面向对象;public class 泛型数组 &#123; public static void main(String[] args) &#123; String arr[] = &#123;"hello","word","nihao"&#125;; //字符串型数组 tell(arr); Integer arr1[] = &#123;1,2,3,4,5&#125;; //整形数组 tell(arr1); &#125; public static &lt;T&gt;void tell(T arr[])&#123; for(int i = 0; i &lt; arr.length; i++) &#123; System.out.println(arr[i]); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux关机命令总结]]></title>
    <url>%2F2017%2F08%2F01%2FLinux%E5%85%B3%E6%9C%BA%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[linux下常用的关机命令有：shutdown、halt、poweroff、init；重启命令有：reboot。下面本文就主要介绍一些常用的关机命令以及各种关机命令之间的区别和具体用法。 首先来看一下linux下比较常用的一些关机命令 关机命令： 1、halt 立刻关机 2、poweroff 立刻关机 3、shutdown -h now 立刻关机(root用户使用) 4、shutdown -h 10 10分钟后自动关机 如果是通过shutdown命令设置关机的话，可以用shutdown -c命令取消重启 重启命令： 1、reboot 2、shutdown -r now 立刻重启(root用户使用) 3、shutdown -r 10 过10分钟自动重启(root用户使用) 4、shutdown -r 20:35 在时间为20:35时候重启(root用户使用) 如果是通过shutdown命令设置重启的话，可以用shutdown -c命令取消重启 下面我们来看看linux的这些具体的关机命令之间的区别和各自的用法 1.shutdown 安全的关机命令 对于shutdown命令，它是大家都推荐的一个安全的命令，通过参数-h或-r的配合来完成关机或重启。不过在linux系统中只有拥有root权限才可以使用这个命令。所以，虽然大家都推荐用这个命令，但是这个命令用起来真的不太方便：想要用这个命令吗？先去获得root权限吧。shutdown执行关机，是送信号给init，要求它改变运行级别，以此来关机。关机或重启实际上是运行级别的调整，所以我们也可以用init直接调整运行级别来进行关机或重启。使用这个命令时，机器立即关机或重启。它也需要root权限。 那么为什么说shutdown命令是安全地将系统关机呢？ 实际中有些用户会使用直接断掉电源的方式来关闭linux，这是十分危险的。因为linux与windows不同，其后台运行着许多进程，所以强制关机可能会导致进程的数据丢失使系统处于不稳定的状态。甚至在有的系统中会损坏硬件设备。而在系统关机前使用shutdown命令，系统管理员会通知所有登录的用户系统将要关闭。并且login指令会被冻结，即新的用户不能再登录。直接关机或者延迟一定的时间才关机都是可能的，还有可能是重启。这是由所有进程〔process〕都会收到系统所送达的信号〔signal〕决定的。 shutdown执行它的工作是送信号〔signal〕给init程序，要求它改变 runlevel。runlevel 0 被用来停机〔halt〕，runlevel 6 是用来重新激活〔reboot〕系统，而 runlevel 1则是被用来让系统进入管理工作可以进行的状态，这是预设的。假定没有-h也没有-r参数给shutdown。要想了解在停机〔halt〕或者重新开机〔reboot〕过程中做了哪些动作？你可以在这个文件/etc/inittab里看到这些runlevels相关的资料。 shutdown 参数说明: [-t] 在改变到其它runlevel之前，告诉init多久以后关机。 [-r] 重启计算器。 [-k] 并不真正关机，只是送警告信号给每位登录者〔login〕。 [-h] 关机后关闭电源〔halt〕。 [-n] 不用init而是自己来关机。不鼓励使用这个选项，而且该选项所产生的后果往往不总是你所预期得到的。 [-c] cancel current process取消目前正在执行的关机程序。所以这个选项当然没有时间参数，但是可以输入一个用来解释的讯息，而这信息将会送到每位使用者。 [-f] 在重启计算器〔reboot〕时忽略fsck。 [-F] 在重启计算器〔reboot〕时强迫fsck。 [-time] 设定关机〔shutdown〕前的时间。 2.halt 最简单的关机命令 用halt命令来关机时，实际调用的是shutdown -h。halt 执行时将杀死应用进程，执行sync系统调用文件系统写操作完成后就会停止内核。 halt 参数说明: [-n] 防止sync系统调用，它用在用fsck修补根分区之后，以阻止内核用老版本的超级块〔superblock〕覆盖修补过的超级块。 [-w] 并不是真正的重启或关机，只是写wtmp〔/var/log/wtmp〕纪录。 [-d] 不写wtmp纪录〔已包含在选项[-n]中〕。 [-f] 没有调用shutdown而强制关机或重启。 [-i] 关机〔或重启〕前关掉所有的网络接口。 [-p] 该选项为缺省选项。就是关机时调用poweroff。 3.poweroff 常用的关机命令 对于poweroff，网上说它是halt命令的链接，基本用法和 halt 差不多，这里就不多说了。 4.init init是所有进程的祖先，他是Linux系统操作中不可缺少的程序之一。它的进程号始终为1，所以发送TERM信号给init会终止所有的用户进程，守护进程等。shutdown 就是使用这种机制。init定义了8个运行级别(runlevel)，init 0为关机，init 1为重启。 5.reboot 重启命令 reboot的工作过程差不多跟halt一样。不过它是引发主机重启，而halt是关机。它的参数与halt相差不多。 转载至：http://www.cnblogs.com/wanggd/archive/2013/07/08/3177398.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习笔记--命令篇]]></title>
    <url>%2F2017%2F07%2F29%2FLinux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%91%BD%E4%BB%A4%E7%AF%87%2F</url>
    <content type="text"><![CDATA[[TOC] Linux基本网络及文件传输命令基本网络命令网络下载—wget wget命令作用： wget命令的作用是从WWW服务器上检索和下载文件。通过HTTP和FTP，该命令可浏览Web战点上的文件并将这些文件下载到本地主机上。 wget不提供交互式的操作界面，但可以在用户登录系统的情况下在后台中执行，因此可以在后台启动并在空闲或固定时间下载网络资源。 wget命令语法：1wget [参数] [URL] wget命令参数： 参数 参数说明 -a或–append-ourput=&lt;记录文件&gt; 把信息输出到记录文件中 -nc或–no-clobber 不覆盖存在的文件或使用.#前缀 -o或–output-file=&lt;记录文件&gt; 同-a，但若制定的记录文件已存在，则覆盖该文件 -r或–recursive 递归下载，应慎用 -t或–tries=&lt;尝试次数&gt; 设定最大尝试连接次数（0表示无限制） wget命令实例：例1：下载www.baidu.com 网站首页数据，如下图所示 1[root]# wget www.baidu.com 图：下载百度首页数据 例2：在后台尝试5次下载文件http://imgsrc.baidu.com/image/c0%3Dshijue1%2C0%2C0%2C294%2C40/sign=99bd7ae7a551f3ded7bfb127fc879a6a/b58f8c5494eef01f3e82aae8eafe9925bc317d0c.jpg 并把提示信息记录到download.log文件中。如下图 1[root]# wget -t 5 -o download.log http://imgsrc.baidu.com/image/c0%3Dshijue1%2C0%2C0%2C294%2C40/sign=99bd7ae7a551f3ded7bfb127fc879a6a/b58f8c5494eef01f3e82aae8eafe9925bc317d0c.jpg 图：尝试五次下载图片 文本浏览—-lynx lynx命令作用： lynx纯是文本模式的Web浏览程序，可以浏览指定的文件，目录或URL中的html文件。 lynx命令语法：1lynx [参数] [文件/目录/URL] wget命令参数： 参数 参数说明 - 从标准输入获取参数信息 -index= 指定该网页为缺省的索引条件 -localhost 仅允许本地主机浏览网页，关闭指向远端主机的URL -version 显示lynx的版本信息 lynx命令实例：例1：浏览网站www.baidu.com 1[root]# lynx baidu.com 例2：打开离线html文档index.html 1[root]# lynx index.html 基本网络配置命令查看或设置基本配置配置或显示网络设备—-ifconfig ifconfig命令作用： ifconfig的作用是配置或显示网络设备（即网络适配器，NIC）。 ifconfig命令语法：1[root]# ifconfig [网络设备] [Ip地址] [参数] ifconfig命令参数： 参数 参数说明 add&lt;地址&gt; 设置IPv6地址 del&lt;地址&gt; 删除IPv6地址 down 关闭指定网络设备 up 启动指定网络设备 netmask&lt;子网掩码&gt; 设置网络子网掩码 -broadcast&lt;地址&gt; 以广播形式将数据包发送到指定地址。符号表示关闭，不加符号表示启动 [IP地址] 指定网络设备的IP地址 [网络设备] 指定网络设备的名称 ifconfig命令实例：例1：显示安装在本地主机的第一块一台网卡eth0的状态。如下图 1[root]# ifconfig eth0 图：本地主机以太网卡eth0的状态 图中参数解释： Hwaddr：本地网卡eth0的MAC地址。 inet addr：iPv4地址。Bcast：广播地址。 inet addr：IPv6地址。 MTU：最大传输单元。 Metric：度量值。 RX：统计接收的数据包。TX：统计发送的数据包。 例2：配置本地主机回送接口。 12[root]# ifconfig lo inet 127.0.0.1 up[root]# ifconfig lo 例3：常用的命令。 显示本地主机所有网络接口信息，包括激活和非激活的。 1[root]# ifconfig 配置eth0网络接口IP地址为192.168.1.1/24 1[root]# ifconfig eth0 192.168.1.1 netmask 255.255.255.0 broadcast 192.168.1.255 启用或关闭eth0接口。 1[root]# ifconfig eth0 up/down 启动或关闭网络适配器——-ifup、ifdown ifup,ifdown命令作用： 启动或关闭网络适配器。 ifup,ifdown命令语法：12ifup [网络设备]ifdown [网络设备] ifup,ifdown命令实例：例：启用eth0网络接口。 1[root]# ifup eth0 查看或设置主机名—–hostname hostname命令作用： hostname的作用是设置或显示当前主机系统的名称、域名和节点名等。root用户才有权限。 hostname命令语法：1hostname [参数] hostname命令参数： 参数 参数说明 -a或-alias 显示主机的别名 -d或-domain 显示DNS域名 -h或–help 显示帮助信息 -i或–ip-address 显示主机IP地址 -n或-node 显示DECnet网络的节点名称 -s或-short 显示短主机名 显示hostname命令版本号 -v或–verbose 显示命令的执行过程 hostname命令实例：例：更改当前主机名为 Linux。 1[root]# hostname Linux 查看或配置arp缓存—–arp arp命令作用： 显示和修改地址解析协议（ARP）使用的IP地址到MAC地址的转化表。 arp命令语法：1arp [参数] [ip地址或物理地址] arp命令参数： 参数 参数说明 -a[hostnamr]或 –display[hostname] 显示指定主机的当前所有arp条目。 -d[hostname] 删除指定ARP条目 -e 以缺省Linux样式显示 -s hostname hw_addr 手工追加ARP条目 eth_addr 指定物理地址 arp命令实例：例1：显示主机arp条目。 1[root]# arp -a 例2：手动添加arp条目。 1[root]# arp -s Linux 00:0C:29:5F:BA:3D 查看网络状态—–netstat netstat命令作用： netstat 命令的作用是显示IP、TCP、 UDP、ICMP等协议相关的统计信息和当前TCP/IP网络连接状态。 netstat命令语法1netstat[参数] netstat命令参数 参数 参数说明 -a或–all 显示所有连线中的Socket -e或–extend 显示网络其他相关信息 -i或–interfaces 显示指定网络接口的所有信息 -l或–listening 显示监控中的服务器的Socket -o或–timers 显示计时器 -r或–route 显示内核路由表信息 -s或–statistice 显示各网络协议的统计信息 -t或–tcp 显示TCP传输协议的连线状态 -u或–udp 显示UDP传输协议的连线状态 netstat命令实例：例1：查看本机内核路由表信息。 1[root]# netstat -nr 图：内核路由表 图中FLags参数解释： G：路由器将采用网关。 U: 准备使用的接口处于“活动”状态。 H：通告该路由，只能抵达一台主机。 D：如果路由表达条目是由ICMP重定向消息生成的，就会设置这个标记。 M：如果路由表达条目是由ICMP重定向消息修改，就会设置这个标记。 例2：查看本机网络接口当前配置信息。 1[root]# netstat -i 图: 本机网络接口当前配置信息 图中Flg参数解释： B: 已经设置了一个广播地址。 L: 该接口是一个回送设备。 M；接收所有数据包（混乱模式）。 N；避免跟踪。 P：这是一个点到点连接。 R：接口正在运行。 U：接口处于“活动”状态。 例3：查看本机TCP传输协议的连线状况。 1[root]# netstat -ta 图: 本机TCP传输协议的连线状况 图中参数解释： Proto：通信协议。 Recv-Q：接收队列中的数据量。 Send-Q：发送队列中的数据量。 Local Address：本地主机名和端口号。 Foreign Address：远程主机名和端口号。 State：通信状态。listen表示处于监听状态。 路由表设置相关命令 #查看或设置路由表——-route route命令作用： route命令作用是查看并编辑主机的IP路由表。 route命令语法：1route [参数] route命令参数： 参数 参数说明 以IP格式显示路由表 -e 以netstst格式显示路由表 -ee 显示一个包含路由表所有参数的行 添加一个新的路由 删除一个指定路由 route命令参数：以下参数需和add、del参数联合使用： 参数 参数说明 表明目标是网络 -host 表明目标是主机 dev 指定设备或接口 gw 指定目标主机或网络的网关 target 目标主机或网络 route命令实例：例1：以IP格式显示路由表的全部内容。如下图： 1[root]# route -n 图：路由表的内容 Flags位解释：描述了路由表当前的状态。 U：表示路由表处于活动状态。 H：表示目标是主机。 G：表示使用网关。 例2：在路由表中添加一个到指定网络的静态路由。如下图： 1[root]# route add -net 192.168.2.0 netmask 255.255.255.0 dev eth0 图：成功添加一个静态路由 例3：添加一条规则，拒绝数据包到私有网络10.0.0.0，子网掩码255.0.0.0。如图： 1[root]# route add -net 10.0.0.0 netmask 255.0.0.0 reject 图：设置拒绝数据包到私有网络 例4：设置访问外网缺省网关位192.168.1.1。 1[root]# route add default gw 192.168.1.1 erh0 查看或设置路由表—–iproute iproute作用： 是一款基于Linxu操作系统的网络配置和流量控制的工具集。 iproute命令语法：1ip [参数] 管理对象 [命令[命令参数]] iproute命令参数： 参数 参数说明 V 打印iproute信息 r 将IP地址转换位域名 s 输出更为详细的结果 iproute命令管理对象： 参数 参数说明 link 指网络设备,可以查看和更改设备的属性 地址管理 neighbour arp表管理 route 路由管理 rule 路由策略 多址广播地址 mroute 多播路由缓存管理 tunnel 通道管理 add 添加命令 delete 删除管理 list/show 列表命令 set 设置命令 change 改变命令 replace 替换命令 link管理相关参数： 参数 参数说明 dev name 指定进行操作的网络设备名称 up/down 激活/禁用网络设备 arp on/arp off 使用/禁用arp协议 multicast on/off 打开/关闭多目传送 dynamic on/off 打开/关闭动态标志 name NAME 更改网络设备名称 mtu number 设置最大传输单元 Address mac 设置网络设备的MAC地址 broadcast mac 设置网络设备的硬件广播地址 txqlen number 设置传输队列长度 address地址管理相关参数： 参数 参数说明 local address 协议地址，如192.168.1.100/24 peer address 使用点对点连接对端协议地址 broadcast address 协议广播地址，可简写成brd label name 地址标志 scope scope_value 地址范围。global：全局有效。 site：仅在本地站点有效，在IPv6中使用。 link：只在网络设备上有效。 host：只在该主机上有效。 neighbour管理相关参数： 参数 参数说明 to address 指定协议地址 dev name 指定网络设备名称 lladdr 指定硬件地址 nud nud_state 指定nud值，即邻居不可达检测 route管理相关参数： 参数 参数说明 to prefix 路由的目标前缀 dev name 输出设备的名字 src 发送数据包的源地址 via Address 下一跳路由器 iproute命令实例：例1：设置网络设备eth0的MAC地址为FF：FF：FF：FF：FF：FF。 1[root]# ip link set eth0 address ff:ff:ff:ff:ff:ff 例2：禁用网络接口lo。如图： 1[root]# ip link set lo down 图：禁用网络设备接口LO 例3：查看网络link信息。如图： 1[roo]# ip link list 图：查看网络link信息 图中选项解释： 第一个数字是网络设备的数字标识，唯一性。 第二部分是网络设备名称，图eth0. 唯一性。 第三部分是尖括号中的内容： UP：设备正在工作。 loopback：回送设备，该接口发出的数据不会被传到网络上。 pointtopoint：P2P网络。 multicast：具有接收和发送多目传送的能力。 promisc：混杂模式，设备将监听并将监听到的数据传递给内核，即使不是发送给主机的数据。通常用于网络探测。 allmulti：表示网络设备将接收所有多目传送的数据报，通常用于多目路由器。 noapp：通常表示不需要地址解析。 dynamic：表示该网络设备可以动态的建立和删除。 slave：表示该网络设备与其他网络设备绑定在一起，形成逻辑上的一个网络设备。 第四部分mtu：最大传输单元。 第五部分qdisc：网络接口所使用的队列算法。noqueue表示不进行排队。pfifo_fast先进先出。 第六部分link/ehier：硬件类型。_ 例4：查看网络设备的数据统计信息。如图： 1[root]# ip -s link show 图：查看网络设备统计信息 例5：查看地址信息。如图： 1[root]# ip addr list 图：查看地址信息 例5：添加地址信息10.0.1.1/24. 1[root]# ip addr add 10.0.1.1/24 brd +dev eth0 label eth0:3 例6：查看并添加arp信息。 12[root]# ip neighbour show[root]# ip neighbour add 10.0..1.3 lladdr 0:0:0:0:0:0:1 dev eth0 nud perm 例7：查看路由表信息。 1[root]# ip route show 网络检测命令 查看主机的连通性——-ping ping命令的作用： ping命令用于检测主机的连通性。 ping命令语法：1ping [参数] [主机名称或ip地址] ping命令参数： 参数 参数说明 -c&lt;完成次数&gt; 指定完成响应次数 -f 极限检测。 -I&lt;网络接口&gt; 使用指定网络接口发出数据 -s&lt;数据包大小&gt; 设置数据包大小。缺省56B，加上8B的ICMP文件头，一共64B 追溯路由——traceroute traceroute命令作用： 用于追溯网络数据包的路由途径。 traceroute命令语法：1traceroute [参数] [主机名称或ip地址] [数据包大小] IP计算—-ipcalc ipcalc命令作用： 计算给定IP地址的相关信息。 ipcalc命令语法：1ipcalc [参数] [/前缀] [掩码] ipcalc命令参数： 参数 参数说明 -b或–broadcast 计算广播地址 -h或–hostname 解析给定ip地址的主机名 -m或–netmask 计算子网掩码 -p或–prefix 计算前缀 -n或–network 计算网络地址 ipcalc命令实例：实例1：显示192.168.1.1的相关信息。如下图： 1[root]# ipcalc -mbpn 192.168.1.1/24 图：计算192.168.1.1的相关信息 文件的基本管理文件的建立、移动、删除 建立文件—–cat cat命令作用： 用来串接文件或显示文件内容，但如果从标准输入设备中读入数据并将结果重定向到一个新的文件中，则可以达到创建文件的目的。cat命令在编辑新的文件时只能从键盘接收数据，不够灵活。 cat命令语法：1cat [参数] &gt;|&gt;&gt; &#123;文件名&#125; 建立文件—————touch touch命令作用： 创建文件是touch命令的一种特殊情况。touch用来修改指定文件的访问和修改时间属性，若指定文件不存在，则将创建一个新的空文件，并以当前时间设置文件的访问和修改时间。 touch命令语法：1touch [参数] [文件名] touch实例：例1：创建abc文件。 1[root]# touch abc 移动和重命名文件—-mv mv命令作用： mv（move）命令可用于对文件，目录的重命名以及移动操作。 mv命令语法：1mv [参数] [原文件或目录] [目标目录或目标文件] mv命令参数： 参数 参数说明 -b或–backup 若需覆盖文件，则覆盖前先行备份 -i或–interactive 交互式操作。如目标目录有同名文件，会提示是否覆盖。 mv命令实例：例1：移动文件cao到home目录下。 1[root]# mv -i cao /home/cao 删除文件—-rm rm命令作用： 利用rm（remove）命令可以将不需要的文件永久删除。若用-r参数，则可以直接删除一个目录以及目录中的所有文件。 rm命令语法：1rm [参数] [文件或目录] rm命令参数： 参数 参数说明 -i 交互式操作 -f 强制删除，与-i相反 -r 删除目录里面全部文件 查看文件内容 查看文件内容—–cat cat命令作用： cat适合查看内天不满一屏的文件。 cat命令实例：例1：查看文件cao的内容。 1[root]# cat cao 查看文件内容—–more more命令作用： 适合查看大文件。 查看文件内容—-less less命令作用： 可以用来浏览文件内容。与more不同的是less命令允许用户往回卷动一浏览以看过的内容。 查看文件头部的内容—-head head命令作用： 查看文件首部内容。默认显示文件的前10行。 查看文件尾部的内容—-tail tail命令作用： 查看文件尾部内容。默认显示文件的后10行。 查看文件部分内容—-cut cut命令作用： 显示文件部分内容。可以灵活指定范围，有很大灵活性。 cut命令实例：例1；查看每行前三个字节。 1[root]# cut -b1-3 cao 例2；查看每行前三个字符。 1[root]# cut -c1-3 cao 查看修改文件的属性 查看文件的类型—-file file命令作用： 可以查看文件的具体属性。 查看文件的属性—-ll ll命令作用： 可以查看文件的属性。不如file强大。 改变文件的属主或属组—–chown改变文件的访问权限—-chmod]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
        <tag>Linux笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手机通讯录系统]]></title>
    <url>%2F2017%2F07%2F02%2F%E6%89%8B%E6%9C%BA%E9%80%9A%E8%AE%AF%E5%BD%95%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[手机通讯录系统1、设计目的与要求1.1题目与设计要求 我们设计的程序为手机通讯录系统，这是使用C语言写成。本程序具有和一般的通讯录一样的功能，有最基本的数据添加、修改、查看、删除等功能。通过对程序的设计的目的是为了提高我们对C语言的整体把握与应用。能把学会的知识真正的会应用。 1.2 本程序涉及的知识点12If语句 switch语句 for循坏 do…while循坏 goto语句 二维数组 指针 字符串复制比较等 文件操作 结构体 函数的套用 2、功能设计2.1 总体设计 整个系统可以设计为数据添加模块、数据修改模块、数据删除模块、数据查看模块文件写入与读取。如图1所示. 图1. 手机通讯录系统模块结构图 2.2 详细设计（1）数据添加模块 首先，查看信息条数是否超过15，如果超过，则提示“通信录已满！”，返回上级菜单；否则，从通讯录末尾开始顺序添加信息。每添加完一条记录，都会询问是否继续添加。如果是，则继续添加。否则返回主菜单。同时把所有数据重新写入文件。 （2）数据修改模块 ​ 修改通信录信息，则需要读文件。然后选择要修改的信息，进行修改。修改完毕后，所有数据重新写入文件。且返回主菜单。 （3）数据删除模块 通过菜单选择删除操作。在删除模块中我们设置了两个选项。删除指定数据和全部删除。若选择删除指定数据，则会提示输入要删除的条数，然后删除。若选择删除全部记录，则会把所有记录清空。每次操作完后，都会重新把数据写入文件并返回主菜单。 （4）数据查看模块 通过菜单选择查看信息，可以选择按姓名查看，或者按类别查看。选择按姓名查找则会显示对应的姓名信息。如果选择按类别查看，则可以选择办公类、个人类或者商务类，然后会显示所选类信息列表。这是一个查找与显示的过程，在手机通信录文件中通过比对查找相应类型符合的记录，并输出。 （5）文件的写入与读取 首先每次运行程序，都会先检测“通讯录”文件是否存在。若存在，则先读取文件。若不存在，则会先新建一个空白文件。然后在每次操作后都会重新把数据写入文件。确保了数据的安全性。防止程序意外退出或电脑断电等造成数据丢失。 3、程序实现3.1 程序实现时应考虑的问题 每次操作后回到主菜单 如何实现退出 每次操作后如何把数据写入文件 读取文件时如何统计数据条数 实现多级菜单 如何实现全部删除 如何实现分类查询 3.2任务分工及源代码说明曹世宏 负责：文件的写入和读取，以及对整个程序的整合调试 在我设计此段代码时我遇到了很多问题，首先是在程序运行时就要读取文件信息，因为刚开始做的为只读方式，所以如果没有文件就会出错，后来经过改正，没有文件的话就新建一个空白文件，这个问题就解决了。在写文件上，刚开始能把数据都写写进去，但只要重新修改程序中的数据后，原来的数据就没了。经过我的反复调试检查发现，是因为每次写入文件是没有记录写进了几条数据，所以导致每次读取出错。经过改正，在每次写文件时先把数据总数写进去再写其他数据，在每次读取时，先读取有几条数据，作为判断条件，然后就能按顺序都能读取出来。最后都调试好后，考虑到文件的安全性，我在每次调用其他函数后都会写一次数据，防止数据的丢失。 123456789101112131415161718文件读取：void Fread()/*读取文件*/&#123; if((fp=fopen("通讯录.text","r+"))==NULL) &#123; return; &#125; fread(&amp;j,sizeof(int),1,fp); for(i=1;i&lt;=j;i++) &#123;fread(&amp;friends[i],sizeof(struct Friend),1,fp); &#125; fclose(fp);&#125;文件写入：void Fwrite()/*写入文件*/&#123; if((fp=fopen("通讯录.text","w+"))==NULL) &#123;printf("不能打开这个文件！\n");return; &#125; fwrite(&amp;j,sizeof(int),1,fp); for(i=1;i&lt;=j;i++) &#123; fwrite(&amp;friends[i],sizeof(struct Friend),1,fp); &#125; fclose(fp);&#125; 程文辉 负责：数据查看模块 12345678910111213141516171819202122232425262728293031323334353637383940414243查看输出：void Date_output(int i)/*信息输出*/&#123; printf("第%d条记录\n",i); printf("姓名：%s\n",friends[i].name); printf("电话号码:%s\n",friends[i].tel); printf("联系人所属类别（1：办公类 2：个人类 3：商务类）:%d\n",friends[i].type); printf("生日：%d/%d/%d\n",friends[i].Brithday.month,friends[i].Brithday.month,friends[i].Brithday.day); printf("e-mail：%s\n",friends[i].email); printf("地址：%s\n",friends[i].addr);&#125;信息查询：void Search()/*按姓名查询功能*/&#123; int a=0; char names[20];/*定义临时姓名*/ printf("请输入要查询的人名：\n"); scanf("%s",&amp;names); for(i=1;i&lt;=j;i++) &#123; if(strcmp(names,friends[i].name)==0)/*对比姓名是否一致*/ &#123; Date_output(i); a=1; break; &#125; &#125; if(a!=1) printf("没有此记录！\n"); printf("\n\n");&#125;void Lei_search()/*按类别查询*/&#123; struct Friend people[10];/*定义临时结构体数组*/ int b=0; int c,d;/*c 存放临时数据 d:统计一个类别有多少人*/ printf("\t\t请输入要查询的类别\n"); printf("\t\t\t1:办公类\n\t\t\t2:个人类\n \t\t\t3:商务类\n "); scanf("%d",&amp;c); for(i=1;i&lt;=j;i++) &#123; if(friends[i].type-c==0) &#123; people[b]=friends[i]; b++;d=b; &#125; &#125; if(b!=0) &#123; for(b=1;b&lt;d+1;b++) &#123;Date_output(b); &#125; &#125; else printf("此类别没有记录！\n"); printf("\n");&#125; 程兴旺 负责：数据添加模块、数据删除模块 12345678910111213141516171819202122232425262728293031323334信息添加：void Insert()/*插入记录函数*/&#123; printf("请输入要插入的位置：第（）位\n"); scanf("%d",&amp;k); for(i=j+1;i&gt;k;i--)/*把插入位置以后的所有数据向后移动一位*/ &#123; strcpy(friends[i].name,friends[i-1].name); strcpy(friends[i].tel,friends[i-1].tel); friends[i].type=friends[i-1].type; friends[i].Brithday.year=friends[i-1].Brithday.year; friends[i].Brithday.month=friends[i-1].Brithday.month; friends[i].Brithday .day=friends[i-1].Brithday.day; strcpy(friends[i].email,friends[i-1].email); strcpy(friends[i].addr,friends[i-1].addr); &#125; Date_Input(k); j++;rintf("\n\n");&#125;信息删除：void Delete()/*删除指定记录*/&#123; printf("请输入要删除的位置：第（）位\n"); scanf("%d",&amp;k); for(i=k;i&lt;j;i++)/*把删除位置以后的所有数据向前移动一位*/ &#123; strcpy(friends[i].name,friends[i+1].name); strcpy(friends[i].tel,friends[i+1].tel); friends[i].type=friends[i+1].type; friends[i].Brithday.year=friends[i+1].Brithday.year; friends[i].Brithday.month=friends[i+1].Brithday.month; friends[i].Brithday .day=friends[i+1].Brithday.day; strcpy(friends[i].email,friends[i+1].email); strcpy(friends[i].addr,friends[i+1].addr); &#125; j--; printf("\n\n");&#125; 董泽琦 负责：数据修改模块 1234567891011121314void Xiugai()/*修改信息*/&#123; char names[20]; int m=0; printf("请输入要修改的姓名：\n"); scanf("%s",names); for(i=1;i&lt;=j;i++) &#123; if(strcmp(names,friends[i].name)==0)/*比较姓名*/ &#123; Date_Input(i); break; &#125; else &#123;m++;&#125; &#125; if(m==j) printf("没有此记录！\n"); printf("\n\n"); 4、程序测试结果4.1显示所有记录 这个功能可以显示出所有的已经存储在文件中的记录，在菜单选项中选择1，就会显示出所有记录。程序运行结果如 图4.1 图4.1 显示所有记录 4.2添加功能 这个功能可以实现顺序添加信息。在主菜单下选择2添加，程序首先会判断文件中有几条数据，然后能从末尾开始添加，在每次添加完记录后，会提示是否继续添加。若选择1是，则会按顺序继续添加。若选择2否，则会返回主菜单。程序运行结果如图4.2。 图4.2 添加记录 4.3插入功能 这个功能可以实现在任何位置插入记录。在主菜单下选择3，就会进入此功能，首先会然用户选择想要插入的位置，然后进行数据输入，输入完成后，在此记录以后的所有数据向后移动一位，这就实现了数据插入。同时返回主菜单。程序运行结果如图4.3。 图4.3 插入信息 4.4修改功能 这个功能可以实现对数据的修改。在主菜单下选择4，就会进入修改功能，首先会让用户查找想要修改的记录，通过查找姓名找出此记录，然后重新输入新的信息实现对数据的修改，同时返回主菜单。程序运行结果如图4.4。 图4.4 修改记录 4.5删除功能 这个功能可以实现对数据的删除。在主菜单下选择5.删除，就会进入删除功能。首先会进入二级菜单，让用户选择删除的方式。若选择1.按指定条数删除，则会让用户输入要删除的记录，回车确认删除，提示“删除成功！”并返回主菜单，程序运行结果如图4.5.1。此算法通过让删除以后的所有数据向前移动一位来实现删除。 若在二级菜单下，用户选择2全部删除，为了方式误删，是设置了三级菜单是否确认删除，选择1是，则所有记录删除，提示“删除成功！”返回主菜单。选择2.否，则不删除直接返回主菜单。程序运行结果如 图4.5.2. 图4.5.1 按指定条数删除 图4.5.2 全部删除 4.6查询功能 这个功能可以实现对数据的查找。在主菜单下选择6.查询，会进入查询菜单，若选择1.按姓名查询，则会让用户输入要查询的姓名，并显示出此人所有信息，同时返回主菜单。此功能是通过输入的姓名与所有数据进行对比，如果有则查找成功输出，如果没有则提示没有此人记录。程序运行结果如下图4.6.1。在查询菜单下，还设置了2.按类别查询。进入此功能后会让用户选择要查询的类别1.办公类，2. .个人类，3商务类。选择相应的序号会显示出此类别的所有记录，若没有相应类别记录会提示“没有此类记录！”。程序运行结果如下图4.6.2 图4.6.1 按姓名查询 图4.6.2 按类别查询 4.7退出系统 在主菜单下选择7.保存并退出，会保存数据并退出系统。程序运行结果如 图4.7。 图4.7保存并退出 5、总结 从拿到这个作业时，我们规划好了小组。都很有信心去完成这个作业。以此来验证我们上一学期的学习成果。在开始时，我们查阅了一些资料并且进行了分工。我们先讨论了整个程序的框架，然后各自开始去完成自己的模块。在最后我们进行了整合。这也是最关键最难得一步。在这个过程中我们遇到了很多问题。比如，变量不统一；文件指针全局声明；还有在文件读写方面出现了许多问题，不能准确读取文件中有几个记录等。对于这些问题我们小组成员进行了讨论，经过一次次的调试，最终终于程序很好的做了出来。通过解决问题，我们更加深了对C语言的认识。对于以前学到的知识能熟练地运用。通过这次的小组模式，我们更感受到了小组成员团结合作的重要性。这将在以后的生活中也对我们有很大帮助。在今后我们将继续合作学习研究C语言。共同学习，共同进步。 6、全部代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364#include&lt;stdio.h&gt;#include&lt;string.h&gt;#include&lt;stdlib.h&gt;FILE*fp;int j=1,i,k;/*i:第几人 j:总人数 k:指定数*/int n;/*统计文件个数*/struct Brithday&#123; int year; int month; int day;&#125;;struct Friend&#123; int num; char name[20]; char tel[13]; int type;/*1：办公类 2：个人类 3：商务类*/ struct Brithday Brithday; char email[20]; char addr[20];&#125;friends[15];int main()&#123; void Date_Input(int i);/*输入信息*/ void Date_output(int i);/*输出信息*/ void Insert();/*插入信息*/ void Delete();/*删除指定记录*/ void Search();/*按姓名查询*/ void Xiugai();/*修改信息*/ void Fwrite();/*写入文件*/ void Fread();/*读取文件*/ void Mean();/*主菜单*/ void Lei_search();/*按类别查询*/ Fread(); do &#123; char s; E: Mean(); scanf("%s",&amp;s); switch(s) &#123; case '1': system("cls"); if((fp=fopen("通讯录.text","r+"))==NULL) &#123; printf("不能打开这个文件！\n"); return; &#125; fread(&amp;j,sizeof(int),1,fp); if(j&gt;=1) &#123; for(i=1;i&lt;=j;i++) &#123; Date_output(i); printf("\n"); &#125; &#125; else printf("没有记录！\n\n"); break; case '2': system("cls"); C: printf("请添加记录：\n"); for(i=j+1;i&lt;15;i++) &#123; Date_Input(i); j++; Fwrite(); printf("\t是否继续插入\n"); printf("\t\t1:是 \n"); printf("\t\t2:否\n"); D: scanf("%d",&amp;k); if(k==1) &#123; goto C; printf("\n"); &#125; else if(k==2) goto E; else &#123; printf("请输入1-2！\n"); goto D; &#125; &#125; case '3': system("cls"); &#123; Insert(); Fwrite(); break; &#125; case '4': system("cls"); &#123; Xiugai(); Fwrite(); break; &#125; case '5': system("cls"); &#123; printf("\t请选择删除的方式\n"); printf("\t\t1:删除指定条数 \n"); printf("\t\t2:全部删除\n"); F: scanf("%d",&amp;k); if(k==1) &#123; Delete(); Fwrite(); printf("删除成功！\n"); printf("\n"); break; &#125; else if(k==2) &#123; R: printf("\t\t\t是否确认删除\n\t\t\t1.是\n\t\t\t2.否\n"); int s=0; scanf("%d",&amp;s); if(s==1) &#123; j=0;Fwrite(); printf("删除成功！\n"); break; &#125; else if(s==2) break; else goto R; break; &#125; else &#123; printf("请输入1-2！\n"); goto F; &#125; break; &#125; case '6': system("cls"); &#123; B: printf("\t请输入查询的方式\n"); printf("\t\t1:按姓名查询 \n"); printf("\t\t2:按类别查询\n"); scanf("%d",&amp;k); if(k==1) &#123; Search(); printf("\n"); break; &#125; else if(k==2) &#123; Lei_search(); printf("\n"); break; &#125; else &#123; printf("请输入1-2！\n"); goto B; &#125; break; &#125; case '7': &#123; printf("按任意键退出！"); Fwrite(); goto A; &#125; default:printf("输入错误！\n"); &#125; &#125;while(6); A: return 0;&#125;void Mean()/*主菜单*/&#123; printf("\n\t主菜单功能选择：\n"); printf("\t1：显示所有记录\n"); printf("\t2：添加\n"); printf("\t3：插入\n"); printf("\t4：修改\n"); printf("\t5：删除\n"); printf("\t6：查询\n"); printf("\t7：保存并退出\n");&#125;void Date_Input(int i)/*信息录入*/&#123; friends[i].num=i; printf("第%d条记录\n",i); printf("请输入姓名：\n"); scanf("%s",friends[i].name); printf("请输入电话号码\n"); scanf("%s",friends[i].tel); printf("请输入联系人所属类别（输数字（1：办公类 2：个人类 3：商务类））：\n"); scanf("%d",&amp;friends[i].type); printf("请输入生日（年）：\n"); scanf("%d",&amp;friends[i].Brithday.year); printf("请输入生日（月）：\n"); scanf("%d",&amp;friends[i].Brithday.month); printf("请输入生日（日）：\n"); scanf("%d",&amp;friends[i].Brithday.day); printf("请输入e-mail地址：\n"); scanf("%s",friends[i].email); printf("请输入地址：\n"); scanf("%s",friends[i].addr);&#125;void Date_output(int i)/*信息输出*/&#123; printf("第%d条记录\n",i); printf("姓名：%s\n",friends[i].name); printf("电话号码:%s\n",friends[i].tel); printf("联系人所属类别（1：办公类 2：个人类 3：商务类）:%d\n",friends[i].type); printf("生日：%d/%d/%d\n",friends[i].Brithday.year,friends[i].Brithday.month,friends[i].Brithday.day); printf("e-mail：%s\n",friends[i].email); printf("地址：%s\n",friends[i].addr);&#125;void Insert()/*插入记录函数*/&#123; printf("请输入要插入的位置：第（）位\n"); scanf("%d",&amp;k); for(i=j+1;i&gt;k;i--) &#123; strcpy(friends[i].name,friends[i-1].name); strcpy(friends[i].tel,friends[i-1].tel); friends[i].type=friends[i-1].type; friends[i].Brithday.year=friends[i-1].Brithday.year; friends[i].Brithday.month=friends[i-1].Brithday.month; friends[i].Brithday .day=friends[i-1].Brithday.day; strcpy(friends[i].email,friends[i-1].email); strcpy(friends[i].addr,friends[i-1].addr); &#125; Date_Input(k); j++; printf("\n\n");&#125;void Delete()/*删除指定记录*/&#123; printf("请输入要删除的位置：第（）位\n"); scanf("%d",&amp;k); for(i=k;i&lt;j;i++) &#123; strcpy(friends[i].name,friends[i+1].name); strcpy(friends[i].tel,friends[i+1].tel); friends[i].type=friends[i+1].type; friends[i].Brithday.year=friends[i+1].Brithday.year; friends[i].Brithday.month=friends[i+1].Brithday.month; friends[i].Brithday .day=friends[i+1].Brithday.day; strcpy(friends[i].email,friends[i+1].email); strcpy(friends[i].addr,friends[i+1].addr); &#125; j--; printf("\n\n");&#125;void Search()/*按姓名查询功能*/&#123; int a=0; char names[20]; printf("请输入要查询的人名：\n"); scanf("%s",&amp;names); for(i=1;i&lt;=j;i++) &#123; if(strcmp(names,friends[i].name)==0) &#123; Date_output(i); a=1; break; &#125; &#125; if(a!=1) printf("没有此记录！\n"); printf("\n\n");&#125;void Lei_search()/*按类别查询*/&#123; struct Friend people[10]; int b=0; int c; printf("\t\t请输入要查询的类别\n"); printf("\t\t\t1:办公类\n"); printf("\t\t\t2:个人类\n"); printf("\t\t\t3:商务类\n"); scanf("%d",&amp;c); for(i=1;i&lt;=j;i++) &#123; if(friends[i].type==c) &#123; Date_output(i); b=1; &#125; &#125; if(b!=1) printf("此类别没有记录！\n"); printf("\n");&#125;void Xiugai()/*修改信息*/&#123; char names[20]; int m=0; printf("请输入要修改的姓名：\n"); scanf("%s",names); for(i=1;i&lt;=j;i++) &#123; if(strcmp(names,friends[i].name)==0) &#123; printf("查找成功，请进行修改：\n"); Date_Input(i); break; &#125; else &#123; m++; &#125; &#125; if(m==j) printf("没有此记录！\n"); printf("\n\n");&#125;void Fwrite()/*写入文件*/&#123; if((fp=fopen("通讯录.text","w+"))==NULL) &#123; printf("不能打开这个文件！\n"); return; &#125; fwrite(&amp;j,sizeof(int),1,fp); for(i=1;i&lt;=j;i++) &#123; fwrite(&amp;friends[i],sizeof(struct Friend),1,fp); &#125; fclose(fp);&#125;void Fread()/*读取文件*/&#123; if((fp=fopen("通讯录.text","r+"))==NULL) &#123; printf("不能打开这个文件！\n"); return; &#125; fread(&amp;j,sizeof(int),1,fp); for(i=1;i&lt;=j;i++) &#123; fread(&amp;friends[i],sizeof(struct Friend),1,fp); &#125; fclose(fp);&#125; 参考文献[1]谭浩强著. C程序设计(第四版).北京：清华大学出版社,2010.6]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>C编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音乐]]></title>
    <url>%2F2017%2F06%2F29%2F%E9%9F%B3%E4%B9%90%2F</url>
    <content type="text"><![CDATA[HCIE点亮荣光]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[友链]]></title>
    <url>%2F2017%2F06%2F25%2F%E5%8F%8B%E9%93%BE%2F</url>
    <content type="text"><![CDATA[我的论坛: “http://caoshihong.88448.com&quot; 百度: “http://baidu.com&quot; 华为培训认证: “http://support.huawei.com/learning/NavigationAction!createNavi?navId=MW000001_term1000025144&amp;lang=zh&quot; 鸿鹄论坛: “http://bbs.hh010.com/&quot; 博客搭建教程: “http://blog.csdn.net/gdutxiaoxu/article/details/53576018&quot; CSDN博客: “http://m.blog.csdn.net/home/index&quot; 博客园: “https://www.cnblogs.com/&quot; w3cshool: “http://www.w3school.com.cn/index.html&quot; 51cto: “http://www.51cto.com/&quot;]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[递归算法]]></title>
    <url>%2F2017%2F06%2F24%2F%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[递归算法​ 在函数或子过程的内部，直接或者间接地调用自己的算法。 特点： (1) 递归就是在过程或函数里调用自身。 (2) 在使用递归策略时，必须有一个明确的递归结束条件，称为递归出口。 (3) 递归算法解题通常显得很简洁，但递归算法解题的运行效率较低。所以一般不提倡用递归算法设计程序。 (4) 在 递归调用的过程当中系统为每一层的返回点、局部量等开辟了栈来存储。递归次数过多容易造成 栈溢出等。所以一般不提倡用递归算法设计程序。 递归算法一般用于解决三类问题： (1)数据的定义是按递归定义的。(Fibonacci函数) (2)问题解法按递归算法实现。(回溯) (3)数据的结构形式是按递归定义的。(树的遍历，图的搜索) 递归设计经验： 找重复（子问题） 找重复中的变化量–&gt;参数 找参数变化趋势 –&gt; 设计出口 解递归的常见思路： 切蛋糕思维，如求阶乘f(n) = n * f(n-1)，数组就和，翻转字符串。 化不开的，看有没有递推公式？有没有等价转化？ 如：斐波那契数列f(n) = f(n-1) + f(n-2)，求最大公约数:f(m,n) = f(n, m%n)。 递归算法C语言实例利用递归实现1到100以内的求和；12345678910111213141516#include&lt;stdho.h&gt;int main()&#123; int Sum(int n); printf("sum=%d\n",Sum(100)); return 0;&#125;int Sum(int n)&#123; int n,sum=0; if(n==0) return 0; else return sum=n+Sum(n-1);&#125; 利用递归求阶乘：123456789101112131415#include&lt;stdio.h&gt;int main()&#123; int Fac(int n); printf("f=%d\n",Fac(5)); return 0;&#125;int Fac(int n)&#123; int f=0; if(n==1) return f=1; else return f=n*Fac(n-1);&#125; 利用递归求数组中最大数： 1234567891011121314151617181920#include&lt;stdio.h&gt;int main()&#123; int Max(int a[],int n); int a[5]=&#123;4,75,23,300,53&#125;; printf("最大数是%d\n",Max(a,5)); return 0;&#125;int Max(int a[],int n)&#123; if(n==1) return a[0]; else &#123; if(a[n-1]&gt;Max(a,n-1)) return a[n-1]; else return Max(a,n-1); &#125;&#125; 递归算法java语言实例：斐波那契序列： 斐波那契数列问题，等价于两个子问题： 求前一项 求前两项 两项求和 1234567891011121314public class 斐波那契序列 &#123; public static void main(String[] args) &#123; for(int i = 1; i &lt; 10; i++) &#123; System.out.print(fibonacci(i) + " "); &#125; &#125; public static int fibonacci(int n) &#123; if(n == 1 || n == 2) return 1; return fibonacci(n-1) + fibonacci(n-2); &#125;&#125; 运行结果: 11 1 2 3 5 8 13 21 34 最大公约数：123456789public class 最大公约数 &#123; public static void main(String[] args) &#123; System.out.println(gcd(24,30)); &#125; public static int gcd(int m, int n) &#123; if(n == 0) return m; return gcd(n, m%n); &#125;&#125; 程序运行结果： 16 插入排序改递归：123456789101112131415161718192021222324252627public class 递归_插入排序 &#123; public static void main(String[] args) &#123; int[] arr = &#123;9, 18, 2, 3, 6 ,4, 0&#125;; insertSort(arr, arr.length-1); for(int i = 0; i &lt; arr.length; i++) System.out.print(arr[i] + " "); &#125; // 对数组0-倒数第一个排序 // 等价于： // 对数组0-倒数第二个元素排序， // 然后把最后一个元素插入到这个有序的部分中 public static void insertSort(int[] arr, int k) &#123; if(k == 0) return; //对前k-1个元素排序 insertSort(arr, k-1); //把位置k的元素插入到前面的部分 int x = arr[k]; int index = k-1; while(index &gt;= 0 &amp;&amp; x &lt; arr[index]) &#123; arr[index+1] = arr[index]; index--; &#125; arr[index+1] = x; &#125;&#125; 程序运行结果： 10 2 3 4 6 9 18 汉诺塔问题： 将1-N从A移动到B，C作为辅助。等价于： 1~N-1移动到C，A作为源，B作为辅助 把N从A移动到B 把1~N-1 从C移动到B,A为辅助 123456789101112131415161718192021222324252627public class 汉诺塔 &#123; public static void main(String[] args) &#123; printHanoiTower(3, "A", "B", "C"); &#125; /** * 将1-N从A移动到B，C作为辅助。等价于： * 1. 1~N-1移动到C，A作为源，B作为辅助 * 2. 把N从A移动到B * 3. 把1~N-1 从C移动到B,A为辅助 * @param N N个盘子 * @param from 放盘子的初始柱子 * @param to 目标柱子 * @param help 辅助柱子 */ public static void printHanoiTower(int N, String from, String to, String help) &#123; if(N == 1) &#123; System.out.println(N + ": " + from + "--&gt;" + to); return; &#125; // 先把前N-1个盘子挪到辅助空间上去 printHanoiTower(N-1, from, help, to); // N可以顺利到达目标 System.out.println(N + ": " + from + "--&gt;" + to); // 让N-1个盘子从辅助空间回到"原位置上" printHanoiTower(N-1, help, to, from); &#125;&#125; 程序运行结果： 123451: A--&gt;B2: A--&gt;C1: B--&gt;C3: A--&gt;B1: C--&gt;A 二分查找递归解法： 全范围二分查找，等价于三个子问题： 左边找（递归） 中间比 右边找（递归） 注意：左边查找和右边查找只选其一 12345678910111213141516171819public class 递归_二分查找 &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 3, 9, 13, 19, 23, 25&#125;; System.out.println(binarySearch(arr, 0, arr.length-1, 13)); &#125; public static int binarySearch(int[] arr, int low, int high, int key)&#123; if(low &gt; high) return -1; int mid = low + ((high-low)&gt;&gt;1);//(low+high)&gt;&gt;1 int midVal = arr[mid]; if(midVal &lt; key) //向左找 return binarySearch(arr, mid + 1, high, key); else if(midVal &gt; key) //向右找 return binarySearch(arr, low, mid - 1, key); else return mid; //key found &#125;&#125; 程序运行结果： 13 递归算法的性能分析：斐波那契数列递归实现改进： 通过记录每次f(n)的值来防止大量重复计算，大大增加了性能。 12345678910public static int fib(int n, int[] tmp) &#123; if(tmp[n] != 0) &#123; return tmp[n]; &#125; if(n == 1 || n == 2) return 1; tmp[n] = fib(n-1, tmp) + fib(n-2, tmp); return fib(n-1, tmp) + fib(n-2, tmp); &#125; 改进前和改进后性能对比： 1234567891011121314151617181920212223242526272829303132333435363738public class 斐波那契序列 &#123; static int count = 0; static int count1 = 0; public static void main(String[] args) &#123; for(int i = 1; i &lt; 20; i++) &#123; System.out.print(fibonacci(i) + " "); &#125; System.out.println(); System.out.println("运算次数：" + count); int[] tmp = new int[20]; for(int i = 1; i &lt; 20; i++) &#123; System.out.print(fib(i, tmp) + " "); &#125; System.out.println(); System.out.println("运算次数：" + count1); &#125; public static int fibonacci(int n) &#123; if(n == 1 || n == 2) return 1; count++; //System.out.print("&lt;" + fibonacci(n-1) + fibonacci(n-2)+ "&gt;") ; return fibonacci(n-1) + fibonacci(n-2); &#125; public static int fib(int n, int[] tmp) &#123; if(tmp[n] != 0) &#123; return tmp[n]; &#125; if(n == 1 || n == 2) return 1; tmp[n] = fib(n-1, tmp) + fib(n-2, tmp); //System.out.print("&lt;" + tmp[n] + "&gt;"); count1++; return fib(n-1, tmp) + fib(n-2, tmp); &#125;&#125; 程序运行结果： 12341 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597 2584 4181 运算次数：109261 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597 2584 4181 运算次数：17 小白上楼梯： 小白正在上楼梯，楼梯有n阶台阶，小白一次可以上1阶，2阶或者3阶，实现一个方法，计算小白有多少种走完楼梯的方式。 1234567891011121314151617181920212223242526272829303132333435363738394041package chapter2;public class 小白上楼梯 &#123; public static void main(String[] args) &#123; long now = System.currentTimeMillis(); for(int i = 1; i &lt; 30; i++) &#123; int[] tmp = new int[1000]; System.out.print(f(i, tmp)+ " "); &#125; System.out.println(); long end = System.currentTimeMillis(); System.out.println(end-now + "ms"); long now1 = System.currentTimeMillis(); for(int i = 1; i &lt; 30; i++) &#123; System.out.print(f1(i) + " "); &#125; System.out.println(); long end1= System.currentTimeMillis(); System.out.println(end1-now1 + "ms"); &#125; public static int f(int n, int[] tmp) &#123; if(tmp[n] != 0) return tmp[n]; if(n == 1) return 1; if(n == 2) return 2; if(n == 3) return 4; tmp[n] = f(n-1, tmp) + f(n-2, tmp) + f(n-3, tmp); return f(n-1, tmp) + f(n-2, tmp) + f(n-3, tmp); &#125; public static int f1(int n) &#123; if(n == 1) return 1; if(n == 2) return 2; if(n == 3) return 4; return f1(n-1) + f1(n-2) + f1(n-3); &#125;&#125; 程序运行结果： 12341 2 4 7 13 24 44 81 149 274 504 927 1705 3136 5768 10609 19513 35890 66012 121415 223317 410744 755476 1389537 2555757 4700770 8646064 15902591 29249425 1ms1 2 4 7 13 24 44 81 149 274 504 927 1705 3136 5768 10609 19513 35890 66012 121415 223317 410744 755476 1389537 2555757 4700770 8646064 15902591 29249425 98ms]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>递归</tag>
      </tags>
  </entry>
</search>
